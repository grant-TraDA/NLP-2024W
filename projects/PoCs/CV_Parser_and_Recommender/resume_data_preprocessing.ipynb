{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Anadu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Anadu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Anadu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Anadu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#spacy\n",
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy.lang.en import English\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "#gensim\n",
    "# import gensim\n",
    "# from gensim import corpora\n",
    "\n",
    "#Visualization\n",
    "from spacy import displacy\n",
    "from wordcloud import WordCloud\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#nltk\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(['stopwords','wordnet'])\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#Data loading/ Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure required NLTK data is downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Import json library\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Resume_html</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16852973</td>\n",
       "      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE\\...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22323967</td>\n",
       "      <td>HR SPECIALIST, US HR OPERATIONS      ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33176873</td>\n",
       "      <td>HR DIRECTOR       Summary      Over 2...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27018550</td>\n",
       "      <td>HR SPECIALIST       Summary    Dedica...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17812897</td>\n",
       "      <td>HR MANAGER         Skill Highlights  ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>99416532</td>\n",
       "      <td>RANK: SGT/E-5 NON- COMMISSIONED OFFIC...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>AVIATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>24589765</td>\n",
       "      <td>GOVERNMENT RELATIONS, COMMUNICATIONS ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>AVIATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>31605080</td>\n",
       "      <td>GEEK SQUAD AGENT         Professional...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>AVIATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>21190805</td>\n",
       "      <td>PROGRAM DIRECTOR / OFFICE MANAGER    ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>AVIATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>37473139</td>\n",
       "      <td>STOREKEEPER II       Professional Sum...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>AVIATION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2484 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                         Resume_str   \n",
       "0     16852973           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...  \\\n",
       "1     22323967           HR SPECIALIST, US HR OPERATIONS      ...   \n",
       "2     33176873           HR DIRECTOR       Summary      Over 2...   \n",
       "3     27018550           HR SPECIALIST       Summary    Dedica...   \n",
       "4     17812897           HR MANAGER         Skill Highlights  ...   \n",
       "...        ...                                                ...   \n",
       "2479  99416532           RANK: SGT/E-5 NON- COMMISSIONED OFFIC...   \n",
       "2480  24589765           GOVERNMENT RELATIONS, COMMUNICATIONS ...   \n",
       "2481  31605080           GEEK SQUAD AGENT         Professional...   \n",
       "2482  21190805           PROGRAM DIRECTOR / OFFICE MANAGER    ...   \n",
       "2483  37473139           STOREKEEPER II       Professional Sum...   \n",
       "\n",
       "                                            Resume_html  Category  \n",
       "0     <div class=\"fontsize fontface vmargins hmargin...        HR  \n",
       "1     <div class=\"fontsize fontface vmargins hmargin...        HR  \n",
       "2     <div class=\"fontsize fontface vmargins hmargin...        HR  \n",
       "3     <div class=\"fontsize fontface vmargins hmargin...        HR  \n",
       "4     <div class=\"fontsize fontface vmargins hmargin...        HR  \n",
       "...                                                 ...       ...  \n",
       "2479  <div class=\"fontsize fontface vmargins hmargin...  AVIATION  \n",
       "2480  <div class=\"fontsize fontface vmargins hmargin...  AVIATION  \n",
       "2481  <div class=\"fontsize fontface vmargins hmargin...  AVIATION  \n",
       "2482  <div class=\"fontsize fontface vmargins hmargin...  AVIATION  \n",
       "2483  <div class=\"fontsize fontface vmargins hmargin...  AVIATION  \n",
       "\n",
       "[2484 rows x 4 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'data/Resume Dataset/Resume/Resume.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "# print(data.head())\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID                                         Resume_str   \n",
      "0  16852973           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...  \\\n",
      "1  22323967           HR SPECIALIST, US HR OPERATIONS      ...   \n",
      "2  33176873           HR DIRECTOR       Summary      Over 2...   \n",
      "3  27018550           HR SPECIALIST       Summary    Dedica...   \n",
      "4  17812897           HR MANAGER         Skill Highlights  ...   \n",
      "\n",
      "                                         Resume_html Category  \n",
      "0  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
      "1  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
      "2  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
      "3  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
      "4  <div class=\"fontsize fontface vmargins hmargin...       HR  \n"
     ]
    }
   ],
   "source": [
    "# put data into a df\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Export the data to another CSV file\n",
    "# df.to_csv('data/Resume Dataset/Resume/Resume_clean.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the Resume_html column\n",
    "df.drop('Resume_html', axis=1, inplace=True)\n",
    "\n",
    "# Remove the ID column\n",
    "df.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "# Display the first few rows\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2484, 2)\n",
      "Category\n",
      "INFORMATION-TECHNOLOGY    120\n",
      "BUSINESS-DEVELOPMENT      120\n",
      "FINANCE                   118\n",
      "ADVOCATE                  118\n",
      "ACCOUNTANT                118\n",
      "ENGINEERING               118\n",
      "CHEF                      118\n",
      "AVIATION                  117\n",
      "FITNESS                   117\n",
      "SALES                     116\n",
      "BANKING                   115\n",
      "HEALTHCARE                115\n",
      "CONSULTANT                115\n",
      "CONSTRUCTION              112\n",
      "PUBLIC-RELATIONS          111\n",
      "HR                        110\n",
      "DESIGNER                  107\n",
      "ARTS                      103\n",
      "TEACHER                   102\n",
      "APPAREL                    97\n",
      "DIGITAL-MEDIA              96\n",
      "AGRICULTURE                63\n",
      "AUTOMOBILE                 36\n",
      "BPO                        22\n",
      "Name: count, dtype: int64\n",
      "(2484, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "\n",
    "# Find distinct categories in Category column\n",
    "print(df['Category'].value_counts())\n",
    "\n",
    "\n",
    "# Display the first few rows\n",
    "# print(df.head())\n",
    "\n",
    "# Reset the index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# See the shape of the data\n",
    "print(df.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2483, 2)\n"
     ]
    }
   ],
   "source": [
    "# Remove commas from the 'Resume_str' column\n",
    "df['Resume_str'] = df['Resume_str'].str.replace('\\n', ' ', regex=True)\n",
    "df['Resume_str'] = df['Resume_str'].str.replace('\\r', ' ', regex=True)\n",
    "df['Resume_str'] = df['Resume_str'].str.strip()\n",
    "\n",
    "df['Resume_str'] = df['Resume_str'].str.replace('\"', '', regex=True)\n",
    "df['Resume_str'] = df['Resume_str'].str.replace(',', ' ', regex=True)\n",
    "\n",
    "df['Resume_str'] = df['Resume_str'].fillna('').astype(str)\n",
    "\n",
    "# Remove rows where all values are NaN\n",
    "df = df.dropna(how='all')\n",
    "\n",
    "# Optionally remove rows where a specific column (e.g., 'Resume_str') is empty\n",
    "df = df[df['Resume_str'].str.strip().astype(bool)]\n",
    "\n",
    "# Display the first few rows\n",
    "# print(df.head())\n",
    "\n",
    "# Display size\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the data to another CSV file\n",
    "df.to_csv('data/Resume Dataset/Resume/Resume_Clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_lg\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "skill_pattern_path = \"skill_patterns_lowercase.jsonl\"\n",
    "\n",
    "\n",
    "# write a script to turn all the jsonl text lowercase\n",
    "# They are in this pattern {\"label\": \"HARD SKILL\", \"pattern\": [{\"TEXT\": \"Programming\"}]}\n",
    "# with open(skill_pattern_path, \"r\") as infile, open(output_file, \"w\") as outfile:\n",
    "#     for line in infile:\n",
    "#         # Load each line as a JSON object\n",
    "#         skill_entry = json.loads(line)\n",
    "        \n",
    "#         # Check if the pattern exists and modify the TEXT field\n",
    "#         if \"pattern\" in skill_entry:\n",
    "#             for item in skill_entry[\"pattern\"]:\n",
    "#                 if \"TEXT\" in item:\n",
    "#                     item[\"TEXT\"] = item[\"TEXT\"].lower()  # Convert to lowercase\n",
    "        \n",
    "#         # Write the updated JSON object back to the output file\n",
    "#         json.dump(skill_entry, outfile)\n",
    "#         outfile.write(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'parser',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'ner',\n",
       " 'entity_ruler']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "ruler.from_disk(skill_pattern_path)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create two python functions to extract all the skills within a resume and create an array containing all the skills. Later we are going to apply this function to our dataset and create a new feature called skill. This will help us visualize trends and patterns within the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skills(text):\n",
    "    doc = nlp(text)\n",
    "    myset = []\n",
    "    subset = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"SKILL\":\n",
    "            subset.append(ent.text)\n",
    "    myset.append(subset)\n",
    "    return subset\n",
    "\n",
    "def get_hard_skills(text):\n",
    "    doc = nlp(text)\n",
    "    myset = []\n",
    "    subset = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"HARD SKILL\":\n",
    "            subset.append(ent.text)\n",
    "    myset.append(subset)\n",
    "    return subset\n",
    "\n",
    "def unique_skills(x):\n",
    "    return list(set(x))\n",
    "\n",
    "# Function to extract roles in all caps\n",
    "def extract_roles(text):\n",
    "    # Find the portion of the text up to the first lowercase letter\n",
    "    match = re.match(r'^([A-Z\\s]+)[^A-Z]', text)\n",
    "    if match:\n",
    "        # Extract the matched string, remove the last letter and space, then lowercase\n",
    "        role = match.group(1).strip()[:-1].lower()\n",
    "        return role\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Resume Text using nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Resume_str Category\n",
      "0  HR ADMINISTRATOR MARKETING ASSOCIATE HR ADMINI...       HR\n",
      "1  HR SPECIALIST US HR OPERATIONS Summary Versati...       HR\n",
      "2  HR DIRECTOR Summary years experience recruitin...       HR\n",
      "3  HR SPECIALIST Summary Dedicated Driven Dynamic...       HR\n",
      "4  HR MANAGER Skill Highlights HR SKILLS HR Depar...       HR\n"
     ]
    }
   ],
   "source": [
    "# Go through each row of the 'Resume_str' column and clean the text\n",
    "df['Resume_str'] = df['Resume_str'].apply(lambda x: re.sub(r'\\s+', ' ', x))\n",
    "\n",
    "# Remove special characters and digits\n",
    "df['Resume_str'] = df['Resume_str'].apply(lambda x: re.sub('[^A-Za-z]+', ' ', x))\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['Resume_str'] = df['Resume_str'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))\n",
    "\n",
    "# Show the first few rows\n",
    "print(df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CSV for the Processed Data\n",
    "df.to_csv('data/Resume Dataset/Resume/Resume_Processed.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Resume_str Category   \n",
      "0  HR ADMINISTRATOR MARKETING ASSOCIATE HR ADMINI...       HR  \\\n",
      "1  HR SPECIALIST US HR OPERATIONS Summary Versati...       HR   \n",
      "2  HR DIRECTOR Summary years experience recruitin...       HR   \n",
      "3  HR SPECIALIST Summary Dedicated Driven Dynamic...       HR   \n",
      "4  HR MANAGER Skill Highlights HR SKILLS HR Depar...       HR   \n",
      "\n",
      "                                              skills  \n",
      "0  [accounting, integrity, customer service, inte...  \n",
      "1  [support, training, process improvement, commu...  \n",
      "2  [support, training, information management, cu...  \n",
      "3  [training, customer service, certificate, conf...  \n",
      "4  [support, training, problem solving, integrity...  \n"
     ]
    }
   ],
   "source": [
    "processed = df\n",
    "\n",
    "processed[\"skills\"] = processed[\"Resume_str\"].str.lower().apply(get_skills)\n",
    "processed[\"skills\"] = processed[\"skills\"].apply(unique_skills)\n",
    "\n",
    "# Display the first few rows\n",
    "print(processed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Resume_str Category   \n",
      "0  HR ADMINISTRATOR MARKETING ASSOCIATE HR ADMINI...       HR  \\\n",
      "1  HR SPECIALIST US HR OPERATIONS Summary Versati...       HR   \n",
      "2  HR DIRECTOR Summary years experience recruitin...       HR   \n",
      "3  HR SPECIALIST Summary Dedicated Driven Dynamic...       HR   \n",
      "4  HR MANAGER Skill Highlights HR SKILLS HR Depar...       HR   \n",
      "\n",
      "                                              skills   \n",
      "0  [accounting, integrity, customer service, inte...  \\\n",
      "1  [support, training, process improvement, commu...   \n",
      "2  [support, training, information management, cu...   \n",
      "3  [training, customer service, certificate, conf...   \n",
      "4  [support, training, problem solving, integrity...   \n",
      "\n",
      "                                         hard_skills  \n",
      "0  [certification, programming, development, stat...  \n",
      "1  [development, web, communication, develop, rep...  \n",
      "2  [databases, retention, development, hiring, te...  \n",
      "3  [dynamic, documentation, database, communicati...  \n",
      "4  [retention, development, hiring, applications,...  \n"
     ]
    }
   ],
   "source": [
    "processed[\"hard_skills\"] = processed[\"Resume_str\"].str.lower().apply(get_hard_skills)\n",
    "processed[\"hard_skills\"] = processed[\"hard_skills\"].apply(unique_skills)\n",
    "\n",
    "# Display the first few rows\n",
    "print(processed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Resume_str Category   \n",
      "0  HR ADMINISTRATOR MARKETING ASSOCIATE HR ADMINI...       HR  \\\n",
      "1  HR SPECIALIST US HR OPERATIONS Summary Versati...       HR   \n",
      "2  HR DIRECTOR Summary years experience recruitin...       HR   \n",
      "3  HR SPECIALIST Summary Dedicated Driven Dynamic...       HR   \n",
      "4  HR MANAGER Skill Highlights HR SKILLS HR Depar...       HR   \n",
      "\n",
      "                                              skills   \n",
      "0  [accounting, integrity, customer service, inte...  \\\n",
      "1  [support, training, process improvement, commu...   \n",
      "2  [support, training, information management, cu...   \n",
      "3  [training, customer service, certificate, conf...   \n",
      "4  [support, training, problem solving, integrity...   \n",
      "\n",
      "                                         hard_skills   \n",
      "0  [certification, programming, development, stat...  \\\n",
      "1  [development, web, communication, develop, rep...   \n",
      "2  [databases, retention, development, hiring, te...   \n",
      "3  [dynamic, documentation, database, communicati...   \n",
      "4  [retention, development, hiring, applications,...   \n",
      "\n",
      "                                               roles  \n",
      "0  hr administrator marketing associate hr admini...  \n",
      "1                    hr specialist us hr operations   \n",
      "2                                       hr director   \n",
      "3                                     hr specialist   \n",
      "4                                        hr manager   \n"
     ]
    }
   ],
   "source": [
    "processed['roles'] = processed['Resume_str'].apply(extract_roles)\n",
    "\n",
    "# Display the first few rows\n",
    "print(processed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Find all distinct roles and extract them to a jsonl file with the pattern format\n",
    "# roles = processed['roles'].unique()\n",
    "# roles = [role for role in roles if role]\n",
    "# roles = [{\"label\": \"ROLE\", \"pattern\": role} for role in roles]\n",
    "# with open(\"role_patterns.jsonl\", \"w\") as f:\n",
    "#     for role in roles:\n",
    "#         f.write(json.dumps(role) + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to a new CSV file\n",
    "processed.to_csv(\"data/Resume Dataset/Resume/Resume_With_Skills_And_Roles.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\spacy\\displacy\\__init__.py:213: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
      "  warnings.warn(Warnings.W006)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"><br><br>    </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent = nlp(\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    ")\n",
    "displacy.render(sent, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"><br><br>    </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "patterns = df.Category.unique()\n",
    "for a in patterns:\n",
    "    ruler.add_patterns([{\"label\": \"Job-Category\", \"pattern\": a}])\n",
    "\n",
    "\n",
    "# options=[{\"ents\": \"Job-Category\", \"colors\": \"#ff3232\"},{\"ents\": \"SKILL\", \"colors\": \"#56c426\"}]\n",
    "colors = {\n",
    "    \"Job-Category\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\",\n",
    "    \"SKILL\": \"linear-gradient(90deg, #9BE15D, #00E3AE)\",\n",
    "    \"ORG\": \"#ffd966\",\n",
    "    \"PERSON\": \"#e06666\",\n",
    "    \"GPE\": \"#9fc5e8\",\n",
    "    \"DATE\": \"#c27ba0\",\n",
    "    \"ORDINAL\": \"#674ea7\",\n",
    "    \"PRODUCT\": \"#f9cb9c\",\n",
    "}\n",
    "options = {\n",
    "    \"ents\": [\n",
    "        \"Job-Category\",\n",
    "        \"SKILL\",\n",
    "        \"ORG\",\n",
    "        \"PERSON\",\n",
    "        \"GPE\",\n",
    "        \"DATE\",\n",
    "        \"ORDINAL\",\n",
    "        \"PRODUCT\",\n",
    "    ],\n",
    "    \"colors\": colors,\n",
    "}\n",
    "displacy.render(sent, style=\"ent\", jupyter=True, options=options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
