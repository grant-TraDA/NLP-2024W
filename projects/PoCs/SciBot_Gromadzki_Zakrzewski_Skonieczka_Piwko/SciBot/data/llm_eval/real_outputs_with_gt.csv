llm,question,context,answer,ex_time,ground_truth
qwen2.5:3b,"What does the term ""learn to optimize"" mean?
","Document 1: 
 NatlSciRev ,2024,Vol.11,nwae132
Solver 4
Solver 1
Solver 2
Solver 3
Configuration space of algorithms
(solver class)
Facilitate the tedious trial-and-error process for
getting a good solver for an unseen instance
Solver 5
Unseen instances
Training set Solver class
Optimization problem class
Knowledge
Learning
Vehicle routing
problem
Machine learning
Traveling
salesman
problem
Problem Instance 1
Problem Instance 2
Problem Instance 3
Optimization problems
Figure 1 Illustration of the general idea of L2O. 
the same general paradigm that is very similar to 
the typical ML paradigm. That is, they leverage on 
a set of training instances from the target optimiza- 
tion problem class to gain something that would help 
alleviate the tedious algorithm configuration process 
on unseen problem instances, as i l lustrated in Fig. 1 . 
This article puts them under the umbrella term learn 
to optimize (L2O) and provides a brief overview on 
the general ideas as well as critical issues of L2O, in- 
cluding the training process, theoretical foundations 
as well as generalization issues. For more algorithmic 
details on NN-based solvers and heuristic solvers, 
readers are referred to [13 ,14 ] and [15 ,16 ], respec- 
tively. 

Document 2: 
 m∑
i=1
U(s, Xi),
where Xi is a random variable, representing an instance randomly drawn from X.
Notice that Um(s) is a random variable.
We deﬁne two properties of SPPAs, generalization and optimality. An SPPA
learning algorithm generalizes well, when the utility on all instances is close to the
utility on the training set. An SPPA learning algorithm is optimal, if the optimal
SPPA on the training set is close to the optimal result on the set of all instances.
These properties are formalized by the following deﬁnition.
Learning parallel portfolios of algorithms 99
Deﬁnition 6.1 We say that an SPPA learning algorithm mean-generalizes,i ff o ra n y
0 <ϵ and 0 <δ< 1 it outputs an SPPA s ∈ S,f o rw h i c h
P [Um(s) − E [U(s, X)] >ϵ ] ≤ δ.
Let the globally optimal algorithm be:
s∗ = arg max
s∈S
E [U(s, X)] .
We say that an SPPA learning algorithm ismean optimal,i ff o ra l l0 <ϵ and 0<δ< 1
it outputs a schedule s
P
[
E
[
U(s∗, X)
]
− E [U(s, X)] >ϵ 

Document 3: 
 model and select conﬁgurations, respectively.
Input :Target algorithm Awith parameter conﬁguration space Θ; instance set Π; cost
metric ˆc
Output :Optimized (incumbent) parameter conﬁguration, θinc
1 [R, θinc] ←Initialize(Θ, Π);
2 repeat
3 [M,tfit ] ←FitModel(R);
4 [ ⃗Θnew,tselect] ←SelectConﬁgurations(M, θinc, Θ);
5 [R,θinc] ←Intensify( ⃗Θnew, θinc, M, R, tfit + tselect, Π, ˆc);
6 until total time budget for conﬁguration exhausted;
7 return θinc;
parameter optimization (SPO) toolbox—which has received considerable attention in the
evolutionary algorithms community—provides many features that facilitate the manual
analysis and optimization of algorithm parameters; it also includes an automated SMBO
procedure for optimizing continuous parameters on single instances. We started our
own work in SMBO by comparing SKO vs SPO, studying their choices for the four
SMBO components [18]. We demonstrated that component Intensify mattered most, and
improved it in our SPO + algorithm [18]. Subsequently, we showed how to reduce the
overhead incurred by construction and use of response surface models via approximate
GP models. We also eliminated the need for a costly initial design by interleaving ran- 

Document 4: 
 this is to be taken as either the efficiency or the 
effectiveness of the solver.
r = n! Ts
Tns
The Challenges 
As presented in the introductory paragraphs, a 
divide-and-conquer approach can be lucky. A run 
can benefit from a good split, which brings a solu -
tion at the beginning of some subspace and allows 
for an early stop. In contrast, a different division 
can decrease performance. What is interesting here 
is that adding resources can decrease the perform -
ance since it can produce more demanding sub -
spaces. 
Even if portfolio-based approaches are less prone 
to this problem, extending the size of a portfolio 
can still be detrimental to its performance. In gen -
eral, this increases the overhead, due to more fre -
quent and broader clause sharing, and worsens 
cache-congestion issues. A priori, the question of 
deciding the most effective number of resources to 
use against a given formula is a difficult one. 
One possible direction of research is to extend 
automatic tuning techniques. These approaches 
use machine learning to craft a predictive function 
that relates the features of an instance and the 
parameters of a given solver to its expected run 
time. This function can be learned and tested 
offline against a large set of representative 
instances and used at run time to configure a solver 
and maximize its performance. This offline 
approach assumes that a large and representative 

Document 5: 
 OPT := inf
θ∈Θ
R(θ).
The search for the optimal conﬁguration is generally too ambitious, as the total runtime
required for the conﬁgurator must be extraordinarily large (possibly inﬁnite) to guarantee
that the best algorithm conﬁguration returned by the conﬁgurator is in fact the optimal
one with high probability.
As a workaround, one can leverage the idea underlying PAC learning (Valiant, 1984) to
the problem at hand. The basic idea is to relax the goal of ﬁnding the optimal conﬁguration
itself and, instead, ﬁnd a conﬁguration that is considered to be “good enough”. As there are
potentially several such “good enough” conﬁgurations 6, this relaxation of the goal allows
the search to be completed in less (and, thus, feasible) time. In this context, “good enough”
means that the expected runtime is only worse than the optimal expected runtime up to
a multiplicative factor of 1 + ε for some ﬁxed precision parameter ε > 0. Formally, a
conﬁguration is said to be ε-optimal (“good enough”) iﬀ
Ei∼P(c(i,θ)) ≤(1 + ε)OPT.
However, this relaxation of the target is problematic in the context of AC problems, since the
runtimes of conﬁgurations often exhibit a heavy-tailed distribution. Indeed, it is not diﬃcult
to construct an example based on such distributions in which any (sensible) conﬁgurator
would, in the worst case, take inﬁnitely long to ﬁnd an ε-optimal conﬁguration; see for 

Document 6: 
 tions of learning machines, which lead to objective 
functions that favor different optimization methods. 
As a result, many optimization techniques, including 
convex optimization methods [1 ], gradient descent 
[2 ], heuristic search [3 ] as well as evolutionary algo- 
rithms (E A s) [4 ], have been utilized by the ML com- 
munity in the past decades. 
Mainstream optimization algorithms are usu- 
ally highly configurable parameterized algorithms, 
i.e. they involve tunable parameters. Performance of 
such algorithms may vary significantly with different 
parameter settings. Hence, to solve the optimization 
problem induced by a learning task, tedious efforts 
are typically needed to configure the optimization al- 
gorithm. Consider the case of training an NN with 
stochastic gradient descent (SGD). It is widely ac- 
knowledged that the training performance is sensi- 
tive to the learning rate [5 ], a parameter of SGD. 
How to determine the optimal or at least appropri- 
ate learning rate has become a major hurdle for train- 
ing NNs, especially for large-scale NNs [6 ], or when 
the objective function is not an explicit differentiable 
function of the weights of an NN, as in the typical re- 
inforcement learning setting [7 ]. 
In order to reduce the human labor required, 
many studies have attempted to automate the config- 
uration of optimization algorithms [6 ,8 ]. However, 

","The term ""learn to optimize"" (L2O) refers to a paradigm where a learning algorithm uses training instances from a target optimization problem class to help alleviate the tedious algorithm configuration process for unseen problem instances.",9.53423309326172,"The term ""learn to optimize"" (L2O) refers to a paradigm in which algorithms utilize a set of training instances from a specific optimization problem class to facilitate the process of configuring optimizers for unseen problem instances. The L2O approach aims to alleviate the tedious trial-and-error process often required to find effective solvers for optimization problems. By leveraging machine learning techniques, L2O seeks to provide solutions that improve the configuration of algorithms when they encounter new instances, enhancing their performance and generalization capabilities."
qwen2.5:3b,"Please give some examples of metaheuristics.
","Document 1: 
 usually provide only sub-optimal solutions because they do
not attempt to escape from local optimum. These drawbacks
have led to the introduction of metaheuristics.
Metaheuristics are high-level methodologies or general al-
gorithmic templates, which generally do not adapt deeply
to speciﬁc problem(s) [4]. Hence, they usually can solve a
wide range of problems [2]. In fact, the preﬁx “meta”, which
means “upper level methodology”, indicates that metaheuristic
algorithms can be viewed as “higher level” heuristics. Hy-
brid approaches based on existing metaheuristic(s) are also
considered metaheuristics [5]. In last decades, metaheuristics
have received widespread attention from researchers and are
widely recognized as efﬁcient approaches for hard optimiza-
tion problems. A number of metaheuristic algorithms have
been developed and extensively applied, including Simulated
Annealing (SA) [6], Tabu Search (TS) [7], Evolutionary Algo-
rithms (EAs) [8], Ant Colony Optimization algorithm (ACO)
[9], Particle Swarm Optimization (PSO) [10], and so forth.
Most of metaheuristics are nature-inspired (inspired from some
principles in physics, biology and etc.), contain stochastic
components, and often have several free parameters that can
be set by users according to problem(s) at hand [4].
The setting of parameters (or parameter setting) has strong 

Document 2: 
 aside any metaphorical language. We utterly believe that eﬀorts in 
this direction should be intensiﬁed, building upon the initial postula- 
tions established in some recent works [105,106] . Speciﬁcally, meta- 
heuristics components (including search operators and algorithmic 
behavioral patterns) and interfaces between them should be stan- 
dardized towards objectively assessing similarities and diﬀerences 
between metaphor-based solvers [107] . A novel metaphor is by no 
means a suﬃcient guarantee for a signiﬁcant scientiﬁc contribution. 
• The third of these reasons is methodological, i.e., the relevance of 
some of the building blocks of the overall algorithm. A particular 
algorithm can include a given component (for example, a local op- 
timizer) that can be of relevance even if the algorithm as a whole 
is not completely competitive with respect to the prevailing liter- 
ature. A good example supporting this claim can be observed in 
co-evolutionary frameworks, which usually include a procedure to 
identify the subcomponents that will be individually co-evolved. In 
those cases, even if the subcomponent optimizer is not very sophis- 
ticated, the co-evolutionary framework can be relevant by itself. In 
this sense, it is important to select the appropriate framework to 
highlight the desired characteristic of the proposed algorithm, as dis- 
cussed in Section 3.1 . Following the same example of subcomponents 
identiﬁcation, a researcher focused on large-scale global optimiza- 

Document 3: 
 J. Durillo , K. Hammond , E. Hart , C.G. Johnson , et al. , A research agenda for meta- 
heuristic standardization, in: Proceedings of the XI metaheuristics international 
conference, 2015, pp. 1–3 . 
[106] J. Swan , S. Adraensen , A.E. Brownlee , C.G. Johnson , A. Kheiri , F. Krawiec , 
J. Merelo , L.L. Minku , E. Özcan , G.L. Pappa , et al. , Towards metaheuristics ”i n 
the large ”, arXiv preprint arXiv:2011.09821 (2020) . 
[107] M.A. Lones , Mitigating metaphors: a comprehensible guide to recent nature-in- 
spired algorithms, SN Computer Science 1 (1) (2020) 49 . 
[108] M. Jain, V. Singh, A. Rani, A novel nature-inspired algorithm for optimiza- 
tion: squirrel search algorithm, Swarm Evol Comput 44 (2019) 148–175, 
doi: 10.1016/j.swevo.2018.02.013 . 
[109] A.W. Mohamed, A.A. Hadi, A.K. Mohamed, Gaining-sharing knowledge 
based algorithm for solving optimization problems: a novel nature- 

Document 4: 
 erations Research54(1):99–114.
Bartz-Beielstein, T. 2006. Experimental Research in Evolution-
ary Computation. Springer V erlag.
Battiti, R., and Brunato, M. 2005. Reactiv e search: machine
learning for memory-based heuristics. Technical Report DIT-05-
058, Universit`a Degli Studi Di Trento, Trento, Italy.
Birattari, M.; St¨utzle, T.; Paquete, L.; and V arrentrapp, K. 2002.
A racing algorithm for conﬁguring metaheuristics. In Proc. of
GECCO-02, 11–18.
Birattari, M. 2004. The Problem of Tuning Metaheuristics as
Seen from a Machine Learning Perspective. Ph.D. Dissertation,
Universit´e Libre de Bruxelles, Brussels, Belgium.
Coy, S. P .; Golden, B. L.; Runger, G. C.; and Wasil, E. A. 2001.
Using experimental design to ﬁnd effective parameter settings for
heuristics. Journal of Heuristics7(1):77–97.
E´en, N., and S¨orensson, N. 2003. An extensible SA T solver. In
Proc. of SAT-03, 502–518. 

Document 5: 
 art algorithm, MOS, has been clearly surprised by SHADE-ILS and 
MLSHADE-SPA, hence becoming the most competitive algorithms 
(with a preference by SHADE-ILS, by its better performance and sim- 
plicity). 
8. Conclusions and outlook 
In this work we have stressed on the need for circumventing com- 
mon mistakes and ﬂaws observed in the ﬁeld of bio-inspired optimiza- 
tion, particularly when new meta-heuristic algorithms are proposed and 
experimentally validated over benchmarks designed to this end. Specif- 
ically, we have reviewed and critically analyzed contributions deal- 
ing with experimental recommendations and practices related to meta- 
heuristics. Following our literature study, we have prescribed a set of 
methodological recommendations for preparing a successful proposal 
of bio-inspired meta-heuristic algorithms, from the deﬁnition of the ex- 
perimentation to the presentation of the results. A number of useful 
techniques (graphically summarized in Fig. 9 ) have been suggested for 
prospective studies to implement our proposed methodological frame- 
work, in an attempt at ensuring fairness, coherence and soundness in 
future studies on the topic. Two diﬀerent case studies have been de- 
signed to exemplify the application of our prescribed methodology, dis- 
cussing on the results of the application of each guideline. Although both 
case studies deal with well-known benchmarks, we envision that our 
methodology can be a core part of the design process of meta-heuristic 

Document 6: 
 achieved using several heuristic mechanisms that interact in complex, non-intuitive
ways. For example, a DPLL-style complete solver for SAT (a prototypical NP-
complete problem with important applications in the design of reliable soft- and
hardware) may use different heuristics for selecting variables to be instantiated and
the values ﬁrst explored for these variables, as well as heuristic mechanisms for
managing and using logical constraints derived from failed solution attempts. The
activation, interaction and precise behaviour of those mechanisms is often controlled
by parameters, and the settings of such parameters have a substantial impact on the
Holger H. Hoos
Department of Computer Science, University of British Columbia, 2366 Main Mall, Vancouver,
BC, V6T 1Z4, Canada, e-mail: hoos@cs.ubc.ca
1 We note that the use of heuristic techniques does not imply that the resulting algorithms are nec-
essarily incomplete or do not have provable performance guarantees, but often results in empirical
performance far better than the bounds guaranteed by rigorous theoretical analysis.
Y . Hamadi et al. (eds.),Autonomous Search,
DOI 10.1007/978-3-642-21434-9 3,
© Springer-Verlag Berlin Heidelberg 2011
37
38 Holger H. Hoos
efﬁcacy with which a heuristic algorithm solves a given problem instance or class of 

","Metaheuristics include various algorithms inspired by nature, such as:

1. Simulated Annealing (SA)
2. Genetic Algorithms (GA)
3. Tabu Search (TS)
4. Ant Colony Optimization (ACO)
5. Particle Swarm Optimization (PSO)

Other examples of metaheuristics are evolutionary algorithms, simulated annealing, tabu search, ant colony optimization, and particle swarm optimization. These methods are used to find near-optimal solutions to complex problems where finding an exact solution might be computationally infeasible.",9.28729009628296,"Some examples of metaheuristics include Simulated Annealing (SA), Tabu Search (TS), Evolutionary Algorithms (EAs), Ant Colony Optimization (ACO), and Particle Swarm Optimization (PSO)."
qwen2.5:3b,"What is the ""no free lunch"" theorem about?
","Document 1: 
 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTA TION, VOL. 1, NO. 1, APRIL 1997 67
No Free Lunch Theorems for Optimization
David H. Wolpert and William G. Macready
Abstract— A framework is developed to explore the connection
between effective optimization algorithms and the problems they
are solving. A number of “no free lunch” (NFL) theorems are
presented which establish that for any algorithm, any elevated
performance over one class of problems is offset by perfor-
mance over another class. These theorems result in a geometric
interpretation of what it means for an algorithm to be well
suited to an optimization problem. Applications of the NFL
theorems to information-theoretic aspects of optimization and
benchmark measures of performance are also presented. Other
issues addressed include time-varying optimization problems and
a priori“head-to-head” minimax distinctions between optimiza-
tion algorithms, distinctions that result despite the NFL theorems’
enforcing of a type of uniformity over all algorithms.
Index T erms— Evolutionary algorithms, information theory,
optimization.
I. I NTRODUCTION
T
HE past few decades have seen an increased interest
in general-purpose “black-box” optimization algorithms
that exploit limited knowledge concerning the optimization
problem on which they are run. In large part these algorithms
have drawn inspiration from optimization processes that occur
in nature. In particular, the two most popular black-box 

Document 2: 
 function, and will produce .
The proof is completed if we show that there is no cost
function so that produces a sample containing and
and such that produces a sample containing and .
There are four possible pairs of samples to consider:
i) ;
ii) ;
iii) ;
iv) .
Since if its ﬁrst point is a , jumps to which is where
starts, when ’s ﬁrst point is a its second point must
equal ’s ﬁrst point. This rules out possibilities i) and ii).
For possibilities iii) and iv), by ’s sample we know that
must be of the form , for some variable . For
case iii), would need to equal , due to the ﬁrst point in
’s sample. For that case, however, the second point sees
would be the value at , which is , contrary to hypothesis.
For case iv), we know that the would have to equal , due
to the ﬁrst point in ’s sample. That would mean, however,
that jumps to for its second point and would therefore
see a , contrary to hypothesis.
Accordingly, none of the four cases is possible. This is
a case both where there is no symmetry under exchange of
’s between and , and no symmetry under exchange of
histograms.
A PPENDIX G 

Document 3: 
 The sum over can be accomplished in the same manner
is summed over. In fact, all the sums over all can
be done, leaving
(7)
In this last step, the statistical independence of and has
been used.
Further progress depends on whether represents or
. We begin with analysis of the case. For this case
, since only reﬂects cost
values from the last cost function, . Using this result gives
The ﬁnal sum over is a constant equal to the number of
ways of generating the sample from cost values drawn
from . The important point is that it is independent of
the particular . Because of this the sum over can be
evaluated eliminating the dependence
This completes the proof of Theorem 2 for the case of .
The proof of Theorem 2 is completed by turning to the
case. This is considerably more difﬁcult since
cannot be simpliﬁed so that the sums over cannot be
WOLPERT AND MACREADY: NO FREE LUNCH THEOREMS FOR OPTIMIZA TION 79
decoupled. Nevertheless, the NFL result still holds. This is
proven by expanding (7) over possible values
(8)
The innermost sum over only has an effect on the
, term so it contributes ,
. This is a constant, equal to . This
leaves
The sum over is now simple
The above equation is of the same form as (8), only with a
remaining sample of size rather than . Consequently, in
an analogous manner to the scheme used to evaluate the sums 

Document 4: 
 always use algorithm . As applied to this case, they
mean that for ﬁxed and ,i f does better (on average)
with the algorithms in some set , then does better (on
average) with the algorithms in the set of all other algorithms.
In particular, if for some favorite algorithms a certain “well-
behaved”results in better performance than does the random
, then that well-behaved gives worse than random behavior
on the set all remaining algorithms. In this sense, just as there
are no universally efﬁcacious search algorithms, there are no
universally benignwhich can be assured of resulting in better
than random performance regardless of one’s algorithm.
In fact, things may very well be worse than this. In super-
vised learning, there is a related result [11]. Translated into
the current context, that result suggests that if one restricts
sums to only be over those algorithms that are a good match
to , then it is often the case that “stupid” choosing
procedures—like the irrational procedure of choosing the
algorithm with the less desirable—outperform “intelligent”
ones. What the set of algorithms summed over must be in
order for a rational choosing procedure to be superior to an
irrational procedure is not currently known.
WOLPERT AND MACREADY: NO FREE LUNCH THEOREMS FOR OPTIMIZA TION 77
VIII. C ONCLUSIONS
A framework has been presented in which to compare 

Document 5: 
 values after distinct cost evaluations produced by using a
particular instantiation of an evolutionary algorithm?”
At ﬁrst glance this seems to be an intractable question,
but the NFL theorem provides a way to answer it. This is
because—according to the NFL theorem—the answer must be
independent of the algorithm used to generate. Consequently,
3 In particular, one may want to impose restrictions on /80 /40 /102 /41 . For instance,
one may wish to only consider /80 /40 /102 /41 that are invariant under at least partial
relabeling of the elements in /88 , to preclude there being an algorithm that will
assuredly “luck out” and land on /109/105 /110 /120 /50/88 /102 /40 /120 /41 on its very ﬁrst query.
WOLPERT AND MACREADY: NO FREE LUNCH THEOREMS FOR OPTIMIZA TION 73
we can choose an algorithm for which the calculation is
tractable.
Theorem 3: For any algorithm, the fraction of cost func-
tions that result in a particular histogram is
For large enough , this can be approximated as
where is the entropy of the distribution , and
is a constant that does not depend on .
This theorem is derived in Appendix C. If some of the are
zero, the approximation still holds, only with redeﬁned to 

Document 6: 
 to-head minimax distinctions. Such an analysis is beyond the
scope of this paper.)
On the other hand, having the sums be equal does carry ob-
vious implications for whether there are head-to-head minimax
distinctions. For example, if both algorithms are deterministic,
then for any particular
equals one for one pair and zero for all others. In such
a case, is just the number
of that result in the pair .S o
implies
that there are no head-to-head minimax distinctions between
and . The converse, however, does not appear to hold. 4
4 Consider the grid of all /40 /122/59 /122 /48 /41 pairs. Assign to each grid point the number
of /102 that result in that grid point’s /40 /122/59 /122 /48 /41 pair. Then our constraints are i)
by the hypothesis that there are no head-to-head minimax distinctions, if grid
point /40 /122 /49 /59/122 /50 /41 is assigned a nonzero number, then so is /40 /122 /50 /59/122 /49 /41 and ii) by
the no-free-lunch theorem, the sum of all numbers in row /122 equals the sum
of all numbers in column /122 . These two constraints do not appear to imply
that the distribution of numbers is symmetric under interchange of rows and 

","The ""no free lunch"" (NFL) theorem states that for any algorithm, elevated performance over one class of problems is offset by performance over another class. This means no single optimization algorithm can be expected to perform best across all possible problems; each algorithm has strengths and weaknesses relative to specific problem classes.",7.663870811462402,"The ""no free lunch"" (NFL) theorem states that for any optimization algorithm, any performance advantage achieved over a specific class of optimization problems is counterbalanced by performance declines over other classes of problems. This implies that no single algorithm is universally superior to others across all possible optimization problems—any gains in performance in one area will result in losses elsewhere. The NFL theorem establishes a framework for understanding the relationship between optimization algorithms and the specific problems they are applied to, leading to insights into the limitations of algorithmic effectiveness. It emphasizes that there are no universally effective or benign algorithms that can guarantee better-than-random performance in all scenarios."
qwen2.5:3b,"What is the concept behind Parallel Algorithm Portfolio?
","Document 1: 
 training set as well as for constructing the solvers.
This article studies effective construction approaches for
parallel portfolios that are less affected by nonrepresentative
training data. The term “parallel portfolio” [25], [26] refers
to a portfolio/set of solvers that is run independently in par-
allel when solving a problem instance (see Section III-A).
As a form of solvers, parallel portfolios have several impor-
tant advantages. First, exploiting parallelism has become very
important in designing efﬁcient solvers for computationally
hard problems, considering the great development and the
wide application of parallel computing architectures [27] (e.g.,
multicore CPUs) over the last decade. Parallel portfolios
employ parallel solution strategies and, thus, could easily make
effective use of modern hardware. Second, utilizing several
different solvers (as in parallel portfolios) is a simple yet
effective strategy for solving computationally hard problems.
Such an idea has also been realized in the form of sequential
portfolios [28], [29], which try to select the best solvers for
solving a problem instance, and adaptive solvers, such as adap-
tive parameter control [30]–[33]; reactive search [34], [35];
and hyper-heuristics [36]–[38], which seek to dynamically
determine the best solver setting while solving a problem
instance. In principle, all these methods need to involve some
mechanisms (e.g., selection or scheduling) to appropriately 

Document 2: 
 is only determined by the current database. As a sequence, we will
introduce two portfolio frameworks as parallel individual-based
944
Algorithm Portfolio for Individual-based Surrogate-Assisted Evolutionary Algorithms GECCO ’19, July 13–17, 2019, Prague, Czech Republic
SAEAs and UCB for individual-based SAEAs which are motivated
from two different aspects as reviewed previously.
3.1 Parallel individual-based SAEAs
澽澶澡濇澵澹澵澧澽澶澡濇澵澹澵澦澽澶澡濇澵澹澵澥 澸濕濨濕澔
澶濕濧濙
濇濨濕濦濨
濇濨濣濤澳
濍
濂
澹濢濘
/ŶŝƚŝĂůŝǌĂƚŝŽŶ
/ŶĚŝǀŝĚƵĂů
^ƵƌƌŽŐĂƚĞ ^ƵƌƌŽŐĂƚĞ ^ƵƌƌŽŐĂƚĞ
/ŶĚŝǀŝĚƵĂů/ŶĚŝǀŝĚƵĂů
Figure1:Thediagramoftheframework:Parallelindividual-
based SAEAs.
Similar with the algorithm portfolio for canonical evolutionary
algorithms, it is intuitive to consider each individual-based SAEA
as a simple evolutionary algorithm and embed them into the exist-
ing framework, like PAP or MultiEA. From this aspect, the parallel
individual-based SAEAs (Par-IBSAEA) framework is proposed that
all algorithm candidates run simultaneously at each generation.
Nevertheless, it is more convenient than portfolio for canonical
evolutionaryalgorithmsbecausealmostallindividual-basedSAEAs
have the same algorithm structure and it does not require a par-
ticular design for each algorithm. A brief diagram for Par-IBSAEA
with only three algorithm instances is presented in Figure 1 where 

Document 3: 
 general-ized to denote a combination of different algorithms intended to outperform the search performance of any of its constituent algorithms [3, 6, 11-14]. Here we extend that formulation, so that an algorithm portfolio schedules its constituent algorithms to run concurrently on a set of processors. Let an algorithm be any CSP solver, as described in the previous section. Given a set A = {a1, a2, …, am} of m algorithms, a set P = {x1, x2, …, xn} of n problems, and a set of B consecutive time intervals T = {t1, t2, …, tB}, a simple schedule Sk for a prob-lem on a single processor specifies 

Document 4: 
 algorithms, and thereby combine parameter tuning and an algo-rithm portfolio in the same framework. We are pursuing this avenue as well. The performance of any algorithm portfolio is, of course, bounded by that of an or-acle. The combination of algorithms as black boxes eliminates any opportunity to im-prove an individual algorithm. In contrast, parallelism can be achieved by a variety of problem decomposition methods (e.g., search space splitting), as discussed in Section 3. Although the results of recent SAT solver competitions suggest that a well-designed algorithm portfolio outperforms decomposition methods on a small number 

Document 5: 
 of processors [22], decomposition methods have shown their potential on many more processors (e.g., 64 cores or more in [19]). We will explore this in future work.  
9   Conclusions This paper presents WG, a constructor for non-parallel algorithm portfolios based on case-based reasoning and a greedy algorithm. It formulates parallel algorithm portfo-lio construction as an integer-programming problem, and generalizes WG to RSR-WG, a constructor for parallel algorithm portfolios based on a property of the optimal solution to the inherent integer-programming problem. To address a set of problems one at a time, RSR-WG creates portfolios of deterministic algorithms offline. Exper-iments show that the parallel algorithm portfolios produced by RSR-WG are statisti-cally significantly better than those produced by naïve parallel versions of popular portfolio constructors. Moreover, with only a few additional processors, RSR-WG portfolios are competitive with an oracle solver on a single processor.  Acknowledgements. This research was supported in part by the National Science Foundation under grants IIS-0811437, CNS-0958379 and CNS-0855217, and the City University of New York High Performance Computing Center. 

Document 6: 
 Ann Math Artif Intell (2006) 48:85–106
DOI 10.1007/s10472-007-9050-9
Learning parallel portfolios of algorithms
Marek Petrik ·Shlomo Zilberstein
Published online: 25 May 2007
© Springer Science + Business Media B.V. 2007
Abstract A wide range of combinatorial optimization algorithms have been devel-
oped for complex reasoning tasks. Frequently, no single algorithm outperforms all
the others. This has raised interest in leveraging the performance of a collection
of algorithms to improve performance. We show how to accomplish this using a
Parallel Portfolio of Algorithms (PPA). A PPA is a collection of diverse algorithms
for solving a single problem, all running concurrently on a single processor until
a solution is produced. The performance of the portfolio may be controlled by
assigning different shares of processor time to each algorithm. We present an
effective method for ﬁnding a PPA in which the share of processor time allocated
to each algorithm is ﬁxed. Finding the optimal static schedule is shown to be an
NP-complete problem for a general class of utility functions. We present bounds on
the performance of the PPA over random instances and evaluate the performance
empirically on a collection of 23 state-of-the-art SAT algorithms. The results show
signiﬁcant performance gains over the fastest individual algorithm in the collection.
Keywords Algorithm portfolios ·Resource bounded reasoning ·
Combinatorial optimization
Mathematics Subject Classiﬁcations (2000) 68T05 ·68T20 

","A Parallel Algorithm Portfolio (AAP) is a collection of diverse algorithms designed to solve a single problem concurrently on a single processor. The key idea is to have each algorithm contribute to solving the problem by running in parallel, with different shares of processing time allocated to each algorithm based on their performance or relevance to the current instance being solved. This approach aims to leverage the strengths of multiple algorithms to improve overall performance and efficiency, particularly for computationally hard problems where no single solver outperforms others universally.",8.298491477966309,"The concept behind a Parallel Algorithm Portfolio (PAP) involves utilizing a collection of diverse algorithms to solve a single problem by running them concurrently on a single processor or across multiple processors. The aim is to leverage the strengths of various algorithms to improve overall performance, especially in combinatorial optimization tasks where no single algorithm universally outperforms the rest. Each algorithm in the portfolio can be assigned different shares of processor time to optimize resource usage. The portfolio operates under the principle that combining algorithms as ""black boxes"" can enhance search performance beyond that of any individual algorithm. This setup allows for effective solving of complex problems, as demonstrated by empirical studies showing performance gains over the fastest individual algorithms in the collection."
qwen2.5:3b,"Please provide some approaches to how Parallel Algorithm Portfolio can be constructed.
","Document 1: 
 algorithms, and thereby combine parameter tuning and an algo-rithm portfolio in the same framework. We are pursuing this avenue as well. The performance of any algorithm portfolio is, of course, bounded by that of an or-acle. The combination of algorithms as black boxes eliminates any opportunity to im-prove an individual algorithm. In contrast, parallelism can be achieved by a variety of problem decomposition methods (e.g., search space splitting), as discussed in Section 3. Although the results of recent SAT solver competitions suggest that a well-designed algorithm portfolio outperforms decomposition methods on a small number 

Document 2: 
 tive parameter control [30]–[33]; reactive search [34], [35];
and hyper-heuristics [36]–[38], which seek to dynamically
determine the best solver setting while solving a problem
instance. In principle, all these methods need to involve some
mechanisms (e.g., selection or scheduling) to appropriately
allocate computational resources to different solvers, while the
parallel portfolios do not necessarily require any extra resource
allocation since each solver is simply assigned with the same
amount of resources. Third, a parallel portfolio could be eas-
ily converted to a sequential portfolio by using the algorithm
selection methods [39] to build selectors on the solvers in the
portfolio, which means the portfolios generated by construc-
tion approaches (e.g., the approach proposed in this article)
could be further used for constructing sequential portfolios.
In this article, we propose a novel approach called the
generative adversarial solver trainer (GAST) for the auto-
matic construction of parallel portfolios. Unlike the existing
construction approaches, GAST would generate additional
training instances and construct a parallel portfolio with the
dynamically changing training set. More speciﬁcally, GAST
puts instance generation and portfolio construction in an adver-
sarial game. The instance generation aims to generate the hard
problem instances that could not be solved well by the cur-
rent portfolio, while the portfolio construction aims to ﬁnd a
new component solver for the portfolio to better solve these 

Document 3: 
 1 for j := 1 ... n do
2 obtain portfolio c(j)
1:k by running AC on conﬁguration space ∏k
l=1{(c) | c ∈ C} on I using m for time t/n
3 choose ˆc1:k ∈ arg minc(j)
1:k |j∈{1...n} m(c(j)
1:k, I) that achieved best performance on I according to m
4 return ˆc1:k
3.1.1. Simultaneous conﬁguration of all component solvers (Global)
Our ﬁrst portfolio conﬁguration method is the straightforward extension of standard algorithm conﬁguration to the 
construction of a parallel portfolio (see Algorithm 1). Speciﬁcally, if the given solver has ℓ parameters, we treat the portfolio 
c1:k as a single algorithm with ℓ · k parameters inducing a conﬁguration space of size |C|k, and conﬁgure it directly. As 
noted above, we identify a single conﬁguration as the best of n independent runs of AC . These runs can be performed in 
parallel, meaning that this procedure requires wall clock time t/n if n machines—one for each AC run—with k cores are 
available. The used CPU time will be the given time budget t for Lines 1 and 2 in Algorithm 1 and some small overhead 
ϵ to choose the best portfolio in Line 3. The scalability of this approach is limited by the fact that the global conﬁguration 

Document 4: 
 Learning Algorithm Portfolios for Parallel Execution Xi Yun1 and Susan L. Epstein1, 2  1 Department of Computer Science, The Graduate School of The City University of New York, New York, NY 10016, USA 2 Department of Computer Science, Hunter College of The City University of New York, New York, NY 10065, USA xyun@gc.cuny.edu, susan.epstein@hunter.cuny.edu 
Abstract. Portfolio-based solvers are both effective and robust, but their prom-ise for parallel execution with constraint satisfaction solvers has received rela-tively little attention. This paper proposes an approach that constructs algorithm portfolios intended for parallel execution based on a combination of case-based reasoning, a greedy algorithm, and three heuristics. Empirical results show that this method is efficient, and can significantly improve performance with only a few additional processors. On problems from solver competitions, the resultant algorithm portfolios perform nearly as well as an oracle. Keywords: constraint satisfaction, algorithm portfolio, parallel processing, ma-chine learning. 

Document 5: 
 sign of parallel algorithm portfolios—sets of solvers that are run in parallel on a given instance of a decision problem, such 
as SAT, until the ﬁrst of them ﬁnds a solution [39,27].
In this work,1 we study generic methods for solving a problem we call Automatic Construction of Parallel Portfolios 
(ACPP): automatically constructing a static2 parallel solver from a sequential solver or a set of sequential solvers. This 
task can be understood as falling within the programming by optimization paradigm [34] in that it involves the design of 
software in which many design decisions have been deliberately left open during the development process (here exposed as 
parameters of SAT solvers) to be made automatically later (here by means of an automated algorithm conﬁgurator) in order 
to obtain optimized performance for speciﬁc use cases. Hence, all that is required by our ACPP methods is a sequential 
solver whose conﬁguration space contains complementary conﬁgurations.
We study three variants of the ACPP problem. First, we consider building parallel portfolios starting from a single, 
highly parametric sequential solver design. However, for well-studied problems (e.g., SAT), there often exist a wide range of 
different solvers that contribute to the state of the art (see, e.g., [73]). Complementarities among such solvers can be ex-
ploited by algorithm portfolios, whether driven by algorithm selection (like SATzilla [72]) or by parallel execution (such as 

Document 6: 
 training set as well as for constructing the solvers.
This article studies effective construction approaches for
parallel portfolios that are less affected by nonrepresentative
training data. The term “parallel portfolio” [25], [26] refers
to a portfolio/set of solvers that is run independently in par-
allel when solving a problem instance (see Section III-A).
As a form of solvers, parallel portfolios have several impor-
tant advantages. First, exploiting parallelism has become very
important in designing efﬁcient solvers for computationally
hard problems, considering the great development and the
wide application of parallel computing architectures [27] (e.g.,
multicore CPUs) over the last decade. Parallel portfolios
employ parallel solution strategies and, thus, could easily make
effective use of modern hardware. Second, utilizing several
different solvers (as in parallel portfolios) is a simple yet
effective strategy for solving computationally hard problems.
Such an idea has also been realized in the form of sequential
portfolios [28], [29], which try to select the best solvers for
solving a problem instance, and adaptive solvers, such as adap-
tive parameter control [30]–[33]; reactive search [34], [35];
and hyper-heuristics [36]–[38], which seek to dynamically
determine the best solver setting while solving a problem
instance. In principle, all these methods need to involve some
mechanisms (e.g., selection or scheduling) to appropriately 

","To construct a parallel algorithm portfolio, several approaches have been explored. One method is based on simultaneous configuration of all component solvers in what is called the ""Global"" approach. This involves treating the portfolio as a single algorithm with multiple parameters and configuring it directly from the solver's conﬁguration space. Another method studies how to automatically construct parallel solvers from sequential ones, which can be seen as part of programming by optimization where many design decisions are left open for automated configuration later.

Additionally, there is research on building portfolios starting from a single highly parametric sequential solver, taking advantage of the complementarities among various different solvers available for well-studied problems like SAT. This approach leverages algorithm selection or parallel execution mechanisms to dynamically find the best solvers and settings. Lastly, approaches that focus on reducing reliance on nonrepresentative training data are also important, as these ensure the portfolio’s effectiveness is not compromised by poor training set quality.",11.127954006195068,"Several approaches can be employed to construct Parallel Algorithm Portfolios. Here are some key methods discussed in the context provided:

1. **Generative Adversarial Solver Trainer (GAST)**: This novel approach involves an adversarial game where instance generation aims to create hard problem instances that the current portfolio struggles with, while the portfolio construction focuses on identifying a new solver component to improve performance on these instances. This dynamic training set generation helps enhance the portfolio's capability over time.

2. **Simultaneous Configuration of Component Solvers (Global Configuration)**: This straightforward method treats the portfolio as a single algorithm with combined parameters. It configures all solvers simultaneously by running independent configurations in parallel on available computing resources. The best-performing configuration is selected based on performance metrics.

3. **Empirical Combination of Heuristics and Case-Based Reasoning**: This approach constructs algorithm portfolios intended for parallel execution by employing a combination of case-based reasoning, greedy algorithms, and various heuristics. This method has shown efficiency and significant performance improvement with limited additional computational resources.

4. **Automatic Construction of Parallel Portfolios (ACPP)**: This method involves developing static parallel solvers from existing sequential solvers. ACPP can optimize performance for specific use cases by automatically configuring parameters of sequential solvers based on their complementary configurations.

5. **Exploit Parallelism with Diverse Solvers**: Utilizing several different solvers in the portfolio can provide a simple yet effective strategy for tackling computationally hard problems. The strategy can leverage modern parallel computing architectures by running solvers independently in parallel to maximize resource utilization.

These approaches illustrate the variety of methods that can be used to construct effective Parallel Algorithm Portfolios for solving complex problems efficiently."
qwen2.5:3b,"Can co-evolution be used in Parallel Algorithm Portfolio construction?
","Document 1: 
 in a series of benchmark problems. Finally, the paper will end with
a brief conclusion and a discussion of future work in Section 5.
2 RELATED WORK
2.1 Portfolio of evolutionary algorithm
In the areas of evolutionary algorithms, algorithm portfolio is ap-
plied to increase the probability of finding a better solution by
allocating computational resources to several complementary algo-
rithms. The algorithm portfolio frameworks in the literature can
be classified into two categories as the parallel-based framework
and the sequential-based framework.
For the parallel-based framework, all candidates will run simul-
taneously in multiple sub-processes. Population-based algorithm
portfolio (PAP) is a typical example [16], which allocates compu-
tational resources before the optimization according to the prior
knowledge.Eachalgorithmhasitsownpopulationandevolveinde-
pendently,buttheinformationissharedamongdifferentalgorithms
bymigrationstrategy.Besides,otherparallel-basedportfolioframe-
works like AMALGAM-SO [21] and the UMOEAs [6] collect the
performance of algorithms during the optimisation process and
allocate more resources to the better algorithm.
On the other hand, the sequential based framework only runs
onealgorithmatmostofthetimeduringtheprocessofoptimisation.
Different from the parallel-based algorithm portfolio, this kind of
frameworktrytoselectthebestalgorithmindifferentoptimisation 

Document 2: 
 tic is likely to have the right properties for
this approach to be useful, thus making it
very general in terms of applications.
So far we have assumed that the com-
ponent algorithms are completely inde -
pendent of each other and do not com-
municate. They can be thought of as
“competing” with one another for ma-
chineresources.However,allowingforco -
operation or dependencies among the in-
dividualalgorithmswhiletheyarerunning
simultaneously can improve performance
(18, 19). This possibility raises the inter-
estingquestionoftheextenttowhichour
economics approach to portfolio algo-
rithms can also benefit from cooperation.
Basically, cooperation will introduce sta-
tistical correlations between the perfor -
mance of the individual algorithms, and
we will accordingly define the correlation
between them as
  
cov•t1,t2 
 var•t1 var•t2 
(3)
where cov(t1, t2) denotes the covariance of
theperformanceofthetwoalgorithms.The
effect of cooperation, when manifested in
negativecorrelations,istoincreasetheper-
formanceaswellasreducetherisk(Fig.5).
This change is easily understood in that
negative correlations mean that one algo-
rithmisparticularlygoodpreciselyonthose 

Document 3: 
 So far, we have shown that our procedures were able to construct effective parallel portfolios based on single solvers 
with rich design spaces. There is considerable evidence from the literature and from SAT competitions that strong portfolios 
can also be built by combining entirely different solvers in their default conﬁgurations (see, e.g., SATzilla [72], ppfolio [63]
and pfolioUZK [70]). For instance, ppfolio was obtained simply by combining the best solvers from the previous competition 
into a parallel portfolio. pfolioUZK included more state-of-the-art solvers from 2011 and relied on additional experiments 
to ﬁnd the best combination of solvers in a portfolio. Neither portfolio considers the conﬁguration space of the component 
solvers and therefore both can be seen as simple baselines for other parallelization approaches, including ours. However, 
ppfolio and pfolioUZK use Plingeling as a portfolio component. Since we aim to investigate the strength of our ACPP methods 
without additional human expert knowledge on parallel solving, we ﬁrst consider only sequential solvers as the basis for 
our ACPP approach. This section and the following section investigates the extension of our automatic techniques to the 
construction of portfolios based on the conﬁguration spaces spanned by such solver sets.
4.1. Approach
As long as all of our component solvers are sequential, we can simply use the ACPP procedures deﬁned in Section 3. 
We can accommodate the multi-solver setting by introducing a solver choice parameter for each portfolio component (see 

Document 4: 
 1
Few-shots Parallel Algorithm Portfolio Construction
via Co-evolution
Ke Tang, Senior Member, IEEE, Shengcai Liu, Member, IEEE, Peng Yang, Member, IEEE,
and Xin Yao, Fellow, IEEE
Abstract—Generalization, i.e., the ability of solving problem
instances that are not available during the system design and
development phase, is a critical goal for intelligent systems.
A typical way to achieve good generalization is to learn a
model from vast data. In the context of heuristic search, such a
paradigm could be implemented as conﬁguring the parameters
of a parallel algorithm portfolio (PAP) based on a set of
“training” problem instances, which is often referred to as PAP
construction. However, compared to traditional machine learning,
PAP construction often suffers from the lack of training instances,
and the obtained PAPs may fail to generalize well. This paper
proposes a novel competitive co-evolution scheme, named Co-
Evolution of Parameterized Search (CEPS), as a remedy to
this challenge. By co-evolving a conﬁguration population and an
instance population, CEPS is capable of obtaining generalizable
PAPs with few training instances. The advantage of CEPS in
improving generalization is analytically shown in this paper. Two
concrete algorithms, namely CEPS-TSP and CEPS-VRPSPDTW,
are presented for the Traveling Salesman Problem (TSP) and 

Document 5: 
 algorithms, and thereby combine parameter tuning and an algo-rithm portfolio in the same framework. We are pursuing this avenue as well. The performance of any algorithm portfolio is, of course, bounded by that of an or-acle. The combination of algorithms as black boxes eliminates any opportunity to im-prove an individual algorithm. In contrast, parallelism can be achieved by a variety of problem decomposition methods (e.g., search space splitting), as discussed in Section 3. Although the results of recent SAT solver competitions suggest that a well-designed algorithm portfolio outperforms decomposition methods on a small number 

Document 6: 
 divides the search space into subspaces, succes -
sively allocated to sequential CDCL workers. Work -
ers cooperate through some load-balancing strate -
gy, which performs the dynamic transfer of 
subspaces to idle workers, and through the 
exchange of conflict clauses.
The parallel portfolio approach was introduced 
in 2008 (Hamadi, Jabbour, and Sais 2008; Winter -
steiger, Hamadi, and de Moura 2009; Guo et al.
2010). It exploits the complementarity of different 
sequential DPLL strategies to let them compete and 
cooperate on the same formula. Since each worker 
addresses the whole formula, there is no need to 
introduce load-balancing overheads, and coopera -
tion is only achieved through the exchange of con -
flict clauses. With this approach, the crafting of the 
strategies is important, especially with only a few 
workers. The objective is to cover the space of good 
search strategies in the best possible way. 
In general, the interleaving of computation can 
lead to the previously mentioned problem of non -
determinism. This is true for solvers that use a 
Articles 
SUMMER 2013   101 
(2) Implication graph
(3) Con/f_lict-clause
(3) Con/f_lict-clause
(1) Literal
(4) Activity
(5) Con/f_lict
Preprocessing
Boolean Unit
Propagation 

","Yes, the paper discusses a competitive co-evolution scheme (CEPS) for constructing parallel algorithm portfolios. It introduces CEPS as a way to improve generalization with few training instances by co-evolving both configuration and instance populations. Two algorithms, CEPS-TSP and CEPS-VRPSPDTW, are presented for solving the Traveling Salesman Problem and Vehicle Routing Problem, respectively.",8.484929084777832,"Yes, co-evolution can be used in Parallel Algorithm Portfolio (PAP) construction. The context describes a novel competitive co-evolution scheme called Co-Evolution of Parameterized Search (CEPS), which is specifically designed to improve generalization in PAPs despite the challenge of having few training instances. By co-evolving both a configuration population and an instance population, CEPS is capable of producing generalizable portfolios. Hence, this method serves as a viable approach to enhance the effectiveness of PAPs through co-evolution."
qwen2.5:3b,"What is the idea behind the PAP approach called ""GLOBAL""?
","Document 1: 
 paper has two major contributions. First, the proposed PAP is
developed for numerical optimization instead of combinatorial
optimization. Second, we investigate the term “risk” in a
different context. Previous work mainly aimed to reduce the
risk of an algorithm on a speciﬁc optimization problem, which
can be measured by applying the algorithm to the problem
for multiple times. In this paper, we are more interested in
reducing the risk overa set of problems , i.e., the risk is
measured by applying the algorithm to multiple problems.
Our PAP is a general framework for combining different
population-based search algorithms. It allocates computation
time among more than one constituent algorithm and acti-
vates interaction among them so that they can beneﬁt from
one another. To be more speciﬁc, the computation time is
measured by the number of ﬁtness evaluations (FEs), and
the allocation of FEs is implemented by dividing the whole
population into several subpopulations and evolving them in
a parallel manner (using different constituent algorithms). To
demonstrate the efﬁcacy of the proposed PAP, we chose four
existing population-based algorithms, including self-adaptive
differential evolution with neighborhood search (SaNSDE)
[7], particle swarm optimizer with inertia weight (wPSO)
[8], generalized generation gap (G3) model with generic
parent-centric recombination (PCX) operator (G3PCX) [9],
and covariance matrix adaptation evolution strategy (CMA-
ES) [10], as the constituent algorithms. These algorithms 

Document 2: 
 with a constraint handling technique. At each generation, each
subpopulation generates new individuals based on its own.
Then, each subpopulation is combined with new individuals
generated by all subpopulations, and selection is conducted
with the corresponding constraint handling technique. Com-
pared to all the above-mentioned work, in which all search
biases have access to the whole population, PAP allows only
its constituent algorithms to work on a subpopulation, i.e.,
full access to the whole population is prohibited. Migration is
the only route that different subpopulations communicate with
each other. This strategy, used by PAP, reduces the likelihood
of different constituent algorithms repeating similar search
behaviors or sharing similar search biases.
From the perspective of employing a multipopulation model
and migration operators, PAP is related to the distributed
EAs (dEAs), which have several subpopulations (islands) and
perform sparse exchange of individuals among them [25],
[26]. However, PAP is quite different from previous dEAs
in three major ways. First, most dEAs run the same EA
on all subpopulations [26]–[31] (either with the same or
different control parameters), while PAP employs different
EAs. Second, the migration scheme of PAP does not assume
any topology of subpopulations, while many dEAs do. By
this means, we solely focus on investigating whether it is 

Document 3: 
 • When constructing MOEAs/PAPs, it is important to maintain the diversity among the
member algorithms. Hence, the population diversity preservation schemes, such as
negatively correlated search [47], can be introduced into the construction approach to
promote cooperation between different member algorithms.
• In real-world applications, one may be unable to collect sufﬁcient MOPs as training
problems. How to automatically build powerful PAPs in these scenarios is also
worth studying.
• The effectiveness of MOEAs/PAP has been primarily demonstrated through exper-
imental evidence, but with an absence of theoretical analysis. A more thorough
investigation of its exceptional performance is crucial for advancing our understand-
ing, which, in turn, can lead to enhancements in its design and the development of a
more comprehensive automatic construction algorithm.
Electronics 2023, 12, 4639 17 of 18
Author Contributions: Conceptualization, S.L.; Methodology, S.L.; Software, X.M.; Validation, X.M.;
Resources, X.M.; Writing—original draft, X.M.; Writing—review and editing, W.H.; Supervision, S.L.
and W.H. All authors have read and agreed to the published version of the manuscript.
Funding: This research was supported by the Strategic Priority Research Program of Chinese
Academy of Science, Grant No. XDB32050100, and the National Natural Science Foundation of
China, Grant No. 91948303.
Data Availability Statement: The data presented in this study are available on request from the 

Document 4: 
 of high-quality PAPs is generally a challenging task, requiring domain experts (with a
deep understanding of both algorithms and problems) to explore the vast design space
of PAPs, which cannot be carried out manually with ease [28–30]. As an alternative, Tang
and Liu [25,26] proposed a general framework, called automatic construction of PAPs, that
seeks to automatically build PAPs by selecting the member algorithms from an algorithm
conﬁguration space, with the goal of optimizing the performance of the resulting PAP on a
given problem set (called training set). Such a framework has been shown to be effective in
building high-performance PAPs for combinatorial problems such as the Boolean Satisﬁa-
bility Problem (SAT) [25], the Traveling Salesman Problem (TSP) [27,31], and the Vehicle
Routing Problem (VRP) [26].
However, to the best of our knowledge, the potential of the automatic construction of
PAPs has not been investigated in the area of multi-objective optimization. Considering its
excellent performance on the above-mentioned problems and the practical signiﬁcance of
MOPs, studying how to utilize it to solve MOPs is thus valuable. In this work, we focus
on automatically building PAPs for continuous MOPs. On the other hand, as a general
framework, appropriately instantiating automatic PAP construction for a speciﬁc problem
domain is non-trivial. Speciﬁcally, it requires careful designs of the algorithm conﬁguration
space and the performance metrics used in the construction process [26]. 

Document 5: 
 are capable of exploring the search space globally. Hence, in order to achieve a better
overall performance for a diverse range of MOPs, it is natural and intuitive to combine
Electronics 2023, 12, 4639. https://doi.org/10.3390/electronics12224639 https://www.mdpi.com/journal/electronics
Electronics 2023, 12, 4639 2 of 18
the advantages of different MOEAs. One notable series of research efforts following this
idea are multi-operator-based MOEAs [11–14], which adaptively allocate computational
resources to MOEAs equipped with different operators when solving a MOP .
Apart from multi-operator-based MOEAs, and from a more general perspective of
problem solving, there is an effective technique that exploits the complementarity between
different algorithms by including them into a so-called algorithm portfolio (AP). To utilize
an AP to solve a problem, Tang et al. [ 20,21] proposed a simple but effective strategy,
called a parallel algorithm portfolio (PAP), that runs all member algorithms in the portfolio
independently in parallel to obtain multiple solutions. Then, the best solution will be
taken as the ﬁnal output of the PAP . Although a PAP would consume more computational
resources than a single algorithm, it has three important advantages. First, PAPs are
easy-to-implement because they do not necessarily require any resource allocation since
each member algorithm is simply assigned with the same amount of resource. Second, 

Document 6: 
 (CEC2005) [12], denoted asfcec1 −fcec14. These 27 functions
span a diverse set of problem features, such as multimodality,
ruggedness, ill-conditioning, interdependency, etc. They pro-
vided an ideal platform for our investigation on reducing risk
on a large variety of problems. Short descriptions of these
functions are presented in Tables I and II. More details of these
functions can be found in [11] and [12]. In our experiments,
all the functions were solved in 30 dimensions.
B. Experimental Settings
All the results presented in this paper were obtained by
executing 30 independent runs for each experiment. Since
we expect the PAP framework to be general enough so that
alternative algorithms can be incorporated with little effort,
it should not rely much on the reﬁnement of the constituent
algorithms. Hence, we did not ﬁne-tune the parameters of
the constituent algorithms to ﬁt PAP. When implementing
SaNSDE, we used all the parameter settings suggested in
the original publication [7]. As suggested in [8], a linearly
decreasing inertia weight over the course of the search is
employed in our implementation of wPSO. The two coefﬁ-
cients of wPSO were both set to 1.49445. We assumed the
researchers who proposed G3PCX and CMA-ES are at the
best position to implement the two algorithms and ﬁne-tune
the parameters. Hence, we simply used the source code of 

","The PAP (Program Analysis and Verification) methodology that includes a component called ""GLOBAL"" primarily aims to address complex and large-scale software systems. The GLOBAL approach, within the context of global program analysis, focuses on:

1. **Global Invariants**: Developing invariants for entire programs or parts of them rather than just individual loops or procedures.

2. **Automatic Program Analysis**: Automating the process of analyzing a system's behavior to verify properties without requiring detailed annotations from developers.

3. **Incremental Verification**: Achieving verification by incrementally refining analyses, which can be more efficient and practical for large systems.

4. **Compositional Reasoning**: Combining results from different parts of the system (such as components or modules) into a whole, to verify overall properties even when only local invariants are known.

5. **Model Checking Techniques**: Utilizing model checking algorithms to check if the global properties hold for all possible states of the system.

In essence, GLOBAL aims to provide more comprehensive and automatic ways to analyze software systems at a higher level of abstraction than traditional loop-based analyses do. This is particularly useful in ensuring safety-critical systems or complex business applications where understanding behavior across various modules or components is crucial.",11.157420635223389,"The PAP approach called ""GLOBAL"" focuses on optimizing performance by exploiting the advantages of different population-based algorithms through a parallel framework. Its main goal is to improve the overall performance across a diverse range of multi-objective problems by employing multiple algorithms that operate independently and in parallel. This strategy allows the algorithm portfolio to explore the search space globally, providing a higher chance of finding better solutions than any single algorithm could achieve on its own. Through the communication and migration of solutions among subpopulations, the PAP framework facilitates the sharing of beneficial information and enhances diversity in the search process. This method aims to effectively reduce the risk associated with solving various problems by improving cooperation between different member algorithms while maintaining their individual search biases."
qwen2.5:3b,"What is the idea behind the PAP approach called ""PARHYDRA""?
","Document 1: 
 on all subpopulations [26]–[31] (either with the same or
different control parameters), while PAP employs different
EAs. Second, the migration scheme of PAP does not assume
any topology of subpopulations, while many dEAs do. By
this means, we solely focus on investigating whether it is
worthy of allocating the limited computation time to different
algorithms so that the overall performance can be enhanced.
In contrast, a speciﬁc topology/structure for the relationship
between subpopulations is usually explicitly deﬁned in existing
dEAs [26]–[29], [32], [33]. Third, we are more interested
in reducing the overall risk of an algorithm ona spectrum
of problems. This issue has never been investigated in the
literature of dEAs.
In addition to dEAs, another notable work that is related
to PAP is the isolation strategy employed by hierarchically
organized evolution strategies (HOES) [34], [35]. In HOES,
a population is partitioned into a number of subpopulations,
and ES is run on them with different control parameters (e.g.,
search step sizes). The isolation strategy works in such a
way that the subpopulations evolve separately for a predeﬁned
isolation period (e.g., a few generations), and then the control
parameters are updated based on the individuals generated in
the subpopulations during the isolation period. Unlike PAP,
the motivation of the isolation strategy is not to make use of 

Document 2: 
 SCENARIOS , THAT IS , SAT-SMALL-BIAS-1/2/3/4. T HE NAME OF THE
CONSTRUCTION APPROACH IS USED TO DENOTE THE PORTFOLIOS
CONSTRUCTED BY IT. “PARHYDRA-A” R EFERS TO PARHYDRA
CONFIGURING BASED ON AUGMENTED TRAINING SETS .AP A R - 1 0
SCORE IS SHOWN IN BOLDFACE IF IT WAS NOT SIGNIFICANTLY
DIFFERENT FROM THE BEST TEST PERFORMANCE IN THE SCENARIO
(ACCORDING TO A WILCOXON SIGNED -RANK TEST WITH p = 0.05)
To answer this question, in each of the eight SAT scenarios,
that is, SAT-SMALL/BIAS-1/2/3/4, we used the same instance
generation procedure as in GAST (lines 13–18 in Algorithm 1)
to generate a large set of instances based on the training set.
The size of the generated set is ﬁve times the size of the
training set. Recall that the training set contains 50 instances,
we thus obtained an augmented training set of 300 instances
in each SAT scenario, and then PARHYDRA was used to
construct a parallel portfolio on these augmented training sets,
and then the obtained portfolio was tested on the test sets. As
before, each portfolio was tested by running it on the test set 

Document 3: 
 of high-quality PAPs is generally a challenging task, requiring domain experts (with a
deep understanding of both algorithms and problems) to explore the vast design space
of PAPs, which cannot be carried out manually with ease [28–30]. As an alternative, Tang
and Liu [25,26] proposed a general framework, called automatic construction of PAPs, that
seeks to automatically build PAPs by selecting the member algorithms from an algorithm
conﬁguration space, with the goal of optimizing the performance of the resulting PAP on a
given problem set (called training set). Such a framework has been shown to be effective in
building high-performance PAPs for combinatorial problems such as the Boolean Satisﬁa-
bility Problem (SAT) [25], the Traveling Salesman Problem (TSP) [27,31], and the Vehicle
Routing Problem (VRP) [26].
However, to the best of our knowledge, the potential of the automatic construction of
PAPs has not been investigated in the area of multi-objective optimization. Considering its
excellent performance on the above-mentioned problems and the practical signiﬁcance of
MOPs, studying how to utilize it to solve MOPs is thus valuable. In this work, we focus
on automatically building PAPs for continuous MOPs. On the other hand, as a general
framework, appropriately instantiating automatic PAP construction for a speciﬁc problem
domain is non-trivial. Speciﬁcally, it requires careful designs of the algorithm conﬁguration
space and the performance metrics used in the construction process [26]. 

Document 4: 
 paper has two major contributions. First, the proposed PAP is
developed for numerical optimization instead of combinatorial
optimization. Second, we investigate the term “risk” in a
different context. Previous work mainly aimed to reduce the
risk of an algorithm on a speciﬁc optimization problem, which
can be measured by applying the algorithm to the problem
for multiple times. In this paper, we are more interested in
reducing the risk overa set of problems , i.e., the risk is
measured by applying the algorithm to multiple problems.
Our PAP is a general framework for combining different
population-based search algorithms. It allocates computation
time among more than one constituent algorithm and acti-
vates interaction among them so that they can beneﬁt from
one another. To be more speciﬁc, the computation time is
measured by the number of ﬁtness evaluations (FEs), and
the allocation of FEs is implemented by dividing the whole
population into several subpopulations and evolving them in
a parallel manner (using different constituent algorithms). To
demonstrate the efﬁcacy of the proposed PAP, we chose four
existing population-based algorithms, including self-adaptive
differential evolution with neighborhood search (SaNSDE)
[7], particle swarm optimizer with inertia weight (wPSO)
[8], generalized generation gap (G3) model with generic
parent-centric recombination (PCX) operator (G3PCX) [9],
and covariance matrix adaptation evolution strategy (CMA-
ES) [10], as the constituent algorithms. These algorithms 

Document 5: 
 be used to build parallel portfolios. (Building a parallel portfolio in this way has the added advantage that no instance 
features are required, since there is no need to select among algorithms.) We introduce some enhancements to this 
approach for the parallel portfolio setting (discussed in Section 3.1.2), and refer to our method as parHydra.
3. Some parallel solvers only achieve strong performance when running on more than one core; such solvers will not 
be found by a greedy approach like parHydra, which only adds one conﬁguration at a time and does not recognize 
interaction effects that arise between different threads of a parallel solver. To overcome this problem, we introduce a 
new method called parHydrab, which augments parHydra to train b solvers per iteration. This method trades off the 
computational beneﬁt of parHydra’s greedy approach with the greater coverage of Global.
We evaluated our ACPP methods on SAT. We chose this domain because it is highly relevant to academia and industry 
and has been widely studied. We thus had access to a wide range of strong, highly parametric solvers and were assured 
that the bar for demonstrating eﬃcacy of parallelization strategies was appropriately high. We note that our approach is not 
limited to SAT solvers and can be directly applied to other domains. To evaluate our methods in the single-solver setting, we 
studied both Lingeling and clasp: prominent, highly parametric state-of-the-art solvers for SAT. Lingeling won a gold medal in 

Document 6: 
 that ihvr ∈(0, 1], and a larger value of ihvr is better. IHVR can distinguish well between
MOEAs with a different performance, and can also save a lot of calculations. In this work,
IHVR is used as the performance metric Metric .
4.3. Automatic Construction Approach
Algorithm 1 presents the automatic construction approach for MOEAs/PAP . Starting
from an empty set (line 2), the approach constructs the PAP (denoted as P) iteratively.
Speciﬁcally, each iteration of the approach (lines 3–15) consists of two subsequent phases.
In the ﬁrst phase, an existing automatic algorithm conﬁguration tool, namely SMAC 3 [44],
is used to search in Θ to ﬁnd the algorithm that can improve the performance of the current
PAP to the largest extent (line 5), and then this algorithm is inserted into P (line 6). This
phase is similar to the commonly-used greedy approach in the automatic construction of
PAPs [27,31]. Additionally, we introduce a new phase, namely simpliﬁcation, as the second
phase in Algorithm 1. In this phase (lines 7–14), P would be simpliﬁed by removing the
member algorithms that do not contribute at all to its performance (meaning removing
these algorithms has no effect on the performance of P on the training set). Considering
the size of P is bounded (line 3), removing the redundant algorithms from P is meaningful
because this will leave space for new member algorithms that can improve the performance 

","I believe there might be a slight confusion with the terms you've used. The PARHYDRA (Partnerships for Hydropower and Renewable Energy Development in Africa) approach does not have an acronym like ""PAP"". However, I can provide some general information about the PARHYDRA approach as it relates to hydropower development on African continent.

The PARHYDRA approach is a collaborative model designed to promote sustainable hydropower development in Sub-Saharan Africa. It involves partnerships between various stakeholders such as governments, private sector entities, local communities, and international organizations. The goal of the PARHYDRA approach is to ensure that hydropower projects are developed sustainably and responsibly.

Key aspects of the PARHYDRA approach include:

1. **Partnership**: Encouraging collaboration among all relevant parties.
2. **African Focus**: Focusing on development in Sub-Saharan African countries, particularly those with abundant hydropower resources.
3. **Responsible Development**: Emphasizing sustainability and environmental protection as core principles of project design and implementation.
4. **Regulatory and Institutional Support**: Supporting the creation or strengthening of regulatory frameworks to ensure responsible practices are followed.

This approach aims to leverage diverse expertise and resources to overcome challenges associated with hydropower development in African contexts, such as political instability, climate variability, and social resistance.",12.441128969192505,"The PAP approach called ""PARHYDRA"" is designed to construct parallel portfolios based on augmented training sets. Specifically, it utilizes a parallel portfolio for solving instances of problems, like SAT, without the need for instance features since it does not select among algorithms but rather integrates them. The method enhances traditional portfolio construction by testing each portfolio on a significantly larger augmented training set, thereby improving the chances of achieving strong performance across diverse problem scenarios. PARHYDRA involves generating a large set of instances from an initial training set, which is then used to develop and evaluate a parallel portfolio intended for efficient computational resource usage and optimal performance."
qwen2.5:3b,"What is the idea behind the PAP approach called ""CLUSTERING""?
","Document 1: 
 with a constraint handling technique. At each generation, each
subpopulation generates new individuals based on its own.
Then, each subpopulation is combined with new individuals
generated by all subpopulations, and selection is conducted
with the corresponding constraint handling technique. Com-
pared to all the above-mentioned work, in which all search
biases have access to the whole population, PAP allows only
its constituent algorithms to work on a subpopulation, i.e.,
full access to the whole population is prohibited. Migration is
the only route that different subpopulations communicate with
each other. This strategy, used by PAP, reduces the likelihood
of different constituent algorithms repeating similar search
behaviors or sharing similar search biases.
From the perspective of employing a multipopulation model
and migration operators, PAP is related to the distributed
EAs (dEAs), which have several subpopulations (islands) and
perform sparse exchange of individuals among them [25],
[26]. However, PAP is quite different from previous dEAs
in three major ways. First, most dEAs run the same EA
on all subpopulations [26]–[31] (either with the same or
different control parameters), while PAP employs different
EAs. Second, the migration scheme of PAP does not assume
any topology of subpopulations, while many dEAs do. By
this means, we solely focus on investigating whether it is 

Document 2: 
 while the size of the configuration space involved in each
configuration task in PARHYDRAb, i.e., |C|b, would grow
exponentially as b gets larger. However, in general the best
value of b may vary across different scenarios, and for a spe-
cific scenario it is very hard to determine a good choice of b
in advance.
The third method CLUSTERING tackles the ACPP prob-
lem via explicit instance grouping. That is, it clusters the
problem instances represented in a normalized instance fea-
ture space into k subsets and then independently runs an
AC procedure on each subset to obtain a component solver.
Similar to PARHYDRAb, CLUSTERING also has an im-
portant design choice that is hard to determine in advance.
Specifically, the clustering result has great influence on the
performance of the final parallel portfolio. However, there
exists different normalization approaches that can be used
here, and different of them can result in different instance
clusters. Generally the appropriate choice of the normaliza-
tion approach may vary across different instance sets, and
the accurate assessment of the cluster quality is not possible
before the portfolio is constructed completely.
From a methodological perspective, ACPP methods based
on explicit instance grouping seek to achieve the comple-
mentarity among the component solvers by promoting each
of them to handle different subsets of the problem instances.
Thus for these methods the quality of the instance group- 

Document 3: 
 two algorithms. It also proposes a population-based algorithm
portfolio (PAP), which not only reduces the risk of failing on
problems from different classes, but also makes ﬁnding high-
quality solutions more likely.
The basic idea of PAP is simple: instead of betting the entire
time budget on a single algorithm, we “invest” our time in
multiple algorithms. This idea has been explored for more than
ten years, based on the theory of investment portfolios that was
developed in the ﬁeld of economics to answer the question:
“How should one allocate his/her ﬁnancial assets (stocks,
bonds, etc.) in order to maximize the expected returns while
minimizing risks” [4]. In analogy with investment portfolios,
PAP focuses on the problem of how to allocate computation
time among algorithms and fully utilize the advantages of
these algorithms in order to maximize the expected utility of a
1089-778X/$26.00 c⃝ 2010 IEEE
PENG et al.: POPULATION-BASED ALGORITHM PORTFOLIOS FOR NUMERICAL OPTIMIZATION 783
Fig. 1. Pseudo-code of PAP.
problem solving episode. Based on the portfolio idea, various
approaches have been developed, either to minimize the ex-
pected time needed to solve problem instances or to maximize
the expected quality of the solution while the available time
is kept constant. However, all the existing approaches were
proposed for combinatorial problems. For example, Huberman
et al.[5] proposed an economic approach for constructing 

Document 4: 
 that ihvr ∈(0, 1], and a larger value of ihvr is better. IHVR can distinguish well between
MOEAs with a different performance, and can also save a lot of calculations. In this work,
IHVR is used as the performance metric Metric .
4.3. Automatic Construction Approach
Algorithm 1 presents the automatic construction approach for MOEAs/PAP . Starting
from an empty set (line 2), the approach constructs the PAP (denoted as P) iteratively.
Speciﬁcally, each iteration of the approach (lines 3–15) consists of two subsequent phases.
In the ﬁrst phase, an existing automatic algorithm conﬁguration tool, namely SMAC 3 [44],
is used to search in Θ to ﬁnd the algorithm that can improve the performance of the current
PAP to the largest extent (line 5), and then this algorithm is inserted into P (line 6). This
phase is similar to the commonly-used greedy approach in the automatic construction of
PAPs [27,31]. Additionally, we introduce a new phase, namely simpliﬁcation, as the second
phase in Algorithm 1. In this phase (lines 7–14), P would be simpliﬁed by removing the
member algorithms that do not contribute at all to its performance (meaning removing
these algorithms has no effect on the performance of P on the training set). Considering
the size of P is bounded (line 3), removing the redundant algorithms from P is meaningful
because this will leave space for new member algorithms that can improve the performance 

Document 5: 
 constituent algorithm with a part of the given time budget and
encourages interaction among the constituent algorithms with a
migration scheme. As a general framework rather than a speciﬁc
algorithm, PAP is easy to implement and can accommodate
any existing population-based search algorithms. In addition, a
metric is also proposed to compare the risks of any two
algorithms on a problem set. We have comprehensively evaluated
PAP via investigating 11 instantiations of it on 27 benchmark
functions. Empirical results have shown that PAP outperforms
its constituent algorithms in terms of solution quality, risk, and
probability of ﬁnding the global optimum. Further analyses
have revealed that the advantages of PAP are mostly credited
to the synergy between constituent algorithms, which should
complement each other either over a set of problems, or during
different stages of an optimization process.
Manuscript received October 14, 2008; revised March 20, 2009, August
31, 2009, and November 30, 2009. Date of publication March 29, 2010; date
of current version October 1, 2010. This paper was partially supported by
the National Natural Science Foundation of China under Grants 60533020,
60802036 and U0835002, the Fund for Foreign Scholars in University
Research and Teaching Programs in China under Grant B07033, and the
Engineering and Physical Science Research Council in U.K. under Grant
EP/D052785/1 on “SEBASE: Software Engineering By Automated Search.”
F. Peng and K. Tang are with the Nature Inspired Computation and
Applications Laboratory, School of Computer Science and Technology, Uni- 

Document 6: 
 • When constructing MOEAs/PAPs, it is important to maintain the diversity among the
member algorithms. Hence, the population diversity preservation schemes, such as
negatively correlated search [47], can be introduced into the construction approach to
promote cooperation between different member algorithms.
• In real-world applications, one may be unable to collect sufﬁcient MOPs as training
problems. How to automatically build powerful PAPs in these scenarios is also
worth studying.
• The effectiveness of MOEAs/PAP has been primarily demonstrated through exper-
imental evidence, but with an absence of theoretical analysis. A more thorough
investigation of its exceptional performance is crucial for advancing our understand-
ing, which, in turn, can lead to enhancements in its design and the development of a
more comprehensive automatic construction algorithm.
Electronics 2023, 12, 4639 17 of 18
Author Contributions: Conceptualization, S.L.; Methodology, S.L.; Software, X.M.; Validation, X.M.;
Resources, X.M.; Writing—original draft, X.M.; Writing—review and editing, W.H.; Supervision, S.L.
and W.H. All authors have read and agreed to the published version of the manuscript.
Funding: This research was supported by the Strategic Priority Research Program of Chinese
Academy of Science, Grant No. XDB32050100, and the National Natural Science Foundation of
China, Grant No. 91948303.
Data Availability Statement: The data presented in this study are available on request from the 

","The PAP (Pattern Analysis, Process and Knowledge Engineering) community often discusses clustering within the context of understanding patterns in data. Clustering in this area usually refers to a process where similar or related objects are grouped together based on their characteristics or features.

In general, clustering is an unsupervised learning method that involves sorting raw data into different groups (or clusters). The idea behind clustering can be summarized as follows:

1. **Data Representation**: Objects (e.g., documents, images) are represented in a high-dimensional space using various features or attributes.

2. **Distance Metrics**: Distances between these objects are computed based on the characteristics they possess. Common distance metrics include Euclidean distance, cosine similarity, and Manhattan distance.

3. **Hierarchical Clustering Algorithms**: These algorithms build nested clusters by recursively splitting data into increasingly smaller subsets. Examples include Agglomerative Hierarchical Clustering (AHC) and Divisive Hierarchical Clustering (DHC).

4. **Non-Hierarchical Methods**: These methods do not form a tree structure but directly provide a set of clusterings. Popular non-hierarchical algorithms are K-Means, DBSCAN, and Mean Shift.

5. **Evaluation Metrics**: Various metrics like silhouette score or within-cluster sum-of-squares (WCSS) are used to evaluate the quality of clustering solutions.

6. **Applications in PAP**: In Pattern Analysis, Process and Knowledge Engineering contexts, clustering can help identify coherent sets of patterns or processes within data. It aids in knowledge discovery by enabling users to understand complex datasets and relationships more easily.

7. **Interpretability**: Clustering results need to be interpretable. This means the clusters should make sense in the context of what is being analyzed (e.g., documents, processes, etc.).

In essence, clustering helps discover inherent structures or patterns within data by grouping similar objects together, which can then inform further analysis and decision-making processes in PAP domains.",15.152610063552856,"The idea behind the PAP approach called ""CLUSTERING"" involves tackling the Algorithm Configuration Problem (ACPP) through explicit instance grouping. Specifically, it clusters problem instances represented in a normalized instance feature space into k subsets, and then independently runs an Algorithm Configuration (AC) procedure on each subset to obtain a component solver. This method aims to achieve complementarity among the component solvers by allowing each of them to handle different subsets of the problem instances. However, the effectiveness of this method is significantly influenced by the quality of the clustering result, which can vary depending on the normalization approaches used. Thus, determining the appropriate normalization approach in advance poses a challenge."
qwen2.5:3b,"What is the idea behind the PAP approach called ""PCIT""?
","Document 1: 
 paper has two major contributions. First, the proposed PAP is
developed for numerical optimization instead of combinatorial
optimization. Second, we investigate the term “risk” in a
different context. Previous work mainly aimed to reduce the
risk of an algorithm on a speciﬁc optimization problem, which
can be measured by applying the algorithm to the problem
for multiple times. In this paper, we are more interested in
reducing the risk overa set of problems , i.e., the risk is
measured by applying the algorithm to multiple problems.
Our PAP is a general framework for combining different
population-based search algorithms. It allocates computation
time among more than one constituent algorithm and acti-
vates interaction among them so that they can beneﬁt from
one another. To be more speciﬁc, the computation time is
measured by the number of ﬁtness evaluations (FEs), and
the allocation of FEs is implemented by dividing the whole
population into several subpopulations and evolving them in
a parallel manner (using different constituent algorithms). To
demonstrate the efﬁcacy of the proposed PAP, we chose four
existing population-based algorithms, including self-adaptive
differential evolution with neighborhood search (SaNSDE)
[7], particle swarm optimizer with inertia weight (wPSO)
[8], generalized generation gap (G3) model with generic
parent-centric recombination (PCX) operator (G3PCX) [9],
and covariance matrix adaptation evolution strategy (CMA-
ES) [10], as the constituent algorithms. These algorithms 

Document 2: 
 them.
PCIT conducts the instance transfer with the help of in-
cumbent configurations (i.e., the best configurations found
by the AC procedure). In each subset, the instances which
cannot be solved satisfactorily by the corresponding incum-
bent are identified as the ones that need to be transferred,
and the target subset of each transferred instance is deter-
mined according to how well the incumbent on the candi-
date subset could perform on the instance. In essence, the
incumbent on a subset can be seen as a common special
characteristic of those “similar” instances (in the sense they
share the same high-quality configurations) within the sub-
set, and PCIT uses it to identify those “dissimilar” instances
and find better subsets for them. In each subset, the perfor-
mance of the incumbent on each instance could be obtained
from the rundata collected from the AC procedure runs.
However, while determining the target subsets for the trans-
ferred instances, how well the incumbents on the candidate
subsets would perform on the transferred instances are un-
known. One way to obtain these performances is to actually
test these incumbents on the transferred instances, which
however would introduce considerable additional compu-
tational costs. To avoid this, PCIT builds empirical perfor-
mance models (EPM) (Hutter et al. 2014) based on the col-
lected rundata to predict these performances.
1562
Algorithm Framework 

Document 3: 
 analogous to the over-ﬁtting phenomenon in machine learning,
has been observed when the size of the training instance set
is rather limited (i.e., few-shots challenge). That is, the test
(generalization) performance of the obtained conﬁgurations is
arbitrarily bad even if their performance on the training set is
excellent. Even worse, given a T collected from real world,
it is non-trivial to know how to verify whether it is a good
representative of Ω. In case the training instance set is too
small, or is not a good representative of the whole problem
class, the best PAP obtained with it would fail to generalize.
B. Related Work
Currently, there exist several approaches for PAP con-
struction, namely GLOBAL [25], PARHYDRA [25], [26],
CLUSTERING [27] and PCIT [13]. GLOBAL considers PAP
construction as an algorithm conﬁguration problem by treating
Θ as a parameterized algorithm. By this means existing
automatic algorithm conﬁguration tools could be directly uti-
lized to conﬁgure all the component solvers of Θ simultane-
ously. In comparison, PARHYDRA constructs Θ iteratively
3
by identifying a single component solver in each iteration that
maximizes marginal performance contribution to the current
PAP. CLUSTERING and PCIT are two approaches based on
instance grouping. That is, they both ﬁrst split the training 

Document 4: 
 of the more state-of-the-art Plingeling. Such results indicate
PCIT could identify powerful parallel portfolios, with little
human effort involved. Thus the portfolios constructed by
PCIT could conveniently provide at least two advantages.
That is, they are high-quality parallel solvers, and they could
be used as starting points for the development of more ad-
Table 4: Test results of parallel solvers on the test set of SAT-
Single and SAT-Multi. The performance of a solver is shown
in boldface if it was not significantly different from the best
performance (according to a permutation test with 100000
permutations and significance level p = 0.05).
SAT-Single SAT-Multi
#TOS PAR-10 PAR-1 #TOS PAR-10 PAR-1
PCIT 181 119 21 35 1164 219
Priss6 225 146 25 - - -
PfolioUZK - - - 36 1185 213
Plinegling-bbc452 276 32 33 1090 199
vanced parallel solvers.
Conclusion
In this paper we proposed a novel ACPP method, named
PCIT, which utilized an instance transfer mechanism to im-
prove the quality of the instance grouping. The experimen-
tal results on two widely studied problem domains, SAT and
TSP, have demonstrated the effectiveness of PCIT. Currently
PCIT relies on the instance features to build the EPM. Since 

Document 5: 
 with a constraint handling technique. At each generation, each
subpopulation generates new individuals based on its own.
Then, each subpopulation is combined with new individuals
generated by all subpopulations, and selection is conducted
with the corresponding constraint handling technique. Com-
pared to all the above-mentioned work, in which all search
biases have access to the whole population, PAP allows only
its constituent algorithms to work on a subpopulation, i.e.,
full access to the whole population is prohibited. Migration is
the only route that different subpopulations communicate with
each other. This strategy, used by PAP, reduces the likelihood
of different constituent algorithms repeating similar search
behaviors or sharing similar search biases.
From the perspective of employing a multipopulation model
and migration operators, PAP is related to the distributed
EAs (dEAs), which have several subpopulations (islands) and
perform sparse exchange of individuals among them [25],
[26]. However, PAP is quite different from previous dEAs
in three major ways. First, most dEAs run the same EA
on all subpopulations [26]–[31] (either with the same or
different control parameters), while PAP employs different
EAs. Second, the migration scheme of PAP does not assume
any topology of subpopulations, while many dEAs do. By
this means, we solely focus on investigating whether it is 

Document 6: 
 that ihvr ∈(0, 1], and a larger value of ihvr is better. IHVR can distinguish well between
MOEAs with a different performance, and can also save a lot of calculations. In this work,
IHVR is used as the performance metric Metric .
4.3. Automatic Construction Approach
Algorithm 1 presents the automatic construction approach for MOEAs/PAP . Starting
from an empty set (line 2), the approach constructs the PAP (denoted as P) iteratively.
Speciﬁcally, each iteration of the approach (lines 3–15) consists of two subsequent phases.
In the ﬁrst phase, an existing automatic algorithm conﬁguration tool, namely SMAC 3 [44],
is used to search in Θ to ﬁnd the algorithm that can improve the performance of the current
PAP to the largest extent (line 5), and then this algorithm is inserted into P (line 6). This
phase is similar to the commonly-used greedy approach in the automatic construction of
PAPs [27,31]. Additionally, we introduce a new phase, namely simpliﬁcation, as the second
phase in Algorithm 1. In this phase (lines 7–14), P would be simpliﬁed by removing the
member algorithms that do not contribute at all to its performance (meaning removing
these algorithms has no effect on the performance of P on the training set). Considering
the size of P is bounded (line 3), removing the redundant algorithms from P is meaningful
because this will leave space for new member algorithms that can improve the performance 

","It seems there might be a mix-up in terminology. The concept you're likely referring to involves PCIT (Parent-Child Interaction Therapy), which is not typically associated with the PAP (Positive Approaches) framework, but rather with behavior therapy for families.

**PCIT** stands for Parent-Child Interaction Therapy and it's specifically designed to help parents improve their interactions with their children in a clinical setting. It involves supervised sessions where parents practice positive parenting strategies in real-time with their child while being observed by a therapist. The goal is to facilitate better parent-child communication and reduce negative behaviors.

If you are looking for information about PAP (Positive Approaches) or another therapeutic framework, please clarify the context so I can provide more accurate information.",9.045445203781128,"The PAP approach called ""PCIT"" (Parallel Configuration Instance Transfer) utilizes an instance transfer mechanism to enhance the quality of instance grouping. It identifies ""dissimilar"" instances that cannot be solved satisfactorily by the corresponding incumbents found through an automatic configuration (AC) procedure. PCIT constructs a target subset for each transferred instance based on how well the incumbent configuration performs on similar instances, aiming to provide high-quality parallel solvers with minimal human intervention. It builds empirical performance models to predict how the incumbents would perform on transferred instances, thus avoiding significant computational costs. The effectiveness of PCIT has been demonstrated through experiments in problem domains such as SAT and TSP."
qwen2.5:3b,"What is the idea behind the PAP approach called ""CEPS""?
","Document 1: 
 also presented. The performance of the two instantiations on
TSP and VRPSPDTW problems support the effectiveness of
CEPS in the sense that, in comparison with state-of-the-art
PAP construction approaches, the PAPs obtained by CEPS
achieves better generalization performance.
Since CEPS is a generic framework, some discussions
would help elaborate issues that are of signiﬁcance in practice.
First, although this work assumes CEPS takes a set of initial
training instances as the input, such training instances are
not necessarily real-world instances but could be generated
randomly. In other words, CEPS could be used in a fully cold-
start setting (a.k.a. zero-shot), i.e., no real-world instances are
available for the target problem class. Further, CEPS could
either be run ofﬂine or online, i.e., it could accommodate new
real instances whenever available.
Second, the potential of CEPS could be further explored
by taking advantage of the data generated during its run,
except for the ﬁnal obtained PAP. The data contain all the
sampled conﬁgurations and instances, and the performance
of the former on the latter. Considering that when using
a search method to solve a problem instance, its optimal
parameter values are usually problem-instance dependent and
thus need to be tuned. To tune parameters for a new problem
instance, we can learn from the historical data generated by
CEPS to build a mapping from problem instances to their
optimal parameter values, i.e., a low-cost online parameter- 

Document 2: 
 paper has two major contributions. First, the proposed PAP is
developed for numerical optimization instead of combinatorial
optimization. Second, we investigate the term “risk” in a
different context. Previous work mainly aimed to reduce the
risk of an algorithm on a speciﬁc optimization problem, which
can be measured by applying the algorithm to the problem
for multiple times. In this paper, we are more interested in
reducing the risk overa set of problems , i.e., the risk is
measured by applying the algorithm to multiple problems.
Our PAP is a general framework for combining different
population-based search algorithms. It allocates computation
time among more than one constituent algorithm and acti-
vates interaction among them so that they can beneﬁt from
one another. To be more speciﬁc, the computation time is
measured by the number of ﬁtness evaluations (FEs), and
the allocation of FEs is implemented by dividing the whole
population into several subpopulations and evolving them in
a parallel manner (using different constituent algorithms). To
demonstrate the efﬁcacy of the proposed PAP, we chose four
existing population-based algorithms, including self-adaptive
differential evolution with neighborhood search (SaNSDE)
[7], particle swarm optimizer with inertia weight (wPSO)
[8], generalized generation gap (G3) model with generic
parent-centric recombination (PCX) operator (G3PCX) [9],
and covariance matrix adaptation evolution strategy (CMA-
ES) [10], as the constituent algorithms. These algorithms 

Document 3: 
 this approach no longer guarantees the validity of the above
assumption. As a consequence, Θ′may generalize worse than
Θ. A remedy to prevent this as much as possible is to increase
redundancy in the evolution of the PAP. More speciﬁcally, one
could repeat the conﬁguration-removal procedure to Θ for n
times, leading to ntemporary PAPs, ¯Θ1,..., ¯Θn; then for each
temporary PAP ¯Θ, the new conﬁgurations are identiﬁed and
inserted, leading to n new PAPs, Θ′
1,..., Θ′
n, each of which
is of the same size as Θ; ﬁnally, the PAP among them that
performs best against T ∪T′ is retained.
III. C O-EVOLUTION OF PARAMETERIZED SEARCH
By incorporating the above-described procedure into the co-
evolution process, we arrive at the proposed CEPS framework,
as demonstrated in Algorithm 1. In general, CEPS consists
of two major phases, i.e., an initialization phase (lines 2-
7), and a co-evolution phase (lines 8-27) which could be
further subdivided into alternating between the evolution of
the conﬁguration population (representing the PAP) (lines 10-
15) and the evolution of the instance population (representing
the training instances) (lines 17-26) for MaxIte iterations in
total. These modules are detailed as follows. 

Document 4: 
 contributions of this paper include:
1) A novel PAP construction framework, namely Co-
Evolution of Parameterized Search (CEPS), is proposed.
It is also shown that CEPS approximates a process that
minimizes the upper bound, i.e., a tractable surrogate,
of the generalization performance.
2) To demonstrate the implementation details of CEPS as
well as to assess its potential, concrete instantiations are
also presented for two hard optimization problems, i.e.,
TSP and the Vehicle Routing Problem with Simultane-
ous Pickup–Delivery and Time Windows (VRPSPDTW)
[18]. Computational studies conﬁrm that CEPS is able
to obtain PAPs with better generalization performance.
3) The proposal of CEPS extends the realm of Co-
Evolution, for the ﬁrst time, to evolving algorithm
conﬁgurations and problem instances. Since CEPS does
not invoke domain-speciﬁc knowledge, its potential ap-
plications can go beyond optimization problems, even to
planning and learning problems.
The rest of the paper is organized as follows. Section II in-
troduces the challenge of seeking generalizable PAPs, existing
PAP construction methods, as well as the theoretical insight
behind CEPS. Section III presents the CEPS framework. Sec-
tion IV presents its instantiations for TSP and VRPSPDTW.
Computational studies on these two problems are presented in
Section V. Threats to validity of this study are discussed in 

Document 5: 
 that ihvr ∈(0, 1], and a larger value of ihvr is better. IHVR can distinguish well between
MOEAs with a different performance, and can also save a lot of calculations. In this work,
IHVR is used as the performance metric Metric .
4.3. Automatic Construction Approach
Algorithm 1 presents the automatic construction approach for MOEAs/PAP . Starting
from an empty set (line 2), the approach constructs the PAP (denoted as P) iteratively.
Speciﬁcally, each iteration of the approach (lines 3–15) consists of two subsequent phases.
In the ﬁrst phase, an existing automatic algorithm conﬁguration tool, namely SMAC 3 [44],
is used to search in Θ to ﬁnd the algorithm that can improve the performance of the current
PAP to the largest extent (line 5), and then this algorithm is inserted into P (line 6). This
phase is similar to the commonly-used greedy approach in the automatic construction of
PAPs [27,31]. Additionally, we introduce a new phase, namely simpliﬁcation, as the second
phase in Algorithm 1. In this phase (lines 7–14), P would be simpliﬁed by removing the
member algorithms that do not contribute at all to its performance (meaning removing
these algorithms has no effect on the performance of P on the training set). Considering
the size of P is bounded (line 3), removing the redundant algorithms from P is meaningful
because this will leave space for new member algorithms that can improve the performance 

Document 6: 
 cores each (2.20 GHz, 30 MB Cache), running Centos 7.5.
D. Results and Analysis
We report the #TOs, PAR-10 and PANC achieved by the
PAPs on the testing set in Table II and also visualize their
medians and variance across all the testing instances by box-
plots in Figure 1. Note the mean value is also plotted in Figure
1 (indicated by “ ▲”) to show that for a PAP how its PAR-
10/PANC is affected by the outliers (the timeout cases) which
would be hidden by boxplots. In Table II the #TOs, PAR-
10/PANC of a PAP is highlighted in grey if it achieved the best
performance. One could make three important observations
from these results. First, the PAPs obtained by CEPS have
the smallest number of timeouts in all the six experiments,
which means they have the highest success rate for solving the
testing instances among all the tested PAPs. Recall that CEPS
actively searches in the instance space to identify the hard-
to-solve instances for further improving the generalization of
the PAPs. Such a mechanism makes CEPS the method that is
least affected by the hard testing instances which signiﬁcantly
differs from the given training instances. This could be further
veriﬁed by Figure 1, in which CEPS is the method that has
the least gap between the mean value (which takes timeouts
into account) and median value (which naturally ﬁlters out the 

","It appears there might be some confusion with terminology, as ""CEPS"" does not directly align with any widely recognized Privacy Enhancing Technologies (PETs) or concepts related to Certificate-Based Privacy-Preserving Systems. 

""PAP"" often stands for ""Privacy Assured Platform,"" which is an approach that combines various privacy-enhancing technologies and practices. However, it doesn't have a specific acronym like CEPS.

If you're looking into Privacy Preserving Techniques in the context of Certificate-Based systems or digital identity management, one relevant concept might be ""CertiKOS,"" which is related to certificate-based authentication and authorization models with emphasis on privacy.

Could you please clarify which specific approach or technology you are referring to under the term ""CEPS""? This would help provide a more accurate answer.",9.19800329208374,"The PAP approach called ""Co-Evolution of Parameterized Search"" (CEPS) is designed to enhance the construction of Parameterized Algorithm Portfolios (PAPs) by effectively combining different population-based search algorithms. The key idea behind CEPS is to co-evolve both algorithm configurations and problem instances, which allows the framework to learn from both the algorithms and the specific characteristics of the problems being solved. The framework consists of two main phases: an initialization phase and a co-evolution phase that alternates between evolving a configuration population (representing the PAP) and an instance population (representing the training instances). CEPS aims to reduce the generalization error of PAPs across a set of problems rather than on individual instances, facilitating adaptation to varying types of problems for better overall performance. This approach also supports both offline and online operations, making it flexible in handling incoming problem instances."
qwen2.5:3b,"Please give me the names of some state-of-the-art SAT solvers.
","Document 1: 
 of determining whether a Boolean formula can 
evaluate to true, benefits from very mature and 
advanced algorithms with large practical impact.
Application and research domains like software 
and hardware verification, automated planning,
computational biology, and many others benefit 
from modern SAT solvers. These domains have 
large and difficult instances that provide the SAT 
community with meaningful benchmarks. 
Most of the following challenges are general in 
such a way that the questions they raise should 
positively affect not only research in parallel SAT 
but in parallel search in general. We first present 
the current situation in sequential and parallel SAT 
solving and then give a set of challenges. Each of 
these challenges comes with an overly optimistic 
estimate of its inherent difficulty represented as 
black circles, where we would estimate that every 
black circle represents, roughly, about two years of 
research. 
Context: Sequential SAT Solvers 
State-of-the-art solvers extend the original Davis,
Putnam, Logemann, and Loveland (DPLL) proce -
dure (Davis, Logemann, and Loveland 1962) with 
conflict analysis (Zhang et al. 2001). The general
architecture of such conflict-directed clause-learn -
ing solvers (CDCL) is presented in figure 1. These 
procedures include an optional preprocessing step 
0, which performs variable elimination and clause 
subsumption checks in order to reduce the size of 
the formula and improve the performance of the 

Document 2: 
 Intelligence (AAAI’02), (pp. 674–681). AAAI Press / The MIT Press, Menlo Park, CA, USA.
KhudaBukhsh, A., Xu, L., Hoos, H. H., & Leyton-Brown, K. (2009). SATenstein: Automatically building lo-
cal search sat solvers from components. In Proceedings of the Twenty-ﬁrst International Joint Conference
on Artiﬁcial Intelligence (IJCAI’09), (pp. 517–524).
Le Berre, D. & Simon, L. (2004). Fifty-ﬁve solvers in Vancouver: The SAT 2004 competition. In Hoos, H. H.
& Mitchell, D. G. (Eds.), Theory and Applications of Satisﬁability Testing: Proceedings of the Seventh
International Conference (SAT’04), volume 3542 of Lecture Notes in Computer Science , (pp. 321–344).
Springer Verlag.
Leyton-Brown, K., Nudelman, E., & Shoham, Y . (2002). Learning the empirical hardness of optimization
problems: The case of combinatorial auctions. In Hentenryck, P. V . (Ed.), Principles and Practice of
Constraint Programming – CP 2002: Eighth International Conference , volume 2470 of Lecture Notes in
Computer Science, (pp. 556–572). Springer Verlag, Berlin, Germany. 

Document 3: 
 212
state-of-the-art SLS algorithms. SATenstein-LS has
41 parameters that control the selection and behavior of
its components, leading to a total conﬁguration space of
size 4.82 ×1012. Automatically-identiﬁed conﬁgurations of
SATenstein-LS have been shown to achieve better per-
formance than existing state-of-the-art SLS algorithms on
several well-known instance distributions.
Instances
We investigated the effectiveness of Hydra on four distri-
butions, drawing on well-known families of SAT instances.
Because no state-of-the-art SLS algorithms are able to prove
unsatisﬁability, we considered only satisﬁable instances. We
identiﬁed these by running all complete algorithms that won
a SAT competition category between 2002 and 2007 for
one hour. First, the BM data set is constructed from 500
instances taken from each of the six distributions used by
KhudaBukhsh et al. (2009) (
QCP, SWGCP, FACT, CBMC,
R3FIX, and HGEN), split evenly into training and test sets.
Second, the INDU data set is a mixture of 500 instances
from each of the CBMC and FACT distributions, again split
evenly into training and test sets. Third and fourth, the HAND
and RAND data sets include all satisﬁable instances from the
Random and Handmade categories of the SAT Competitions 

Document 4: 
 form (a conjunction of disjunctions of variables and their negations) and determine a satisﬁable assignment or prove that 
none exists. An incomplete SAT solver can ﬁnd satisfying assignments, but not prove unsatisﬁability.
Most state-of-the-art complete SAT solvers are based on conﬂict-driven clause learning (CDCL; [57]). Their parameters 
control variable selection for branching decisions, clause learning and restart techniques. State-of-the-art incomplete SAT 
solvers use stochastic local search (SLS; [38]), and their parameters control the selection of the variable whose value is 
modiﬁed in each local search step as well as the diversiﬁcation and additional intensiﬁcation strategies. Furthermore, there 
exist several preprocessing techniques (e.g., [21]) to simplify formulas and their parameters control how long and how 
aggressive preprocessing will be used – too much preprocessing can remove important structural information and hence, 
it can increase the hardness of formulas. The eﬃcacy of SAT solvers depends on multiple heuristic components whose 
basic functions and the interplay between them are controlled by parameters. Some parameters are categorical (e.g., choice 
between different search strategies in SLS), while many others are integer- or real-valued (e.g., the damping factor used in 
computing heuristic variable scores in CDCL).
Parallel SAT solvers have received increasing attention in recent years. ManySAT [30,31,29] was one of the ﬁrst parallel 

Document 5: 
 tial solver baselines, indicating the great benefit by combin-
ing complementary configurations obtained from a rich con-
figuration space.
Comparison with Hand-designed Parallel Solvers
To further evaluate the portfolios constructed by PCIT, we
compared them with the state-of-the-art manually designed
parallel solvers. Specifically, we considered the ones con-
structed for SAT. We chose Priss6 (Manthey, Stephan, and
Werner 2016) to compare with the one constructed in SAT-
Single, since Priss6 is the official parallel version of Riss6
(the base solver in SAT-Single). For the same reason, we
chose PfolioUZK (Wotzlaw et al. 2012) (the gold medal
winning solver of the parallel track of the SAT’12 Chal-
lenge) to compare with the one constructed in SAT-Multi.
Finally, we chose Plingeling (version bbc) (Biere 2016),
the gold medal winning solver of the parallel track of the
SAT’16 Competition, to compare with both. Note that all
the manually designed solvers considered here have imple-
mented far more advanced parallel solving strategies (e.g.,
clause sharing) than only independently running component
solvers in parallel. In the experiments the default settings of
these solvers were used and the same statistical tests as be-
fore were conducted. As shown in Table 4, on SAT-Single 

Document 6: 
 ACM 52(10):56–67.
Balyo, T.; Heule, M. J. H.; and J¨arvisalo, M., eds. 2016. Proceed-
ings of SAT Competition 2016: Solver and Benchmark Descrip-
tions, volume B-2016-1 of Department of Computer Science Se-
ries of Publications B. University of Helsinki.
Battiti, R.; Brunato, M.; and Mascia, F., eds. 2008. Reactive
Search and Intelligent Optimization. Springer.
Biere, A. 2016. Splatz, Lingeling, Plingeling, Treengeling, Yal-
SAT Entering the SAT Competition 2016. In Balyo et al. (2016),
44–45.
Burke, E. K.; Gendreau, M.; Hyde, M.; Kendall, G.; Ochoa, G.;
¨Ozcan, E.; and Qu, R. 2013. Hyper-heuristics: A Survey of the
State of the Art. Journal of the Operational Research Society
64(12):1695–1724.
Gomes, C. P., and Selman, B. 2001. Algorithm Portfolios. Arti-
ficial Intelligence 126(1-2):43–62.
Hamadi, Y ., and Wintersteiger, C. M. 2013. Seven Challenges in
Parallel SAT Solving. AI Magazine 34(2):99–106. 

","Some state-of-the-art SAT solvers include MiniSAT, Glucose, Maple, and Picosat. Additionally, there are more recent ones like Plingeling and YalCrypt that have performed well in competition settings. The field includes many others with varying strengths depending on the complexity of the problem at hand.",8.233237028121948,"Some state-of-the-art SAT solvers include SATenstein, Priss6, PfolioUZK, and Plingeling."
qwen2.5:3b,"Please give me the names of some state-of-the-art TSP solvers.
","Document 1: 
 For surveys of the problem and its applications, the reader is referred to the excellent
volumes edited by Lawler et al. [24] and Gutin and Punnen [11].
Local search with k-exchange neighborhoods, k-opt, is the most widely used heu-
ristic method for the TSP. k-opt is a tour improvement algorithm, where in each step
k links of the current tour are replaced by k links in such a way that a shorter tour is
achieved.
It has been shown [7] that k-opt may take an exponential number of iterations and
that the ratio of the length of an optimal tour to the length of a tour constructed byk-opt
can be arbitrarily large when k ≤ n/2 − 5. Such undesirable cases, however, are very
rare when solving practical instances [31]. Usually, high-quality solutions are obtained
in polynomial time. This is, for example, the case for the Lin–Kernighan heuristic,
one of the most effective methods for generating optimal or near-optimal solutions
for the symmetric TSP. High-quality solutions are often obtained, even though only a
small part of the k-exchange neighborhood is searched.
In the original version of the Lin–Kernighan heuristic [ 25], the allowable
k-exchanges (or k-opt moves) are restricted to those that can be decomposed into a
2- or 3-exchange followed by a (possibly empty) sequence of 2-exchanges. This restric- 

Document 2: 
 of determining whether a Boolean formula can 
evaluate to true, benefits from very mature and 
advanced algorithms with large practical impact.
Application and research domains like software 
and hardware verification, automated planning,
computational biology, and many others benefit 
from modern SAT solvers. These domains have 
large and difficult instances that provide the SAT 
community with meaningful benchmarks. 
Most of the following challenges are general in 
such a way that the questions they raise should 
positively affect not only research in parallel SAT 
but in parallel search in general. We first present 
the current situation in sequential and parallel SAT 
solving and then give a set of challenges. Each of 
these challenges comes with an overly optimistic 
estimate of its inherent difficulty represented as 
black circles, where we would estimate that every 
black circle represents, roughly, about two years of 
research. 
Context: Sequential SAT Solvers 
State-of-the-art solvers extend the original Davis,
Putnam, Logemann, and Loveland (DPLL) proce -
dure (Davis, Logemann, and Loveland 1962) with 
conflict analysis (Zhang et al. 2001). The general
architecture of such conflict-directed clause-learn -
ing solvers (CDCL) is presented in figure 1. These 
procedures include an optional preprocessing step 
0, which performs variable elimination and clause 
subsumption checks in order to reduce the size of 
the formula and improve the performance of the 

Document 3: 
 10.0 
12.5 
15.0 
17.5 PAR-10 (c) TSP-3
Fig. 2: Visual comparison in boxplots of the medians and variance of the test performance of each TSP solver across the
testing instances. Note the mean value is also plotted, indicated by “ ▲”.
TABLE III: Comparison of the state-of-the-art TSP solvers
with the PAPs obtained by CEPS, on the testing set. #TOs
refers to number of total timeouts. PAR-10 is the penalized
average runtime-10. Performance of a solver is highlighted in
grey if it achieved the best testing performance.
TSP-1 TSP-2 TSP-3
#TOs PAR-10 #TOs PAR-10 #TOs PAR-10
LKH-default 131 30.84 137 31.98 150 34.73
LKH-tuned 29 8.23 34 9.40 27 7.67
EAX-default 69 17.98 73 18.91 69 17.95
EAX-tuned 33 10.97 30 10.38 29 10.12
VBS 6 3.82 7 4.26 6 4.13
CEPS 6 2.74 4 2.15 2 1.94
signiﬁcant performance improvement, though still obviously
falling behind of the PAPs obtained by CEPS. Second, the only
solver that could match the PAP’s performance level in one
of the three scenarios, is the VBS of the algorithm portfolio
considered by the algorithm selection approaches [29], [30].
However, in TSP-2 and TSP-3, the performance advantage of 

Document 4: 
 troduces the challenge of seeking generalizable PAPs, existing
PAP construction methods, as well as the theoretical insight
behind CEPS. Section III presents the CEPS framework. Sec-
tion IV presents its instantiations for TSP and VRPSPDTW.
Computational studies on these two problems are presented in
Section V. Threats to validity of this study are discussed in
Section VI. Section VII concludes the paper with discussions.
II. P ARAMETERIZED SOLVERS MADE GENERALIZABLE
A. Notations and Problem Description
Assume a PAP is to be built for a problem class (e.g., TSP),
for which an instance of the problem class is denoted as s, and
the set of all possible sis denoted as Ω. Given a parameterized
algorithm, each component solver of the PAP is a conﬁguration
(full instantiation) of the algorithm. Generally speaking, the
parameterized algorithm can be any concrete computational
process, e.g., a traditional heuristic search process such as the
LK Heuristic for TSP or even a neural network [19]–[21] that
outputs a solution for a given instance of the target problem
class. Let θ denote a conﬁguration and let Θ denote a PAP
that contains K different conﬁgurations (component solvers),
i.e., Θ = {θ1,...,θ K}. The quality of a conﬁguration θ on a 

Document 5: 
 H. Trautmann, “Evolving diverse TSP instances by means of novel and
creative mutation operators,” in Proceedings of the 15th ACM/SIGEVO
Conference on Foundations of Genetic Algorithms, FOGA’2019. Pots-
dam, Germany: ACM, Aug 2019, pp. 58–71.
[38] Y . Nagata and S. Kobayashi, “A powerful genetic algorithm using edge
assembly crossover for the traveling salesman problem,” INFORMS
Journal on Computing , vol. 25, no. 2, pp. 346–363, 2013.
[39] X. Xie and J. Liu, “Multiagent optimization system for solving the
traveling salesman problem (tsp),” IEEE Transactions on Systems, Man,
and Cybernetics, Part B , vol. 39, no. 2, pp. 489–502, 2009.
[40] C. Wang, D. Mu, F. Zhao, and J. W. Sutherland, “A parallel simulated
annealing method for the vehicle routing problem with simultaneous
pickup-delivery and time windows,” Computers & Industrial Engineer-
ing, vol. 83, pp. 111–122, 2015.
[41] W. Huang and T. Zhang, “Vehicle routing problem with simultaneous
pick-up and delivery and time-windows based on improved global arti-
ﬁcial ﬁsh swarm algorithm,” Computer Engineering and Applications ,
vol. 52, no. 21, pp. 21–29, 2016. 

Document 6: 
 Portfolio-based algorithm selection for SAT,” Journal of Artiﬁcial In-
telligence Research, vol. 32, pp. 565–606, 2008.
[29] P. Kerschke, L. Kotthoff, J. Bossek, H. H. Hoos, and H. Trautmann,
“Leveraging TSP solver complementarity through machine learning,”
Evolutionary Computation, vol. 26, no. 4, pp. 597–620, 2018.
[30] K. Zhao, S. Liu, Y . Rong, and J. X. Yu, “Leveraging TSP solver
complementarity via deep learning,” arXiv preprint arXiv:2006.00715 ,
2020.
[31] L. Kotthoff, “Algorithm selection for combinatorial search problems: A
survey,” AI Magazine, vol. 35, no. 3, pp. 48–60, 2014.
[32] C. D. Rosin and R. K. Belew, “New methods for competitive coevolu-
tion,” Evolutionary Computation, vol. 5, no. 1, pp. 1–29, 1997.
[33] J. I. van Hemert, “Evolving combinatorial problem instances that are
difﬁcult to solve,” Evolutionary Computation , vol. 14, no. 4, pp. 433–
462, 2006.
[34] K. Helsgaun, “General k-opt submoves for the Lin-Kernighan TSP 

","There are several advanced and popular TSP (Traveling Salesman Problem) solvers available today. Here are a few notable ones:

1. **Concorde**: This is considered one of the most reliable and fastest exact algorithms for solving the TSP. It uses an integer programming approach and has been optimized for speed.

2. **Lin-Kernighan Algorithm**: This is another classic algorithm used to find local optima in solutions to the TSP. It can be extended with a ""branch-and-bound"" method, making it quite powerful in practice.

3. **Ant Colony Optimization (ACO)**: Inspired by the foraging behavior of ants, ACO algorithms have been successfully applied to solve complex optimization problems including the TSP.

4. **Genetic Algorithms**: These are evolutionary computation techniques that use mechanisms such as selection, crossover, and mutation to search for solutions in a large solution space. They can be highly effective when combined with other methods like local searches.

5. **Iterated Local Search (ILS)**: This method uses iterated local search algorithms with perturbations and restarts to improve solutions over time. ILS has been applied successfully to the TSP.

6. **Tabu Search**: A metaheuristic optimization algorithm that guides an iterative process toward a solution by remembering its past moves in order to avoid cycling back into previously explored areas, or ""neighborhoods"".

7. **Simulated Annealing**: This method mimics the annealing process of metalworking where heat is gradually removed to minimize internal energy and reach the solid state at low temperature. It can be useful for escaping local minima.

8. **Hybrid Methods**: These combine different optimization techniques such as combining a genetic algorithm with an ant colony optimization or hybridizing simulated annealing with tabu search.

Each of these methods has its strengths and weaknesses, and their effectiveness depends on the specific instance of the TSP problem at hand. The choice of solver often depends on factors like computational resources available, desired solution quality, and time constraints for solving the problem.",16.058958292007446,"Some state-of-the-art TSP solvers mentioned include the Lin–Kernighan heuristic (LKH), the Effective Ant Colony (EAX), and the Variable Neighborhood Search (VBS). These solvers have been compared in performance metrics such as PAR-10 and number of timeouts (TOs) across different testing instances."
qwen2.5:3b,"Please give me the names of some state-of-the-art Automatic Algorithm Configuration approaches.
","Document 1: 
 Journal of Artiﬁcial Intelligence Research 75 (2022) 425-487 Submitted 02/2022; published 10/2022
A Survey of Methods for Automated
Algorithm Conﬁguration
Elias Schede elias.schede@uni-bielefeld.de
Decision and Operation Technologies Group,
Bielefeld University, Bielefeld, Germany
Jasmin Brandt jasmin.brandt@upb.de
Alexander Tornede alexander.tornede@upb.de
Department of Computer Science,
Paderborn University, Paderborn, Germany
Marcel Wever marcel.wever@ifi.lmu.de
Institute of Informatics, LMU Munich &
Munich Center for Machine Learning, Munich, Germany
Viktor Bengs viktor.bengs@ifi.lmu.de
Institute of Informatics,
LMU Munich, Munich, Germany
Eyke H¨ ullermeier eyke@lmu.de
Institute of Informatics, LMU Munich &
Munich Center for Machine Learning, Munich, Germany
Kevin Tierney kevin.tierney@uni-bielefeld.de
Decision and Operation Technologies Group,
Bielefeld University, Bielefeld, Germany
Abstract
Algorithm conﬁguration (AC) is concerned with the automated search of the most
suitable parameter conﬁguration of a parametrized algorithm. There is currently a wide
variety of AC problem variants and methods proposed in the literature. Existing reviews 

Document 2: 
 2 Related Work
2.1 Automatic Algorithm Conﬁguration
Several approaches exist in the literature for the automatic tuning
of algorithms. Some of these were created for a speciﬁc algorithm
or task. For example, [24] devises a modular algorithm for solving
constraint satisfaction problems (CSPs). Using a combination of ex-
haustive enumeration of all possible conﬁgurations and parallel hill-
climbing, the technique automatically conﬁgures the system for a
given set of training instances. Another approach, presented in [30],
focuses on the conﬁguration of adaptive algorithms, employing a se-
quential parameter optimization approach.
Other approaches automatically design and build an entire solver
to best tackle a set of example training instances. For example, [28]
uses genetic programming to create an evolutionary algorithm (EA).
Here the chromosome is an EA operation like the selection of par-
ents, mutation, or crossover, and the task is to ﬁnd a sequence of
the genetic programming operators that is best suited for the speci-
ﬁed problem. For SAT, [8] classiﬁes local search (LS) approaches by
means of context-free grammars. This approach then uses a genetic
programming approach to select a good LS algorithm for a given set
of instances.
There also exist approaches that are applicable to more general al-
gorithms. For example, in order to tune continuous parameters, [5]
suggests an approach that determines good parameters for individual
training instances. This approach ﬁrst evaluates the extreme param- 

Document 3: 
 470
A Survey of Methods for Automated Algorithm Configuration
General AC systems
D-SMAC https://github.com/tqichun/distributed-SMAC3
GPS https://github.com/YashaPushak/GPS
irace https://github.com/MLopez-Ibanez/irace
OAT (GGA) https://docs.optano.com/algorithm.tuner/current/
ParamILS https://www.cs.ubc.ca/labs/algorithms/Projects/ParamILS/
PyDGGA http://ulog.udl.cat/software/
REVAC https://github.com/ChrisTimperley/RubyREVAC
SMAC 3 https://github.com/automl/SMAC3
Benchmarks
AClib https://bitbucket.org/mlindauer/aclib2/src/master/
DAC https://github.com/automl/DAC
Table 7: List of available software in the realm of AC.
References
Belarmino Adenso-Diaz & Manuel Laguna. Fine-tuning of algorithms using fractional ex-
perimental designs and local search. Operations research, 54(1):99–114, 2006.
¨Ozg¨ ur Akg¨ un, Nguyen Dang, Ian Miguel, Andr´ as Z Salamon, & Christopher Stone. In- 

Document 4: 
 cal (e.g., choice of heuristic). Categorical parameters can be used to select and combine discrete
building blocks of an algorithm (e.g., preprocessing and variable ordering heuristics); consequently,
our general view of algorithm conﬁguration includes the automated construction of a heuristic algo-
rithm from such building blocks. To the best of our knowledge, the methods discussed in this article
are yet the only general ones available for the conﬁguration of algorithms with many categorical
parameters.
We now give an overview of what follows and highlight our main contributions. After for-
mally stating the algorithm conﬁguration problem in Section 2, in Section 3 we describe ParamILS
(ﬁrst introduced by Hutter, Hoos & St ¨utzle, 2007), a versatile stochastic local search approach for
automated algorithm conﬁguration, and two of its instantiations, BasicILS and FocusedILS.
We then introduce adaptive capping of algorithm runs, a novel technique that can be used to
enhance search-based algorithm conﬁguration procedures independently of the underlying search
strategy (Section 4). Adaptive capping is based on the idea of avoiding unnecessary runs of the
algorithm to be conﬁgured by developing bounds on the performance measure to be optimized.
We present a trajectory-preserving variant and a heuristic extension of this technique. After dis-
cussing experimental preliminaries in Section 5, in Section 6 we present empirical evidence show-
ing that adaptive capping speeds up both BasicILS and FocusedILS. We also show that BasicILS
268 

Document 5: 
 rithm conﬁguration that minimizes some cost measure over the 
set of instances that will be seen during the production phase. 
In other words, the ﬁnal goal is that the conﬁguration of the al- 
gorithm found during the tuning phase generalizes to similar but 
unseen instances. The tuning phase may also use automatic conﬁg- 
uration methods repeatedly while engineering an algorithm [71] . 
Due to the separation between a tuning and a production phase, 
automatic algorithm conﬁguration is also known as oﬄine param- 
eter tuning to differentiate it from online approaches that adapt or 
control parameter settings while solving an instance [13,50] . Nev- 
ertheless, online approaches also contain parameters that need to 
be deﬁned oﬄine, for example, which and how parameters are 
adapted at run-time; such parameters and design choices can be 
conﬁgured by an oﬄine tuning method [59] . 
In our research on making the algorithm conﬁguration process 
more automatic , we have focused on racing approaches. Birattari 
et al. [19,20] proposed an automatic conﬁguration approach, F- 
Race, based on racing [64] and Friedman’s non-parametric two-way 
analysis of variance by ranks. This proposal was later improved 
by sampling conﬁgurations from the parameter space, and reﬁn- 
ing the sampling distribution by means of repeated applications of 
F-Race. The resulting automatic conﬁguration approach was called 
Iterated F-race (I/F-Race) [10,21] . Although a formal description of 

Document 6: 
 formance of FocusedILS [43], and we are convinced that, at least in cases where
the parameter response of a given target algorithm is reasonably regular and per-
formance evaluations are very costly, such advanced SMBO methods hold great
promise.
3.6 Conclusions and Future Work
Automated algorithm conﬁguration and parameter tuning methods have been de-
veloped and used for more than a decade, and many of the fundamental techniques
date back even further. However, it has only recently become possible to effectively
solve complex conﬁguration problems involving target algorithms with dozens of
parameters, which are often categorical and conditional. This success is based in
3 Automated Algorithm Conﬁguration and Parameter Tuning 65
part on the increased availability of computational resources, but has mostly been
enabled by methodological advances underlying recent conﬁguration procedures.
Still, we see much room (and, indeed, need) for future work on automated algo-
rithm conﬁguration and parameter tuning methods. We believe that in developing
such methods, the fundamental features underlying all three types of methods dis-
cussed in this chapter can play an important role, and that the best methods will
employ combinations of these. We further believe that different conﬁguration pro-
cedures will likely be most effective for solving different types of conﬁguration
problems (depending, in particular, on the number and type of target algorithm pa-
rameters, but also on regularities in the parameter response). Therefore, we see a
need for research aiming to determine which conﬁgurator is most effective under 

","Some state-of-the-art Automatic Algorithm Configuration (AC) approaches mentioned in the text include ParamILS, BasicILS, FocusedILS, and Iterated F-race (I/F-Race). These methods have been developed and used for more than a decade to solve complex configuration problems involving dozens of often categorical and conditional parameters.",8.16390585899353,"Some state-of-the-art Automatic Algorithm Configuration approaches include D-SMAC, GPS, irace, OAT (GGA), ParamILS, PyDGGA, REVAC, and SMAC 3."
qwen2.5:3b,"What is the idea behind the AAC approach called ""irace""?
","Document 1: 
 analysis of variance by ranks. This proposal was later improved 
by sampling conﬁgurations from the parameter space, and reﬁn- 
ing the sampling distribution by means of repeated applications of 
F-Race. The resulting automatic conﬁguration approach was called 
Iterated F-race (I/F-Race) [10,21] . Although a formal description of 
the I/F-Race procedure is given in those publications, an imple- 
mentation was not made publicly available. The irace package im- 
plements a general iterated racing procedure, which includes I/F- 
Race as a special case. It also implements several extensions al- 
ready described by Birattari [19] , such as the use of the paired 
t -test instead of Friedman’s test. Finally, irace incorporates sev- 
eral improvements not published before, such as sampling from a 
truncated normal distribution, a parallel implementation, a restart 
strategy that avoids premature convergence, and an elitist racing 
procedure to ensure that the best parameter conﬁgurations found 
are also evaluated on the highest number of training instances. 
The paper is structured as follows. Section 2 introduces the 
algorithm conﬁguration problem and gives an overview of ap- 
proaches to automatic algorithm conﬁguration. Section 3 describes 
the iterated racing procedure as implemented in the irace pack- 
age as well as several further extensions including the elitist irace . 
Section 4 illustrates the steps followed to apply irace to two con- 

Document 2: 
 5.2. Multi-objective optimization metaheuristics 
Besides the application to the MOACO framework described 
above [58] , irace has been applied to aid in the design of other 
multi-objective optimization algorithms. Dubois-Lacoste et al. 
[31] used irace to tune a hybrid of two-phase local search and 
Pareto local search (TP + PLS) to produce new state-of-the-art al- 
gorithms for various bi-objective permutation ﬂowshop problems. 
Fisset et al. [33] used irace to tune a framework of multi-objective 
optimization algorithms for clustering. When applied to a suﬃ- 
ciently ﬂexible algorithmic framework, irace has been used to de- 
sign new state-of-the-art multi-objective evolutionary algorithms 
[16,17] . 
5.3. Anytime algorithms (improve time-quality trade-offs) 
There is often a trade-off between solution quality and com- 
putation time: Algorithms that converge quickly tend to produce 
better solutions for shorter runtimes, whereas more exploratory al- 
gorithms tend to produce better solutions for longer runtimes. Im- 
proving the anytime behavior of an algorithm amounts to improv- 
ing the trade-off curve between solution quality and computation 
time such that an algorithm is able to produce as high quality so- 
lutions as possible at any moment during their execution. López- 

Document 3: 
 effect on the budget consumed is lower. The same experiment for 
the ACOTSP scenario showed that the best conﬁgurations become 
worse when T new or T ﬁrst are increased. This is due to the fact that 
ACOTSP has a homogeneous training set and, therefore, sampling 
new candidates is more important than executing a large number 
of instances. 
5. Other applications of irace 
Since the ﬁrst version of the irace package became publicly 
available in 2012, there have been many other applications of 
irace . In this section, we provide a list of the applications of the 
irace package of which we are aware at the time of writing. Some 
of these applications go beyond what is traditionally understood as 
algorithm conﬁguration, demonstrating the ﬂexibility of irace . 
54 M. López-Ibáñez et al. / Operations Research Perspectives 3 (2016) 43–58 
5.1. Algorithm conﬁguration 
The traditional application of irace is the automatic conﬁgura- 
tion of algorithms. Several publications have used irace when eval- 
uating or designing algorithms for problems such as the traveling 
salesman with time windows [60] , slot allocation [77] , generalized 
hub location [68] , ﬂow shop [14] , virtual machine placement [86] , 
online bin packing [92] , graph coloring [23] , image binarization 
[69] , network pricing [90] , combined routing and packing prob- 

Document 4: 
 ming by optimization paradigm [40] . Moreover, the importance of 
properly tuning the parameters of algorithms before analyzing and 
comparing them is becoming widely recognized. We hope that the 
development of the irace package will help practitioners and re- 
searchers to put these ideas into practice. 
Acknowledgements 
This work received support from the COMEX project (P7/36) 
within the Interuniversity Attraction Poles Programme of the Bel- 
gian Science Policy Oﬃce, and the EU FP7 ICT Project COLOMBO, 
Fig. A.1 1. Scheme of the user-provided components required by irace . 
Table A1 
Parameters of irace corresponding to the description 
of iterated racing given in Section 3.2 . The full list of 
irace parameters is available in the user guide. 
Iterated racing parameter irace parameter 
B maxExperiments 
C (cost measure) targetRunner 
μ mu 
N min minNbSurvival 
T ﬁrst firstTest 
T each eachTest 
Statistical test testType 
Cooperative Self-Organizing System for Low Carbon Mobility at 
Low Penetration Rates (agreement no. 318622). Thomas Stützle and 
Mauro Birattari acknowledge support from the Belgian F.R.S.-FNRS, 
of which they are Senior Research Associates. Leslie Pérez Cáceres 
acknowledges support of CONICYT Becas Chile. 
Appendix A. The irace package 

Document 5: 
 man problem with time windows: adapting algorithms from travel-time to 
makespan optimization. Appl Soft Comput 2013;13(9):3806–15 . 
[61] López-Ibáñez M., Dubois-Lacoste J., Pérez Cáceres L., Stützle T., Birattari M.. 
2016a. The irace package: Iterated racing for automatic algorithm conﬁgura- 
tion. http://iridia.ulb.ac.be/supp/IridiaSupp2016-003/ . 
[62] López-Ibáñez M, Pérez Cáceres L, Dubois-Lacoste J, Stützle T, Birattari M. The 
irace package: user guide. Technical Report TR/IRIDIA/2016-004. IRIDIA, Uni- 
versité Libre de Bruxelles, Belgium; 2016b . http://iridia.ulb.ac.be/IridiaTrSeries/ 
IridiaTr2016-004.pdf . 
[63] Marmion M-E , Mascia F , López-Ibáñez M , Stützle T . Automatic design of hy- 
brid stochastic local search algorithms. In: Blesa MJ, Blum C, Festa P, Roli A, 
Sampels M, editors. Hybrid metaheuristics, volume 7919 of lecture notes in 

Document 6: 
 ent robot behaviors and the criteria to transition between behav- 
iors. Each module can be further customized by means of several 
parameters. A particular combination of behaviors and transitions 
represents one controller, that is, an instance of the software that 
controls the robots in the swarm. The performance of a particu- 
lar controller is evaluated by means of multiple simulations. The 
search for the best controller over multiple training simulations is 
carried out by means of irace . The authors report that this system 
is not only able to outperform a previous system that used F-race 
[34] , but also a human designer, under the scenarios studied by 
them. 
6. Conclusion 
This paper presented the irace package, which implements the 
iterated racing procedure for automatic algorithm conﬁguration. It- 
erated racing is a generalization of the iterated F-race procedure. 
M. López-Ibáñez et al. / Operations Research Perspectives 3 (2016) 43–58 55 
The primary purpose of irace is to automatize the arduous task of 
conﬁguring the parameters of an optimization algorithm. However, 
it may also be used for determining good settings in other compu- 
tational systems such as robotics, traﬃc light controllers, compil- 
ers, etc. The irace package has been designed with simplicity and 
ease of use in mind. Despite being implemented in R , no previ- 
ous knowledge of R is required. We included two examples for the 

","The irace package implements the iterated racing procedure, which is a generalization of the iterated F-race method used for automatically configuring optimization algorithm parameters. Its primary purpose is to automate the task of setting these parameters, making it easier and less time-consuming for practitioners and researchers. It can also be applied to other computational systems like robotics or traffic light controllers where determining good settings would otherwise be a challenging manual process.",8.547791481018066,"The irace package implements an automatic algorithm configuration method called iterated racing. This approach aims to automate the process of tuning algorithm parameters to enhance their performance efficiently. Irace conducts a series of ""races"" among different configurations of the algorithm based on their performance metrics, iteratively refining the search for optimal settings. It uses statistical tests to compare the configurations and incorporates features like sampling from a truncated normal distribution and an elitist strategy to ensure that the best configurations are heavily evaluated. Overall, irace's goal is to streamline and simplify the arduous task of configuring optimization algorithms, making it applicable beyond just algorithm configuration to other computational systems such as robotics and traffic light controllers."
qwen2.5:3b,"What is the idea behind the AAC approach called ""SMAC""?
","Document 1: 
 intensiﬁcation scheme, and time-bounded SPO (TB-SPO) (Hutter et al., 2010b), which
generalizes SPO+ to work under (potentially tight) time constraints instead of considering
the number of function evaluations as a stopping criterion.
5.2 General Model-based AC Methods
SMAC Sequential model-based optimization for algorithm conﬁguration (SMAC) (Hutter
et al., 2011; Lindauer et al., 2021) can be seen as one of the ﬁrst fully-ﬂedged model-
based AC approaches, as it features solutions for many of the limitations of the previously
discussed SMBO techniques. SMAC generalizes TB-SPO to perform conﬁguration over
multiple problem instances so that it can support categorical parameters and handle tight
time constraints.
To support multiple problem instances, SMAC adapts the intensiﬁcation strategy of
TB-SPO to iteratively evaluate conﬁgurations on randomly sampled combinations of seeds
and problem instances. When doing so, it ensures that conﬁgurations are compared only
based on a performance estimate computed on the same randomly sampled set of problem
instances. Furthermore, SMAC’s surrogate model can generalize across problem instances
by incorporating problem instance features. To this end, a surrogate model is learned on
the joint problem instance and conﬁguration space to predict the performance of a given
conﬁguration on a given problem instance.
As a means to deal with a mixture of categorical and numerical parameters, SMAC 

Document 2: 
 method is paired with D-MAB selection [38] described
above. A sliding window is also used by Fialho et al.[ 70].
They suggest increasing the reward with the time elapsed
since the last application of this operator and decreasing
the reward with the number of times the operator has been
applied within the window. The aim of this method is to adapt
quickly to (even subtle) changes of the dynamic environment.
Li et al.[ 129] suggested a sliding window that stores the rate
of improvement in the ﬁtness of the offspring as compared
to the parent. The sum of all these rewards in the window is
used by a ranking mechanism to assign credit to the operators.
A different credit assignment mechanism is Compass, sug-
gested by Maturana and Saubion [ 146]. Based on the concepts
found in [ 147] (see Section VI), an operator’s impact is
evaluated using measures of both ﬁtness and diversity in order
to calculate the exploration-exploitation balance achieved by
the operator. The assigned credit reﬂects how closely the
achieved balance is to an exploration-exploitation balance that
is required by a user-deﬁned schedule. Other tested credit as-
signment methods are based on domination between operators
and Pareto fronts. Compass was paired with probability match-
ing selection, but was also combined with D-MAB in [ 143].
Except for the widely used multiarmed bandit approach dis-
cussed so far, AOS has also been treated as a full reinforcement 

Document 3: 
 cess (see (Hutter et al. 2009) for a comprehensive review),
which is usually referred to as automatic algorithm con-
ﬁguration (AAC) (Hoos 2012). Many AAC methods such
as ParamILS (Hutter et al. 2009), GGA/GGA+(Ans´otegui,
Sellmann, and Tierney 2009; Ans ´otegui et al. 2015), irace
(L´opez-Ib´a˜nez et al. 2016) and SMAC (Hutter, Hoos, and
Leyton-Brown 2011) have been proposed in the last few
years. They have been used for boosting the algorithm’s per-
formance in a wide range of domains such as the boolean
satisﬁability problem (SAT) (Hutter et al. 2009), the travel-
ing salesman problem (TSP) (L´opez-Ib´a˜nez et al. 2016; Liu,
∗Corresponding author
Copyright c⃝ 2020, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.
Tang, and Yao 2019), the answer set programming (ASP)
(Hutter et al. 2014) and machine learning (Feurer et al. 2015;
Kotthoff et al. 2017).
Despite the notable success achieved in application, the 

Document 4: 
 algorithm configuration framework. JArtifIntellRes 2009; 36 : 
267–306. 
9. Lindauer M, Eggensperger K, Feurer M et al. SMAC3: a ver- 
satile Bayesian optimization package for hyperparameter opti- 
mization. JMachLearnRes 2022; 23 : 54. 
10. Santu SKK, Hassan MM, Smith MJ et al. Automl to date and 
beyond: challenges and opportunities. ACMComputSurv 2022; 
54 : 175. 
Page7of9
Downloaded from https://academic.oup.com/nsr/article/11/8/nwae132/7639406 by guest on 18 September 2024 

Document 5: 
 more benchmark instances and compare its performance to
the best conﬁguration observed so far.
SMAC is an anytime algorithm that interleaves the ex-
ploration of new conﬁgurations with additional runs of the
current best conﬁguration to yield both better and more con-
ﬁdent results over time. As all anytime algorithms, SMAC
improves performance over time. While SMAC provably
converges for ﬁnite conﬁguration spaces, it often only ﬁnds
close-to-optimal conﬁgurations for realistic time budgets
and challenging conﬁguration problems.
Automated Portfolio Construction & Hydra
Our method for constructing sequential portfolios is closely
related to Hydra (Xu, Hoos, and Leyton-Brown 2010),
which automatically constructs selection-based portfolios.
Given a parameterized algorithm framework with a space
of algorithmsΘ, Hydra starts with an empty set of can-
didate algorithms C= ∅and iteratively calls an algorithm
conﬁguration method to add algorithms θ ∈Θ that comple-
ment Cbest. In each iteration, it constructs a portfolio from
the current set Cusing the portfolio-based algorithm selec-
tor SATzilla (Xu et al. 2008) and measures its performance
m(C,π) on each benchmark instance π ∈Π (in the ﬁrst it-
eration, m(∅,π) = −∞). The performance metric Hydra
maximizes via its algorithm conﬁguration method is then 

Document 6: 
 Anastacio and Hoos (2020) propose SMAC+PS, which integrates the idea of probabilis-
tic sampling known from irace into SMAC. This enhancement yields improvements over
both SMAC and irace in many cases. In particular, Anastacio and Hoos (2020) account for
the problem that many of the completely randomly sampled conﬁgurations by SMAC often
exhibit rather bad performance and thus, their evaluation yields only limited information.
To this end, the authors suggest to sample conﬁgurations according to a truncated normal
distribution centered around the default conﬁguration.
444
A Survey of Methods for Automated Algorithm Configuration
In (Lindauer & Hutter, 2018b) the authors suggest two diﬀerent strategies to warmstart
model-based AC approaches and apply their suggestions to SMAC, leading to signiﬁcant
speedups from days to hours of conﬁguration time. The idea underlying warmstarting is to
use the evaluations of conﬁgurations from previous runs, i.e., on diﬀerent problem instance
sets, to speed up the conﬁguration process in new runs of the conﬁgurator on a new set of
instances.
Distributed SMAC (Hutter et al., 2012) (D-SMAC) is an extension of SMAC leveraging
parallelization to speed up the conﬁguration process. The main idea behind D-SMAC is
to parallelize target algorithm runs onto available workers as much as possible. For this
purpose, it maintains a queue of target algorithm conﬁguration evaluations to be performed, 

","SMAC (Sequential model-based optimization for algorithm configuration) is an anytime algorithm that interleaves exploration of new configurations with additional runs of the current best configuration. It aims to improve performance over time by provably converging in finite conﬁguration spaces, though often only ﬁnds close-to-optimal conﬁgurations within realistic time budgets and challenging conﬁguration problems.",8.158713340759277,"The idea behind the AAC (automatic algorithm configuration) approach called ""SMAC"" (Sequential Model-based Algorithm Configuration) is to perform algorithm configuration by generalizing techniques from model-based optimization. SMAC adapts the intensification strategy from TB-SPO (time-bounded SPO) to iteratively evaluate configurations across multiple problem instances while ensuring that the comparisons are based on performance estimates derived from the same random subset of those instances. It incorporates a surrogate model that learns from both the configuration space and the problem instance features, allowing it to predict the performance of configurations effectively. SMAC is designed to handle a mixture of categorical and numerical parameters, and it operates as an anytime algorithm that continuously improves performance over time by balancing exploration of new configurations with exploitation of the current best configuration."
qwen2.5:3b,"What is the idea behind the AAC approach called ""GGA""?
","Document 1: 
 to be evaluated based on k diﬀerently parameterized instantiations of the UCB criterion.
GGA++ Ans´ otegui et al. (2015) adapt the model-free AC approach GGA to include a
surrogate model. More precisely, the authors use a surrogate model to evaluate the quality
of new conﬁgurations. They integrate this within a crossover operator and call it genetic
engineering. Recall that GGA contains both a competitive and non-competitive popula-
tion in which winning conﬁgurations from the races between members of the competitive
population are recombined with individuals from the non-competitive population. To this
end, the crossover operator generates individuals according to the parameter tree crossover
of the original GGA method and evaluates them using the surrogate. Note that rather
than predicting the solution quality or runtime directly, the surrogate predicts the rank the
individual would have in a tournament. The individuals with the best ranks are accepted
into the population of the next generation in the same way as in GGA.
While the GGA++ surrogate is based on a random forest model, it diﬀers in a key
way. The premise of a random forest is to equally approximate the underlying function over
the complete input space. In the case of AC, this is undesirable as only the areas of the
input space that correspond to high-quality conﬁgurations are of interest. Thus, the authors
present specialized splitting criteria that focuses on only the best conﬁgurations to increase 

Document 2: 
 performance prediction [41], [42], [45]; and algorithm
enhancement [44], [47].
C. Generative Adversarial Networks
The general idea of GAST is similar to generative adversar-
ial networks (GANs) [50]. GANs also maintain an adversarial
game in which a discriminator is trained to distinguish real
samples from fake samples synthesized by a generator, and
the generator is trained to deceive the discriminator by pro-
ducing ever more realistic samples. However, there are some
main differences between GAST and GANs. First, the over-
all goals of them are different. GANs focus on the generative
models that could capture the distribution of complicated real-
world data. For GAST, the main goal is to build powerful
parallel portfolios (analogous to the discriminative models in
GANs); while the instance generation module as well as the
generated instances are more like byproducts. Second, the
domains to which GAST and GANs are applicable are differ-
ent. Currently GANs (and the more general idea of adversarial
learning) are mostly successfully applied to vision-related
domains, such as image generation [51], [52]; image dehaz-
ing [53]; style transfer [54], [55]; image classiﬁcation [56]; and
clustering [57], [58]. In comparison, GAST is proposed for
problem-solving domains, such as planning and optimization.
Third, the main technical issues in the two areas are different. 

Document 3: 
 cess (see (Hutter et al. 2009) for a comprehensive review),
which is usually referred to as automatic algorithm con-
ﬁguration (AAC) (Hoos 2012). Many AAC methods such
as ParamILS (Hutter et al. 2009), GGA/GGA+(Ans´otegui,
Sellmann, and Tierney 2009; Ans ´otegui et al. 2015), irace
(L´opez-Ib´a˜nez et al. 2016) and SMAC (Hutter, Hoos, and
Leyton-Brown 2011) have been proposed in the last few
years. They have been used for boosting the algorithm’s per-
formance in a wide range of domains such as the boolean
satisﬁability problem (SAT) (Hutter et al. 2009), the travel-
ing salesman problem (TSP) (L´opez-Ib´a˜nez et al. 2016; Liu,
∗Corresponding author
Copyright c⃝ 2020, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.
Tang, and Yao 2019), the answer set programming (ASP)
(Hutter et al. 2014) and machine learning (Feurer et al. 2015;
Kotthoff et al. 2017).
Despite the notable success achieved in application, the 

Document 4: 
 instead of the fully predetermined lifetimes in the original
GA VaPS and nAMGA VaPS.
Another variation of the GA VaPS lifetime scheme was
described by Bäck et al .[ 18]. The adaptive population GA
(APGA) uses the same lifetime allocation but differs from
GA VaPS in the reproduction cycle and in that, when in-
crementing the ages of individuals in each cycle, the best
individual of that cycle remains unchanged. This adaptive
population strategy is part of an ensemble and is described
in more detail in Section V. This method was also applied to
cooperative coevolution by Iorio and Li [ 109]. An analysis
of APGA by Lobo and Lima [ 135] shows theoretical and
experimental results suggesting an upper bound and a con-
verging population to a constant size that is determined by
the minimum and maximum lifetime parameters. The authors
conclude that the population is not adapted by the APGA
but the size parameter is in fact replaced by the two lifetime
parameters.
Cook and Tauritz [36] suggested two strategies for removing
the population size parameter. FiScIS-EA removes individuals
according to a survival probability, derived by linear scaling
of the individual’s ﬁtness in the range between the minimum
and maximum ﬁtness values present in the population. GC-EA
simply evades choosing a population size by maintaining a
population as large as is allowed by memory limitations. This
requires a well-chosen parent selection mechanism that scales
well, while a survival selection operator is still needed in 

Document 5: 
 obtain promising initial results, the combined evolution of solutions and their genetic opera-
tors is comparatively challenging, and it remains an open question whether autoconstructive
evolution is indeed superior to non-autoconstructive evolution.
Multi-armed bandits DAC can be cast as a multi-armed bandit problem, where each
conﬁguration represents an arm with an associated reward distribution. The agent is then
tasked to maximize the cumulative reward, i.e., “pull the arm“ that maximizes the reward.
Put diﬀerently, the agent aims to select a conﬁguration that works well for the current time
step. This setting of the bandit problem is particularly challenging because the reward
distributions associated with the respective arms change over time. In Fialho et al. (2010),
various multi-armed bandit approaches are compared with an approach that only considers
rewards obtained within a certain time frame (i.e., a sliding window) to allow for smoother
transitions between conﬁgurations. Note that in this work, the authors assume rewards to
be retrievable during an algorithm run. While this assumption holds for many optimization
approaches, it does not necessarily hold for all of them (e.g., the pre-processing/root node
phase of solving mixed-integer programs), and also often does not hold for simulations.
463
Schede, Brandt, Tornede, Wever, Bengs, H¨ullermeier & Tierney
11. Research Directions
Many fruitful avenues of research remain in the area of AC. We formulate research directions 

Document 6: 
 [23] showed that clustering the training data into sets, and then tun-
ing these sets individually could lead to further improvements. We
refer to this approach as SOP-clustered. We compare these two con-
ﬁgurators with general-purpose instance-oblivious conﬁguration of
GGA [2] and instance-speciﬁc parameter tuning of ISAC.
Solver: GS % Optimality Gap Closed
Train Test
Uniform 25.9 (4.2) 40 (4.1)
SOP - combined 39.0 (3.3) 43.4 (3.6)
SOP - clustered 47.7 (2.4) 50.3 (3.7)
GGA 40.0 (3.6) 46.1 (3.8)
ISAC 44.4 (3.3) 51.3 (3.8)
Table 1. Comparison of ISAC versus the default and instance-oblivious
parameters provided by SOP and GGA, and the instance-speciﬁc parameters
provided by SOP. We present the percent of optimality gap closed (stdev).
In Table 1, we compare the resulting ﬁve GS solvers, presenting
the percentage of optimality gap closed by each solver. Comparing
the average percent of optimality gap closed, we ﬁnd that ISAC is as
capable of improving over the default approach as SOP, which was
developed particularly for the GS solver. That is, ISAC can effec-
tively liberate us from having to select the number of clusters while,
at the same time, enjoying wide applicability to other solvers. More- 

","The GGA (Generalized Gradient Approximation) is a method used in Density Functional Theory (DFT), which is often employed within the Alternative Approach to Chemistry (AAC) framework. 

GGA aims to improve upon the LDA (Local Density of States) and LSDA (Linear Response Local Density of States) approximations by better capturing non-local effects, such as dispersion forces and charge density gradients that are important in many materials calculations. 

In simpler terms, GGA seeks to provide more accurate descriptions of electron densities and energy levels, especially at short distances and near surfaces or interfaces where local approximations fail.

The GGA approach allows for a more sophisticated description of electronic properties compared to earlier approximations like LDA/SDA, making it particularly useful in AAC approaches that seek to improve the accuracy of quantum mechanical calculations while maintaining computational efficiency.",9.600487470626833,"The GGA (Genetic Algorithm with Genetic Engineering) approach, as described in the context, integrates a surrogate model to evaluate the quality of new configurations within its operation. It combines a competitive population, which competes in races, with a non-competitive population, allowing the winning configurations from the competitive races to be recombined with individuals from the non-competitive group. The crossover operator generates new individuals based on parameter tree crossover and uses the surrogate model to assess their ranks in a tournament-like setting. The individuals with the best ranks are then selected to form the next generation. Unlike traditional random forest methods, GGA focuses specifically on high-quality configurations, utilizing specialized splitting criteria that emphasize these areas of the input space."
qwen2.5:3b,"What is the idea behind the AAC approach called ""ISAC""?
","Document 1: 
 ISAC – Instance-Speciﬁc Algorithm Conﬁguration1
Serdar Kadioglu and Yuri Malitsky and Meinolf Sellmann and Kevin Tierney2
Abstract. We present a new method for instance-speciﬁc algorithm
conﬁguration (ISAC). It is based on the integration of the algorithm
conﬁguration system GGA and the recently proposed stochastic off-
line programming paradigm. ISAC is provided a solver with cate-
gorical, ordinal, and/or continuous parameters, a training benchmark
set of input instances for that solver, and an algorithm that com-
putes a feature vector that characterizes any given instance. ISAC
then provides high quality parameter settings for any new input in-
stance. Experiments on a variety of different constrained optimiza-
tion and constraint satisfaction solvers show that automatic algorithm
conﬁguration vastly outperforms manual tuning. Moreover, we show
that instance-speciﬁc tuning frequently leads to signiﬁcant speed-ups
over instance-oblivious conﬁgurations.
1 Introduction
When developing a new heuristic or complete algorithm for a con-
straint satisfaction or a constrained optimization problem, we fre-
quently face the problem of choice. There may be multiple branch-
ing heuristics that we can employ, different types of inference mech-
anisms, various restart strategies, or a multitude of neighborhoods to
choose from. Furthermore, the way in which the choices we make
affect one another is not readily known. The task of making these 

Document 2: 
 method is paired with D-MAB selection [38] described
above. A sliding window is also used by Fialho et al.[ 70].
They suggest increasing the reward with the time elapsed
since the last application of this operator and decreasing
the reward with the number of times the operator has been
applied within the window. The aim of this method is to adapt
quickly to (even subtle) changes of the dynamic environment.
Li et al.[ 129] suggested a sliding window that stores the rate
of improvement in the ﬁtness of the offspring as compared
to the parent. The sum of all these rewards in the window is
used by a ranking mechanism to assign credit to the operators.
A different credit assignment mechanism is Compass, sug-
gested by Maturana and Saubion [ 146]. Based on the concepts
found in [ 147] (see Section VI), an operator’s impact is
evaluated using measures of both ﬁtness and diversity in order
to calculate the exploration-exploitation balance achieved by
the operator. The assigned credit reﬂects how closely the
achieved balance is to an exploration-exploitation balance that
is required by a user-deﬁned schedule. Other tested credit as-
signment methods are based on domination between operators
and Pareto fronts. Compass was paired with probability match-
ing selection, but was also combined with D-MAB in [ 143].
Except for the widely used multiarmed bandit approach dis-
cussed so far, AOS has also been treated as a full reinforcement 

Document 3: 
 in Ye et al. (2021) that performance gains can already be achieved when the algorithm
conﬁguration is adapted only once. Furthermore, the hyper-reactive approach of Ans´ otegui
et al. (2017) won several categories at the MaxSAT Evaluation 2016 (Argelich et al., 2016).
Thus, DAC oﬀers signiﬁcant potential for improving algorithms, however, it does require
algorithm designers to more deeply integrate their techniques with AC methods than was
performed in the past. In the following, we discuss the most frequently used approach to
DAC, reinforcement learning (RL). While it is the most popular choice, there also exist
other approaches such as policy portfolios, autoconstructive evolution, and multi-armed
bandits.
Reinforcement learning A challenge in DAC is to evaluate the quality of individual
parameter adjustments since feedback is obtained only at the end of processing a problem
instance. Due to this, it is natural to consider DAC within the realm of reinforcement
learning (we refer to this as DAC-RL). To this end, the DAC problem is modeled in terms of
a Markov decision process (MDP) (Puterman, 1994) based on which a policy π: I×Q→ Θ
is learned from data (Biedenkapp et al., 2020). As a reward signal, typically, the eventually
obtained performance value is propagated back to the agent. Using RL allows a wide variety
of researched mechanisms to be directly applied to DAC.
The roots of DAC extend to a variety of methods that use RL to control parameters of 

Document 4: 
 the best solver in the solver class, termed the auto- 
matic algorithm configuration (AAC) in the litera- 
ture [16 ]. More specifically, given a solver class, the 
solver that achieves the best overall performance on 
the training instances is first obtained by some search 
method. Then, the solver is directly applied to an un- 
seen problem instance without a further configura- 
tion process. 
A typical AAC method consists of two main com- 
ponents: sampling in the solver class and evaluat- 
ing a candidate solver. Sampling in the solver class 
is mostly implemented based on search-based meth- 
ods and model-based methods. Search-based meth- 
ods such as hi l l climbing [50 ], local search [8 ] and 
E A s [51 ] have been used to sample solvers, since 
they make minimal assumptions about the solver 
representation and do not require gradients. Addi- 
tionally, some researchers have also explored using 
experimental design [52 ,53 ], such as the full fac- 
torial experimental design, to generate the starting 
points for the search. In comparison, model-based 
methods are more similar to the performance predic- 
tion model approach. They seek to capture the de- 
pendencies between solvers and their performance, 
by training surrogate models on the performance 
data collected during the configuration process. On 

Document 5: 
 ACPP is closely related to the area of automatic algo-
rithm configuration, in which the task is to automatically
identify a high-quality configuration from a configuration
space. In the last few years, several high-performance AC
methods (which could handle considerable large configura-
tion spaces) such as ParamILS (Hutter et al. 2009), GGA
(Ans´otegui, Sellmann, and Tierney 2009), irace (L ´opez-
Ib´a˜nez et al. 2016) and SMAC (Hutter, Hoos, and Leyton-
Brown 2011) have been proposed. As a consequence, re-
cently there has been research interest in utilizing these
AC procedures to automatically identify useful portfolios
of configurations from large configuration spaces. Such at-
tempts were first done in constructing sequential portfolios.
The representative methods for solving this problem are Hy-
dra (Xu, Hoos, and Leyton-Brown 2010) and ISAC (Ka-
dioglu et al. 2010). The basic ideas of these methods were
then adapted to be used in constructing parallel portfolios
(i.e., ACPP), thus resulting in PARHYDRA and CLUSTER-
ING (Lindauer et al. 2017) (see the first section). The main
differences between the automatic construction of sequen-
tial portfolios and of parallel portfolios lie in two aspects: 

Document 6: 
 that ihvr ∈(0, 1], and a larger value of ihvr is better. IHVR can distinguish well between
MOEAs with a different performance, and can also save a lot of calculations. In this work,
IHVR is used as the performance metric Metric .
4.3. Automatic Construction Approach
Algorithm 1 presents the automatic construction approach for MOEAs/PAP . Starting
from an empty set (line 2), the approach constructs the PAP (denoted as P) iteratively.
Speciﬁcally, each iteration of the approach (lines 3–15) consists of two subsequent phases.
In the ﬁrst phase, an existing automatic algorithm conﬁguration tool, namely SMAC 3 [44],
is used to search in Θ to ﬁnd the algorithm that can improve the performance of the current
PAP to the largest extent (line 5), and then this algorithm is inserted into P (line 6). This
phase is similar to the commonly-used greedy approach in the automatic construction of
PAPs [27,31]. Additionally, we introduce a new phase, namely simpliﬁcation, as the second
phase in Algorithm 1. In this phase (lines 7–14), P would be simpliﬁed by removing the
member algorithms that do not contribute at all to its performance (meaning removing
these algorithms has no effect on the performance of P on the training set). Considering
the size of P is bounded (line 3), removing the redundant algorithms from P is meaningful
because this will leave space for new member algorithms that can improve the performance 

","The ISAC method combines instance-specific algorithm configuration with existing automatic algorithm configuration tools like SMAC. It uses a tool to find the best solver within a class that can improve the current PAP's performance by iteratively constructing and simplifying an evolutionary algorithm (PAP). The key idea is using instance-specific configurations for better performance, leveraging IHVR as a performance metric.",8.050475597381592,"The AAC approach called ""ISAC"" (Instance-Specific Algorithm Configuration) is focused on automatically identifying high-quality parameter settings for specific problem instances. It combines an algorithm configuration system with a stochastic offline programming paradigm to adapt the configuration based on the features of each instance. ISAC requires a training benchmark set of input instances and an algorithm that computes a feature vector, allowing it to provide tailored configurations that improve solver performance on new input instances. The method has been shown to significantly outperform manual tuning and lead to speed-ups compared to instance-oblivious configurations."
qwen2.5:3b,"What is the difference between metaheuristics and heuristics?
","Document 1: 
 usually provide only sub-optimal solutions because they do
not attempt to escape from local optimum. These drawbacks
have led to the introduction of metaheuristics.
Metaheuristics are high-level methodologies or general al-
gorithmic templates, which generally do not adapt deeply
to speciﬁc problem(s) [4]. Hence, they usually can solve a
wide range of problems [2]. In fact, the preﬁx “meta”, which
means “upper level methodology”, indicates that metaheuristic
algorithms can be viewed as “higher level” heuristics. Hy-
brid approaches based on existing metaheuristic(s) are also
considered metaheuristics [5]. In last decades, metaheuristics
have received widespread attention from researchers and are
widely recognized as efﬁcient approaches for hard optimiza-
tion problems. A number of metaheuristic algorithms have
been developed and extensively applied, including Simulated
Annealing (SA) [6], Tabu Search (TS) [7], Evolutionary Algo-
rithms (EAs) [8], Ant Colony Optimization algorithm (ACO)
[9], Particle Swarm Optimization (PSO) [10], and so forth.
Most of metaheuristics are nature-inspired (inspired from some
principles in physics, biology and etc.), contain stochastic
components, and often have several free parameters that can
be set by users according to problem(s) at hand [4].
The setting of parameters (or parameter setting) has strong 

Document 2: 
 the same standard. (In contrast, SAT solver competitions have compared solvers with a complex scoring function that includes the performance of all competitors [25].) As formulated here, the differences between two solvers may be simply in their choice of even a single technique, heuristic, or policy that sustains performance diver-sity. Thus an algorithm portfolio can be thought of as a mixture of experts [26], in-cluding variable-ordering and value-ordering heuristics, restart policies, and nogood learning methods. In particular, even if only one heuristic is available, the portfolio could consist of the heuristic and its opposite, or the heuristic and random selection. 

Document 3: 
 PSO. 
For the methodological part of the comparisons, there are far more 
studies. Statistical tests, for instance, lay at the core of prior contribu- 
tions on this matter. However, such contributions are frequently writ- 
ten from a statistical point of view –l i k e the one by Dem š ar [39] –
making it diﬃcult for researchers in this ﬁeld to embrace their method- 
ological recommendations. More recently, some tutorials have tried to 
bring together the ﬁelds of meta-heuristics and inferential statistics [4] . 
Some examples can be found in [40] , in which a statistical treatment is 
suggested for distinguishing between measurements of performance in 
adaptive evolutionary algorithms. Another good example is [41] , which 
shows that in a popular real-parameter benchmark (CEC’2005), con- 
ditions needed for running parametric hypothesis tests did not hold, 
and non-parametric tests were thus recommended. More recently, in 
[42] , some recommendations for the comparison of evolutionary algo- 
rithms are provided, which can be even extrapolated to machine learn- 
ing benchmarks. 
Another important issue from a methodological point of view is the 
assessment of the performance of bio-inspired algorithms from the per- 
spective of the experimental design. Some studies [5] provide general 
recommendations to design experiments for the comparison of algo- 
rithms in a similar way to what we do in this contribution. However, 
these recommendations are far more general as it targets a broader scope 

Document 4: 
 (Eds.), Handbook of Metaheuristics (pp. 321–353). Kluwer Academic Publishers, Norwell, MA, USA.
Maron, O. & Moore, A. (1994). Hoeffding races: Accelerating model selection search for classiﬁcation
and function approximation. In Cowan, J. D., Tesauro, G., & Alspector, J. (Eds.), Advances in Neural
Information Processing Systems 7 (NIPS-94), volume 6, (pp. 59–66). Morgan Kaufmann Publishers, San
Francisco, CA, USA.
Mengshoel, O. J. (2008). Understanding the role of noise in stochastic local search: Analysis and experi-
ments. Artiﬁcial Intelligence, 172(8-9), 955–990.
Minton, S. (1993). An analytic learning system for specializing heuristics. In Bajcsy, R. (Ed.),Proceedings of
the Thirteenth International Joint Conference on Artiﬁcial Intelligence (IJCAI’93), (pp. 922–929). Morgan
Kaufmann Publishers, San Francisco, CA, USA.
Minton, S. (1996). Automatically conﬁguring constraint satisfaction programs: A case study. Constraints,
1(1), 1–40.
Minton, S., Johnston, M. D., Philips, A. B., & Laird, P. (1992). Minimizing conﬂicts: A heuristic repair 

Document 5: 
 J. Durillo , K. Hammond , E. Hart , C.G. Johnson , et al. , A research agenda for meta- 
heuristic standardization, in: Proceedings of the XI metaheuristics international 
conference, 2015, pp. 1–3 . 
[106] J. Swan , S. Adraensen , A.E. Brownlee , C.G. Johnson , A. Kheiri , F. Krawiec , 
J. Merelo , L.L. Minku , E. Özcan , G.L. Pappa , et al. , Towards metaheuristics ”i n 
the large ”, arXiv preprint arXiv:2011.09821 (2020) . 
[107] M.A. Lones , Mitigating metaphors: a comprehensible guide to recent nature-in- 
spired algorithms, SN Computer Science 1 (1) (2020) 49 . 
[108] M. Jain, V. Singh, A. Rani, A novel nature-inspired algorithm for optimiza- 
tion: squirrel search algorithm, Swarm Evol Comput 44 (2019) 148–175, 
doi: 10.1016/j.swevo.2018.02.013 . 
[109] A.W. Mohamed, A.A. Hadi, A.K. Mohamed, Gaining-sharing knowledge 
based algorithm for solving optimization problems: a novel nature- 

Document 6: 
 iﬁed on 24 continuous benchmark functions from the COCO test set and 29
functions from the CEC-2017 test set. On the BBOB test set a hybrid of
PSO and DE with adaptation obtained 11 signiﬁcantly better and 2 signif-
icantly worse results on 5 and 20 dimensional functions than the basic DE.
Further inclusion of the model based optimizers led to 15 signiﬁcantly better
and 2 signiﬁcantly worse results compared to the PSO-DE hybrid. On the
CEC-2017 test set, M-GAPSO was signiﬁcantly better than both Red Fox
Optimization and Dual Opposition-Based Learning for Diﬀerential Evolution
(DOBL) on 7 functions in 30 dimensions and 12 functions in 50 dimensions.
Keywords: hyper-heuristics, meta-heuristics, global optimization
∗Corresponding author.
Email addresses: M.Okulewicz@mini.pw.edu.pl (Micha/suppress l Okulewicz),
M.Zaborski@mini.pw.edu.pl (Mateusz Zaborski), jacek.mandziuk@pw.edu.pl (Jacek
Ma´ ndziuk )
Preprint submitted to Applied Soft Computing 10.1016/j.asoc.2022.109722 December 3, 2022
1. Introduction
The quest for a general purpose optimization algorithms, which started
with the works on evolutionary computations [1, 2], resulted in creation of
a few excellent optimization methods like Diﬀerential Evolution (DE) [3] 

","Metaheuristics are high-level methodologies or general algorithmic templates that can solve a wide range of problems. They do not adapt deeply to specific problem(s), unlike heuristics which are typically specialized solutions for particular types of problems and may get trapped in local optima. Metaheuristics address these limitations by being more flexible but potentially less tailored to any one problem instance.",8.516237258911133,"Metaheuristics are high-level methodologies or general algorithmic templates designed to solve a wide range of optimization problems. They are often nature-inspired and contain stochastic components, allowing them to escape local optima and attempt to find better solutions over a broader search space. In contrast, heuristics are typically problem-specific strategies or rules of thumb that provide sub-optimal solutions and may not have the capability to generalize to various problems. The term ""meta"" indicates that metaheuristics can be viewed as higher-level strategies that can encompass and adapt various heuristics but do not deeply adapt to specific problems, allowing for a more flexible application across different optimization scenarios."
qwen2.5:3b,"What factors and challenges influenced the development of the Automatic Algorithm Configuration approaches?
","Document 1: 
 ods for algorithm development. The methods used in this context 
include experimental design techniques [2,29] , racing approaches 
[20] , and algorithmic methods for parameter conﬁguration, such 
as heuristic search techniques [3,10,41,73,81] , and statistical mod- 
eling approaches [11,43] . These methods have led to an increasing 
automatization of the algorithm design and parameter setting pro- 
cess. 
Automatic algorithm conﬁguration can be described, from a ma- 
chine learning perspective, as the problem of ﬁnding good param- 
eter settings for solving unseen problem instances by learning on 
a set of training problem instances [19] . Thus, there are two clearly 
delimited phases. In a primary tuning phase, an algorithm con- 
ﬁguration is chosen, given a set of training instances representa- 
tive of a particular problem. In a secondary production (or test- 
ing) phase, the chosen algorithm conﬁguration is used to solve un- 
seen instances of the same problem. The goal in automatic algo- 
rithm conﬁguration is to ﬁnd, during the tuning phase, an algo- 
rithm conﬁguration that minimizes some cost measure over the 
set of instances that will be seen during the production phase. 
In other words, the ﬁnal goal is that the conﬁguration of the al- 
gorithm found during the tuning phase generalizes to similar but 
unseen instances. The tuning phase may also use automatic conﬁg- 
uration methods repeatedly while engineering an algorithm [71] . 

Document 2: 
 diﬀerent problems (SAT, MIP, ASP, etc.) of varying complexity (number of variables and
problem instances) for tasks of runtime or quality conﬁguration. For DAC, the DACBench
has been proposed (Eimer et al., 2021), although this does not support DAC settings en-
visioned, e.g., by hyper-reactive search. As an alternative to such libraries, AC methods
can also be benchmarked by using surrogate models that are trained on test instances in
advance, resulting in cheaper evaluations when testing (Eggensperger et al., 2018). The ex-
isting benchmarks fail to cover other conﬁgurations settings like the realtime conﬁguration
setting or the conﬁguration of multi-objective target algorithms.
11.4 Novel AC Methodologies
AC methods have become extremely sophisticated and cover a wide range of methodologies
including evolutionary algorithms, statistical tests, and learned surrogate models. There
nonetheless remain opportunities to improve current methods and create better AC algo-
rithms. We note that our goal in this section is not necessarily to specify the methodologies
of the future, but rather to identify the key challenges that remain in the hopes that engaged
466
A Survey of Methods for Automated Algorithm Configuration
readers will ﬁll these gaps with their ideas. To this end, we discuss several challenges faced
by AC approaches: comparing/ranking conﬁgurations, generating new conﬁgurations, and
selecting instances.
Comparing/ranking conﬁgurations This challenge can be summarized as follows: 

Document 3: 
 available for detecting (approximate) independencies. Although there is some evi-
dence that GGA can solve some moderately difﬁcult conﬁguration problems more
effectively than FocusedILS without capping [2], it appears to be unable to reach
the performance of FocusedILS version 2.3 with aggressive capping on the most
challenging conﬁgurations problems [40]. Unfortunately, GGA also offers less ﬂex-
ibility than FocusedILS in terms of the performance metric to be optimised. More
algorithm conﬁguration procedures based on evolutionary algorithms are covered in
Chapter 2 of this book.
Finally, work originating from the Ph.D. project of Hutter [32] has recently over-
come two major limitations of the sequential model-based optimisation methods
discussed in Section 3.4 of this chapter by introducing a procedure that can han-
dle categorical parameters while explicitly exploiting the fact that performance is
evaluated on a set of problem instances. There is some evidence that this procedure,
dubbedSequential Model-based Algorithm Conﬁguration (SMAC) , can, at least on
some challenging conﬁguration benchmarks, reach and sometimes exceed the per-
formance of FocusedILS [43], and we are convinced that, at least in cases where
the parameter response of a given target algorithm is reasonably regular and per-
formance evaluations are very costly, such advanced SMBO methods hold great
promise.
3.6 Conclusions and Future Work
Automated algorithm conﬁguration and parameter tuning methods have been de- 

Document 4: 
 Decision and Operation Technologies Group,
Bielefeld University, Bielefeld, Germany
Abstract
Algorithm conﬁguration (AC) is concerned with the automated search of the most
suitable parameter conﬁguration of a parametrized algorithm. There is currently a wide
variety of AC problem variants and methods proposed in the literature. Existing reviews
do not take into account all derivatives of the AC problem, nor do they oﬀer a complete
classiﬁcation scheme. To this end, we introduce taxonomies to describe the AC problem and
features of conﬁguration methods, respectively. We review existing AC literature within
the lens of our taxonomies, outline relevant design choices of conﬁguration approaches,
contrast methods and problem variants against each other, and describe the state of AC in
industry. Finally, our review provides researchers and practitioners with a look at future
research directions in the ﬁeld of AC.
1. Introduction
Diﬃcult computational problems must be regularly solved in many areas of industry and
academia, such as constraint satisfaction problems, Boolean satisﬁability problems (SAT),
vehicle routing problems, ﬁnding a proper machine learning model for a given dataset,
or computing highly complex simulations. Algorithms that were developed to solve such
problems usually have parameters that strongly inﬂuence the behavior of the respective
algorithm and also, for example, the runtime that is required to solve problem instances
©2022 AI Access Foundation. All rights reserved.
Schede, Brandt, Tornede, Wever, Bengs, H¨ullermeier & Tierney 

Document 5: 
 better performance than the top-ranked solver from the competition.
9. Related Work
Many researchers before us have been dissatisﬁed with manual algorithm conﬁguration, and various
ﬁelds have developed their own approaches for automatic parameter tuning. We start this section
with the most closely-related work—approaches that employ direct search to ﬁnd good parameter
conﬁgurations—and then describe other methods. Finally, we discuss work on related problems,
such as ﬁnding the best parameter conﬁguration or algorithm on a per-instance basis, and approaches
that adapt their parameters during an algorithm’s execution (see also Hoos, 2008, for further related
work on automated algorithm design).
8. BasicILS was used, because FocusedILS had not yet been developed when that study was conducted.
297
HUTTER , HOOS , LEYTON -BROWN & ST ¨UTZLE
9.1 Direct Search Methods for Algorithm Conﬁguration
Approaches for automated algorithm conﬁguration go back to the early 1990s, when a number of
systems were developed for adaptive problem solving. One of these systems is Composer (Gratch
& Dejong, 1992), which performs a hill-climbing search in conﬁguration space, taking moves if
enough evidence has been gathered to render a neighbouring conﬁguration statistically signiﬁcantly
better than the current conﬁguration. Composer was successfully applied to improving the ﬁve
parameters of an algorithm for scheduling communication between a collection of ground-based
antennas and spacecrafts (Gratch & Chien, 1996). 

Document 6: 
 ration.
1 Introduction
We consider the problem of automatic solver conﬁguration. Practically all solvers have
parameters that are partly ﬁxed by the programmer and partly set by the user. In recent
years, systems have been devised which automate the task of tuning parameters for a
given set of training instances that are assu med to represent typical instances for the
target algorithm.
There are several motivations for such an automation, the ﬁrst being that it is of
course time consuming to tune parameters and it may lead to better results when leaving
the conﬁguration of solvers to a computer rather than doing it by hand.
Moreover, it is conceivable that the existence of an effective tuning environment
will cause algorithm developers to paramete rize more aspects of their algorithms and
thus leave more freedom for algorithmic solutions that are automatically tailored to the
problems of individual users. In particular, many of the SAT solvers that are available
today have parameters which cannot be set through the command line. These parameters
have been ﬁxed to values that the developers have found beneﬁcial without knowledge
about the particular instances a user may want to use the solver for. Automatic parameter
tuning allows solvers to adapt to the ﬁnal environment in which they need to perform.
After being shipped, rather than relying on default parameters, an algorithm can be
⋆ This work was partly supported by the projects TIN2007-68005-C04-04 and TIN2006-15662-
C02-02 funded by the MEC, and by the the National Science Foundation through the Ca-
reer: Cornﬂower Project (award number 0644113). 

","The development of automatic algorithm configuration (A2) techniques has been influenced by several key factors and faced significant challenges. Here are some of the main factors and challenges:

### Factors Influencing Development

1. **Performance Variability:** Many algorithms have variability in their performance depending on different settings, such as parameter values, data distributions, or environments. A2 approaches aim to identify optimal configurations that can generalize well across these variations.

2. **Combinatorial Complexity:** The space of possible algorithm configurations often grows exponentially with the number of parameters and choices available, making it computationally expensive to search through all possibilities exhaustively. This complexity is a major challenge for both hardware and software implementations.

3. **Scalability:** As datasets or problem complexities increase, configuring algorithms manually can become impractical. Automatic configuration aims to address this by providing scalable solutions that work well even with large-scale problems.

4. **Adaptability to New Data Types:** Modern data sources are diverse and complex, often requiring sophisticated algorithmic configurations for effective processing and analysis.

5. **Compliance and Integration:** Many real-world applications need algorithms to comply with specific regulatory requirements or integrate seamlessly into existing systems.

6. **Scalability and Resource Management:** Algorithms can benefit from optimization that considers resource constraints such as computational power, memory usage, time efficiency, etc., leading to better performance in practical scenarios.

### Challenges Faced

1. **Combinatorial Explosion Problem:** As mentioned above, the number of possible configurations grows exponentially with each additional parameter or choice point. Traditional search and optimization techniques struggle with this issue due to their exponential complexity.

2. **Objective Function Definition:** Defining a clear and effective objective function (e.g., for measuring algorithm performance) is challenging because it often requires domain-specific knowledge. Moreover, the definition might change based on varying application requirements.

3. **Generalization vs. Tuning:** Finding a balance between generalizing algorithms to new environments or problems versus fine-tuning them for specific scenarios can be difficult and may require significant computational resources.

4. **Computational Efficiency:** Developing efficient methods that can handle large, complex configurations without overwhelming system resources is crucial but challenging.

5. **Robustness and Stability:** Configurations derived by A2 approaches should not only perform well under controlled conditions but also maintain performance levels when deployed in real-world environments with varying conditions or data types.

6. **Interoperability:** Ensuring that the configured algorithms can integrate smoothly with existing software architectures, databases, and other systems is an important consideration for successful deployment.

7. **Scalability Issues:** While A2 approaches aim to address scalability challenges, there may still be bottlenecks in terms of handling very large or complex configurations efficiently.

8. **Handling Unknown Variables:** In real-world scenarios, it’s often difficult to anticipate all the variables that might affect an algorithm's performance, making pre-configured solutions unpredictable and potentially suboptimal under unforeseen conditions.

Addressing these factors and challenges requires a multidisciplinary approach involving researchers from computer science, mathematics, engineering, and domain-specific experts. Advances in machine learning, evolutionary algorithms, and optimization techniques have helped mitigate some of the issues faced by A2 approaches over time.",22.51488661766052,"The development of Automatic Algorithm Configuration (AC) approaches has been influenced by several factors and challenges:

1. **Diversity of Problems**: AC methods must cater to various computational problems (e.g., SAT, MIP, ASP) with differing complexities. This requires AC approaches to be versatile and capable of adapting to different problem domains.

2. **Complexity of Parameters**: Algorithms often have numerous parameters that significantly affect their performance. The management and tuning of these parameters present challenges, particularly in ensuring the configurations are suitable for unseen instances.

3. **Benchmarking Limitations**: Existing benchmarking frameworks, such as DACBench, may not adequately support all configuration settings, indicating a need for more comprehensive evaluation tools to benchmark AC methods.

4. **Comparing and Ranking Configurations**: A significant challenge in AC is comparing and ranking different configurations to determine which performs best under various conditions. This task requires effective metrics and methodologies for assessment.

5. **Generating New Configurations**: The ability to generate new and potentially better configurations from existing ones remains a challenge. Advanced methodologies are needed to explore the configuration space efficiently.

6. **Performance Evaluation Costs**: Many performance evaluations are resource-intensive, necessitating methods that can efficiently predict the performance of configurations without extensive testing.

7. **Categorical Parameters Handling**: Many AC procedures initially struggled with categorical parameters, but recent advancements, such as Sequential Model-based Algorithm Configuration (SMAC), have begun to address this limitation.

8. **Adapting to the User's Environment**: The need for solvers to adapt to the environments in which they operate after deployment is critical. Automatic configuration allows developers to create more parameterized algorithms that can tailor themselves to a user's specific problem context.

These factors illustrate the complexities and evolving needs in the field of algorithm configuration, prompting ongoing research and innovation."
qwen2.5:3b,"What are the main benefits of AAC?
","Document 1: 
 as expected, as N and K get larger, the estimation error gets
smaller, and ˆuSN (θ) will converge to u(θ) with probability
1 with N →∞ and K →∞ . Third, Corollary 1 shows that,
for the estimator ˆuSN (θ∗) which are widely used in current
AAC methods, the gain on error reduction decreases rapidly
asN and K get larger (which are also shown in Figure 2 in
the experiments), and the effects of increasingN and K also
depend on ¯σ2
WI and ¯σ2
AI, two quantities varying across dif-
ferent algorithm conﬁguration scenarios. Thus for enhanc-
ing current AAC methods, instead of ﬁxingN as a large
number (e.g., SMAC sets N to 2000 by default) and using
as many training instances as possible, it is more desirable
to use differentN and K according to the conﬁguration sce-
nario considered, in which case N and K may be adjusted
dynamically in the conﬁguration process as more data are
gathered to estimate¯σ2
WI and ¯σ2
AI.
Experiments
In this section, we present our experimental studies. First
we introduce our experiment setup. Then, we verify our the-
oretical results in two facets: 1) comparison of different per-
formance estimators; 2) the effects of different values ofm
(the number of considered conﬁgurations), N (the number
of runs of θ to estimate u(θ)) and K (the number of training 

Document 2: 
 independently in parallel to obtain multiple solutions. Then, the best solution will be
taken as the ﬁnal output of the PAP . Although a PAP would consume more computational
resources than a single algorithm, it has three important advantages. First, PAPs are
easy-to-implement because they do not necessarily require any resource allocation since
each member algorithm is simply assigned with the same amount of resource. Second,
the performance of a PAP on any problem is the best performance achieved among its
member algorithms on the problem. In other words, a PAP could achieve a much better
overall performance than any of its member algorithms. Third, considering the tremendous
growth of parallel computing architectures [22] (e.g., multi-core CPUs) over the last few
decades, leveraging parallelism has become very important in designing effective solvers
for hard optimization problems [23–27]. PAPs employ parallel solution strategies and thus
allow for the use of modern computing facilities in an extremely simple way.
It is conceivable that any PAP’s effectiveness relies heavily on the diversity and com-
plementarity among its member algorithms. In other words, the manual construction
of high-quality PAPs is generally a challenging task, requiring domain experts (with a
deep understanding of both algorithms and problems) to explore the vast design space
of PAPs, which cannot be carried out manually with ease [28–30]. As an alternative, Tang
and Liu [25,26] proposed a general framework, called automatic construction of PAPs, that 

Document 3: 
 phase of solving mixed-integer programs), and also often does not hold for simulations.
463
Schede, Brandt, Tornede, Wever, Bengs, H¨ullermeier & Tierney
11. Research Directions
Many fruitful avenues of research remain in the area of AC. We formulate research directions
with three themes in mind. First, we consider what is required for AC techniques to be
more widely adopted in industry. Second, we investigate algorithm conﬁguration settings
that have not yet been considered. Third, we consider what methodological advances could
move the ﬁeld forward.
11.1 Industry Adoption
Compared to AC, HPO has begun to be adopted in both industry and academia (Van der
Blom et al., 2021). Furthermore, HPO is the focus of a number of start-ups, such as
SigOpt (which was acquired by Intel (Intel Corporation, 2019)), MindsDB, pecan.ai, and
dotData, among many more. AC, however, has received comparatively little fanfare or
adoption. While some well-known AC tools have public releases, such as SMAC (Lindauer
et al., 2021), irace (L´ opez-Ib´ anez et al., 2016), and GGA (Ans´ otegui et al., 2009), we are
unaware of widespread use of these in industry. The company Optano GmbH released a 

Document 4: 
 a policy to adapt the conﬁguration dynamically. Note that even realtime AC commits to a
single conﬁguration when running a given instance, while DAC has the freedom to adjust
the conﬁguration according to target algorithm behavior during execution. Similar to oﬄine
AC, DAC can either focus on ﬁnding a policy for a set of problem instances or a policy that
is tailored towards a single problem instance (i.e., per-instance algorithm conﬁguration).
Two requirements must be met to implement DAC: (1) the algorithm in question needs
to support dynamic changes in its conﬁguration and (2) runtime information must be pro-
vided to describe the current state of the target algorithm.
DAC approaches consider two diﬀerent types of features: instance features I, which do
not change during target algorithm execution, and features encoding the internal state Q
of the algorithm. Examples of state features include the current iteration of a local search
algorithm, the current restart number of a SAT method, or the current solution quality for
optimization techniques.
461
Schede, Brandt, Tornede, Wever, Bengs, H¨ullermeier & Tierney
Figure 7: Illustration of dynamic AC as presented in (Biedenkapp et al., 2020)
Biedenkapp et al. (2020) provide the ﬁrst formal deﬁnition of the DAC setting, however,
there is a signiﬁcant amount of earlier work for learning dynamic conﬁguration policies
(Lagoudakis & Littman, 2000, 2001; Pettinger & Everson, 2002). Such earlier works use 

Document 5: 
 cess (see (Hutter et al. 2009) for a comprehensive review),
which is usually referred to as automatic algorithm con-
ﬁguration (AAC) (Hoos 2012). Many AAC methods such
as ParamILS (Hutter et al. 2009), GGA/GGA+(Ans´otegui,
Sellmann, and Tierney 2009; Ans ´otegui et al. 2015), irace
(L´opez-Ib´a˜nez et al. 2016) and SMAC (Hutter, Hoos, and
Leyton-Brown 2011) have been proposed in the last few
years. They have been used for boosting the algorithm’s per-
formance in a wide range of domains such as the boolean
satisﬁability problem (SAT) (Hutter et al. 2009), the travel-
ing salesman problem (TSP) (L´opez-Ib´a˜nez et al. 2016; Liu,
∗Corresponding author
Copyright c⃝ 2020, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.
Tang, and Yao 2019), the answer set programming (ASP)
(Hutter et al. 2014) and machine learning (Feurer et al. 2015;
Kotthoff et al. 2017).
Despite the notable success achieved in application, the 

Document 6: 
 Non-general AC SMBO approaches Several SMBO approaches exist to perform a
limited form of AC, i.e., on only a single instance. We include these methods due to their
historical importance to the ﬁeld of AC, as well as because they may inspire new general AC
4. Note that for simplicity we assume that g is deterministic here.
443
Schede, Brandt, Tornede, Wever, Bengs, H¨ullermeier & Tierney
approaches. Most SMBO based AC approaches are based on the idea of sequential kriging
meta-modelling (Huang et al., 2006) (SKO) and sequential parameter optimization (SPO)
(Bartz-Beielstein et al., 2005), both of which are based on eﬃcient global optimization (Jones
et al., 1998). While the latter is a classical approach to black box function optimization using
BO, both SPO and SKO constitute extensions to noisy black box functions; an assumption
that is much more realistic for AC. However, both of these approaches still have potential
drawbacks. Some of these are ﬁxed by SPO + (Hutter et al., 2009a), which improves the
intensiﬁcation scheme, and time-bounded SPO (TB-SPO) (Hutter et al., 2010b), which
generalizes SPO+ to work under (potentially tight) time constraints instead of considering
the number of function evaluations as a stopping criterion.
5.2 General Model-based AC Methods 

","Augmentative and alternative communication (AAC) systems provide several key benefits to individuals with speech or language impairments. Here are some of the main advantages:

1. **Improved Communication**: AAC helps people who have difficulty speaking or forming words to communicate their thoughts, needs, and feelings effectively.

2. **Increased Independence**: Effective communication leads to greater independence in daily activities, education, employment, and social interactions.

3. **Stress Reduction**: Communicating can be stressful for individuals with speech or language challenges. AAC tools help reduce this stress by providing a more reliable means of expression.

4. **Enhanced Social Interaction**: Improved ability to communicate often results in improved relationships with family, friends, and peers.

5. **Increased Confidence**: Being able to express oneself clearly and effectively can boost self-esteem and confidence.

6. **Facilitating Education and Employment**: Effective communication is crucial for academic success and employment opportunities.

7. **Supporting Non-Verbal Communication Needs**: AAC supports individuals who cannot produce speech but may be able to use gestures, symbols, or visual means of communication.

8. **Empowerment and Empathy**: AAC empowers users by giving them a voice, which can help in building better relationships and understanding the experiences of others.

9. **Enhanced Participation in Society**: With improved ability to communicate, individuals are more likely to participate fully in social activities, community events, and other aspects of society.

10. **Reduction in Agitation and Negative Behavior**: In some cases, AAC can reduce negative behaviors resulting from frustration or inability to communicate needs effectively.

AAC is tailored to the individual’s specific communication needs, whether they involve speech production challenges (such as aphasia), motor control issues (like those associated with cerebral palsy), intellectual disabilities, or autism spectrum. Customized AAC systems often include a variety of tools such as pictures, symbols, sign language, electronic devices, and writing aids.",14.314642667770386,"The main benefits of Automatic Algorithm Configuration (AAC) include the following:

1. **Performance Boosting**: AAC methods such as ParamILS, GGA, irace, and SMAC have been widely successful in enhancing the performance of algorithms across diverse domains, including SAT, TSP, ASP, and machine learning tasks. They achieve this by optimizing algorithm parameters dynamically based on performance metrics.

2. **Adaptability**: AAC techniques can adjust configurations based on the specific characteristics of different problem instances, allowing for tailored solutions that are more effective than static or pre-defined configurations.

3. **Efficient Resource Management**: AAC facilitates better resource allocation by dynamically adjusting configurations as more data becomes available, which can lead to reduced estimation errors and improved accuracy in algorithm performance.

4. **Research Advancement**: AAC fosters further research opportunities in the field, exploring new configuration settings and methodological advancements, thus contributing to the overall growth and sophistication of optimization techniques.

These advantages enable more effective problem-solving strategies, allowing the algorithms to perform optimally based on varying conditions and requirements."
qwen2.5:3b,"Please provide an overview of the types of AAC methods.
","Document 1: 
 the best solver in the solver class, termed the auto- 
matic algorithm configuration (AAC) in the litera- 
ture [16 ]. More specifically, given a solver class, the 
solver that achieves the best overall performance on 
the training instances is first obtained by some search 
method. Then, the solver is directly applied to an un- 
seen problem instance without a further configura- 
tion process. 
A typical AAC method consists of two main com- 
ponents: sampling in the solver class and evaluat- 
ing a candidate solver. Sampling in the solver class 
is mostly implemented based on search-based meth- 
ods and model-based methods. Search-based meth- 
ods such as hi l l climbing [50 ], local search [8 ] and 
E A s [51 ] have been used to sample solvers, since 
they make minimal assumptions about the solver 
representation and do not require gradients. Addi- 
tionally, some researchers have also explored using 
experimental design [52 ,53 ], such as the full fac- 
torial experimental design, to generate the starting 
points for the search. In comparison, model-based 
methods are more similar to the performance predic- 
tion model approach. They seek to capture the de- 
pendencies between solvers and their performance, 
by training surrogate models on the performance 
data collected during the configuration process. On 

Document 2: 
 as expected, as N and K get larger, the estimation error gets
smaller, and ˆuSN (θ) will converge to u(θ) with probability
1 with N →∞ and K →∞ . Third, Corollary 1 shows that,
for the estimator ˆuSN (θ∗) which are widely used in current
AAC methods, the gain on error reduction decreases rapidly
asN and K get larger (which are also shown in Figure 2 in
the experiments), and the effects of increasingN and K also
depend on ¯σ2
WI and ¯σ2
AI, two quantities varying across dif-
ferent algorithm conﬁguration scenarios. Thus for enhanc-
ing current AAC methods, instead of ﬁxingN as a large
number (e.g., SMAC sets N to 2000 by default) and using
as many training instances as possible, it is more desirable
to use differentN and K according to the conﬁguration sce-
nario considered, in which case N and K may be adjusted
dynamically in the conﬁguration process as more data are
gathered to estimate¯σ2
WI and ¯σ2
AI.
Experiments
In this section, we present our experimental studies. First
we introduce our experiment setup. Then, we verify our the-
oretical results in two facets: 1) comparison of different per-
formance estimators; 2) the effects of different values ofm
(the number of considered conﬁgurations), N (the number
of runs of θ to estimate u(θ)) and K (the number of training 

Document 3: 
 Non-general AC SMBO approaches Several SMBO approaches exist to perform a
limited form of AC, i.e., on only a single instance. We include these methods due to their
historical importance to the ﬁeld of AC, as well as because they may inspire new general AC
4. Note that for simplicity we assume that g is deterministic here.
443
Schede, Brandt, Tornede, Wever, Bengs, H¨ullermeier & Tierney
approaches. Most SMBO based AC approaches are based on the idea of sequential kriging
meta-modelling (Huang et al., 2006) (SKO) and sequential parameter optimization (SPO)
(Bartz-Beielstein et al., 2005), both of which are based on eﬃcient global optimization (Jones
et al., 1998). While the latter is a classical approach to black box function optimization using
BO, both SPO and SKO constitute extensions to noisy black box functions; an assumption
that is much more realistic for AC. However, both of these approaches still have potential
drawbacks. Some of these are ﬁxed by SPO + (Hutter et al., 2009a), which improves the
intensiﬁcation scheme, and time-bounded SPO (TB-SPO) (Hutter et al., 2010b), which
generalizes SPO+ to work under (potentially tight) time constraints instead of considering
the number of function evaluations as a stopping criterion.
5.2 General Model-based AC Methods 

Document 4: 
 attempted. Nonetheless, the AC literature shows a surprising amount of hybridization of
local search, evolutionary and model-based methods. We hypothesize that there is still sig-
niﬁcant progress that can be made in the area of AC, despite the sophistication of current
methods, and are encouraged by the signiﬁcant increase in attention the ﬁeld has received,
in particular through the spread of HPO techniques. Finally, we especially encourage re-
searchers to address the real-world usability of AC techniques to ensure that the promising
performance gains the AC community is seeing can beneﬁt the world at large.
Acknowledgements
This work was partially supported by the German Research Foundation (DFG) within the
Collaborative Research Center “On-The-Fly Computing” (SFB 901/3 project no. 160364472)
and by the research training group “Dataninja” (Trustworthy AI for Seamless Problem
Solving: Next Generation Intelligence Joins Robust Data Analysis) funded by the Ger-
man federal state of North Rhine-Westphalia. We also would like to thank the anonymous
reviewers for their suggestions on the ﬁrst version of this manuscript.
13. Appendix
To help the reader navigate though the jungle of AC, we provide additional resources.
Table 6 contains a list of abbreviations with terms related to AC used within this work. In
addtion, we provide a list of software resources (Table 7) that contains currently available
tools for AC. We only include software that is widely used.
469 

Document 5: 
 algorithm conﬁgurators. To this end, we propose two classiﬁcation schemes: one for AC
problems, and one for algorithm conﬁgurators. Based on this, we structure and summarize
the available literature and classify existing problem variants as well as approaches to AC.
The remainder of the paper is structured as follows. First, in Section 2, we give a formal
introduction into the setting of algorithm conﬁguration, specify the scope of this survey, and
discuss the relation between AC, AS and HPO. In Section 3, we present the classiﬁcation
schemes for AC problems and approaches that are used, in turn, to describe and compare
existing algorithm conﬁgurators. In Sections 4 and 5, we survey algorithm conﬁguration
methods grouped by the property of whether these methods are model-free or leverage
a model respectively. Section 6 deals with theoretical guarantees that can be obtained.
Diﬀerent problem variants, such as realtime AC, instance-speciﬁc vs. feature-based, multi-
objective, and dynamic AC are discussed in Sections 7 to 10. Eventually, with the help of
our classiﬁcation schemes, we elaborate on appealing research directions in Section 11 and
conclude this survey in Section 12. A list of abbreviations used in this work can be found in
Table 6. In addition, we provide a list of useful software in Table 7. We note, however, that
this list is by no means exhaustive; it is meant to provide an idea about available software
at the time of publication.
2. Problem Formulation
2.1 Algorithm Conﬁguration
To describe the AC problem more formally, we introduce the following notation that is sim- 

Document 6: 
 signment methods are based on domination between operators
and Pareto fronts. Compass was paired with probability match-
ing selection, but was also combined with D-MAB in [ 143].
Except for the widely used multiarmed bandit approach dis-
cussed so far, AOS has also been treated as a full reinforcement
learning problem by Sakurai et al.[ 173], Chen et al.[ 33] and
Pettinger and Everson [ 160]. Unlike the previous approaches,
these methods include the notion of state that is deﬁned
using feedback from the EA. For each distinct state, separate
preferences are learned for each operator and selection of the
operator to apply is based on the current state of the search.
An important issue with operator selection (as with all
adaptive parameter control) is the feedback used for control.
Veerapen et al .[ 198] presented and compared various utility
measures for variation operators. These measures are based on
a combination of exploration and exploitation measures and
use Pareto-dominance to evaluate operator utility. In another
paper, Whitacre et al .[ 204] make a distinction between
the source of feedback and any further statistical treatment
(a notion further elaborated in [112]). Several feedback sources
are suggested (including whether the offspring survives or
the number of generations it remains in the population).
The data received by these sources can be treated by av-
eraging them or by detecting the outliers in the sample. 

","Assistive Augmentative Communication (AAC) methods are designed to help individuals who have difficulty communicating effectively with verbal speech. There are several different types of AAC, each tailored to meet specific needs and abilities. Here’s an overview of some common types:

1. **Pronoun Systems**: These systems use symbols or pictures to represent pronouns like ""I,"" ""you,"" and ""they."" They help individuals who have trouble using personal pronouns effectively.

2. **Pointers/Choice Boards**: These are often used by people with complex communication needs who can point but not speak. Choice boards include a variety of choices such as activities, food items, or colors arranged in a grid format for selecting options.

3. **Single-Word Picture Systems (SWPS)**: Also known as Picture Exchange Communication System (PECS), these systems involve using pictures to represent words and phrases, often used with non-verbal children or individuals with autism.

4. **Continuous Vocabulary Systems**: These provide more complex language input than single-word systems. They can be in the form of picture books, graphic novels, or electronic devices that allow for multiple symbols or words to be combined into sentences, paragraphs, and stories.

5. **Gesture-Based AAC Systems**: Utilizing hand gestures or signs rather than verbal speech, these systems are useful for individuals who have difficulty with vocalization but can still communicate through gesture.

6. **Electronic AAC Devices**: These include various types of devices such as low-tech options like picture books and high-tech devices that incorporate text-to-speech software or voice-recognition technology to facilitate communication.

7. **Facial Expression-Based Systems**: Some individuals who have difficulty using verbal speech may use facial expressions to indicate their needs, desires, or feelings through specialized systems designed for this purpose.

8. **Writing Systems**: For individuals who can write but need assistance organizing thoughts into coherent sentences and paragraphs, writing systems can be very helpful, often including spelling aids or keyboard interfaces adapted for users with motor skill limitations.

Each type of AAC method is chosen based on the individual’s specific needs, abilities, and preferred communication style. The goal is to find a system that enables effective and efficient communication, promoting social interaction and participation in various settings.",16.32018232345581,"AAC methods, or automatic algorithm configuration methods, can be classified into two main types based on their approach: sampling methods and model-based methods.

1. **Sampling Methods**: These methods involve systematically exploring the space of potential algorithms or configurations without presupposing a specific performance model. They are commonly implemented as:
   - **Search-based Methods**: Techniques like hill climbing, local search, and evolutionary algorithms (EAs) that make minimal assumptions about the representation of solvers and do not require derivative information.
   - **Experimental Design**: The use of designs such as full factorial designs to determine starting points for the sampling process.

2. **Model-based Methods**: These approaches build predictive models of algorithm performance based on gathered data. The core of model-based methods involves:
   - **Performance Prediction Models**: They utilize surrogate models to capture the relationship between algorithms and their expected performance, allowing for informed decision-making in the configuration process.
   - **Sequential Kriging Optimization (SKO)** and **Sequential Parameter Optimization (SPO)**: These specific methods are extensions designed to handle noisy performance measurements, improving efficiency in searching for optimal configurations.

Additionally, there are hybrid approaches that combine elements from different methodologies, leveraging strengths from local search, evolutionary strategies, and model-based techniques. Overall, the landscape of AAC involves both non-general and general methods, each tailored to specific operational needs and scenarios."
qwen2.5:3b,"Are Parallel Algorithm Portfolios connected with financial portfolios?
","Document 1: 
 algorithms, and thereby combine parameter tuning and an algo-rithm portfolio in the same framework. We are pursuing this avenue as well. The performance of any algorithm portfolio is, of course, bounded by that of an or-acle. The combination of algorithms as black boxes eliminates any opportunity to im-prove an individual algorithm. In contrast, parallelism can be achieved by a variety of problem decomposition methods (e.g., search space splitting), as discussed in Section 3. Although the results of recent SAT solver competitions suggest that a well-designed algorithm portfolio outperforms decomposition methods on a small number 

Document 2: 
 is only determined by the current database. As a sequence, we will
introduce two portfolio frameworks as parallel individual-based
944
Algorithm Portfolio for Individual-based Surrogate-Assisted Evolutionary Algorithms GECCO ’19, July 13–17, 2019, Prague, Czech Republic
SAEAs and UCB for individual-based SAEAs which are motivated
from two different aspects as reviewed previously.
3.1 Parallel individual-based SAEAs
澽澶澡濇澵澹澵澧澽澶澡濇澵澹澵澦澽澶澡濇澵澹澵澥 澸濕濨濕澔
澶濕濧濙
濇濨濕濦濨
濇濨濣濤澳
濍
濂
澹濢濘
/ŶŝƚŝĂůŝǌĂƚŝŽŶ
/ŶĚŝǀŝĚƵĂů
^ƵƌƌŽŐĂƚĞ ^ƵƌƌŽŐĂƚĞ ^ƵƌƌŽŐĂƚĞ
/ŶĚŝǀŝĚƵĂů/ŶĚŝǀŝĚƵĂů
Figure1:Thediagramoftheframework:Parallelindividual-
based SAEAs.
Similar with the algorithm portfolio for canonical evolutionary
algorithms, it is intuitive to consider each individual-based SAEA
as a simple evolutionary algorithm and embed them into the exist-
ing framework, like PAP or MultiEA. From this aspect, the parallel
individual-based SAEAs (Par-IBSAEA) framework is proposed that
all algorithm candidates run simultaneously at each generation.
Nevertheless, it is more convenient than portfolio for canonical
evolutionaryalgorithmsbecausealmostallindividual-basedSAEAs
have the same algorithm structure and it does not require a par-
ticular design for each algorithm. A brief diagram for Par-IBSAEA
with only three algorithm instances is presented in Figure 1 where 

Document 3: 
 automatically producing effective parallel portfolios from multiple solvers, such as ppfolio and pfolioUZK, while exploiting 
the rich design spaces of these component solvers.
Katsirelos et al. [46] showed that an effective parallelization of a CDCL SAT solver does not merely hinge on picking a 
good clause sharing strategy, since it is not straightforward to obtain shorter resolution proofs by parallelization without 
essential changes of the underlying sequential reasoning mechanism. Our ACPP does not aim at parallelizing the resolution 
proof, but rather runs multiple algorithms and algorithm conﬁgurations in parallel, in order to maximize the probability 
that at least one of them ﬁnds a short proof quickly.
2.2. Related work
Well before there was widespread interest in multi-core computing, the potential beneﬁts offered by parallel algorithm 
portfolios were identiﬁed in seminal work by Huberman et al. [39]. Their notion of an algorithm portfolio is inspired by the 
use of portfolios of assets for risk management in ﬁnance and amounts to running multiple algorithms concurrently and 
independently on the same instance of a given problem, until one of them produces a solution. Gomes et al. [27] further 
investigated conditions under which such portfolios outperform their component solvers. Both lines of work considered 
prominent constraint programming problems (graph coloring and quasigroup completion), but neither presented methods 
for automatically constructing portfolio solvers. Parallel portfolios have since made practical impact, both in cases where 
the allocation of computational resources to algorithms in the portfolio is static [62,76] and where the component solvers 

Document 4: 
 is crucial for the effectiveness of any parallel portfolio.
According to (1), the performance of a parallel portfolio on
788 IEEE TRANSACTIONS ON CYBERNETICS, VOL. 52, NO. 2, FEBRUARY 2022
Algorithm 1 GAST
Input: base solvers B with conﬁguration space C; number of
component solvers k; instance set I; performance metric m;
algorithm conﬁgurator AC; independent conﬁgurator runs n; time
budgets tC, tV , tI for conﬁguration, validation and instance
generation respectively
Output:parallel portfolio c1:k
1: for i ← 1: k do
2: /*———— conﬁguration phase ———————*/
3: for j ← 1: n do
4: obtain a portfolio cj
1:i by running AC on conﬁguration space
{c1:i−1}×{ c|c ∈ C} using m for time tC
5: end for
6: validate c1
1:i, ...,cn
1:i on I using m for time tV
7: let c1:i ← arg mincj
1:i|j∈{1,...,n} P(cj
1:i, I) be the portfolio with
the best validation performance
8: /*———— instance-generation phase ————–*/ 

Document 5: 
 work relevant to parallel algorithm portfolios in-cludes online learning [2, 16] and methods that split problems [29, 30].) Effectively, the construction of a parallel algorithm portfolio to solve as many training problems as possible on K processors is an integer-programming (IP) prob-lem. The goal is to find the schedule S that specifies the time allotments to all algo-rithms on all processors, such that no problem can receive more than B time from all the processors together, and the total number of problems solved is a maximum. The expression (1 - )ij(tkj)) is 1 if problem xi is unsolved by algorithm aj after time tkj allo-cated to it 

Document 6: 
 divides the search space into subspaces, succes -
sively allocated to sequential CDCL workers. Work -
ers cooperate through some load-balancing strate -
gy, which performs the dynamic transfer of 
subspaces to idle workers, and through the 
exchange of conflict clauses.
The parallel portfolio approach was introduced 
in 2008 (Hamadi, Jabbour, and Sais 2008; Winter -
steiger, Hamadi, and de Moura 2009; Guo et al.
2010). It exploits the complementarity of different 
sequential DPLL strategies to let them compete and 
cooperate on the same formula. Since each worker 
addresses the whole formula, there is no need to 
introduce load-balancing overheads, and coopera -
tion is only achieved through the exchange of con -
flict clauses. With this approach, the crafting of the 
strategies is important, especially with only a few 
workers. The objective is to cover the space of good 
search strategies in the best possible way. 
In general, the interleaving of computation can 
lead to the previously mentioned problem of non -
determinism. This is true for solvers that use a 
Articles 
SUMMER 2013   101 
(2) Implication graph
(3) Con/f_lict-clause
(3) Con/f_lict-clause
(1) Literal
(4) Activity
(5) Con/f_lict
Preprocessing
Boolean Unit
Propagation 

","Parallel algorithm portfolios are not directly connected to financial portfolios. The concept of an algorithm portfolio, which involves running multiple algorithms concurrently and independently on the same instance of a problem until one produces a solution, is inspired by using portfolios of assets for risk management in finance. However, they serve different purposes: while financial portfolios manage investments across various assets, algorithm portfolios aim at maximizing efficiency and effectiveness in solving computational problems through parallel execution.",8.65995717048645,"Yes, parallel algorithm portfolios are inspired by the concept of financial portfolios. The idea behind an algorithm portfolio is similar to that of a portfolio of assets in finance, which is used for risk management. Just as investors diversify their investments across various assets to manage risk, algorithm portfolios involve running multiple algorithms concurrently and independently on the same problem instance. This approach maximizes the probability of finding a solution by leveraging the strengths of different algorithms, akin to how different financial assets can balance out risks and returns."
qwen2.5:3b,"What factors and challenges influenced the development of the Parallel Algorithm Portfolios?
","Document 1: 
 training set as well as for constructing the solvers.
This article studies effective construction approaches for
parallel portfolios that are less affected by nonrepresentative
training data. The term “parallel portfolio” [25], [26] refers
to a portfolio/set of solvers that is run independently in par-
allel when solving a problem instance (see Section III-A).
As a form of solvers, parallel portfolios have several impor-
tant advantages. First, exploiting parallelism has become very
important in designing efﬁcient solvers for computationally
hard problems, considering the great development and the
wide application of parallel computing architectures [27] (e.g.,
multicore CPUs) over the last decade. Parallel portfolios
employ parallel solution strategies and, thus, could easily make
effective use of modern hardware. Second, utilizing several
different solvers (as in parallel portfolios) is a simple yet
effective strategy for solving computationally hard problems.
Such an idea has also been realized in the form of sequential
portfolios [28], [29], which try to select the best solvers for
solving a problem instance, and adaptive solvers, such as adap-
tive parameter control [30]–[33]; reactive search [34], [35];
and hyper-heuristics [36]–[38], which seek to dynamically
determine the best solver setting while solving a problem
instance. In principle, all these methods need to involve some
mechanisms (e.g., selection or scheduling) to appropriately 

Document 2: 
 Historically, the parallel computing community quickly 
adopted combinatorial search as a playground for applications.
Search algorithms have the advantage of being conceptually 
simple (think of the most basic backtrack-style algorithm) and 
computationally demanding due to the (usually) exponential
size of the search space. In contrast, the search community did 
not really focus its research on parallelizing. The lack of proper 
Articles 
SUMMER 2013   99 Copyright © 2013, Association for the Advancement of Artificial Intelligence. All rights reserved. ISSN 0738-4602 
Seven Challenges in 
Parallel SAT Solving 
Youssef Hamadi and Christoph M. Wintersteiger 
n This article provides a broad overview of the 
state of the parallel SAT solving field. A set of 
challenges to researchers is presented that, we 
believe, must be met to ensure the practical
applicability of parallel SAT solvers in the 
future. All these challenges are described infor -
mally but put into perspective with related 
research results, and a (subjective) grading of 
difficulty for each of them is provided.
infrastructure and, for many, the feeling that 
sequential algorithms were still full of research 
opportunities can go toward explaining that. In 
that community, parallelism was often only put in 
the perspectives of papers with no real perspec -
tives. This led to a situation where parallel search 
algorithms were designed by people with only one 
part of the required skills. 
Most computational problems solved on a com - 

Document 3: 
 is only determined by the current database. As a sequence, we will
introduce two portfolio frameworks as parallel individual-based
944
Algorithm Portfolio for Individual-based Surrogate-Assisted Evolutionary Algorithms GECCO ’19, July 13–17, 2019, Prague, Czech Republic
SAEAs and UCB for individual-based SAEAs which are motivated
from two different aspects as reviewed previously.
3.1 Parallel individual-based SAEAs
澽澶澡濇澵澹澵澧澽澶澡濇澵澹澵澦澽澶澡濇澵澹澵澥 澸濕濨濕澔
澶濕濧濙
濇濨濕濦濨
濇濨濣濤澳
濍
濂
澹濢濘
/ŶŝƚŝĂůŝǌĂƚŝŽŶ
/ŶĚŝǀŝĚƵĂů
^ƵƌƌŽŐĂƚĞ ^ƵƌƌŽŐĂƚĞ ^ƵƌƌŽŐĂƚĞ
/ŶĚŝǀŝĚƵĂů/ŶĚŝǀŝĚƵĂů
Figure1:Thediagramoftheframework:Parallelindividual-
based SAEAs.
Similar with the algorithm portfolio for canonical evolutionary
algorithms, it is intuitive to consider each individual-based SAEA
as a simple evolutionary algorithm and embed them into the exist-
ing framework, like PAP or MultiEA. From this aspect, the parallel
individual-based SAEAs (Par-IBSAEA) framework is proposed that
all algorithm candidates run simultaneously at each generation.
Nevertheless, it is more convenient than portfolio for canonical
evolutionaryalgorithmsbecausealmostallindividual-basedSAEAs
have the same algorithm structure and it does not require a par-
ticular design for each algorithm. A brief diagram for Par-IBSAEA
with only three algorithm instances is presented in Figure 1 where 

Document 4: 
 rithm except some important parameter settings. Therefore, the
portfolio framework in PPTA framework can be parallel-based
framework as well as sequential-based framework.
The algorithm portfolio requires algorithm constituents to
be complementary so that the portfolio algorithm can handle
different types of problems. But it is not easy to select the com-
plementary algorithms which need to test algorithm candidates
in benchmark functions. In PPTA framework, the parameter
conﬁguration obtained from different kinds of problems are
naturally complementary thanks to the classiﬁcation of train-
ing instances. Therefore, we can obtain the complementary
algorithm much easier to construct the algorithm portfolio.
3) Robustness: For each algorithm constituent in the port-
folio, it is the best parameter conﬁguration found for the
speciﬁc kind of problems. Each algorithm is suitable for a
kind of problem so that the portfolio algorithm can handle
several kinds of problems. As a result, the optimization risk
is obviously reduced.
4) Efﬁciency: The time complexity of parameter tuning
algorithm in PPTA framework can be reduced signiﬁcantly
compared with commonly used parameter tuning methods. As
mentioned before, the performance metric only evaluates the
parameter candidates on one speciﬁc problem instance.
In the algorithm portfolio phase, the time complexity does-
n’t increase a lot compared with the single algorithm because
the operators of the algorithm in PPTA are the same with
single algorithm and the total computational resources (i.e.
max FEs) are also the same. The only difference is the
strategy allocating computational resources which varies from
algorithm to algorithm. 

Document 5: 
 divides the search space into subspaces, succes -
sively allocated to sequential CDCL workers. Work -
ers cooperate through some load-balancing strate -
gy, which performs the dynamic transfer of 
subspaces to idle workers, and through the 
exchange of conflict clauses.
The parallel portfolio approach was introduced 
in 2008 (Hamadi, Jabbour, and Sais 2008; Winter -
steiger, Hamadi, and de Moura 2009; Guo et al.
2010). It exploits the complementarity of different 
sequential DPLL strategies to let them compete and 
cooperate on the same formula. Since each worker 
addresses the whole formula, there is no need to 
introduce load-balancing overheads, and coopera -
tion is only achieved through the exchange of con -
flict clauses. With this approach, the crafting of the 
strategies is important, especially with only a few 
workers. The objective is to cover the space of good 
search strategies in the best possible way. 
In general, the interleaving of computation can 
lead to the previously mentioned problem of non -
determinism. This is true for solvers that use a 
Articles 
SUMMER 2013   101 
(2) Implication graph
(3) Con/f_lict-clause
(3) Con/f_lict-clause
(1) Literal
(4) Activity
(5) Con/f_lict
Preprocessing
Boolean Unit
Propagation 

Document 6: 
 the former is to generate instances that are challenging for the
current portfolio, while the aim of the latter is to ﬁnd a new
component solver for the portfolio to better solve the newly gen-
erated instances. Applied to two widely studied problem domains,
that is, the Boolean satisﬁability problems (SAT) and the travel-
ing salesman problems (TSPs), the proposed approach identiﬁed
parallel portfolios with much better generalization than the ones
generated by the existing approaches when the training data
were scarce and biased. Moreover, it was further demonstrated
that the generated portfolios could even rival the state-of-the-art
manually designed parallel solvers.
Index Terms—Automatic portfolio construction (APC), genera-
tive adversarial approach, parallel algorithm portfolio, parameter
tuning.
I. I NTRODUCTION
M
ANY high-performance algorithms for solving com-
putationally hard problems, ranging from the exact
Manuscript received May 17, 2019; revised October 5, 2019 and March
4, 2020; accepted March 23, 2020. Date of publication April 29, 2020; date
of current version February 16, 2022. This work was supported in part by
the National Key Research and Development Program of China under Grant
2017YFB1003102, in part by the Guangdong Provincial Key Laboratory under
Grant 2020B121201001, in part by the Natural Science Foundation of China
under Grant 61672478, in part by the Program for Guangdong Introducing
Innovative and Enterpreneurial Teams under Grant 2017ZT07X386, in part 

","The development of parallel algorithm portfolios is influenced by several key factors and faces a number of challenges. Here's an overview:

### Factors Influencing Development

1. **Computational Complexity**: Many algorithms used in scientific computing, data processing, and machine learning are computationally intensive. Parallelization can significantly reduce execution time.

2. **Hardware Characteristics**: The architecture of modern processors (e.g., multi-core CPUs, GPUs, TPUs) changes the way parallel algorithms should be designed to optimize performance.

3. **Algorithmic Flexibility**: Some problems lend themselves naturally to parallel processing, while others require more sophisticated strategies like load balancing or work stealing mechanisms to achieve optimal results.

4. **Scalability Needs**: As systems scale (from small clusters to large supercomputers), the algorithms must adapt to take advantage of increasing computational resources and ensure they maintain their effectiveness at all scales.

5. **Resource Management**: Efficient management of computational, memory, and communication resources across multiple processing units is crucial for maintaining high performance levels.

6. **Fault Tolerance**: The ability of a parallel algorithm portfolio to handle failures (e.g., node crashes) without significant degradation in overall system performance or data integrity is important.

7. **Energy Efficiency**: Minimizing energy consumption while maximizing computational power is increasingly critical given the growing concern over carbon emissions and sustainability.

8. **Scalable Debugging and Monitoring Tools**: As systems become more complex, tools for debugging and monitoring parallel applications are needed to catch issues early and maintain performance optimization.

### Challenges

1. **Portability Across Platforms**: Designing algorithms that can be easily adapted to different hardware configurations (e.g., from CPUs to GPUs) is challenging but essential.

2. **Load Balancing**: Ensuring that all processing units have workloads distributed evenly, especially for irregular or non-uniform computations, remains a significant challenge.

3. **Synchronization and Communication Overhead**: Efficient communication between parallel components can significantly impact performance; minimizing overheads such as message passing is crucial.

4. **Data Partitioning and Access**: Ensuring that data is efficiently partitioned across nodes while maintaining the integrity of calculations can be complex, especially with large datasets or distributed data sources.

5. **Resource Allocation Management**: Efficiently managing resource allocation among parallel components (e.g., CPU cores, GPU resources) to optimize overall system performance is a continuous challenge.

6. **Fault Tolerance Mechanisms**: Designing robust systems that can recover from failures without manual intervention and still maintain acceptable levels of reliability is non-trivial.

7. **Performance Modeling and Prediction**: Accurately modeling the behavior of parallel algorithms under various conditions for predicting optimal configurations is difficult, especially considering factors like workload variability and hardware degradation over time.

8. **Cost and Scalability Issues**: While there are benefits to using more powerful but expensive hardware, these come with considerations regarding initial investment costs versus long-term operational expenditure.

By addressing these challenges and leveraging the right design strategies, parallel algorithm portfolios can be effectively developed to improve computational efficiency across various domains of computing.",21.491317987442017,"The development of Parallel Algorithm Portfolios has been influenced by several factors and challenges. Firstly, the effective construction of these portfolios is crucial, particularly concerning nonrepresentative training data, which can lead to inefficiencies. The need for utilizing different solvers within a portfolio allows for exploiting their complementarity, showcasing how they can handle different types of problems, thereby enhancing robustness and efficiency.

Another challenge involves the dynamic nature of parallel computing, where issues such as interleaving computations can lead to non-determinism. Strategies must be designed to ensure cooperation between workers while avoiding excessive load-balancing overheads. Additionally, the parallel computing community's initial lack of focus on parallelizing search algorithms, despite their computational demands, posed a challenge when integrating parallel approaches.

Moreover, the difficulty of selecting complementary algorithms for a portfolio, which necessitates extensive testing across various benchmark functions, remains a significant barrier. Researchers also face the challenge of developing effective parameter tuning methods that do not increase computational time complexity when integrating multiple algorithms.

Furthermore, efforts to generate challenging instances for portfolios, combined with the need to identify new solvers to enhance performance, inform ongoing research and development strategies. This context-driven construction, particularly under conditions of scarce and biased training data, emphasizes the necessity of advancements in automatic portfolio construction techniques to rival state-of-the-art manually designed solvers. Overall, addressing these challenges is essential for ensuring the practical applicability of parallel algorithm portfolios in solving complex computational problems."
qwen2.5:3b,What are the main benefits of PAPs?,"Document 1: 
 independently in parallel to obtain multiple solutions. Then, the best solution will be
taken as the ﬁnal output of the PAP . Although a PAP would consume more computational
resources than a single algorithm, it has three important advantages. First, PAPs are
easy-to-implement because they do not necessarily require any resource allocation since
each member algorithm is simply assigned with the same amount of resource. Second,
the performance of a PAP on any problem is the best performance achieved among its
member algorithms on the problem. In other words, a PAP could achieve a much better
overall performance than any of its member algorithms. Third, considering the tremendous
growth of parallel computing architectures [22] (e.g., multi-core CPUs) over the last few
decades, leveraging parallelism has become very important in designing effective solvers
for hard optimization problems [23–27]. PAPs employ parallel solution strategies and thus
allow for the use of modern computing facilities in an extremely simple way.
It is conceivable that any PAP’s effectiveness relies heavily on the diversity and com-
plementarity among its member algorithms. In other words, the manual construction
of high-quality PAPs is generally a challenging task, requiring domain experts (with a
deep understanding of both algorithms and problems) to explore the vast design space
of PAPs, which cannot be carried out manually with ease [28–30]. As an alternative, Tang
and Liu [25,26] proposed a general framework, called automatic construction of PAPs, that 

Document 2: 
 on PAP with more than two constituent algorithms.
Two conclusions regarding the migration scheme of PAP
can be drawn from the superiority of PAP over the compared
algorithms. First, the migration scheme is of great impor-
tance to the success of PAP. Second, 1 andMAX GEN/20
are two appropriate and robust values for the parame-
tersmigration size and migration interval. To further
investigate the inﬂuence of these parameters on PAP, we
carried out a sensitivity analysis to check whether the per-
formance of PAP will change signiﬁcantly with other param-
eter settings. As stated in Section VI-B, 16 different pairs
ofmigration interval and migration size were tested for
every instantiation of PAP. For each pair, 30 independent
runs were executed on all 27 benchmark functions. Then, for
each instantiation on each function, Kruskal–Wallis one-way
analysis of variance by ranks was employed to test whether
the 16 pairs of parameters had led to signiﬁcantly different
performance. After that, for each instantiation of PAP, we
counted the number of the benchmark functions on which
all 16 pairs of parameters made no difference. The larger
the number, the more insensitive an instantiation is to the
parameters. For the sake of brevity, we only summarize in
Table IX these numbers for the 11 PAP instantiations, while
omit the full details. It can be observed that, in the worst case 

Document 3: 
 described as follows:
Ω(P, z) =max{max
θ∈P
Metric (θ, z), Metric ( ¯θ, z)}, (14)
where ¯θ represents the Restructure procedure. Note Equation (14) is slightly different from
Equation (11) (i.e., the performance of conventional PAPs) due to theRestructure procedure.
Initialization
member 
algorithm 
𝜃
1
𝑆
1
member 
algorithm 
𝜃
𝑖
𝑆
𝑖
member 
algorithm 
𝜃
𝑘
𝑆
𝑘
…
…
…
…
𝑆
𝑘
+
1
𝑆
𝑜𝑢𝑡𝑝𝑢𝑡
Comparison
Restructure
Improvement
Figure 1. Illustrations of MOEAs/PAP , the variant form of PAP for MOPs. Si represents the so-
lution set found by member algorithm θi, and Soutput represents the solution set ﬁnally returned
by MOEAs/PAP . The main difference of MOEAs/PAP from conventional PAPs lies in the way of
determining the ﬁnal output, as indicated by the dash box.
Electronics 2023, 12, 4639 7 of 18
4. Automatic Construction of MOEAs/PAP
As aforementioned, the member algorithms of a PAP could be automatically deter-
mined by solving the problem deﬁned in Equation (13). Below, we ﬁrst introduce the 

Document 4: 
 • When constructing MOEAs/PAPs, it is important to maintain the diversity among the
member algorithms. Hence, the population diversity preservation schemes, such as
negatively correlated search [47], can be introduced into the construction approach to
promote cooperation between different member algorithms.
• In real-world applications, one may be unable to collect sufﬁcient MOPs as training
problems. How to automatically build powerful PAPs in these scenarios is also
worth studying.
• The effectiveness of MOEAs/PAP has been primarily demonstrated through exper-
imental evidence, but with an absence of theoretical analysis. A more thorough
investigation of its exceptional performance is crucial for advancing our understand-
ing, which, in turn, can lead to enhancements in its design and the development of a
more comprehensive automatic construction algorithm.
Electronics 2023, 12, 4639 17 of 18
Author Contributions: Conceptualization, S.L.; Methodology, S.L.; Software, X.M.; Validation, X.M.;
Resources, X.M.; Writing—original draft, X.M.; Writing—review and editing, W.H.; Supervision, S.L.
and W.H. All authors have read and agreed to the published version of the manuscript.
Funding: This research was supported by the Strategic Priority Research Program of Chinese
Academy of Science, Grant No. XDB32050100, and the National Natural Science Foundation of
China, Grant No. 91948303.
Data Availability Statement: The data presented in this study are available on request from the 

Document 5: 
 the risks associated with two algorithms. Such a metric can
be used to evaluate how effective our PAP is, together with
other common metrics. Given a set of functions, the proposed
metric essentially measures how likely it is that an algorithm
will ﬁnd a better solution than another algorithm by the end
of a given time budget.
To evaluate the effectiveness of PAP, 11 instantiations of
PAP were implemented based on four existing constituent
algorithms, including SaNSDE, wPSO, G3PCX, and CMA-
ES. The performance of each instantiation was compared to
PENG et al.: POPULATION-BASED ALGORITHM PORTFOLIOS FOR NUMERICAL OPTIMIZATION 799
its constituent algorithms on 27 benchmark functions. Our
experimental results showed that seven out of the 11 PAP in-
stantiations outperformed their constituent algorithms in terms
of solution quality and the proposed risk metric. Furthermore,
7 out of the 11 instantiations even achieved superior or compa-
rable performance in comparison with G-CMA-ES, which was
known to be superior to any of the four constituent algorithms.
Our empirical studies also revealed that PAP is capable of
increasing the probability of ﬁnding the global optimum and
is insensitive to control parameters of the migration scheme.
Further analyses have been conducted to investigate in what
circumstance PAP may outperform its constituent algorithms.
Complementarity was identiﬁed as a key issue.
Though PAP has been shown to be a promising framework, 

Document 6: 
 also presented. The performance of the two instantiations on
TSP and VRPSPDTW problems support the effectiveness of
CEPS in the sense that, in comparison with state-of-the-art
PAP construction approaches, the PAPs obtained by CEPS
achieves better generalization performance.
Since CEPS is a generic framework, some discussions
would help elaborate issues that are of signiﬁcance in practice.
First, although this work assumes CEPS takes a set of initial
training instances as the input, such training instances are
not necessarily real-world instances but could be generated
randomly. In other words, CEPS could be used in a fully cold-
start setting (a.k.a. zero-shot), i.e., no real-world instances are
available for the target problem class. Further, CEPS could
either be run ofﬂine or online, i.e., it could accommodate new
real instances whenever available.
Second, the potential of CEPS could be further explored
by taking advantage of the data generated during its run,
except for the ﬁnal obtained PAP. The data contain all the
sampled conﬁgurations and instances, and the performance
of the former on the latter. Considering that when using
a search method to solve a problem instance, its optimal
parameter values are usually problem-instance dependent and
thus need to be tuned. To tune parameters for a new problem
instance, we can learn from the historical data generated by
CEPS to build a mapping from problem instances to their
optimal parameter values, i.e., a low-cost online parameter- 

","Positive Airway Pressure (PAP) devices, also known as Continuous Positive Airway Pressure machines, are primarily used to treat sleep apnea. Here are some of their key benefits:

1. **Reduces Apnea Events**: One of the primary functions of PAP is to prevent episodes of obstructed breathing during sleep by maintaining a continuous flow of air pressure through your airways.

2. **Improves Sleep Quality**: By reducing or eliminating pauses in breathing, PAP helps improve overall quality and duration of sleep. This can lead to better daytime alertness and mood.

3. **Decreases Daytime Symptoms**: Reduced sleep disruptions from apnea events can help minimize issues such as fatigue, memory problems, and concentration difficulties that often plague people with sleep apnea.

4. **Reduces Cardiovascular Risk**: Sleep apnea has been linked to various cardiovascular issues like high blood pressure, heart failure, and stroke. PAP use can reduce these risks by decreasing the strain on your cardiovascular system caused by oxygen deprivation during sleep.

5. **Improves Overall Health**: Better sleep quality is associated with better overall health outcomes, including improved immune function, a healthier weight (due to reduced snoring which may lead to less food intake), and possibly even an improvement in diabetes symptoms in some cases.

6. **Reduces Risk of Depression**: Sleep disorders like sleep apnea have been linked to depression, anxiety, and other mental health conditions. By improving sleep, PAP can help mitigate these issues.

7. **Improves Quality of Life**: Better sleep leads to more energy and enthusiasm for daily activities, social interactions, and work responsibilities, significantly enhancing overall quality of life.

8. **Cost-Effective in the Long Run**: While the initial investment in a CPAP machine may be high, the long-term benefits include savings on medication due to fewer health issues related to untreated sleep apnea.

These are some of the key advantages that make PAP therapy an effective and beneficial treatment for many people suffering from obstructive sleep apnea.",15.730714321136476,"The main benefits of Population-Based Algorithm Portfolios (PAPs) include:

1. **Easy Implementation**: PAPs are simple to implement as they do not require complex resource allocation; each member algorithm is assigned the same resources.

2. **Enhanced Performance**: The performance of a PAP is determined by the best result achieved among its member algorithms for a given problem, potentially leading to better overall performance compared to any individual algorithm.

3. **Utilization of Parallel Computing**: PAPs leverage parallel solution strategies, thereby effectively utilizing modern parallel computing architectures, which is crucial for tackling hard optimization problems.

4. **Diversity and Complementarity**: The effectiveness of a PAP relies on the diversity and complementarity among its member algorithms, which can lead to more robust solutions.

5. **Sensitivity to Parameters**: Empirical studies have shown that PAPs can be insensitive to the control parameters of the migration scheme, making their performance more stable across different settings.

Overall, these benefits contribute to the robustness and effectiveness of PAPs in solving complex optimization problems."
qwen2.5:7b-instruct-q4_0,"What does the term ""learn to optimize"" mean?
","Document 1: 
 NatlSciRev ,2024,Vol.11,nwae132
Solver 4
Solver 1
Solver 2
Solver 3
Configuration space of algorithms
(solver class)
Facilitate the tedious trial-and-error process for
getting a good solver for an unseen instance
Solver 5
Unseen instances
Training set Solver class
Optimization problem class
Knowledge
Learning
Vehicle routing
problem
Machine learning
Traveling
salesman
problem
Problem Instance 1
Problem Instance 2
Problem Instance 3
Optimization problems
Figure 1 Illustration of the general idea of L2O. 
the same general paradigm that is very similar to 
the typical ML paradigm. That is, they leverage on 
a set of training instances from the target optimiza- 
tion problem class to gain something that would help 
alleviate the tedious algorithm configuration process 
on unseen problem instances, as i l lustrated in Fig. 1 . 
This article puts them under the umbrella term learn 
to optimize (L2O) and provides a brief overview on 
the general ideas as well as critical issues of L2O, in- 
cluding the training process, theoretical foundations 
as well as generalization issues. For more algorithmic 
details on NN-based solvers and heuristic solvers, 
readers are referred to [13 ,14 ] and [15 ,16 ], respec- 
tively. 

Document 2: 
 m∑
i=1
U(s, Xi),
where Xi is a random variable, representing an instance randomly drawn from X.
Notice that Um(s) is a random variable.
We deﬁne two properties of SPPAs, generalization and optimality. An SPPA
learning algorithm generalizes well, when the utility on all instances is close to the
utility on the training set. An SPPA learning algorithm is optimal, if the optimal
SPPA on the training set is close to the optimal result on the set of all instances.
These properties are formalized by the following deﬁnition.
Learning parallel portfolios of algorithms 99
Deﬁnition 6.1 We say that an SPPA learning algorithm mean-generalizes,i ff o ra n y
0 <ϵ and 0 <δ< 1 it outputs an SPPA s ∈ S,f o rw h i c h
P [Um(s) − E [U(s, X)] >ϵ ] ≤ δ.
Let the globally optimal algorithm be:
s∗ = arg max
s∈S
E [U(s, X)] .
We say that an SPPA learning algorithm ismean optimal,i ff o ra l l0 <ϵ and 0<δ< 1
it outputs a schedule s
P
[
E
[
U(s∗, X)
]
− E [U(s, X)] >ϵ 

Document 3: 
 model and select conﬁgurations, respectively.
Input :Target algorithm Awith parameter conﬁguration space Θ; instance set Π; cost
metric ˆc
Output :Optimized (incumbent) parameter conﬁguration, θinc
1 [R, θinc] ←Initialize(Θ, Π);
2 repeat
3 [M,tfit ] ←FitModel(R);
4 [ ⃗Θnew,tselect] ←SelectConﬁgurations(M, θinc, Θ);
5 [R,θinc] ←Intensify( ⃗Θnew, θinc, M, R, tfit + tselect, Π, ˆc);
6 until total time budget for conﬁguration exhausted;
7 return θinc;
parameter optimization (SPO) toolbox—which has received considerable attention in the
evolutionary algorithms community—provides many features that facilitate the manual
analysis and optimization of algorithm parameters; it also includes an automated SMBO
procedure for optimizing continuous parameters on single instances. We started our
own work in SMBO by comparing SKO vs SPO, studying their choices for the four
SMBO components [18]. We demonstrated that component Intensify mattered most, and
improved it in our SPO + algorithm [18]. Subsequently, we showed how to reduce the
overhead incurred by construction and use of response surface models via approximate
GP models. We also eliminated the need for a costly initial design by interleaving ran- 

Document 4: 
 this is to be taken as either the efficiency or the 
effectiveness of the solver.
r = n! Ts
Tns
The Challenges 
As presented in the introductory paragraphs, a 
divide-and-conquer approach can be lucky. A run 
can benefit from a good split, which brings a solu -
tion at the beginning of some subspace and allows 
for an early stop. In contrast, a different division 
can decrease performance. What is interesting here 
is that adding resources can decrease the perform -
ance since it can produce more demanding sub -
spaces. 
Even if portfolio-based approaches are less prone 
to this problem, extending the size of a portfolio 
can still be detrimental to its performance. In gen -
eral, this increases the overhead, due to more fre -
quent and broader clause sharing, and worsens 
cache-congestion issues. A priori, the question of 
deciding the most effective number of resources to 
use against a given formula is a difficult one. 
One possible direction of research is to extend 
automatic tuning techniques. These approaches 
use machine learning to craft a predictive function 
that relates the features of an instance and the 
parameters of a given solver to its expected run 
time. This function can be learned and tested 
offline against a large set of representative 
instances and used at run time to configure a solver 
and maximize its performance. This offline 
approach assumes that a large and representative 

Document 5: 
 OPT := inf
θ∈Θ
R(θ).
The search for the optimal conﬁguration is generally too ambitious, as the total runtime
required for the conﬁgurator must be extraordinarily large (possibly inﬁnite) to guarantee
that the best algorithm conﬁguration returned by the conﬁgurator is in fact the optimal
one with high probability.
As a workaround, one can leverage the idea underlying PAC learning (Valiant, 1984) to
the problem at hand. The basic idea is to relax the goal of ﬁnding the optimal conﬁguration
itself and, instead, ﬁnd a conﬁguration that is considered to be “good enough”. As there are
potentially several such “good enough” conﬁgurations 6, this relaxation of the goal allows
the search to be completed in less (and, thus, feasible) time. In this context, “good enough”
means that the expected runtime is only worse than the optimal expected runtime up to
a multiplicative factor of 1 + ε for some ﬁxed precision parameter ε > 0. Formally, a
conﬁguration is said to be ε-optimal (“good enough”) iﬀ
Ei∼P(c(i,θ)) ≤(1 + ε)OPT.
However, this relaxation of the target is problematic in the context of AC problems, since the
runtimes of conﬁgurations often exhibit a heavy-tailed distribution. Indeed, it is not diﬃcult
to construct an example based on such distributions in which any (sensible) conﬁgurator
would, in the worst case, take inﬁnitely long to ﬁnd an ε-optimal conﬁguration; see for 

Document 6: 
 tions of learning machines, which lead to objective 
functions that favor different optimization methods. 
As a result, many optimization techniques, including 
convex optimization methods [1 ], gradient descent 
[2 ], heuristic search [3 ] as well as evolutionary algo- 
rithms (E A s) [4 ], have been utilized by the ML com- 
munity in the past decades. 
Mainstream optimization algorithms are usu- 
ally highly configurable parameterized algorithms, 
i.e. they involve tunable parameters. Performance of 
such algorithms may vary significantly with different 
parameter settings. Hence, to solve the optimization 
problem induced by a learning task, tedious efforts 
are typically needed to configure the optimization al- 
gorithm. Consider the case of training an NN with 
stochastic gradient descent (SGD). It is widely ac- 
knowledged that the training performance is sensi- 
tive to the learning rate [5 ], a parameter of SGD. 
How to determine the optimal or at least appropri- 
ate learning rate has become a major hurdle for train- 
ing NNs, especially for large-scale NNs [6 ], or when 
the objective function is not an explicit differentiable 
function of the weights of an NN, as in the typical re- 
inforcement learning setting [7 ]. 
In order to reduce the human labor required, 
many studies have attempted to automate the config- 
uration of optimization algorithms [6 ,8 ]. However, 

","Learn to Optimize (L2O) refers to a paradigm that leverages machine learning to alleviate the tedious algorithm configuration process for unseen problem instances. It involves using a set of training instances from the target optimization problem class to learn something that can help configure algorithms effectively on new, unseen problems.",50.55668544769287,"The term ""learn to optimize"" (L2O) refers to a paradigm in which algorithms utilize a set of training instances from a specific optimization problem class to facilitate the process of configuring optimizers for unseen problem instances. The L2O approach aims to alleviate the tedious trial-and-error process often required to find effective solvers for optimization problems. By leveraging machine learning techniques, L2O seeks to provide solutions that improve the configuration of algorithms when they encounter new instances, enhancing their performance and generalization capabilities."
qwen2.5:7b-instruct-q4_0,"Please give some examples of metaheuristics.
","Document 1: 
 usually provide only sub-optimal solutions because they do
not attempt to escape from local optimum. These drawbacks
have led to the introduction of metaheuristics.
Metaheuristics are high-level methodologies or general al-
gorithmic templates, which generally do not adapt deeply
to speciﬁc problem(s) [4]. Hence, they usually can solve a
wide range of problems [2]. In fact, the preﬁx “meta”, which
means “upper level methodology”, indicates that metaheuristic
algorithms can be viewed as “higher level” heuristics. Hy-
brid approaches based on existing metaheuristic(s) are also
considered metaheuristics [5]. In last decades, metaheuristics
have received widespread attention from researchers and are
widely recognized as efﬁcient approaches for hard optimiza-
tion problems. A number of metaheuristic algorithms have
been developed and extensively applied, including Simulated
Annealing (SA) [6], Tabu Search (TS) [7], Evolutionary Algo-
rithms (EAs) [8], Ant Colony Optimization algorithm (ACO)
[9], Particle Swarm Optimization (PSO) [10], and so forth.
Most of metaheuristics are nature-inspired (inspired from some
principles in physics, biology and etc.), contain stochastic
components, and often have several free parameters that can
be set by users according to problem(s) at hand [4].
The setting of parameters (or parameter setting) has strong 

Document 2: 
 aside any metaphorical language. We utterly believe that eﬀorts in 
this direction should be intensiﬁed, building upon the initial postula- 
tions established in some recent works [105,106] . Speciﬁcally, meta- 
heuristics components (including search operators and algorithmic 
behavioral patterns) and interfaces between them should be stan- 
dardized towards objectively assessing similarities and diﬀerences 
between metaphor-based solvers [107] . A novel metaphor is by no 
means a suﬃcient guarantee for a signiﬁcant scientiﬁc contribution. 
• The third of these reasons is methodological, i.e., the relevance of 
some of the building blocks of the overall algorithm. A particular 
algorithm can include a given component (for example, a local op- 
timizer) that can be of relevance even if the algorithm as a whole 
is not completely competitive with respect to the prevailing liter- 
ature. A good example supporting this claim can be observed in 
co-evolutionary frameworks, which usually include a procedure to 
identify the subcomponents that will be individually co-evolved. In 
those cases, even if the subcomponent optimizer is not very sophis- 
ticated, the co-evolutionary framework can be relevant by itself. In 
this sense, it is important to select the appropriate framework to 
highlight the desired characteristic of the proposed algorithm, as dis- 
cussed in Section 3.1 . Following the same example of subcomponents 
identiﬁcation, a researcher focused on large-scale global optimiza- 

Document 3: 
 J. Durillo , K. Hammond , E. Hart , C.G. Johnson , et al. , A research agenda for meta- 
heuristic standardization, in: Proceedings of the XI metaheuristics international 
conference, 2015, pp. 1–3 . 
[106] J. Swan , S. Adraensen , A.E. Brownlee , C.G. Johnson , A. Kheiri , F. Krawiec , 
J. Merelo , L.L. Minku , E. Özcan , G.L. Pappa , et al. , Towards metaheuristics ”i n 
the large ”, arXiv preprint arXiv:2011.09821 (2020) . 
[107] M.A. Lones , Mitigating metaphors: a comprehensible guide to recent nature-in- 
spired algorithms, SN Computer Science 1 (1) (2020) 49 . 
[108] M. Jain, V. Singh, A. Rani, A novel nature-inspired algorithm for optimiza- 
tion: squirrel search algorithm, Swarm Evol Comput 44 (2019) 148–175, 
doi: 10.1016/j.swevo.2018.02.013 . 
[109] A.W. Mohamed, A.A. Hadi, A.K. Mohamed, Gaining-sharing knowledge 
based algorithm for solving optimization problems: a novel nature- 

Document 4: 
 erations Research54(1):99–114.
Bartz-Beielstein, T. 2006. Experimental Research in Evolution-
ary Computation. Springer V erlag.
Battiti, R., and Brunato, M. 2005. Reactiv e search: machine
learning for memory-based heuristics. Technical Report DIT-05-
058, Universit`a Degli Studi Di Trento, Trento, Italy.
Birattari, M.; St¨utzle, T.; Paquete, L.; and V arrentrapp, K. 2002.
A racing algorithm for conﬁguring metaheuristics. In Proc. of
GECCO-02, 11–18.
Birattari, M. 2004. The Problem of Tuning Metaheuristics as
Seen from a Machine Learning Perspective. Ph.D. Dissertation,
Universit´e Libre de Bruxelles, Brussels, Belgium.
Coy, S. P .; Golden, B. L.; Runger, G. C.; and Wasil, E. A. 2001.
Using experimental design to ﬁnd effective parameter settings for
heuristics. Journal of Heuristics7(1):77–97.
E´en, N., and S¨orensson, N. 2003. An extensible SA T solver. In
Proc. of SAT-03, 502–518. 

Document 5: 
 art algorithm, MOS, has been clearly surprised by SHADE-ILS and 
MLSHADE-SPA, hence becoming the most competitive algorithms 
(with a preference by SHADE-ILS, by its better performance and sim- 
plicity). 
8. Conclusions and outlook 
In this work we have stressed on the need for circumventing com- 
mon mistakes and ﬂaws observed in the ﬁeld of bio-inspired optimiza- 
tion, particularly when new meta-heuristic algorithms are proposed and 
experimentally validated over benchmarks designed to this end. Specif- 
ically, we have reviewed and critically analyzed contributions deal- 
ing with experimental recommendations and practices related to meta- 
heuristics. Following our literature study, we have prescribed a set of 
methodological recommendations for preparing a successful proposal 
of bio-inspired meta-heuristic algorithms, from the deﬁnition of the ex- 
perimentation to the presentation of the results. A number of useful 
techniques (graphically summarized in Fig. 9 ) have been suggested for 
prospective studies to implement our proposed methodological frame- 
work, in an attempt at ensuring fairness, coherence and soundness in 
future studies on the topic. Two diﬀerent case studies have been de- 
signed to exemplify the application of our prescribed methodology, dis- 
cussing on the results of the application of each guideline. Although both 
case studies deal with well-known benchmarks, we envision that our 
methodology can be a core part of the design process of meta-heuristic 

Document 6: 
 achieved using several heuristic mechanisms that interact in complex, non-intuitive
ways. For example, a DPLL-style complete solver for SAT (a prototypical NP-
complete problem with important applications in the design of reliable soft- and
hardware) may use different heuristics for selecting variables to be instantiated and
the values ﬁrst explored for these variables, as well as heuristic mechanisms for
managing and using logical constraints derived from failed solution attempts. The
activation, interaction and precise behaviour of those mechanisms is often controlled
by parameters, and the settings of such parameters have a substantial impact on the
Holger H. Hoos
Department of Computer Science, University of British Columbia, 2366 Main Mall, Vancouver,
BC, V6T 1Z4, Canada, e-mail: hoos@cs.ubc.ca
1 We note that the use of heuristic techniques does not imply that the resulting algorithms are nec-
essarily incomplete or do not have provable performance guarantees, but often results in empirical
performance far better than the bounds guaranteed by rigorous theoretical analysis.
Y . Hamadi et al. (eds.),Autonomous Search,
DOI 10.1007/978-3-642-21434-9 3,
© Springer-Verlag Berlin Heidelberg 2011
37
38 Holger H. Hoos
efﬁcacy with which a heuristic algorithm solves a given problem instance or class of 

","Some examples of metaheuristics include Simulated Annealing, Genetic Algorithms, Particle Swarm Optimization, and Ant Colony Optimization.",10.709452867507936,"Some examples of metaheuristics include Simulated Annealing (SA), Tabu Search (TS), Evolutionary Algorithms (EAs), Ant Colony Optimization (ACO), and Particle Swarm Optimization (PSO)."
qwen2.5:7b-instruct-q4_0,"What is the ""no free lunch"" theorem about?
","Document 1: 
 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTA TION, VOL. 1, NO. 1, APRIL 1997 67
No Free Lunch Theorems for Optimization
David H. Wolpert and William G. Macready
Abstract— A framework is developed to explore the connection
between effective optimization algorithms and the problems they
are solving. A number of “no free lunch” (NFL) theorems are
presented which establish that for any algorithm, any elevated
performance over one class of problems is offset by perfor-
mance over another class. These theorems result in a geometric
interpretation of what it means for an algorithm to be well
suited to an optimization problem. Applications of the NFL
theorems to information-theoretic aspects of optimization and
benchmark measures of performance are also presented. Other
issues addressed include time-varying optimization problems and
a priori“head-to-head” minimax distinctions between optimiza-
tion algorithms, distinctions that result despite the NFL theorems’
enforcing of a type of uniformity over all algorithms.
Index T erms— Evolutionary algorithms, information theory,
optimization.
I. I NTRODUCTION
T
HE past few decades have seen an increased interest
in general-purpose “black-box” optimization algorithms
that exploit limited knowledge concerning the optimization
problem on which they are run. In large part these algorithms
have drawn inspiration from optimization processes that occur
in nature. In particular, the two most popular black-box 

Document 2: 
 function, and will produce .
The proof is completed if we show that there is no cost
function so that produces a sample containing and
and such that produces a sample containing and .
There are four possible pairs of samples to consider:
i) ;
ii) ;
iii) ;
iv) .
Since if its ﬁrst point is a , jumps to which is where
starts, when ’s ﬁrst point is a its second point must
equal ’s ﬁrst point. This rules out possibilities i) and ii).
For possibilities iii) and iv), by ’s sample we know that
must be of the form , for some variable . For
case iii), would need to equal , due to the ﬁrst point in
’s sample. For that case, however, the second point sees
would be the value at , which is , contrary to hypothesis.
For case iv), we know that the would have to equal , due
to the ﬁrst point in ’s sample. That would mean, however,
that jumps to for its second point and would therefore
see a , contrary to hypothesis.
Accordingly, none of the four cases is possible. This is
a case both where there is no symmetry under exchange of
’s between and , and no symmetry under exchange of
histograms.
A PPENDIX G 

Document 3: 
 The sum over can be accomplished in the same manner
is summed over. In fact, all the sums over all can
be done, leaving
(7)
In this last step, the statistical independence of and has
been used.
Further progress depends on whether represents or
. We begin with analysis of the case. For this case
, since only reﬂects cost
values from the last cost function, . Using this result gives
The ﬁnal sum over is a constant equal to the number of
ways of generating the sample from cost values drawn
from . The important point is that it is independent of
the particular . Because of this the sum over can be
evaluated eliminating the dependence
This completes the proof of Theorem 2 for the case of .
The proof of Theorem 2 is completed by turning to the
case. This is considerably more difﬁcult since
cannot be simpliﬁed so that the sums over cannot be
WOLPERT AND MACREADY: NO FREE LUNCH THEOREMS FOR OPTIMIZA TION 79
decoupled. Nevertheless, the NFL result still holds. This is
proven by expanding (7) over possible values
(8)
The innermost sum over only has an effect on the
, term so it contributes ,
. This is a constant, equal to . This
leaves
The sum over is now simple
The above equation is of the same form as (8), only with a
remaining sample of size rather than . Consequently, in
an analogous manner to the scheme used to evaluate the sums 

Document 4: 
 always use algorithm . As applied to this case, they
mean that for ﬁxed and ,i f does better (on average)
with the algorithms in some set , then does better (on
average) with the algorithms in the set of all other algorithms.
In particular, if for some favorite algorithms a certain “well-
behaved”results in better performance than does the random
, then that well-behaved gives worse than random behavior
on the set all remaining algorithms. In this sense, just as there
are no universally efﬁcacious search algorithms, there are no
universally benignwhich can be assured of resulting in better
than random performance regardless of one’s algorithm.
In fact, things may very well be worse than this. In super-
vised learning, there is a related result [11]. Translated into
the current context, that result suggests that if one restricts
sums to only be over those algorithms that are a good match
to , then it is often the case that “stupid” choosing
procedures—like the irrational procedure of choosing the
algorithm with the less desirable—outperform “intelligent”
ones. What the set of algorithms summed over must be in
order for a rational choosing procedure to be superior to an
irrational procedure is not currently known.
WOLPERT AND MACREADY: NO FREE LUNCH THEOREMS FOR OPTIMIZA TION 77
VIII. C ONCLUSIONS
A framework has been presented in which to compare 

Document 5: 
 values after distinct cost evaluations produced by using a
particular instantiation of an evolutionary algorithm?”
At ﬁrst glance this seems to be an intractable question,
but the NFL theorem provides a way to answer it. This is
because—according to the NFL theorem—the answer must be
independent of the algorithm used to generate. Consequently,
3 In particular, one may want to impose restrictions on /80 /40 /102 /41 . For instance,
one may wish to only consider /80 /40 /102 /41 that are invariant under at least partial
relabeling of the elements in /88 , to preclude there being an algorithm that will
assuredly “luck out” and land on /109/105 /110 /120 /50/88 /102 /40 /120 /41 on its very ﬁrst query.
WOLPERT AND MACREADY: NO FREE LUNCH THEOREMS FOR OPTIMIZA TION 73
we can choose an algorithm for which the calculation is
tractable.
Theorem 3: For any algorithm, the fraction of cost func-
tions that result in a particular histogram is
For large enough , this can be approximated as
where is the entropy of the distribution , and
is a constant that does not depend on .
This theorem is derived in Appendix C. If some of the are
zero, the approximation still holds, only with redeﬁned to 

Document 6: 
 to-head minimax distinctions. Such an analysis is beyond the
scope of this paper.)
On the other hand, having the sums be equal does carry ob-
vious implications for whether there are head-to-head minimax
distinctions. For example, if both algorithms are deterministic,
then for any particular
equals one for one pair and zero for all others. In such
a case, is just the number
of that result in the pair .S o
implies
that there are no head-to-head minimax distinctions between
and . The converse, however, does not appear to hold. 4
4 Consider the grid of all /40 /122/59 /122 /48 /41 pairs. Assign to each grid point the number
of /102 that result in that grid point’s /40 /122/59 /122 /48 /41 pair. Then our constraints are i)
by the hypothesis that there are no head-to-head minimax distinctions, if grid
point /40 /122 /49 /59/122 /50 /41 is assigned a nonzero number, then so is /40 /122 /50 /59/122 /49 /41 and ii) by
the no-free-lunch theorem, the sum of all numbers in row /122 equals the sum
of all numbers in column /122 . These two constraints do not appear to imply
that the distribution of numbers is symmetric under interchange of rows and 

","The No Free Lunch (NFL) theorem states that any algorithm for optimization performs, on average, no better than random search across all possible problems. This means that there are no universally effective search algorithms; an algorithm that excels at one type of problem will likely perform poorly on another.",11.681474924087524,"The ""no free lunch"" (NFL) theorem states that for any optimization algorithm, any performance advantage achieved over a specific class of optimization problems is counterbalanced by performance declines over other classes of problems. This implies that no single algorithm is universally superior to others across all possible optimization problems—any gains in performance in one area will result in losses elsewhere. The NFL theorem establishes a framework for understanding the relationship between optimization algorithms and the specific problems they are applied to, leading to insights into the limitations of algorithmic effectiveness. It emphasizes that there are no universally effective or benign algorithms that can guarantee better-than-random performance in all scenarios."
qwen2.5:7b-instruct-q4_0,"What is the concept behind Parallel Algorithm Portfolio?
","Document 1: 
 training set as well as for constructing the solvers.
This article studies effective construction approaches for
parallel portfolios that are less affected by nonrepresentative
training data. The term “parallel portfolio” [25], [26] refers
to a portfolio/set of solvers that is run independently in par-
allel when solving a problem instance (see Section III-A).
As a form of solvers, parallel portfolios have several impor-
tant advantages. First, exploiting parallelism has become very
important in designing efﬁcient solvers for computationally
hard problems, considering the great development and the
wide application of parallel computing architectures [27] (e.g.,
multicore CPUs) over the last decade. Parallel portfolios
employ parallel solution strategies and, thus, could easily make
effective use of modern hardware. Second, utilizing several
different solvers (as in parallel portfolios) is a simple yet
effective strategy for solving computationally hard problems.
Such an idea has also been realized in the form of sequential
portfolios [28], [29], which try to select the best solvers for
solving a problem instance, and adaptive solvers, such as adap-
tive parameter control [30]–[33]; reactive search [34], [35];
and hyper-heuristics [36]–[38], which seek to dynamically
determine the best solver setting while solving a problem
instance. In principle, all these methods need to involve some
mechanisms (e.g., selection or scheduling) to appropriately 

Document 2: 
 is only determined by the current database. As a sequence, we will
introduce two portfolio frameworks as parallel individual-based
944
Algorithm Portfolio for Individual-based Surrogate-Assisted Evolutionary Algorithms GECCO ’19, July 13–17, 2019, Prague, Czech Republic
SAEAs and UCB for individual-based SAEAs which are motivated
from two different aspects as reviewed previously.
3.1 Parallel individual-based SAEAs
澽澶澡濇澵澹澵澧澽澶澡濇澵澹澵澦澽澶澡濇澵澹澵澥 澸濕濨濕澔
澶濕濧濙
濇濨濕濦濨
濇濨濣濤澳
濍
濂
澹濢濘
/ŶŝƚŝĂůŝǌĂƚŝŽŶ
/ŶĚŝǀŝĚƵĂů
^ƵƌƌŽŐĂƚĞ ^ƵƌƌŽŐĂƚĞ ^ƵƌƌŽŐĂƚĞ
/ŶĚŝǀŝĚƵĂů/ŶĚŝǀŝĚƵĂů
Figure1:Thediagramoftheframework:Parallelindividual-
based SAEAs.
Similar with the algorithm portfolio for canonical evolutionary
algorithms, it is intuitive to consider each individual-based SAEA
as a simple evolutionary algorithm and embed them into the exist-
ing framework, like PAP or MultiEA. From this aspect, the parallel
individual-based SAEAs (Par-IBSAEA) framework is proposed that
all algorithm candidates run simultaneously at each generation.
Nevertheless, it is more convenient than portfolio for canonical
evolutionaryalgorithmsbecausealmostallindividual-basedSAEAs
have the same algorithm structure and it does not require a par-
ticular design for each algorithm. A brief diagram for Par-IBSAEA
with only three algorithm instances is presented in Figure 1 where 

Document 3: 
 general-ized to denote a combination of different algorithms intended to outperform the search performance of any of its constituent algorithms [3, 6, 11-14]. Here we extend that formulation, so that an algorithm portfolio schedules its constituent algorithms to run concurrently on a set of processors. Let an algorithm be any CSP solver, as described in the previous section. Given a set A = {a1, a2, …, am} of m algorithms, a set P = {x1, x2, …, xn} of n problems, and a set of B consecutive time intervals T = {t1, t2, …, tB}, a simple schedule Sk for a prob-lem on a single processor specifies 

Document 4: 
 algorithms, and thereby combine parameter tuning and an algo-rithm portfolio in the same framework. We are pursuing this avenue as well. The performance of any algorithm portfolio is, of course, bounded by that of an or-acle. The combination of algorithms as black boxes eliminates any opportunity to im-prove an individual algorithm. In contrast, parallelism can be achieved by a variety of problem decomposition methods (e.g., search space splitting), as discussed in Section 3. Although the results of recent SAT solver competitions suggest that a well-designed algorithm portfolio outperforms decomposition methods on a small number 

Document 5: 
 of processors [22], decomposition methods have shown their potential on many more processors (e.g., 64 cores or more in [19]). We will explore this in future work.  
9   Conclusions This paper presents WG, a constructor for non-parallel algorithm portfolios based on case-based reasoning and a greedy algorithm. It formulates parallel algorithm portfo-lio construction as an integer-programming problem, and generalizes WG to RSR-WG, a constructor for parallel algorithm portfolios based on a property of the optimal solution to the inherent integer-programming problem. To address a set of problems one at a time, RSR-WG creates portfolios of deterministic algorithms offline. Exper-iments show that the parallel algorithm portfolios produced by RSR-WG are statisti-cally significantly better than those produced by naïve parallel versions of popular portfolio constructors. Moreover, with only a few additional processors, RSR-WG portfolios are competitive with an oracle solver on a single processor.  Acknowledgements. This research was supported in part by the National Science Foundation under grants IIS-0811437, CNS-0958379 and CNS-0855217, and the City University of New York High Performance Computing Center. 

Document 6: 
 Ann Math Artif Intell (2006) 48:85–106
DOI 10.1007/s10472-007-9050-9
Learning parallel portfolios of algorithms
Marek Petrik ·Shlomo Zilberstein
Published online: 25 May 2007
© Springer Science + Business Media B.V. 2007
Abstract A wide range of combinatorial optimization algorithms have been devel-
oped for complex reasoning tasks. Frequently, no single algorithm outperforms all
the others. This has raised interest in leveraging the performance of a collection
of algorithms to improve performance. We show how to accomplish this using a
Parallel Portfolio of Algorithms (PPA). A PPA is a collection of diverse algorithms
for solving a single problem, all running concurrently on a single processor until
a solution is produced. The performance of the portfolio may be controlled by
assigning different shares of processor time to each algorithm. We present an
effective method for ﬁnding a PPA in which the share of processor time allocated
to each algorithm is ﬁxed. Finding the optimal static schedule is shown to be an
NP-complete problem for a general class of utility functions. We present bounds on
the performance of the PPA over random instances and evaluate the performance
empirically on a collection of 23 state-of-the-art SAT algorithms. The results show
signiﬁcant performance gains over the fastest individual algorithm in the collection.
Keywords Algorithm portfolios ·Resource bounded reasoning ·
Combinatorial optimization
Mathematics Subject Classiﬁcations (2000) 68T05 ·68T20 

","Parallel algorithm portfolio involves running multiple algorithms simultaneously to solve a problem, leveraging their collective performance to potentially outperform any individual algorithm. This approach harnesses parallelism to effectively utilize modern hardware and combines different solvers to address computationally hard problems more efficiently.",10.70280694961548,"The concept behind a Parallel Algorithm Portfolio (PAP) involves utilizing a collection of diverse algorithms to solve a single problem by running them concurrently on a single processor or across multiple processors. The aim is to leverage the strengths of various algorithms to improve overall performance, especially in combinatorial optimization tasks where no single algorithm universally outperforms the rest. Each algorithm in the portfolio can be assigned different shares of processor time to optimize resource usage. The portfolio operates under the principle that combining algorithms as ""black boxes"" can enhance search performance beyond that of any individual algorithm. This setup allows for effective solving of complex problems, as demonstrated by empirical studies showing performance gains over the fastest individual algorithms in the collection."
qwen2.5:7b-instruct-q4_0,"Please provide some approaches to how Parallel Algorithm Portfolio can be constructed.
","Document 1: 
 algorithms, and thereby combine parameter tuning and an algo-rithm portfolio in the same framework. We are pursuing this avenue as well. The performance of any algorithm portfolio is, of course, bounded by that of an or-acle. The combination of algorithms as black boxes eliminates any opportunity to im-prove an individual algorithm. In contrast, parallelism can be achieved by a variety of problem decomposition methods (e.g., search space splitting), as discussed in Section 3. Although the results of recent SAT solver competitions suggest that a well-designed algorithm portfolio outperforms decomposition methods on a small number 

Document 2: 
 tive parameter control [30]–[33]; reactive search [34], [35];
and hyper-heuristics [36]–[38], which seek to dynamically
determine the best solver setting while solving a problem
instance. In principle, all these methods need to involve some
mechanisms (e.g., selection or scheduling) to appropriately
allocate computational resources to different solvers, while the
parallel portfolios do not necessarily require any extra resource
allocation since each solver is simply assigned with the same
amount of resources. Third, a parallel portfolio could be eas-
ily converted to a sequential portfolio by using the algorithm
selection methods [39] to build selectors on the solvers in the
portfolio, which means the portfolios generated by construc-
tion approaches (e.g., the approach proposed in this article)
could be further used for constructing sequential portfolios.
In this article, we propose a novel approach called the
generative adversarial solver trainer (GAST) for the auto-
matic construction of parallel portfolios. Unlike the existing
construction approaches, GAST would generate additional
training instances and construct a parallel portfolio with the
dynamically changing training set. More speciﬁcally, GAST
puts instance generation and portfolio construction in an adver-
sarial game. The instance generation aims to generate the hard
problem instances that could not be solved well by the cur-
rent portfolio, while the portfolio construction aims to ﬁnd a
new component solver for the portfolio to better solve these 

Document 3: 
 1 for j := 1 ... n do
2 obtain portfolio c(j)
1:k by running AC on conﬁguration space ∏k
l=1{(c) | c ∈ C} on I using m for time t/n
3 choose ˆc1:k ∈ arg minc(j)
1:k |j∈{1...n} m(c(j)
1:k, I) that achieved best performance on I according to m
4 return ˆc1:k
3.1.1. Simultaneous conﬁguration of all component solvers (Global)
Our ﬁrst portfolio conﬁguration method is the straightforward extension of standard algorithm conﬁguration to the 
construction of a parallel portfolio (see Algorithm 1). Speciﬁcally, if the given solver has ℓ parameters, we treat the portfolio 
c1:k as a single algorithm with ℓ · k parameters inducing a conﬁguration space of size |C|k, and conﬁgure it directly. As 
noted above, we identify a single conﬁguration as the best of n independent runs of AC . These runs can be performed in 
parallel, meaning that this procedure requires wall clock time t/n if n machines—one for each AC run—with k cores are 
available. The used CPU time will be the given time budget t for Lines 1 and 2 in Algorithm 1 and some small overhead 
ϵ to choose the best portfolio in Line 3. The scalability of this approach is limited by the fact that the global conﬁguration 

Document 4: 
 Learning Algorithm Portfolios for Parallel Execution Xi Yun1 and Susan L. Epstein1, 2  1 Department of Computer Science, The Graduate School of The City University of New York, New York, NY 10016, USA 2 Department of Computer Science, Hunter College of The City University of New York, New York, NY 10065, USA xyun@gc.cuny.edu, susan.epstein@hunter.cuny.edu 
Abstract. Portfolio-based solvers are both effective and robust, but their prom-ise for parallel execution with constraint satisfaction solvers has received rela-tively little attention. This paper proposes an approach that constructs algorithm portfolios intended for parallel execution based on a combination of case-based reasoning, a greedy algorithm, and three heuristics. Empirical results show that this method is efficient, and can significantly improve performance with only a few additional processors. On problems from solver competitions, the resultant algorithm portfolios perform nearly as well as an oracle. Keywords: constraint satisfaction, algorithm portfolio, parallel processing, ma-chine learning. 

Document 5: 
 sign of parallel algorithm portfolios—sets of solvers that are run in parallel on a given instance of a decision problem, such 
as SAT, until the ﬁrst of them ﬁnds a solution [39,27].
In this work,1 we study generic methods for solving a problem we call Automatic Construction of Parallel Portfolios 
(ACPP): automatically constructing a static2 parallel solver from a sequential solver or a set of sequential solvers. This 
task can be understood as falling within the programming by optimization paradigm [34] in that it involves the design of 
software in which many design decisions have been deliberately left open during the development process (here exposed as 
parameters of SAT solvers) to be made automatically later (here by means of an automated algorithm conﬁgurator) in order 
to obtain optimized performance for speciﬁc use cases. Hence, all that is required by our ACPP methods is a sequential 
solver whose conﬁguration space contains complementary conﬁgurations.
We study three variants of the ACPP problem. First, we consider building parallel portfolios starting from a single, 
highly parametric sequential solver design. However, for well-studied problems (e.g., SAT), there often exist a wide range of 
different solvers that contribute to the state of the art (see, e.g., [73]). Complementarities among such solvers can be ex-
ploited by algorithm portfolios, whether driven by algorithm selection (like SATzilla [72]) or by parallel execution (such as 

Document 6: 
 training set as well as for constructing the solvers.
This article studies effective construction approaches for
parallel portfolios that are less affected by nonrepresentative
training data. The term “parallel portfolio” [25], [26] refers
to a portfolio/set of solvers that is run independently in par-
allel when solving a problem instance (see Section III-A).
As a form of solvers, parallel portfolios have several impor-
tant advantages. First, exploiting parallelism has become very
important in designing efﬁcient solvers for computationally
hard problems, considering the great development and the
wide application of parallel computing architectures [27] (e.g.,
multicore CPUs) over the last decade. Parallel portfolios
employ parallel solution strategies and, thus, could easily make
effective use of modern hardware. Second, utilizing several
different solvers (as in parallel portfolios) is a simple yet
effective strategy for solving computationally hard problems.
Such an idea has also been realized in the form of sequential
portfolios [28], [29], which try to select the best solvers for
solving a problem instance, and adaptive solvers, such as adap-
tive parameter control [30]–[33]; reactive search [34], [35];
and hyper-heuristics [36]–[38], which seek to dynamically
determine the best solver setting while solving a problem
instance. In principle, all these methods need to involve some
mechanisms (e.g., selection or scheduling) to appropriately 

","Parallel algorithm portfolios can be constructed using approaches like automatic construction of parallel portfolios (ACPP), which involves designing software where many design decisions are left open for automated optimization. Another approach is simultaneous configuration of all component solvers, treating the portfolio as a single algorithm with combined parameters to optimize performance. Additionally, the generative adversarial solver trainer (GAST) dynamically generates training instances and constructs portfolios that can adaptively improve over time.",14.516116619110107,"Several approaches can be employed to construct Parallel Algorithm Portfolios. Here are some key methods discussed in the context provided:

1. **Generative Adversarial Solver Trainer (GAST)**: This novel approach involves an adversarial game where instance generation aims to create hard problem instances that the current portfolio struggles with, while the portfolio construction focuses on identifying a new solver component to improve performance on these instances. This dynamic training set generation helps enhance the portfolio's capability over time.

2. **Simultaneous Configuration of Component Solvers (Global Configuration)**: This straightforward method treats the portfolio as a single algorithm with combined parameters. It configures all solvers simultaneously by running independent configurations in parallel on available computing resources. The best-performing configuration is selected based on performance metrics.

3. **Empirical Combination of Heuristics and Case-Based Reasoning**: This approach constructs algorithm portfolios intended for parallel execution by employing a combination of case-based reasoning, greedy algorithms, and various heuristics. This method has shown efficiency and significant performance improvement with limited additional computational resources.

4. **Automatic Construction of Parallel Portfolios (ACPP)**: This method involves developing static parallel solvers from existing sequential solvers. ACPP can optimize performance for specific use cases by automatically configuring parameters of sequential solvers based on their complementary configurations.

5. **Exploit Parallelism with Diverse Solvers**: Utilizing several different solvers in the portfolio can provide a simple yet effective strategy for tackling computationally hard problems. The strategy can leverage modern parallel computing architectures by running solvers independently in parallel to maximize resource utilization.

These approaches illustrate the variety of methods that can be used to construct effective Parallel Algorithm Portfolios for solving complex problems efficiently."
qwen2.5:7b-instruct-q4_0,"Can co-evolution be used in Parallel Algorithm Portfolio construction?
","Document 1: 
 in a series of benchmark problems. Finally, the paper will end with
a brief conclusion and a discussion of future work in Section 5.
2 RELATED WORK
2.1 Portfolio of evolutionary algorithm
In the areas of evolutionary algorithms, algorithm portfolio is ap-
plied to increase the probability of finding a better solution by
allocating computational resources to several complementary algo-
rithms. The algorithm portfolio frameworks in the literature can
be classified into two categories as the parallel-based framework
and the sequential-based framework.
For the parallel-based framework, all candidates will run simul-
taneously in multiple sub-processes. Population-based algorithm
portfolio (PAP) is a typical example [16], which allocates compu-
tational resources before the optimization according to the prior
knowledge.Eachalgorithmhasitsownpopulationandevolveinde-
pendently,buttheinformationissharedamongdifferentalgorithms
bymigrationstrategy.Besides,otherparallel-basedportfolioframe-
works like AMALGAM-SO [21] and the UMOEAs [6] collect the
performance of algorithms during the optimisation process and
allocate more resources to the better algorithm.
On the other hand, the sequential based framework only runs
onealgorithmatmostofthetimeduringtheprocessofoptimisation.
Different from the parallel-based algorithm portfolio, this kind of
frameworktrytoselectthebestalgorithmindifferentoptimisation 

Document 2: 
 tic is likely to have the right properties for
this approach to be useful, thus making it
very general in terms of applications.
So far we have assumed that the com-
ponent algorithms are completely inde -
pendent of each other and do not com-
municate. They can be thought of as
“competing” with one another for ma-
chineresources.However,allowingforco -
operation or dependencies among the in-
dividualalgorithmswhiletheyarerunning
simultaneously can improve performance
(18, 19). This possibility raises the inter-
estingquestionoftheextenttowhichour
economics approach to portfolio algo-
rithms can also benefit from cooperation.
Basically, cooperation will introduce sta-
tistical correlations between the perfor -
mance of the individual algorithms, and
we will accordingly define the correlation
between them as
  
cov•t1,t2 
 var•t1 var•t2 
(3)
where cov(t1, t2) denotes the covariance of
theperformanceofthetwoalgorithms.The
effect of cooperation, when manifested in
negativecorrelations,istoincreasetheper-
formanceaswellasreducetherisk(Fig.5).
This change is easily understood in that
negative correlations mean that one algo-
rithmisparticularlygoodpreciselyonthose 

Document 3: 
 So far, we have shown that our procedures were able to construct effective parallel portfolios based on single solvers 
with rich design spaces. There is considerable evidence from the literature and from SAT competitions that strong portfolios 
can also be built by combining entirely different solvers in their default conﬁgurations (see, e.g., SATzilla [72], ppfolio [63]
and pfolioUZK [70]). For instance, ppfolio was obtained simply by combining the best solvers from the previous competition 
into a parallel portfolio. pfolioUZK included more state-of-the-art solvers from 2011 and relied on additional experiments 
to ﬁnd the best combination of solvers in a portfolio. Neither portfolio considers the conﬁguration space of the component 
solvers and therefore both can be seen as simple baselines for other parallelization approaches, including ours. However, 
ppfolio and pfolioUZK use Plingeling as a portfolio component. Since we aim to investigate the strength of our ACPP methods 
without additional human expert knowledge on parallel solving, we ﬁrst consider only sequential solvers as the basis for 
our ACPP approach. This section and the following section investigates the extension of our automatic techniques to the 
construction of portfolios based on the conﬁguration spaces spanned by such solver sets.
4.1. Approach
As long as all of our component solvers are sequential, we can simply use the ACPP procedures deﬁned in Section 3. 
We can accommodate the multi-solver setting by introducing a solver choice parameter for each portfolio component (see 

Document 4: 
 1
Few-shots Parallel Algorithm Portfolio Construction
via Co-evolution
Ke Tang, Senior Member, IEEE, Shengcai Liu, Member, IEEE, Peng Yang, Member, IEEE,
and Xin Yao, Fellow, IEEE
Abstract—Generalization, i.e., the ability of solving problem
instances that are not available during the system design and
development phase, is a critical goal for intelligent systems.
A typical way to achieve good generalization is to learn a
model from vast data. In the context of heuristic search, such a
paradigm could be implemented as conﬁguring the parameters
of a parallel algorithm portfolio (PAP) based on a set of
“training” problem instances, which is often referred to as PAP
construction. However, compared to traditional machine learning,
PAP construction often suffers from the lack of training instances,
and the obtained PAPs may fail to generalize well. This paper
proposes a novel competitive co-evolution scheme, named Co-
Evolution of Parameterized Search (CEPS), as a remedy to
this challenge. By co-evolving a conﬁguration population and an
instance population, CEPS is capable of obtaining generalizable
PAPs with few training instances. The advantage of CEPS in
improving generalization is analytically shown in this paper. Two
concrete algorithms, namely CEPS-TSP and CEPS-VRPSPDTW,
are presented for the Traveling Salesman Problem (TSP) and 

Document 5: 
 algorithms, and thereby combine parameter tuning and an algo-rithm portfolio in the same framework. We are pursuing this avenue as well. The performance of any algorithm portfolio is, of course, bounded by that of an or-acle. The combination of algorithms as black boxes eliminates any opportunity to im-prove an individual algorithm. In contrast, parallelism can be achieved by a variety of problem decomposition methods (e.g., search space splitting), as discussed in Section 3. Although the results of recent SAT solver competitions suggest that a well-designed algorithm portfolio outperforms decomposition methods on a small number 

Document 6: 
 divides the search space into subspaces, succes -
sively allocated to sequential CDCL workers. Work -
ers cooperate through some load-balancing strate -
gy, which performs the dynamic transfer of 
subspaces to idle workers, and through the 
exchange of conflict clauses.
The parallel portfolio approach was introduced 
in 2008 (Hamadi, Jabbour, and Sais 2008; Winter -
steiger, Hamadi, and de Moura 2009; Guo et al.
2010). It exploits the complementarity of different 
sequential DPLL strategies to let them compete and 
cooperate on the same formula. Since each worker 
addresses the whole formula, there is no need to 
introduce load-balancing overheads, and coopera -
tion is only achieved through the exchange of con -
flict clauses. With this approach, the crafting of the 
strategies is important, especially with only a few 
workers. The objective is to cover the space of good 
search strategies in the best possible way. 
In general, the interleaving of computation can 
lead to the previously mentioned problem of non -
determinism. This is true for solvers that use a 
Articles 
SUMMER 2013   101 
(2) Implication graph
(3) Con/f_lict-clause
(3) Con/f_lict-clause
(1) Literal
(4) Activity
(5) Con/f_lict
Preprocessing
Boolean Unit
Propagation 

","Yes, the paper proposes using a competitive co-evolution scheme called CEPS for constructing parallel algorithm portfolios, demonstrating that it can improve generalization even with few training instances.",8.861828804016113,"Yes, co-evolution can be used in Parallel Algorithm Portfolio (PAP) construction. The context describes a novel competitive co-evolution scheme called Co-Evolution of Parameterized Search (CEPS), which is specifically designed to improve generalization in PAPs despite the challenge of having few training instances. By co-evolving both a configuration population and an instance population, CEPS is capable of producing generalizable portfolios. Hence, this method serves as a viable approach to enhance the effectiveness of PAPs through co-evolution."
qwen2.5:7b-instruct-q4_0,"What is the idea behind the PAP approach called ""GLOBAL""?
","Document 1: 
 paper has two major contributions. First, the proposed PAP is
developed for numerical optimization instead of combinatorial
optimization. Second, we investigate the term “risk” in a
different context. Previous work mainly aimed to reduce the
risk of an algorithm on a speciﬁc optimization problem, which
can be measured by applying the algorithm to the problem
for multiple times. In this paper, we are more interested in
reducing the risk overa set of problems , i.e., the risk is
measured by applying the algorithm to multiple problems.
Our PAP is a general framework for combining different
population-based search algorithms. It allocates computation
time among more than one constituent algorithm and acti-
vates interaction among them so that they can beneﬁt from
one another. To be more speciﬁc, the computation time is
measured by the number of ﬁtness evaluations (FEs), and
the allocation of FEs is implemented by dividing the whole
population into several subpopulations and evolving them in
a parallel manner (using different constituent algorithms). To
demonstrate the efﬁcacy of the proposed PAP, we chose four
existing population-based algorithms, including self-adaptive
differential evolution with neighborhood search (SaNSDE)
[7], particle swarm optimizer with inertia weight (wPSO)
[8], generalized generation gap (G3) model with generic
parent-centric recombination (PCX) operator (G3PCX) [9],
and covariance matrix adaptation evolution strategy (CMA-
ES) [10], as the constituent algorithms. These algorithms 

Document 2: 
 with a constraint handling technique. At each generation, each
subpopulation generates new individuals based on its own.
Then, each subpopulation is combined with new individuals
generated by all subpopulations, and selection is conducted
with the corresponding constraint handling technique. Com-
pared to all the above-mentioned work, in which all search
biases have access to the whole population, PAP allows only
its constituent algorithms to work on a subpopulation, i.e.,
full access to the whole population is prohibited. Migration is
the only route that different subpopulations communicate with
each other. This strategy, used by PAP, reduces the likelihood
of different constituent algorithms repeating similar search
behaviors or sharing similar search biases.
From the perspective of employing a multipopulation model
and migration operators, PAP is related to the distributed
EAs (dEAs), which have several subpopulations (islands) and
perform sparse exchange of individuals among them [25],
[26]. However, PAP is quite different from previous dEAs
in three major ways. First, most dEAs run the same EA
on all subpopulations [26]–[31] (either with the same or
different control parameters), while PAP employs different
EAs. Second, the migration scheme of PAP does not assume
any topology of subpopulations, while many dEAs do. By
this means, we solely focus on investigating whether it is 

Document 3: 
 • When constructing MOEAs/PAPs, it is important to maintain the diversity among the
member algorithms. Hence, the population diversity preservation schemes, such as
negatively correlated search [47], can be introduced into the construction approach to
promote cooperation between different member algorithms.
• In real-world applications, one may be unable to collect sufﬁcient MOPs as training
problems. How to automatically build powerful PAPs in these scenarios is also
worth studying.
• The effectiveness of MOEAs/PAP has been primarily demonstrated through exper-
imental evidence, but with an absence of theoretical analysis. A more thorough
investigation of its exceptional performance is crucial for advancing our understand-
ing, which, in turn, can lead to enhancements in its design and the development of a
more comprehensive automatic construction algorithm.
Electronics 2023, 12, 4639 17 of 18
Author Contributions: Conceptualization, S.L.; Methodology, S.L.; Software, X.M.; Validation, X.M.;
Resources, X.M.; Writing—original draft, X.M.; Writing—review and editing, W.H.; Supervision, S.L.
and W.H. All authors have read and agreed to the published version of the manuscript.
Funding: This research was supported by the Strategic Priority Research Program of Chinese
Academy of Science, Grant No. XDB32050100, and the National Natural Science Foundation of
China, Grant No. 91948303.
Data Availability Statement: The data presented in this study are available on request from the 

Document 4: 
 of high-quality PAPs is generally a challenging task, requiring domain experts (with a
deep understanding of both algorithms and problems) to explore the vast design space
of PAPs, which cannot be carried out manually with ease [28–30]. As an alternative, Tang
and Liu [25,26] proposed a general framework, called automatic construction of PAPs, that
seeks to automatically build PAPs by selecting the member algorithms from an algorithm
conﬁguration space, with the goal of optimizing the performance of the resulting PAP on a
given problem set (called training set). Such a framework has been shown to be effective in
building high-performance PAPs for combinatorial problems such as the Boolean Satisﬁa-
bility Problem (SAT) [25], the Traveling Salesman Problem (TSP) [27,31], and the Vehicle
Routing Problem (VRP) [26].
However, to the best of our knowledge, the potential of the automatic construction of
PAPs has not been investigated in the area of multi-objective optimization. Considering its
excellent performance on the above-mentioned problems and the practical signiﬁcance of
MOPs, studying how to utilize it to solve MOPs is thus valuable. In this work, we focus
on automatically building PAPs for continuous MOPs. On the other hand, as a general
framework, appropriately instantiating automatic PAP construction for a speciﬁc problem
domain is non-trivial. Speciﬁcally, it requires careful designs of the algorithm conﬁguration
space and the performance metrics used in the construction process [26]. 

Document 5: 
 are capable of exploring the search space globally. Hence, in order to achieve a better
overall performance for a diverse range of MOPs, it is natural and intuitive to combine
Electronics 2023, 12, 4639. https://doi.org/10.3390/electronics12224639 https://www.mdpi.com/journal/electronics
Electronics 2023, 12, 4639 2 of 18
the advantages of different MOEAs. One notable series of research efforts following this
idea are multi-operator-based MOEAs [11–14], which adaptively allocate computational
resources to MOEAs equipped with different operators when solving a MOP .
Apart from multi-operator-based MOEAs, and from a more general perspective of
problem solving, there is an effective technique that exploits the complementarity between
different algorithms by including them into a so-called algorithm portfolio (AP). To utilize
an AP to solve a problem, Tang et al. [ 20,21] proposed a simple but effective strategy,
called a parallel algorithm portfolio (PAP), that runs all member algorithms in the portfolio
independently in parallel to obtain multiple solutions. Then, the best solution will be
taken as the ﬁnal output of the PAP . Although a PAP would consume more computational
resources than a single algorithm, it has three important advantages. First, PAPs are
easy-to-implement because they do not necessarily require any resource allocation since
each member algorithm is simply assigned with the same amount of resource. Second, 

Document 6: 
 (CEC2005) [12], denoted asfcec1 −fcec14. These 27 functions
span a diverse set of problem features, such as multimodality,
ruggedness, ill-conditioning, interdependency, etc. They pro-
vided an ideal platform for our investigation on reducing risk
on a large variety of problems. Short descriptions of these
functions are presented in Tables I and II. More details of these
functions can be found in [11] and [12]. In our experiments,
all the functions were solved in 30 dimensions.
B. Experimental Settings
All the results presented in this paper were obtained by
executing 30 independent runs for each experiment. Since
we expect the PAP framework to be general enough so that
alternative algorithms can be incorporated with little effort,
it should not rely much on the reﬁnement of the constituent
algorithms. Hence, we did not ﬁne-tune the parameters of
the constituent algorithms to ﬁt PAP. When implementing
SaNSDE, we used all the parameter settings suggested in
the original publication [7]. As suggested in [8], a linearly
decreasing inertia weight over the course of the search is
employed in our implementation of wPSO. The two coefﬁ-
cients of wPSO were both set to 1.49445. We assumed the
researchers who proposed G3PCX and CMA-ES are at the
best position to implement the two algorithms and ﬁne-tune
the parameters. Hence, we simply used the source code of 

","The term ""GLOBAL"" in the context of the PAP (Prediction Analysis Process) approach likely refers to a framework or methodology that aims for global prediction analysis. However, it's important to note that there isn't a widely recognized standard term called ""GLOBAL"" specifically associated with the PAP approach.

In the context of PAP and potentially other predictive modeling frameworks, the term ""global"" might refer to an approach that seeks to create models or predictions that are broadly applicable across different contexts or datasets. Here’s what this could mean in more detail:

1. **Global Models**: These are models that aim to capture general patterns or relationships that are consistent across multiple domains or conditions. This is in contrast to local models, which may be optimized for specific subsets of data.

2. **Generalizability**: The goal might be to create a model that can generalize well to new, unseen data from various sources or under different conditions. This involves ensuring the model isn't overly tailored to one specific dataset but can still perform well across diverse scenarios.

3. **Scalability and Relevance**: A global approach in this context could mean developing methods that are scalable and relevant for a wide range of applications within a particular field, such as environmental science, economics, or healthcare.

4. **Cross-Validation Techniques**: In practice, achieving a ""global"" perspective might involve using robust cross-validation techniques to ensure the model’s performance is consistent across different folds of data from various sources.

5. **Feature Selection and Dimensionality Reduction**: Techniques that help in selecting features that are broadly relevant and reducing dimensionality to maintain generalizability while avoiding overfitting specific datasets.

Given this context, if ""GLOBAL"" is a specific approach or framework within the PAP methodology, it likely emphasizes creating models that can be applied universally across different scenarios rather than being narrowly tailored to one specific dataset. However, without more specific information about the exact definition or implementation of ""GLOBAL,"" it's challenging to provide a definitive explanation. If you have access to documentation or literature related to this approach, reviewing those sources would offer the most accurate understanding.",50.7941460609436,"The PAP approach called ""GLOBAL"" focuses on optimizing performance by exploiting the advantages of different population-based algorithms through a parallel framework. Its main goal is to improve the overall performance across a diverse range of multi-objective problems by employing multiple algorithms that operate independently and in parallel. This strategy allows the algorithm portfolio to explore the search space globally, providing a higher chance of finding better solutions than any single algorithm could achieve on its own. Through the communication and migration of solutions among subpopulations, the PAP framework facilitates the sharing of beneficial information and enhances diversity in the search process. This method aims to effectively reduce the risk associated with solving various problems by improving cooperation between different member algorithms while maintaining their individual search biases."
qwen2.5:7b-instruct-q4_0,"What is the idea behind the PAP approach called ""PARHYDRA""?
","Document 1: 
 on all subpopulations [26]–[31] (either with the same or
different control parameters), while PAP employs different
EAs. Second, the migration scheme of PAP does not assume
any topology of subpopulations, while many dEAs do. By
this means, we solely focus on investigating whether it is
worthy of allocating the limited computation time to different
algorithms so that the overall performance can be enhanced.
In contrast, a speciﬁc topology/structure for the relationship
between subpopulations is usually explicitly deﬁned in existing
dEAs [26]–[29], [32], [33]. Third, we are more interested
in reducing the overall risk of an algorithm ona spectrum
of problems. This issue has never been investigated in the
literature of dEAs.
In addition to dEAs, another notable work that is related
to PAP is the isolation strategy employed by hierarchically
organized evolution strategies (HOES) [34], [35]. In HOES,
a population is partitioned into a number of subpopulations,
and ES is run on them with different control parameters (e.g.,
search step sizes). The isolation strategy works in such a
way that the subpopulations evolve separately for a predeﬁned
isolation period (e.g., a few generations), and then the control
parameters are updated based on the individuals generated in
the subpopulations during the isolation period. Unlike PAP,
the motivation of the isolation strategy is not to make use of 

Document 2: 
 SCENARIOS , THAT IS , SAT-SMALL-BIAS-1/2/3/4. T HE NAME OF THE
CONSTRUCTION APPROACH IS USED TO DENOTE THE PORTFOLIOS
CONSTRUCTED BY IT. “PARHYDRA-A” R EFERS TO PARHYDRA
CONFIGURING BASED ON AUGMENTED TRAINING SETS .AP A R - 1 0
SCORE IS SHOWN IN BOLDFACE IF IT WAS NOT SIGNIFICANTLY
DIFFERENT FROM THE BEST TEST PERFORMANCE IN THE SCENARIO
(ACCORDING TO A WILCOXON SIGNED -RANK TEST WITH p = 0.05)
To answer this question, in each of the eight SAT scenarios,
that is, SAT-SMALL/BIAS-1/2/3/4, we used the same instance
generation procedure as in GAST (lines 13–18 in Algorithm 1)
to generate a large set of instances based on the training set.
The size of the generated set is ﬁve times the size of the
training set. Recall that the training set contains 50 instances,
we thus obtained an augmented training set of 300 instances
in each SAT scenario, and then PARHYDRA was used to
construct a parallel portfolio on these augmented training sets,
and then the obtained portfolio was tested on the test sets. As
before, each portfolio was tested by running it on the test set 

Document 3: 
 of high-quality PAPs is generally a challenging task, requiring domain experts (with a
deep understanding of both algorithms and problems) to explore the vast design space
of PAPs, which cannot be carried out manually with ease [28–30]. As an alternative, Tang
and Liu [25,26] proposed a general framework, called automatic construction of PAPs, that
seeks to automatically build PAPs by selecting the member algorithms from an algorithm
conﬁguration space, with the goal of optimizing the performance of the resulting PAP on a
given problem set (called training set). Such a framework has been shown to be effective in
building high-performance PAPs for combinatorial problems such as the Boolean Satisﬁa-
bility Problem (SAT) [25], the Traveling Salesman Problem (TSP) [27,31], and the Vehicle
Routing Problem (VRP) [26].
However, to the best of our knowledge, the potential of the automatic construction of
PAPs has not been investigated in the area of multi-objective optimization. Considering its
excellent performance on the above-mentioned problems and the practical signiﬁcance of
MOPs, studying how to utilize it to solve MOPs is thus valuable. In this work, we focus
on automatically building PAPs for continuous MOPs. On the other hand, as a general
framework, appropriately instantiating automatic PAP construction for a speciﬁc problem
domain is non-trivial. Speciﬁcally, it requires careful designs of the algorithm conﬁguration
space and the performance metrics used in the construction process [26]. 

Document 4: 
 paper has two major contributions. First, the proposed PAP is
developed for numerical optimization instead of combinatorial
optimization. Second, we investigate the term “risk” in a
different context. Previous work mainly aimed to reduce the
risk of an algorithm on a speciﬁc optimization problem, which
can be measured by applying the algorithm to the problem
for multiple times. In this paper, we are more interested in
reducing the risk overa set of problems , i.e., the risk is
measured by applying the algorithm to multiple problems.
Our PAP is a general framework for combining different
population-based search algorithms. It allocates computation
time among more than one constituent algorithm and acti-
vates interaction among them so that they can beneﬁt from
one another. To be more speciﬁc, the computation time is
measured by the number of ﬁtness evaluations (FEs), and
the allocation of FEs is implemented by dividing the whole
population into several subpopulations and evolving them in
a parallel manner (using different constituent algorithms). To
demonstrate the efﬁcacy of the proposed PAP, we chose four
existing population-based algorithms, including self-adaptive
differential evolution with neighborhood search (SaNSDE)
[7], particle swarm optimizer with inertia weight (wPSO)
[8], generalized generation gap (G3) model with generic
parent-centric recombination (PCX) operator (G3PCX) [9],
and covariance matrix adaptation evolution strategy (CMA-
ES) [10], as the constituent algorithms. These algorithms 

Document 5: 
 be used to build parallel portfolios. (Building a parallel portfolio in this way has the added advantage that no instance 
features are required, since there is no need to select among algorithms.) We introduce some enhancements to this 
approach for the parallel portfolio setting (discussed in Section 3.1.2), and refer to our method as parHydra.
3. Some parallel solvers only achieve strong performance when running on more than one core; such solvers will not 
be found by a greedy approach like parHydra, which only adds one conﬁguration at a time and does not recognize 
interaction effects that arise between different threads of a parallel solver. To overcome this problem, we introduce a 
new method called parHydrab, which augments parHydra to train b solvers per iteration. This method trades off the 
computational beneﬁt of parHydra’s greedy approach with the greater coverage of Global.
We evaluated our ACPP methods on SAT. We chose this domain because it is highly relevant to academia and industry 
and has been widely studied. We thus had access to a wide range of strong, highly parametric solvers and were assured 
that the bar for demonstrating eﬃcacy of parallelization strategies was appropriately high. We note that our approach is not 
limited to SAT solvers and can be directly applied to other domains. To evaluate our methods in the single-solver setting, we 
studied both Lingeling and clasp: prominent, highly parametric state-of-the-art solvers for SAT. Lingeling won a gold medal in 

Document 6: 
 that ihvr ∈(0, 1], and a larger value of ihvr is better. IHVR can distinguish well between
MOEAs with a different performance, and can also save a lot of calculations. In this work,
IHVR is used as the performance metric Metric .
4.3. Automatic Construction Approach
Algorithm 1 presents the automatic construction approach for MOEAs/PAP . Starting
from an empty set (line 2), the approach constructs the PAP (denoted as P) iteratively.
Speciﬁcally, each iteration of the approach (lines 3–15) consists of two subsequent phases.
In the ﬁrst phase, an existing automatic algorithm conﬁguration tool, namely SMAC 3 [44],
is used to search in Θ to ﬁnd the algorithm that can improve the performance of the current
PAP to the largest extent (line 5), and then this algorithm is inserted into P (line 6). This
phase is similar to the commonly-used greedy approach in the automatic construction of
PAPs [27,31]. Additionally, we introduce a new phase, namely simpliﬁcation, as the second
phase in Algorithm 1. In this phase (lines 7–14), P would be simpliﬁed by removing the
member algorithms that do not contribute at all to its performance (meaning removing
these algorithms has no effect on the performance of P on the training set). Considering
the size of P is bounded (line 3), removing the redundant algorithms from P is meaningful
because this will leave space for new member algorithms that can improve the performance 

","The term ""PARHYDRA"" does not appear to be a widely recognized or established acronym in the context of the PAP (Participatory Action Planning) methodology. However, it's possible that PARHYDRA is an internal or locally developed term used within a specific organization or project.

If you're referring to an adaptation or localized version of a PAP approach, ""PARHYDRA"" could be an acronym meant to stand for a specific set of principles or steps tailored to the particular context in which it's being applied. Here’s how we might interpret each letter based on common practices in participatory research and action:

- **P** - Participatory
- **A** - Action
- **R** - Research (or Reflection)
- **H** - Health
- **Y** - Youth (if focusing on youth involvement)
- **D** - Development
- **R** - Rights

Without more context, it's difficult to provide a precise meaning. If you have additional information about the specific context or organization using this term, that would be helpful in providing a more accurate explanation.

If ""PARHYDRA"" is indeed an established approach, please provide more details so I can offer a more precise answer.",32.24822187423706,"The PAP approach called ""PARHYDRA"" is designed to construct parallel portfolios based on augmented training sets. Specifically, it utilizes a parallel portfolio for solving instances of problems, like SAT, without the need for instance features since it does not select among algorithms but rather integrates them. The method enhances traditional portfolio construction by testing each portfolio on a significantly larger augmented training set, thereby improving the chances of achieving strong performance across diverse problem scenarios. PARHYDRA involves generating a large set of instances from an initial training set, which is then used to develop and evaluate a parallel portfolio intended for efficient computational resource usage and optimal performance."
qwen2.5:7b-instruct-q4_0,"What is the idea behind the PAP approach called ""CLUSTERING""?
","Document 1: 
 with a constraint handling technique. At each generation, each
subpopulation generates new individuals based on its own.
Then, each subpopulation is combined with new individuals
generated by all subpopulations, and selection is conducted
with the corresponding constraint handling technique. Com-
pared to all the above-mentioned work, in which all search
biases have access to the whole population, PAP allows only
its constituent algorithms to work on a subpopulation, i.e.,
full access to the whole population is prohibited. Migration is
the only route that different subpopulations communicate with
each other. This strategy, used by PAP, reduces the likelihood
of different constituent algorithms repeating similar search
behaviors or sharing similar search biases.
From the perspective of employing a multipopulation model
and migration operators, PAP is related to the distributed
EAs (dEAs), which have several subpopulations (islands) and
perform sparse exchange of individuals among them [25],
[26]. However, PAP is quite different from previous dEAs
in three major ways. First, most dEAs run the same EA
on all subpopulations [26]–[31] (either with the same or
different control parameters), while PAP employs different
EAs. Second, the migration scheme of PAP does not assume
any topology of subpopulations, while many dEAs do. By
this means, we solely focus on investigating whether it is 

Document 2: 
 while the size of the configuration space involved in each
configuration task in PARHYDRAb, i.e., |C|b, would grow
exponentially as b gets larger. However, in general the best
value of b may vary across different scenarios, and for a spe-
cific scenario it is very hard to determine a good choice of b
in advance.
The third method CLUSTERING tackles the ACPP prob-
lem via explicit instance grouping. That is, it clusters the
problem instances represented in a normalized instance fea-
ture space into k subsets and then independently runs an
AC procedure on each subset to obtain a component solver.
Similar to PARHYDRAb, CLUSTERING also has an im-
portant design choice that is hard to determine in advance.
Specifically, the clustering result has great influence on the
performance of the final parallel portfolio. However, there
exists different normalization approaches that can be used
here, and different of them can result in different instance
clusters. Generally the appropriate choice of the normaliza-
tion approach may vary across different instance sets, and
the accurate assessment of the cluster quality is not possible
before the portfolio is constructed completely.
From a methodological perspective, ACPP methods based
on explicit instance grouping seek to achieve the comple-
mentarity among the component solvers by promoting each
of them to handle different subsets of the problem instances.
Thus for these methods the quality of the instance group- 

Document 3: 
 two algorithms. It also proposes a population-based algorithm
portfolio (PAP), which not only reduces the risk of failing on
problems from different classes, but also makes ﬁnding high-
quality solutions more likely.
The basic idea of PAP is simple: instead of betting the entire
time budget on a single algorithm, we “invest” our time in
multiple algorithms. This idea has been explored for more than
ten years, based on the theory of investment portfolios that was
developed in the ﬁeld of economics to answer the question:
“How should one allocate his/her ﬁnancial assets (stocks,
bonds, etc.) in order to maximize the expected returns while
minimizing risks” [4]. In analogy with investment portfolios,
PAP focuses on the problem of how to allocate computation
time among algorithms and fully utilize the advantages of
these algorithms in order to maximize the expected utility of a
1089-778X/$26.00 c⃝ 2010 IEEE
PENG et al.: POPULATION-BASED ALGORITHM PORTFOLIOS FOR NUMERICAL OPTIMIZATION 783
Fig. 1. Pseudo-code of PAP.
problem solving episode. Based on the portfolio idea, various
approaches have been developed, either to minimize the ex-
pected time needed to solve problem instances or to maximize
the expected quality of the solution while the available time
is kept constant. However, all the existing approaches were
proposed for combinatorial problems. For example, Huberman
et al.[5] proposed an economic approach for constructing 

Document 4: 
 that ihvr ∈(0, 1], and a larger value of ihvr is better. IHVR can distinguish well between
MOEAs with a different performance, and can also save a lot of calculations. In this work,
IHVR is used as the performance metric Metric .
4.3. Automatic Construction Approach
Algorithm 1 presents the automatic construction approach for MOEAs/PAP . Starting
from an empty set (line 2), the approach constructs the PAP (denoted as P) iteratively.
Speciﬁcally, each iteration of the approach (lines 3–15) consists of two subsequent phases.
In the ﬁrst phase, an existing automatic algorithm conﬁguration tool, namely SMAC 3 [44],
is used to search in Θ to ﬁnd the algorithm that can improve the performance of the current
PAP to the largest extent (line 5), and then this algorithm is inserted into P (line 6). This
phase is similar to the commonly-used greedy approach in the automatic construction of
PAPs [27,31]. Additionally, we introduce a new phase, namely simpliﬁcation, as the second
phase in Algorithm 1. In this phase (lines 7–14), P would be simpliﬁed by removing the
member algorithms that do not contribute at all to its performance (meaning removing
these algorithms has no effect on the performance of P on the training set). Considering
the size of P is bounded (line 3), removing the redundant algorithms from P is meaningful
because this will leave space for new member algorithms that can improve the performance 

Document 5: 
 constituent algorithm with a part of the given time budget and
encourages interaction among the constituent algorithms with a
migration scheme. As a general framework rather than a speciﬁc
algorithm, PAP is easy to implement and can accommodate
any existing population-based search algorithms. In addition, a
metric is also proposed to compare the risks of any two
algorithms on a problem set. We have comprehensively evaluated
PAP via investigating 11 instantiations of it on 27 benchmark
functions. Empirical results have shown that PAP outperforms
its constituent algorithms in terms of solution quality, risk, and
probability of ﬁnding the global optimum. Further analyses
have revealed that the advantages of PAP are mostly credited
to the synergy between constituent algorithms, which should
complement each other either over a set of problems, or during
different stages of an optimization process.
Manuscript received October 14, 2008; revised March 20, 2009, August
31, 2009, and November 30, 2009. Date of publication March 29, 2010; date
of current version October 1, 2010. This paper was partially supported by
the National Natural Science Foundation of China under Grants 60533020,
60802036 and U0835002, the Fund for Foreign Scholars in University
Research and Teaching Programs in China under Grant B07033, and the
Engineering and Physical Science Research Council in U.K. under Grant
EP/D052785/1 on “SEBASE: Software Engineering By Automated Search.”
F. Peng and K. Tang are with the Nature Inspired Computation and
Applications Laboratory, School of Computer Science and Technology, Uni- 

Document 6: 
 • When constructing MOEAs/PAPs, it is important to maintain the diversity among the
member algorithms. Hence, the population diversity preservation schemes, such as
negatively correlated search [47], can be introduced into the construction approach to
promote cooperation between different member algorithms.
• In real-world applications, one may be unable to collect sufﬁcient MOPs as training
problems. How to automatically build powerful PAPs in these scenarios is also
worth studying.
• The effectiveness of MOEAs/PAP has been primarily demonstrated through exper-
imental evidence, but with an absence of theoretical analysis. A more thorough
investigation of its exceptional performance is crucial for advancing our understand-
ing, which, in turn, can lead to enhancements in its design and the development of a
more comprehensive automatic construction algorithm.
Electronics 2023, 12, 4639 17 of 18
Author Contributions: Conceptualization, S.L.; Methodology, S.L.; Software, X.M.; Validation, X.M.;
Resources, X.M.; Writing—original draft, X.M.; Writing—review and editing, W.H.; Supervision, S.L.
and W.H. All authors have read and agreed to the published version of the manuscript.
Funding: This research was supported by the Strategic Priority Research Program of Chinese
Academy of Science, Grant No. XDB32050100, and the National Natural Science Foundation of
China, Grant No. 91948303.
Data Availability Statement: The data presented in this study are available on request from the 

","In the context of Particle Swarm Optimization (PSO) and its various modifications, including the Clustering-based PSO (C-PSO), clustering refers to a technique that groups particles into clusters based on their similarity. This approach aims to enhance the search process by focusing on promising areas in the search space.

The key idea behind using clustering in PSO is to leverage the collective intelligence of the swarm while avoiding premature convergence to local optima. Here's how it works:

1. **Cluster Formation**: Particles are grouped into clusters based on their positions or velocities. This grouping helps identify regions with high potential for containing global optima.

2. **Local Search within Clusters**: Within each cluster, particles continue to search the space as in standard PSO but with a focus on exploring and exploiting within the cluster boundaries. This ensures that the swarm doesn't get stuck in local minima prematurely.

3. **Global Search across Clusters**: Particles from different clusters can exchange information or influence each other, allowing for a broader exploration of the search space. This helps maintain diversity and prevents the swarm from converging too quickly to suboptimal solutions.

4. **Adaptive Mechanisms**: The clustering approach often includes mechanisms to dynamically adjust the size and composition of clusters based on the progress of the optimization process. This adaptability is crucial for effective search in non-uniform or complex landscapes.

By combining these elements, Clustering-based PSO (C-PSO) aims to balance exploration (searching new regions) and exploitation (refining solutions within identified promising areas), leading to more efficient and robust optimization results compared to traditional PSO.",40.53430795669556,"The idea behind the PAP approach called ""CLUSTERING"" involves tackling the Algorithm Configuration Problem (ACPP) through explicit instance grouping. Specifically, it clusters problem instances represented in a normalized instance feature space into k subsets, and then independently runs an Algorithm Configuration (AC) procedure on each subset to obtain a component solver. This method aims to achieve complementarity among the component solvers by allowing each of them to handle different subsets of the problem instances. However, the effectiveness of this method is significantly influenced by the quality of the clustering result, which can vary depending on the normalization approaches used. Thus, determining the appropriate normalization approach in advance poses a challenge."
qwen2.5:7b-instruct-q4_0,"What is the idea behind the PAP approach called ""PCIT""?
","Document 1: 
 paper has two major contributions. First, the proposed PAP is
developed for numerical optimization instead of combinatorial
optimization. Second, we investigate the term “risk” in a
different context. Previous work mainly aimed to reduce the
risk of an algorithm on a speciﬁc optimization problem, which
can be measured by applying the algorithm to the problem
for multiple times. In this paper, we are more interested in
reducing the risk overa set of problems , i.e., the risk is
measured by applying the algorithm to multiple problems.
Our PAP is a general framework for combining different
population-based search algorithms. It allocates computation
time among more than one constituent algorithm and acti-
vates interaction among them so that they can beneﬁt from
one another. To be more speciﬁc, the computation time is
measured by the number of ﬁtness evaluations (FEs), and
the allocation of FEs is implemented by dividing the whole
population into several subpopulations and evolving them in
a parallel manner (using different constituent algorithms). To
demonstrate the efﬁcacy of the proposed PAP, we chose four
existing population-based algorithms, including self-adaptive
differential evolution with neighborhood search (SaNSDE)
[7], particle swarm optimizer with inertia weight (wPSO)
[8], generalized generation gap (G3) model with generic
parent-centric recombination (PCX) operator (G3PCX) [9],
and covariance matrix adaptation evolution strategy (CMA-
ES) [10], as the constituent algorithms. These algorithms 

Document 2: 
 them.
PCIT conducts the instance transfer with the help of in-
cumbent configurations (i.e., the best configurations found
by the AC procedure). In each subset, the instances which
cannot be solved satisfactorily by the corresponding incum-
bent are identified as the ones that need to be transferred,
and the target subset of each transferred instance is deter-
mined according to how well the incumbent on the candi-
date subset could perform on the instance. In essence, the
incumbent on a subset can be seen as a common special
characteristic of those “similar” instances (in the sense they
share the same high-quality configurations) within the sub-
set, and PCIT uses it to identify those “dissimilar” instances
and find better subsets for them. In each subset, the perfor-
mance of the incumbent on each instance could be obtained
from the rundata collected from the AC procedure runs.
However, while determining the target subsets for the trans-
ferred instances, how well the incumbents on the candidate
subsets would perform on the transferred instances are un-
known. One way to obtain these performances is to actually
test these incumbents on the transferred instances, which
however would introduce considerable additional compu-
tational costs. To avoid this, PCIT builds empirical perfor-
mance models (EPM) (Hutter et al. 2014) based on the col-
lected rundata to predict these performances.
1562
Algorithm Framework 

Document 3: 
 analogous to the over-ﬁtting phenomenon in machine learning,
has been observed when the size of the training instance set
is rather limited (i.e., few-shots challenge). That is, the test
(generalization) performance of the obtained conﬁgurations is
arbitrarily bad even if their performance on the training set is
excellent. Even worse, given a T collected from real world,
it is non-trivial to know how to verify whether it is a good
representative of Ω. In case the training instance set is too
small, or is not a good representative of the whole problem
class, the best PAP obtained with it would fail to generalize.
B. Related Work
Currently, there exist several approaches for PAP con-
struction, namely GLOBAL [25], PARHYDRA [25], [26],
CLUSTERING [27] and PCIT [13]. GLOBAL considers PAP
construction as an algorithm conﬁguration problem by treating
Θ as a parameterized algorithm. By this means existing
automatic algorithm conﬁguration tools could be directly uti-
lized to conﬁgure all the component solvers of Θ simultane-
ously. In comparison, PARHYDRA constructs Θ iteratively
3
by identifying a single component solver in each iteration that
maximizes marginal performance contribution to the current
PAP. CLUSTERING and PCIT are two approaches based on
instance grouping. That is, they both ﬁrst split the training 

Document 4: 
 of the more state-of-the-art Plingeling. Such results indicate
PCIT could identify powerful parallel portfolios, with little
human effort involved. Thus the portfolios constructed by
PCIT could conveniently provide at least two advantages.
That is, they are high-quality parallel solvers, and they could
be used as starting points for the development of more ad-
Table 4: Test results of parallel solvers on the test set of SAT-
Single and SAT-Multi. The performance of a solver is shown
in boldface if it was not significantly different from the best
performance (according to a permutation test with 100000
permutations and significance level p = 0.05).
SAT-Single SAT-Multi
#TOS PAR-10 PAR-1 #TOS PAR-10 PAR-1
PCIT 181 119 21 35 1164 219
Priss6 225 146 25 - - -
PfolioUZK - - - 36 1185 213
Plinegling-bbc452 276 32 33 1090 199
vanced parallel solvers.
Conclusion
In this paper we proposed a novel ACPP method, named
PCIT, which utilized an instance transfer mechanism to im-
prove the quality of the instance grouping. The experimen-
tal results on two widely studied problem domains, SAT and
TSP, have demonstrated the effectiveness of PCIT. Currently
PCIT relies on the instance features to build the EPM. Since 

Document 5: 
 with a constraint handling technique. At each generation, each
subpopulation generates new individuals based on its own.
Then, each subpopulation is combined with new individuals
generated by all subpopulations, and selection is conducted
with the corresponding constraint handling technique. Com-
pared to all the above-mentioned work, in which all search
biases have access to the whole population, PAP allows only
its constituent algorithms to work on a subpopulation, i.e.,
full access to the whole population is prohibited. Migration is
the only route that different subpopulations communicate with
each other. This strategy, used by PAP, reduces the likelihood
of different constituent algorithms repeating similar search
behaviors or sharing similar search biases.
From the perspective of employing a multipopulation model
and migration operators, PAP is related to the distributed
EAs (dEAs), which have several subpopulations (islands) and
perform sparse exchange of individuals among them [25],
[26]. However, PAP is quite different from previous dEAs
in three major ways. First, most dEAs run the same EA
on all subpopulations [26]–[31] (either with the same or
different control parameters), while PAP employs different
EAs. Second, the migration scheme of PAP does not assume
any topology of subpopulations, while many dEAs do. By
this means, we solely focus on investigating whether it is 

Document 6: 
 that ihvr ∈(0, 1], and a larger value of ihvr is better. IHVR can distinguish well between
MOEAs with a different performance, and can also save a lot of calculations. In this work,
IHVR is used as the performance metric Metric .
4.3. Automatic Construction Approach
Algorithm 1 presents the automatic construction approach for MOEAs/PAP . Starting
from an empty set (line 2), the approach constructs the PAP (denoted as P) iteratively.
Speciﬁcally, each iteration of the approach (lines 3–15) consists of two subsequent phases.
In the ﬁrst phase, an existing automatic algorithm conﬁguration tool, namely SMAC 3 [44],
is used to search in Θ to ﬁnd the algorithm that can improve the performance of the current
PAP to the largest extent (line 5), and then this algorithm is inserted into P (line 6). This
phase is similar to the commonly-used greedy approach in the automatic construction of
PAPs [27,31]. Additionally, we introduce a new phase, namely simpliﬁcation, as the second
phase in Algorithm 1. In this phase (lines 7–14), P would be simpliﬁed by removing the
member algorithms that do not contribute at all to its performance (meaning removing
these algorithms has no effect on the performance of P on the training set). Considering
the size of P is bounded (line 3), removing the redundant algorithms from P is meaningful
because this will leave space for new member algorithms that can improve the performance 

","The Parent-Child Interaction Therapy (PCIT) is an evidence-based treatment approach designed to improve parent-child relationships and enhance children's social, emotional, and behavioral outcomes. PCIT was developed by Dr. David Olds in 1980 specifically for families with young children who have conduct problems or are at risk of developing them.

The core idea behind PCIT revolves around:

1. **Enhancing Positive Parent-Child Interactions**: PCIT focuses on increasing positive, nurturing interactions between parents and their children. This includes teaching parenting skills such as praise, encouragement, and modeling appropriate behavior for children to imitate.

2. **Behavioral Management Techniques**: The therapy also teaches parents how to effectively manage problem behaviors using techniques like time-out, redirection, and consistent discipline.

3. **Staged Learning Approach**: PCIT is structured into two stages:
   - **Observation Stage**: Parents observe a therapist interacting with their child while learning the skills.
   - **Active Play Stage**: Parents practice the skills in real-time under direct supervision by the therapist.

4. **Collaborative Relationship Building**: The goal is to build a collaborative relationship between parent and child, where both feel heard, supported, and understood.

5. **Empowerment**: PCIT aims to empower parents by equipping them with the knowledge and tools needed to manage their children's behaviors effectively without relying on punishment or yelling.

Overall, PCIT provides a comprehensive framework for addressing challenging behaviors in young children by focusing on improving parent-child relationships through skill-building and behavioral management techniques.",38.52834987640381,"The PAP approach called ""PCIT"" (Parallel Configuration Instance Transfer) utilizes an instance transfer mechanism to enhance the quality of instance grouping. It identifies ""dissimilar"" instances that cannot be solved satisfactorily by the corresponding incumbents found through an automatic configuration (AC) procedure. PCIT constructs a target subset for each transferred instance based on how well the incumbent configuration performs on similar instances, aiming to provide high-quality parallel solvers with minimal human intervention. It builds empirical performance models to predict how the incumbents would perform on transferred instances, thus avoiding significant computational costs. The effectiveness of PCIT has been demonstrated through experiments in problem domains such as SAT and TSP."
qwen2.5:7b-instruct-q4_0,"What is the idea behind the PAP approach called ""CEPS""?
","Document 1: 
 also presented. The performance of the two instantiations on
TSP and VRPSPDTW problems support the effectiveness of
CEPS in the sense that, in comparison with state-of-the-art
PAP construction approaches, the PAPs obtained by CEPS
achieves better generalization performance.
Since CEPS is a generic framework, some discussions
would help elaborate issues that are of signiﬁcance in practice.
First, although this work assumes CEPS takes a set of initial
training instances as the input, such training instances are
not necessarily real-world instances but could be generated
randomly. In other words, CEPS could be used in a fully cold-
start setting (a.k.a. zero-shot), i.e., no real-world instances are
available for the target problem class. Further, CEPS could
either be run ofﬂine or online, i.e., it could accommodate new
real instances whenever available.
Second, the potential of CEPS could be further explored
by taking advantage of the data generated during its run,
except for the ﬁnal obtained PAP. The data contain all the
sampled conﬁgurations and instances, and the performance
of the former on the latter. Considering that when using
a search method to solve a problem instance, its optimal
parameter values are usually problem-instance dependent and
thus need to be tuned. To tune parameters for a new problem
instance, we can learn from the historical data generated by
CEPS to build a mapping from problem instances to their
optimal parameter values, i.e., a low-cost online parameter- 

Document 2: 
 paper has two major contributions. First, the proposed PAP is
developed for numerical optimization instead of combinatorial
optimization. Second, we investigate the term “risk” in a
different context. Previous work mainly aimed to reduce the
risk of an algorithm on a speciﬁc optimization problem, which
can be measured by applying the algorithm to the problem
for multiple times. In this paper, we are more interested in
reducing the risk overa set of problems , i.e., the risk is
measured by applying the algorithm to multiple problems.
Our PAP is a general framework for combining different
population-based search algorithms. It allocates computation
time among more than one constituent algorithm and acti-
vates interaction among them so that they can beneﬁt from
one another. To be more speciﬁc, the computation time is
measured by the number of ﬁtness evaluations (FEs), and
the allocation of FEs is implemented by dividing the whole
population into several subpopulations and evolving them in
a parallel manner (using different constituent algorithms). To
demonstrate the efﬁcacy of the proposed PAP, we chose four
existing population-based algorithms, including self-adaptive
differential evolution with neighborhood search (SaNSDE)
[7], particle swarm optimizer with inertia weight (wPSO)
[8], generalized generation gap (G3) model with generic
parent-centric recombination (PCX) operator (G3PCX) [9],
and covariance matrix adaptation evolution strategy (CMA-
ES) [10], as the constituent algorithms. These algorithms 

Document 3: 
 this approach no longer guarantees the validity of the above
assumption. As a consequence, Θ′may generalize worse than
Θ. A remedy to prevent this as much as possible is to increase
redundancy in the evolution of the PAP. More speciﬁcally, one
could repeat the conﬁguration-removal procedure to Θ for n
times, leading to ntemporary PAPs, ¯Θ1,..., ¯Θn; then for each
temporary PAP ¯Θ, the new conﬁgurations are identiﬁed and
inserted, leading to n new PAPs, Θ′
1,..., Θ′
n, each of which
is of the same size as Θ; ﬁnally, the PAP among them that
performs best against T ∪T′ is retained.
III. C O-EVOLUTION OF PARAMETERIZED SEARCH
By incorporating the above-described procedure into the co-
evolution process, we arrive at the proposed CEPS framework,
as demonstrated in Algorithm 1. In general, CEPS consists
of two major phases, i.e., an initialization phase (lines 2-
7), and a co-evolution phase (lines 8-27) which could be
further subdivided into alternating between the evolution of
the conﬁguration population (representing the PAP) (lines 10-
15) and the evolution of the instance population (representing
the training instances) (lines 17-26) for MaxIte iterations in
total. These modules are detailed as follows. 

Document 4: 
 contributions of this paper include:
1) A novel PAP construction framework, namely Co-
Evolution of Parameterized Search (CEPS), is proposed.
It is also shown that CEPS approximates a process that
minimizes the upper bound, i.e., a tractable surrogate,
of the generalization performance.
2) To demonstrate the implementation details of CEPS as
well as to assess its potential, concrete instantiations are
also presented for two hard optimization problems, i.e.,
TSP and the Vehicle Routing Problem with Simultane-
ous Pickup–Delivery and Time Windows (VRPSPDTW)
[18]. Computational studies conﬁrm that CEPS is able
to obtain PAPs with better generalization performance.
3) The proposal of CEPS extends the realm of Co-
Evolution, for the ﬁrst time, to evolving algorithm
conﬁgurations and problem instances. Since CEPS does
not invoke domain-speciﬁc knowledge, its potential ap-
plications can go beyond optimization problems, even to
planning and learning problems.
The rest of the paper is organized as follows. Section II in-
troduces the challenge of seeking generalizable PAPs, existing
PAP construction methods, as well as the theoretical insight
behind CEPS. Section III presents the CEPS framework. Sec-
tion IV presents its instantiations for TSP and VRPSPDTW.
Computational studies on these two problems are presented in
Section V. Threats to validity of this study are discussed in 

Document 5: 
 that ihvr ∈(0, 1], and a larger value of ihvr is better. IHVR can distinguish well between
MOEAs with a different performance, and can also save a lot of calculations. In this work,
IHVR is used as the performance metric Metric .
4.3. Automatic Construction Approach
Algorithm 1 presents the automatic construction approach for MOEAs/PAP . Starting
from an empty set (line 2), the approach constructs the PAP (denoted as P) iteratively.
Speciﬁcally, each iteration of the approach (lines 3–15) consists of two subsequent phases.
In the ﬁrst phase, an existing automatic algorithm conﬁguration tool, namely SMAC 3 [44],
is used to search in Θ to ﬁnd the algorithm that can improve the performance of the current
PAP to the largest extent (line 5), and then this algorithm is inserted into P (line 6). This
phase is similar to the commonly-used greedy approach in the automatic construction of
PAPs [27,31]. Additionally, we introduce a new phase, namely simpliﬁcation, as the second
phase in Algorithm 1. In this phase (lines 7–14), P would be simpliﬁed by removing the
member algorithms that do not contribute at all to its performance (meaning removing
these algorithms has no effect on the performance of P on the training set). Considering
the size of P is bounded (line 3), removing the redundant algorithms from P is meaningful
because this will leave space for new member algorithms that can improve the performance 

Document 6: 
 cores each (2.20 GHz, 30 MB Cache), running Centos 7.5.
D. Results and Analysis
We report the #TOs, PAR-10 and PANC achieved by the
PAPs on the testing set in Table II and also visualize their
medians and variance across all the testing instances by box-
plots in Figure 1. Note the mean value is also plotted in Figure
1 (indicated by “ ▲”) to show that for a PAP how its PAR-
10/PANC is affected by the outliers (the timeout cases) which
would be hidden by boxplots. In Table II the #TOs, PAR-
10/PANC of a PAP is highlighted in grey if it achieved the best
performance. One could make three important observations
from these results. First, the PAPs obtained by CEPS have
the smallest number of timeouts in all the six experiments,
which means they have the highest success rate for solving the
testing instances among all the tested PAPs. Recall that CEPS
actively searches in the instance space to identify the hard-
to-solve instances for further improving the generalization of
the PAPs. Such a mechanism makes CEPS the method that is
least affected by the hard testing instances which signiﬁcantly
differs from the given training instances. This could be further
veriﬁed by Figure 1, in which CEPS is the method that has
the least gap between the mean value (which takes timeouts
into account) and median value (which naturally ﬁlters out the 

","The term ""CEPS"" in the context of the PAP (Policy Advice and Planning) approach typically refers to a specific framework or methodology used for policy analysis, decision-making, and planning. However, without more specific information about the organization or source that uses this terminology, it's challenging to provide an exact definition.

If you're referring to a particular institution or context where ""CEPS"" is used in relation to PAP (Policy Advice and Planning), here are some general ideas about what CEPS might stand for:

1. **Centre for European Policy Studies (CEPS)**: This is a think tank based in Brussels, Belgium, that focuses on policy research related to the European Union and broader international issues. While not directly tied to PAP, it could be an organization that uses PAP methodologies.

2. **Cost-Effectiveness in Planning Strategy**: In some contexts, ""CEPS"" might stand for a method of assessing the cost-effectiveness of different planning strategies or policy options.

3. **Combined Effectivity and Performance Standards**: This is less common but might refer to a framework combining different metrics to evaluate the performance and effectiveness of policies or programs.

4. **Cognitive Enhancement in Planning Systems**: In some academic or research contexts, ""CEPS"" could stand for a method that enhances cognitive processes in planning systems by integrating various analytical tools and methodologies.

To provide a more precise answer, it would be helpful to know:

- The specific organization or context where you encountered the term ""CEPS.""
- Any additional details about how this term is being used in relation to PAP.
- Whether there are any acronyms or terms that follow ""CEPS"" (e.g., CEPS-Tax, CEPS-Plan).

If you can provide more context, I would be better equipped to offer a detailed explanation.",44.97544360160828,"The PAP approach called ""Co-Evolution of Parameterized Search"" (CEPS) is designed to enhance the construction of Parameterized Algorithm Portfolios (PAPs) by effectively combining different population-based search algorithms. The key idea behind CEPS is to co-evolve both algorithm configurations and problem instances, which allows the framework to learn from both the algorithms and the specific characteristics of the problems being solved. The framework consists of two main phases: an initialization phase and a co-evolution phase that alternates between evolving a configuration population (representing the PAP) and an instance population (representing the training instances). CEPS aims to reduce the generalization error of PAPs across a set of problems rather than on individual instances, facilitating adaptation to varying types of problems for better overall performance. This approach also supports both offline and online operations, making it flexible in handling incoming problem instances."
qwen2.5:7b-instruct-q4_0,"Please give me the names of some state-of-the-art SAT solvers.
","Document 1: 
 of determining whether a Boolean formula can 
evaluate to true, benefits from very mature and 
advanced algorithms with large practical impact.
Application and research domains like software 
and hardware verification, automated planning,
computational biology, and many others benefit 
from modern SAT solvers. These domains have 
large and difficult instances that provide the SAT 
community with meaningful benchmarks. 
Most of the following challenges are general in 
such a way that the questions they raise should 
positively affect not only research in parallel SAT 
but in parallel search in general. We first present 
the current situation in sequential and parallel SAT 
solving and then give a set of challenges. Each of 
these challenges comes with an overly optimistic 
estimate of its inherent difficulty represented as 
black circles, where we would estimate that every 
black circle represents, roughly, about two years of 
research. 
Context: Sequential SAT Solvers 
State-of-the-art solvers extend the original Davis,
Putnam, Logemann, and Loveland (DPLL) proce -
dure (Davis, Logemann, and Loveland 1962) with 
conflict analysis (Zhang et al. 2001). The general
architecture of such conflict-directed clause-learn -
ing solvers (CDCL) is presented in figure 1. These 
procedures include an optional preprocessing step 
0, which performs variable elimination and clause 
subsumption checks in order to reduce the size of 
the formula and improve the performance of the 

Document 2: 
 Intelligence (AAAI’02), (pp. 674–681). AAAI Press / The MIT Press, Menlo Park, CA, USA.
KhudaBukhsh, A., Xu, L., Hoos, H. H., & Leyton-Brown, K. (2009). SATenstein: Automatically building lo-
cal search sat solvers from components. In Proceedings of the Twenty-ﬁrst International Joint Conference
on Artiﬁcial Intelligence (IJCAI’09), (pp. 517–524).
Le Berre, D. & Simon, L. (2004). Fifty-ﬁve solvers in Vancouver: The SAT 2004 competition. In Hoos, H. H.
& Mitchell, D. G. (Eds.), Theory and Applications of Satisﬁability Testing: Proceedings of the Seventh
International Conference (SAT’04), volume 3542 of Lecture Notes in Computer Science , (pp. 321–344).
Springer Verlag.
Leyton-Brown, K., Nudelman, E., & Shoham, Y . (2002). Learning the empirical hardness of optimization
problems: The case of combinatorial auctions. In Hentenryck, P. V . (Ed.), Principles and Practice of
Constraint Programming – CP 2002: Eighth International Conference , volume 2470 of Lecture Notes in
Computer Science, (pp. 556–572). Springer Verlag, Berlin, Germany. 

Document 3: 
 212
state-of-the-art SLS algorithms. SATenstein-LS has
41 parameters that control the selection and behavior of
its components, leading to a total conﬁguration space of
size 4.82 ×1012. Automatically-identiﬁed conﬁgurations of
SATenstein-LS have been shown to achieve better per-
formance than existing state-of-the-art SLS algorithms on
several well-known instance distributions.
Instances
We investigated the effectiveness of Hydra on four distri-
butions, drawing on well-known families of SAT instances.
Because no state-of-the-art SLS algorithms are able to prove
unsatisﬁability, we considered only satisﬁable instances. We
identiﬁed these by running all complete algorithms that won
a SAT competition category between 2002 and 2007 for
one hour. First, the BM data set is constructed from 500
instances taken from each of the six distributions used by
KhudaBukhsh et al. (2009) (
QCP, SWGCP, FACT, CBMC,
R3FIX, and HGEN), split evenly into training and test sets.
Second, the INDU data set is a mixture of 500 instances
from each of the CBMC and FACT distributions, again split
evenly into training and test sets. Third and fourth, the HAND
and RAND data sets include all satisﬁable instances from the
Random and Handmade categories of the SAT Competitions 

Document 4: 
 form (a conjunction of disjunctions of variables and their negations) and determine a satisﬁable assignment or prove that 
none exists. An incomplete SAT solver can ﬁnd satisfying assignments, but not prove unsatisﬁability.
Most state-of-the-art complete SAT solvers are based on conﬂict-driven clause learning (CDCL; [57]). Their parameters 
control variable selection for branching decisions, clause learning and restart techniques. State-of-the-art incomplete SAT 
solvers use stochastic local search (SLS; [38]), and their parameters control the selection of the variable whose value is 
modiﬁed in each local search step as well as the diversiﬁcation and additional intensiﬁcation strategies. Furthermore, there 
exist several preprocessing techniques (e.g., [21]) to simplify formulas and their parameters control how long and how 
aggressive preprocessing will be used – too much preprocessing can remove important structural information and hence, 
it can increase the hardness of formulas. The eﬃcacy of SAT solvers depends on multiple heuristic components whose 
basic functions and the interplay between them are controlled by parameters. Some parameters are categorical (e.g., choice 
between different search strategies in SLS), while many others are integer- or real-valued (e.g., the damping factor used in 
computing heuristic variable scores in CDCL).
Parallel SAT solvers have received increasing attention in recent years. ManySAT [30,31,29] was one of the ﬁrst parallel 

Document 5: 
 tial solver baselines, indicating the great benefit by combin-
ing complementary configurations obtained from a rich con-
figuration space.
Comparison with Hand-designed Parallel Solvers
To further evaluate the portfolios constructed by PCIT, we
compared them with the state-of-the-art manually designed
parallel solvers. Specifically, we considered the ones con-
structed for SAT. We chose Priss6 (Manthey, Stephan, and
Werner 2016) to compare with the one constructed in SAT-
Single, since Priss6 is the official parallel version of Riss6
(the base solver in SAT-Single). For the same reason, we
chose PfolioUZK (Wotzlaw et al. 2012) (the gold medal
winning solver of the parallel track of the SAT’12 Chal-
lenge) to compare with the one constructed in SAT-Multi.
Finally, we chose Plingeling (version bbc) (Biere 2016),
the gold medal winning solver of the parallel track of the
SAT’16 Competition, to compare with both. Note that all
the manually designed solvers considered here have imple-
mented far more advanced parallel solving strategies (e.g.,
clause sharing) than only independently running component
solvers in parallel. In the experiments the default settings of
these solvers were used and the same statistical tests as be-
fore were conducted. As shown in Table 4, on SAT-Single 

Document 6: 
 ACM 52(10):56–67.
Balyo, T.; Heule, M. J. H.; and J¨arvisalo, M., eds. 2016. Proceed-
ings of SAT Competition 2016: Solver and Benchmark Descrip-
tions, volume B-2016-1 of Department of Computer Science Se-
ries of Publications B. University of Helsinki.
Battiti, R.; Brunato, M.; and Mascia, F., eds. 2008. Reactive
Search and Intelligent Optimization. Springer.
Biere, A. 2016. Splatz, Lingeling, Plingeling, Treengeling, Yal-
SAT Entering the SAT Competition 2016. In Balyo et al. (2016),
44–45.
Burke, E. K.; Gendreau, M.; Hyde, M.; Kendall, G.; Ochoa, G.;
¨Ozcan, E.; and Qu, R. 2013. Hyper-heuristics: A Survey of the
State of the Art. Journal of the Operational Research Society
64(12):1695–1724.
Gomes, C. P., and Selman, B. 2001. Algorithm Portfolios. Arti-
ficial Intelligence 126(1-2):43–62.
Hamadi, Y ., and Wintersteiger, C. M. 2013. Seven Challenges in
Parallel SAT Solving. AI Magazine 34(2):99–106. 

","Some state-of-the-art SAT solvers include ManySAT, Priss6 (official parallel version of Riss6), PfolioUZK, and Plingeling (version bbc).",10.001795768737791,"Some state-of-the-art SAT solvers include SATenstein, Priss6, PfolioUZK, and Plingeling."
qwen2.5:7b-instruct-q4_0,"Please give me the names of some state-of-the-art TSP solvers.
","Document 1: 
 For surveys of the problem and its applications, the reader is referred to the excellent
volumes edited by Lawler et al. [24] and Gutin and Punnen [11].
Local search with k-exchange neighborhoods, k-opt, is the most widely used heu-
ristic method for the TSP. k-opt is a tour improvement algorithm, where in each step
k links of the current tour are replaced by k links in such a way that a shorter tour is
achieved.
It has been shown [7] that k-opt may take an exponential number of iterations and
that the ratio of the length of an optimal tour to the length of a tour constructed byk-opt
can be arbitrarily large when k ≤ n/2 − 5. Such undesirable cases, however, are very
rare when solving practical instances [31]. Usually, high-quality solutions are obtained
in polynomial time. This is, for example, the case for the Lin–Kernighan heuristic,
one of the most effective methods for generating optimal or near-optimal solutions
for the symmetric TSP. High-quality solutions are often obtained, even though only a
small part of the k-exchange neighborhood is searched.
In the original version of the Lin–Kernighan heuristic [ 25], the allowable
k-exchanges (or k-opt moves) are restricted to those that can be decomposed into a
2- or 3-exchange followed by a (possibly empty) sequence of 2-exchanges. This restric- 

Document 2: 
 of determining whether a Boolean formula can 
evaluate to true, benefits from very mature and 
advanced algorithms with large practical impact.
Application and research domains like software 
and hardware verification, automated planning,
computational biology, and many others benefit 
from modern SAT solvers. These domains have 
large and difficult instances that provide the SAT 
community with meaningful benchmarks. 
Most of the following challenges are general in 
such a way that the questions they raise should 
positively affect not only research in parallel SAT 
but in parallel search in general. We first present 
the current situation in sequential and parallel SAT 
solving and then give a set of challenges. Each of 
these challenges comes with an overly optimistic 
estimate of its inherent difficulty represented as 
black circles, where we would estimate that every 
black circle represents, roughly, about two years of 
research. 
Context: Sequential SAT Solvers 
State-of-the-art solvers extend the original Davis,
Putnam, Logemann, and Loveland (DPLL) proce -
dure (Davis, Logemann, and Loveland 1962) with 
conflict analysis (Zhang et al. 2001). The general
architecture of such conflict-directed clause-learn -
ing solvers (CDCL) is presented in figure 1. These 
procedures include an optional preprocessing step 
0, which performs variable elimination and clause 
subsumption checks in order to reduce the size of 
the formula and improve the performance of the 

Document 3: 
 10.0 
12.5 
15.0 
17.5 PAR-10 (c) TSP-3
Fig. 2: Visual comparison in boxplots of the medians and variance of the test performance of each TSP solver across the
testing instances. Note the mean value is also plotted, indicated by “ ▲”.
TABLE III: Comparison of the state-of-the-art TSP solvers
with the PAPs obtained by CEPS, on the testing set. #TOs
refers to number of total timeouts. PAR-10 is the penalized
average runtime-10. Performance of a solver is highlighted in
grey if it achieved the best testing performance.
TSP-1 TSP-2 TSP-3
#TOs PAR-10 #TOs PAR-10 #TOs PAR-10
LKH-default 131 30.84 137 31.98 150 34.73
LKH-tuned 29 8.23 34 9.40 27 7.67
EAX-default 69 17.98 73 18.91 69 17.95
EAX-tuned 33 10.97 30 10.38 29 10.12
VBS 6 3.82 7 4.26 6 4.13
CEPS 6 2.74 4 2.15 2 1.94
signiﬁcant performance improvement, though still obviously
falling behind of the PAPs obtained by CEPS. Second, the only
solver that could match the PAP’s performance level in one
of the three scenarios, is the VBS of the algorithm portfolio
considered by the algorithm selection approaches [29], [30].
However, in TSP-2 and TSP-3, the performance advantage of 

Document 4: 
 troduces the challenge of seeking generalizable PAPs, existing
PAP construction methods, as well as the theoretical insight
behind CEPS. Section III presents the CEPS framework. Sec-
tion IV presents its instantiations for TSP and VRPSPDTW.
Computational studies on these two problems are presented in
Section V. Threats to validity of this study are discussed in
Section VI. Section VII concludes the paper with discussions.
II. P ARAMETERIZED SOLVERS MADE GENERALIZABLE
A. Notations and Problem Description
Assume a PAP is to be built for a problem class (e.g., TSP),
for which an instance of the problem class is denoted as s, and
the set of all possible sis denoted as Ω. Given a parameterized
algorithm, each component solver of the PAP is a conﬁguration
(full instantiation) of the algorithm. Generally speaking, the
parameterized algorithm can be any concrete computational
process, e.g., a traditional heuristic search process such as the
LK Heuristic for TSP or even a neural network [19]–[21] that
outputs a solution for a given instance of the target problem
class. Let θ denote a conﬁguration and let Θ denote a PAP
that contains K different conﬁgurations (component solvers),
i.e., Θ = {θ1,...,θ K}. The quality of a conﬁguration θ on a 

Document 5: 
 H. Trautmann, “Evolving diverse TSP instances by means of novel and
creative mutation operators,” in Proceedings of the 15th ACM/SIGEVO
Conference on Foundations of Genetic Algorithms, FOGA’2019. Pots-
dam, Germany: ACM, Aug 2019, pp. 58–71.
[38] Y . Nagata and S. Kobayashi, “A powerful genetic algorithm using edge
assembly crossover for the traveling salesman problem,” INFORMS
Journal on Computing , vol. 25, no. 2, pp. 346–363, 2013.
[39] X. Xie and J. Liu, “Multiagent optimization system for solving the
traveling salesman problem (tsp),” IEEE Transactions on Systems, Man,
and Cybernetics, Part B , vol. 39, no. 2, pp. 489–502, 2009.
[40] C. Wang, D. Mu, F. Zhao, and J. W. Sutherland, “A parallel simulated
annealing method for the vehicle routing problem with simultaneous
pickup-delivery and time windows,” Computers & Industrial Engineer-
ing, vol. 83, pp. 111–122, 2015.
[41] W. Huang and T. Zhang, “Vehicle routing problem with simultaneous
pick-up and delivery and time-windows based on improved global arti-
ﬁcial ﬁsh swarm algorithm,” Computer Engineering and Applications ,
vol. 52, no. 21, pp. 21–29, 2016. 

Document 6: 
 Portfolio-based algorithm selection for SAT,” Journal of Artiﬁcial In-
telligence Research, vol. 32, pp. 565–606, 2008.
[29] P. Kerschke, L. Kotthoff, J. Bossek, H. H. Hoos, and H. Trautmann,
“Leveraging TSP solver complementarity through machine learning,”
Evolutionary Computation, vol. 26, no. 4, pp. 597–620, 2018.
[30] K. Zhao, S. Liu, Y . Rong, and J. X. Yu, “Leveraging TSP solver
complementarity via deep learning,” arXiv preprint arXiv:2006.00715 ,
2020.
[31] L. Kotthoff, “Algorithm selection for combinatorial search problems: A
survey,” AI Magazine, vol. 35, no. 3, pp. 48–60, 2014.
[32] C. D. Rosin and R. K. Belew, “New methods for competitive coevolu-
tion,” Evolutionary Computation, vol. 5, no. 1, pp. 1–29, 1997.
[33] J. I. van Hemert, “Evolving combinatorial problem instances that are
difﬁcult to solve,” Evolutionary Computation , vol. 14, no. 4, pp. 433–
462, 2006.
[34] K. Helsgaun, “General k-opt submoves for the Lin-Kernighan TSP 

","Certainly! Here are some state-of-the-art Traveling Salesman Problem (TSP) solvers:

1. **Concorde TSP Solver**:
   - **Website**: http://www.math.uwaterloo.ca/tsp/concorde.html
   - **Description**: Concorde is one of the most well-known and widely used exact algorithms for solving TSP instances to optimality. It uses a combination of branch-and-cut techniques.

2. **Google OR-Tools**:
   - **Website**: https://developers.google.com/optimization/
   - **Description**: Google's open-source tools include an extensive suite of solvers, including the Routing Library which has powerful TSP and Vehicle Routing Problem (VRP) capabilities.

3. **LKH (Lin-Kernighan-Helsgaun)**:
   - **Website**: http://www.ak-solver.com/
   - **Description**: LKH is a heuristic solver that can find near-optimal solutions to the TSP quickly, often outperforming exact methods on large instances.

4. **TSPLIB** (not a solver but a library of TSP instances):
   - **Website**: http://www.iwr.uni-heidelberg.de/groups/comopt/software/TSPLIB95/
   - **Description**: TSPLIB is a collection of benchmark instances for the TSP and related problems, often used in testing and comparing different solvers.

5. **Google OR-Tools with SA (Simulated Annealing)**:
   - **Website**: https://developers.google.com/optimization/
   - **Description**: Google OR-Tools also offers a simulated annealing solver that can find near-optimal solutions for TSP instances using heuristic methods.

6. **Concorde's Branch-and-Cut Solver**:
   - **Description**: This is an exact method that uses advanced branch-and-cut techniques to solve TSP instances optimally, especially useful for smaller to medium-sized problems.

7. **VRP Solver with TSP Integration**:
   - **Description**: While primarily a vehicle routing solver, VRP solvers like those found in Google OR-Tools can also handle TSP by treating each node as a delivery point and eliminating the vehicle dimension.

8. **Rapid-Hull Algorithm (RHA)**:
   - **Description**: RHA is a heuristic algorithm that provides fast approximations to the TSP, often used in large-scale problems where exact solutions are impractical.

These solvers cover a range of approaches from exact algorithms to heuristics and can be chosen based on the specific requirements of your problem, such as instance size and need for optimality or just good approximate solutions.",65.15470337867737,"Some state-of-the-art TSP solvers mentioned include the Lin–Kernighan heuristic (LKH), the Effective Ant Colony (EAX), and the Variable Neighborhood Search (VBS). These solvers have been compared in performance metrics such as PAR-10 and number of timeouts (TOs) across different testing instances."
qwen2.5:7b-instruct-q4_0,"Please give me the names of some state-of-the-art Automatic Algorithm Configuration approaches.
","Document 1: 
 Journal of Artiﬁcial Intelligence Research 75 (2022) 425-487 Submitted 02/2022; published 10/2022
A Survey of Methods for Automated
Algorithm Conﬁguration
Elias Schede elias.schede@uni-bielefeld.de
Decision and Operation Technologies Group,
Bielefeld University, Bielefeld, Germany
Jasmin Brandt jasmin.brandt@upb.de
Alexander Tornede alexander.tornede@upb.de
Department of Computer Science,
Paderborn University, Paderborn, Germany
Marcel Wever marcel.wever@ifi.lmu.de
Institute of Informatics, LMU Munich &
Munich Center for Machine Learning, Munich, Germany
Viktor Bengs viktor.bengs@ifi.lmu.de
Institute of Informatics,
LMU Munich, Munich, Germany
Eyke H¨ ullermeier eyke@lmu.de
Institute of Informatics, LMU Munich &
Munich Center for Machine Learning, Munich, Germany
Kevin Tierney kevin.tierney@uni-bielefeld.de
Decision and Operation Technologies Group,
Bielefeld University, Bielefeld, Germany
Abstract
Algorithm conﬁguration (AC) is concerned with the automated search of the most
suitable parameter conﬁguration of a parametrized algorithm. There is currently a wide
variety of AC problem variants and methods proposed in the literature. Existing reviews 

Document 2: 
 2 Related Work
2.1 Automatic Algorithm Conﬁguration
Several approaches exist in the literature for the automatic tuning
of algorithms. Some of these were created for a speciﬁc algorithm
or task. For example, [24] devises a modular algorithm for solving
constraint satisfaction problems (CSPs). Using a combination of ex-
haustive enumeration of all possible conﬁgurations and parallel hill-
climbing, the technique automatically conﬁgures the system for a
given set of training instances. Another approach, presented in [30],
focuses on the conﬁguration of adaptive algorithms, employing a se-
quential parameter optimization approach.
Other approaches automatically design and build an entire solver
to best tackle a set of example training instances. For example, [28]
uses genetic programming to create an evolutionary algorithm (EA).
Here the chromosome is an EA operation like the selection of par-
ents, mutation, or crossover, and the task is to ﬁnd a sequence of
the genetic programming operators that is best suited for the speci-
ﬁed problem. For SAT, [8] classiﬁes local search (LS) approaches by
means of context-free grammars. This approach then uses a genetic
programming approach to select a good LS algorithm for a given set
of instances.
There also exist approaches that are applicable to more general al-
gorithms. For example, in order to tune continuous parameters, [5]
suggests an approach that determines good parameters for individual
training instances. This approach ﬁrst evaluates the extreme param- 

Document 3: 
 470
A Survey of Methods for Automated Algorithm Configuration
General AC systems
D-SMAC https://github.com/tqichun/distributed-SMAC3
GPS https://github.com/YashaPushak/GPS
irace https://github.com/MLopez-Ibanez/irace
OAT (GGA) https://docs.optano.com/algorithm.tuner/current/
ParamILS https://www.cs.ubc.ca/labs/algorithms/Projects/ParamILS/
PyDGGA http://ulog.udl.cat/software/
REVAC https://github.com/ChrisTimperley/RubyREVAC
SMAC 3 https://github.com/automl/SMAC3
Benchmarks
AClib https://bitbucket.org/mlindauer/aclib2/src/master/
DAC https://github.com/automl/DAC
Table 7: List of available software in the realm of AC.
References
Belarmino Adenso-Diaz & Manuel Laguna. Fine-tuning of algorithms using fractional ex-
perimental designs and local search. Operations research, 54(1):99–114, 2006.
¨Ozg¨ ur Akg¨ un, Nguyen Dang, Ian Miguel, Andr´ as Z Salamon, & Christopher Stone. In- 

Document 4: 
 cal (e.g., choice of heuristic). Categorical parameters can be used to select and combine discrete
building blocks of an algorithm (e.g., preprocessing and variable ordering heuristics); consequently,
our general view of algorithm conﬁguration includes the automated construction of a heuristic algo-
rithm from such building blocks. To the best of our knowledge, the methods discussed in this article
are yet the only general ones available for the conﬁguration of algorithms with many categorical
parameters.
We now give an overview of what follows and highlight our main contributions. After for-
mally stating the algorithm conﬁguration problem in Section 2, in Section 3 we describe ParamILS
(ﬁrst introduced by Hutter, Hoos & St ¨utzle, 2007), a versatile stochastic local search approach for
automated algorithm conﬁguration, and two of its instantiations, BasicILS and FocusedILS.
We then introduce adaptive capping of algorithm runs, a novel technique that can be used to
enhance search-based algorithm conﬁguration procedures independently of the underlying search
strategy (Section 4). Adaptive capping is based on the idea of avoiding unnecessary runs of the
algorithm to be conﬁgured by developing bounds on the performance measure to be optimized.
We present a trajectory-preserving variant and a heuristic extension of this technique. After dis-
cussing experimental preliminaries in Section 5, in Section 6 we present empirical evidence show-
ing that adaptive capping speeds up both BasicILS and FocusedILS. We also show that BasicILS
268 

Document 5: 
 rithm conﬁguration that minimizes some cost measure over the 
set of instances that will be seen during the production phase. 
In other words, the ﬁnal goal is that the conﬁguration of the al- 
gorithm found during the tuning phase generalizes to similar but 
unseen instances. The tuning phase may also use automatic conﬁg- 
uration methods repeatedly while engineering an algorithm [71] . 
Due to the separation between a tuning and a production phase, 
automatic algorithm conﬁguration is also known as oﬄine param- 
eter tuning to differentiate it from online approaches that adapt or 
control parameter settings while solving an instance [13,50] . Nev- 
ertheless, online approaches also contain parameters that need to 
be deﬁned oﬄine, for example, which and how parameters are 
adapted at run-time; such parameters and design choices can be 
conﬁgured by an oﬄine tuning method [59] . 
In our research on making the algorithm conﬁguration process 
more automatic , we have focused on racing approaches. Birattari 
et al. [19,20] proposed an automatic conﬁguration approach, F- 
Race, based on racing [64] and Friedman’s non-parametric two-way 
analysis of variance by ranks. This proposal was later improved 
by sampling conﬁgurations from the parameter space, and reﬁn- 
ing the sampling distribution by means of repeated applications of 
F-Race. The resulting automatic conﬁguration approach was called 
Iterated F-race (I/F-Race) [10,21] . Although a formal description of 

Document 6: 
 formance of FocusedILS [43], and we are convinced that, at least in cases where
the parameter response of a given target algorithm is reasonably regular and per-
formance evaluations are very costly, such advanced SMBO methods hold great
promise.
3.6 Conclusions and Future Work
Automated algorithm conﬁguration and parameter tuning methods have been de-
veloped and used for more than a decade, and many of the fundamental techniques
date back even further. However, it has only recently become possible to effectively
solve complex conﬁguration problems involving target algorithms with dozens of
parameters, which are often categorical and conditional. This success is based in
3 Automated Algorithm Conﬁguration and Parameter Tuning 65
part on the increased availability of computational resources, but has mostly been
enabled by methodological advances underlying recent conﬁguration procedures.
Still, we see much room (and, indeed, need) for future work on automated algo-
rithm conﬁguration and parameter tuning methods. We believe that in developing
such methods, the fundamental features underlying all three types of methods dis-
cussed in this chapter can play an important role, and that the best methods will
employ combinations of these. We further believe that different conﬁguration pro-
cedures will likely be most effective for solving different types of conﬁguration
problems (depending, in particular, on the number and type of target algorithm pa-
rameters, but also on regularities in the parameter response). Therefore, we see a
need for research aiming to determine which conﬁgurator is most effective under 

","Some state-of-the-art Automatic Algorithm Configuration approaches include D-SMAC, ParamILS, and Iterated F-Race (I/F-Race). These methods have shown effectiveness in configuring algorithms with many parameters, often using advanced Sequential Model-Based Optimization techniques.",11.397127628326416,"Some state-of-the-art Automatic Algorithm Configuration approaches include D-SMAC, GPS, irace, OAT (GGA), ParamILS, PyDGGA, REVAC, and SMAC 3."
qwen2.5:7b-instruct-q4_0,"What is the idea behind the AAC approach called ""irace""?
","Document 1: 
 analysis of variance by ranks. This proposal was later improved 
by sampling conﬁgurations from the parameter space, and reﬁn- 
ing the sampling distribution by means of repeated applications of 
F-Race. The resulting automatic conﬁguration approach was called 
Iterated F-race (I/F-Race) [10,21] . Although a formal description of 
the I/F-Race procedure is given in those publications, an imple- 
mentation was not made publicly available. The irace package im- 
plements a general iterated racing procedure, which includes I/F- 
Race as a special case. It also implements several extensions al- 
ready described by Birattari [19] , such as the use of the paired 
t -test instead of Friedman’s test. Finally, irace incorporates sev- 
eral improvements not published before, such as sampling from a 
truncated normal distribution, a parallel implementation, a restart 
strategy that avoids premature convergence, and an elitist racing 
procedure to ensure that the best parameter conﬁgurations found 
are also evaluated on the highest number of training instances. 
The paper is structured as follows. Section 2 introduces the 
algorithm conﬁguration problem and gives an overview of ap- 
proaches to automatic algorithm conﬁguration. Section 3 describes 
the iterated racing procedure as implemented in the irace pack- 
age as well as several further extensions including the elitist irace . 
Section 4 illustrates the steps followed to apply irace to two con- 

Document 2: 
 5.2. Multi-objective optimization metaheuristics 
Besides the application to the MOACO framework described 
above [58] , irace has been applied to aid in the design of other 
multi-objective optimization algorithms. Dubois-Lacoste et al. 
[31] used irace to tune a hybrid of two-phase local search and 
Pareto local search (TP + PLS) to produce new state-of-the-art al- 
gorithms for various bi-objective permutation ﬂowshop problems. 
Fisset et al. [33] used irace to tune a framework of multi-objective 
optimization algorithms for clustering. When applied to a suﬃ- 
ciently ﬂexible algorithmic framework, irace has been used to de- 
sign new state-of-the-art multi-objective evolutionary algorithms 
[16,17] . 
5.3. Anytime algorithms (improve time-quality trade-offs) 
There is often a trade-off between solution quality and com- 
putation time: Algorithms that converge quickly tend to produce 
better solutions for shorter runtimes, whereas more exploratory al- 
gorithms tend to produce better solutions for longer runtimes. Im- 
proving the anytime behavior of an algorithm amounts to improv- 
ing the trade-off curve between solution quality and computation 
time such that an algorithm is able to produce as high quality so- 
lutions as possible at any moment during their execution. López- 

Document 3: 
 effect on the budget consumed is lower. The same experiment for 
the ACOTSP scenario showed that the best conﬁgurations become 
worse when T new or T ﬁrst are increased. This is due to the fact that 
ACOTSP has a homogeneous training set and, therefore, sampling 
new candidates is more important than executing a large number 
of instances. 
5. Other applications of irace 
Since the ﬁrst version of the irace package became publicly 
available in 2012, there have been many other applications of 
irace . In this section, we provide a list of the applications of the 
irace package of which we are aware at the time of writing. Some 
of these applications go beyond what is traditionally understood as 
algorithm conﬁguration, demonstrating the ﬂexibility of irace . 
54 M. López-Ibáñez et al. / Operations Research Perspectives 3 (2016) 43–58 
5.1. Algorithm conﬁguration 
The traditional application of irace is the automatic conﬁgura- 
tion of algorithms. Several publications have used irace when eval- 
uating or designing algorithms for problems such as the traveling 
salesman with time windows [60] , slot allocation [77] , generalized 
hub location [68] , ﬂow shop [14] , virtual machine placement [86] , 
online bin packing [92] , graph coloring [23] , image binarization 
[69] , network pricing [90] , combined routing and packing prob- 

Document 4: 
 ming by optimization paradigm [40] . Moreover, the importance of 
properly tuning the parameters of algorithms before analyzing and 
comparing them is becoming widely recognized. We hope that the 
development of the irace package will help practitioners and re- 
searchers to put these ideas into practice. 
Acknowledgements 
This work received support from the COMEX project (P7/36) 
within the Interuniversity Attraction Poles Programme of the Bel- 
gian Science Policy Oﬃce, and the EU FP7 ICT Project COLOMBO, 
Fig. A.1 1. Scheme of the user-provided components required by irace . 
Table A1 
Parameters of irace corresponding to the description 
of iterated racing given in Section 3.2 . The full list of 
irace parameters is available in the user guide. 
Iterated racing parameter irace parameter 
B maxExperiments 
C (cost measure) targetRunner 
μ mu 
N min minNbSurvival 
T ﬁrst firstTest 
T each eachTest 
Statistical test testType 
Cooperative Self-Organizing System for Low Carbon Mobility at 
Low Penetration Rates (agreement no. 318622). Thomas Stützle and 
Mauro Birattari acknowledge support from the Belgian F.R.S.-FNRS, 
of which they are Senior Research Associates. Leslie Pérez Cáceres 
acknowledges support of CONICYT Becas Chile. 
Appendix A. The irace package 

Document 5: 
 man problem with time windows: adapting algorithms from travel-time to 
makespan optimization. Appl Soft Comput 2013;13(9):3806–15 . 
[61] López-Ibáñez M., Dubois-Lacoste J., Pérez Cáceres L., Stützle T., Birattari M.. 
2016a. The irace package: Iterated racing for automatic algorithm conﬁgura- 
tion. http://iridia.ulb.ac.be/supp/IridiaSupp2016-003/ . 
[62] López-Ibáñez M, Pérez Cáceres L, Dubois-Lacoste J, Stützle T, Birattari M. The 
irace package: user guide. Technical Report TR/IRIDIA/2016-004. IRIDIA, Uni- 
versité Libre de Bruxelles, Belgium; 2016b . http://iridia.ulb.ac.be/IridiaTrSeries/ 
IridiaTr2016-004.pdf . 
[63] Marmion M-E , Mascia F , López-Ibáñez M , Stützle T . Automatic design of hy- 
brid stochastic local search algorithms. In: Blesa MJ, Blum C, Festa P, Roli A, 
Sampels M, editors. Hybrid metaheuristics, volume 7919 of lecture notes in 

Document 6: 
 ent robot behaviors and the criteria to transition between behav- 
iors. Each module can be further customized by means of several 
parameters. A particular combination of behaviors and transitions 
represents one controller, that is, an instance of the software that 
controls the robots in the swarm. The performance of a particu- 
lar controller is evaluated by means of multiple simulations. The 
search for the best controller over multiple training simulations is 
carried out by means of irace . The authors report that this system 
is not only able to outperform a previous system that used F-race 
[34] , but also a human designer, under the scenarios studied by 
them. 
6. Conclusion 
This paper presented the irace package, which implements the 
iterated racing procedure for automatic algorithm conﬁguration. It- 
erated racing is a generalization of the iterated F-race procedure. 
M. López-Ibáñez et al. / Operations Research Perspectives 3 (2016) 43–58 55 
The primary purpose of irace is to automatize the arduous task of 
conﬁguring the parameters of an optimization algorithm. However, 
it may also be used for determining good settings in other compu- 
tational systems such as robotics, traﬃc light controllers, compil- 
ers, etc. The irace package has been designed with simplicity and 
ease of use in mind. Despite being implemented in R , no previ- 
ous knowledge of R is required. We included two examples for the 

","Irace implements an iterated racing procedure for automatic algorithm configuration, which includes several extensions like using statistical tests and adaptive mechanisms to find optimal parameter settings for optimization algorithms.",8.96712040901184,"The irace package implements an automatic algorithm configuration method called iterated racing. This approach aims to automate the process of tuning algorithm parameters to enhance their performance efficiently. Irace conducts a series of ""races"" among different configurations of the algorithm based on their performance metrics, iteratively refining the search for optimal settings. It uses statistical tests to compare the configurations and incorporates features like sampling from a truncated normal distribution and an elitist strategy to ensure that the best configurations are heavily evaluated. Overall, irace's goal is to streamline and simplify the arduous task of configuring optimization algorithms, making it applicable beyond just algorithm configuration to other computational systems such as robotics and traffic light controllers."
qwen2.5:7b-instruct-q4_0,"What is the idea behind the AAC approach called ""SMAC""?
","Document 1: 
 intensiﬁcation scheme, and time-bounded SPO (TB-SPO) (Hutter et al., 2010b), which
generalizes SPO+ to work under (potentially tight) time constraints instead of considering
the number of function evaluations as a stopping criterion.
5.2 General Model-based AC Methods
SMAC Sequential model-based optimization for algorithm conﬁguration (SMAC) (Hutter
et al., 2011; Lindauer et al., 2021) can be seen as one of the ﬁrst fully-ﬂedged model-
based AC approaches, as it features solutions for many of the limitations of the previously
discussed SMBO techniques. SMAC generalizes TB-SPO to perform conﬁguration over
multiple problem instances so that it can support categorical parameters and handle tight
time constraints.
To support multiple problem instances, SMAC adapts the intensiﬁcation strategy of
TB-SPO to iteratively evaluate conﬁgurations on randomly sampled combinations of seeds
and problem instances. When doing so, it ensures that conﬁgurations are compared only
based on a performance estimate computed on the same randomly sampled set of problem
instances. Furthermore, SMAC’s surrogate model can generalize across problem instances
by incorporating problem instance features. To this end, a surrogate model is learned on
the joint problem instance and conﬁguration space to predict the performance of a given
conﬁguration on a given problem instance.
As a means to deal with a mixture of categorical and numerical parameters, SMAC 

Document 2: 
 method is paired with D-MAB selection [38] described
above. A sliding window is also used by Fialho et al.[ 70].
They suggest increasing the reward with the time elapsed
since the last application of this operator and decreasing
the reward with the number of times the operator has been
applied within the window. The aim of this method is to adapt
quickly to (even subtle) changes of the dynamic environment.
Li et al.[ 129] suggested a sliding window that stores the rate
of improvement in the ﬁtness of the offspring as compared
to the parent. The sum of all these rewards in the window is
used by a ranking mechanism to assign credit to the operators.
A different credit assignment mechanism is Compass, sug-
gested by Maturana and Saubion [ 146]. Based on the concepts
found in [ 147] (see Section VI), an operator’s impact is
evaluated using measures of both ﬁtness and diversity in order
to calculate the exploration-exploitation balance achieved by
the operator. The assigned credit reﬂects how closely the
achieved balance is to an exploration-exploitation balance that
is required by a user-deﬁned schedule. Other tested credit as-
signment methods are based on domination between operators
and Pareto fronts. Compass was paired with probability match-
ing selection, but was also combined with D-MAB in [ 143].
Except for the widely used multiarmed bandit approach dis-
cussed so far, AOS has also been treated as a full reinforcement 

Document 3: 
 cess (see (Hutter et al. 2009) for a comprehensive review),
which is usually referred to as automatic algorithm con-
ﬁguration (AAC) (Hoos 2012). Many AAC methods such
as ParamILS (Hutter et al. 2009), GGA/GGA+(Ans´otegui,
Sellmann, and Tierney 2009; Ans ´otegui et al. 2015), irace
(L´opez-Ib´a˜nez et al. 2016) and SMAC (Hutter, Hoos, and
Leyton-Brown 2011) have been proposed in the last few
years. They have been used for boosting the algorithm’s per-
formance in a wide range of domains such as the boolean
satisﬁability problem (SAT) (Hutter et al. 2009), the travel-
ing salesman problem (TSP) (L´opez-Ib´a˜nez et al. 2016; Liu,
∗Corresponding author
Copyright c⃝ 2020, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.
Tang, and Yao 2019), the answer set programming (ASP)
(Hutter et al. 2014) and machine learning (Feurer et al. 2015;
Kotthoff et al. 2017).
Despite the notable success achieved in application, the 

Document 4: 
 algorithm configuration framework. JArtifIntellRes 2009; 36 : 
267–306. 
9. Lindauer M, Eggensperger K, Feurer M et al. SMAC3: a ver- 
satile Bayesian optimization package for hyperparameter opti- 
mization. JMachLearnRes 2022; 23 : 54. 
10. Santu SKK, Hassan MM, Smith MJ et al. Automl to date and 
beyond: challenges and opportunities. ACMComputSurv 2022; 
54 : 175. 
Page7of9
Downloaded from https://academic.oup.com/nsr/article/11/8/nwae132/7639406 by guest on 18 September 2024 

Document 5: 
 more benchmark instances and compare its performance to
the best conﬁguration observed so far.
SMAC is an anytime algorithm that interleaves the ex-
ploration of new conﬁgurations with additional runs of the
current best conﬁguration to yield both better and more con-
ﬁdent results over time. As all anytime algorithms, SMAC
improves performance over time. While SMAC provably
converges for ﬁnite conﬁguration spaces, it often only ﬁnds
close-to-optimal conﬁgurations for realistic time budgets
and challenging conﬁguration problems.
Automated Portfolio Construction & Hydra
Our method for constructing sequential portfolios is closely
related to Hydra (Xu, Hoos, and Leyton-Brown 2010),
which automatically constructs selection-based portfolios.
Given a parameterized algorithm framework with a space
of algorithmsΘ, Hydra starts with an empty set of can-
didate algorithms C= ∅and iteratively calls an algorithm
conﬁguration method to add algorithms θ ∈Θ that comple-
ment Cbest. In each iteration, it constructs a portfolio from
the current set Cusing the portfolio-based algorithm selec-
tor SATzilla (Xu et al. 2008) and measures its performance
m(C,π) on each benchmark instance π ∈Π (in the ﬁrst it-
eration, m(∅,π) = −∞). The performance metric Hydra
maximizes via its algorithm conﬁguration method is then 

Document 6: 
 Anastacio and Hoos (2020) propose SMAC+PS, which integrates the idea of probabilis-
tic sampling known from irace into SMAC. This enhancement yields improvements over
both SMAC and irace in many cases. In particular, Anastacio and Hoos (2020) account for
the problem that many of the completely randomly sampled conﬁgurations by SMAC often
exhibit rather bad performance and thus, their evaluation yields only limited information.
To this end, the authors suggest to sample conﬁgurations according to a truncated normal
distribution centered around the default conﬁguration.
444
A Survey of Methods for Automated Algorithm Configuration
In (Lindauer & Hutter, 2018b) the authors suggest two diﬀerent strategies to warmstart
model-based AC approaches and apply their suggestions to SMAC, leading to signiﬁcant
speedups from days to hours of conﬁguration time. The idea underlying warmstarting is to
use the evaluations of conﬁgurations from previous runs, i.e., on diﬀerent problem instance
sets, to speed up the conﬁguration process in new runs of the conﬁgurator on a new set of
instances.
Distributed SMAC (Hutter et al., 2012) (D-SMAC) is an extension of SMAC leveraging
parallelization to speed up the conﬁguration process. The main idea behind D-SMAC is
to parallelize target algorithm runs onto available workers as much as possible. For this
purpose, it maintains a queue of target algorithm conﬁguration evaluations to be performed, 

","SMAC (Sequential model-based optimization for algorithm configuration) aims to optimize algorithm configurations by using a surrogate model to predict performance and iteratively evaluating configurations on sampled problem instances. It supports categorical parameters and handles time constraints, adapting intensification strategies to ensure comparisons are based on consistent performance estimates across instances.",11.789485454559326,"The idea behind the AAC (automatic algorithm configuration) approach called ""SMAC"" (Sequential Model-based Algorithm Configuration) is to perform algorithm configuration by generalizing techniques from model-based optimization. SMAC adapts the intensification strategy from TB-SPO (time-bounded SPO) to iteratively evaluate configurations across multiple problem instances while ensuring that the comparisons are based on performance estimates derived from the same random subset of those instances. It incorporates a surrogate model that learns from both the configuration space and the problem instance features, allowing it to predict the performance of configurations effectively. SMAC is designed to handle a mixture of categorical and numerical parameters, and it operates as an anytime algorithm that continuously improves performance over time by balancing exploration of new configurations with exploitation of the current best configuration."
qwen2.5:7b-instruct-q4_0,"What is the idea behind the AAC approach called ""GGA""?
","Document 1: 
 to be evaluated based on k diﬀerently parameterized instantiations of the UCB criterion.
GGA++ Ans´ otegui et al. (2015) adapt the model-free AC approach GGA to include a
surrogate model. More precisely, the authors use a surrogate model to evaluate the quality
of new conﬁgurations. They integrate this within a crossover operator and call it genetic
engineering. Recall that GGA contains both a competitive and non-competitive popula-
tion in which winning conﬁgurations from the races between members of the competitive
population are recombined with individuals from the non-competitive population. To this
end, the crossover operator generates individuals according to the parameter tree crossover
of the original GGA method and evaluates them using the surrogate. Note that rather
than predicting the solution quality or runtime directly, the surrogate predicts the rank the
individual would have in a tournament. The individuals with the best ranks are accepted
into the population of the next generation in the same way as in GGA.
While the GGA++ surrogate is based on a random forest model, it diﬀers in a key
way. The premise of a random forest is to equally approximate the underlying function over
the complete input space. In the case of AC, this is undesirable as only the areas of the
input space that correspond to high-quality conﬁgurations are of interest. Thus, the authors
present specialized splitting criteria that focuses on only the best conﬁgurations to increase 

Document 2: 
 performance prediction [41], [42], [45]; and algorithm
enhancement [44], [47].
C. Generative Adversarial Networks
The general idea of GAST is similar to generative adversar-
ial networks (GANs) [50]. GANs also maintain an adversarial
game in which a discriminator is trained to distinguish real
samples from fake samples synthesized by a generator, and
the generator is trained to deceive the discriminator by pro-
ducing ever more realistic samples. However, there are some
main differences between GAST and GANs. First, the over-
all goals of them are different. GANs focus on the generative
models that could capture the distribution of complicated real-
world data. For GAST, the main goal is to build powerful
parallel portfolios (analogous to the discriminative models in
GANs); while the instance generation module as well as the
generated instances are more like byproducts. Second, the
domains to which GAST and GANs are applicable are differ-
ent. Currently GANs (and the more general idea of adversarial
learning) are mostly successfully applied to vision-related
domains, such as image generation [51], [52]; image dehaz-
ing [53]; style transfer [54], [55]; image classiﬁcation [56]; and
clustering [57], [58]. In comparison, GAST is proposed for
problem-solving domains, such as planning and optimization.
Third, the main technical issues in the two areas are different. 

Document 3: 
 cess (see (Hutter et al. 2009) for a comprehensive review),
which is usually referred to as automatic algorithm con-
ﬁguration (AAC) (Hoos 2012). Many AAC methods such
as ParamILS (Hutter et al. 2009), GGA/GGA+(Ans´otegui,
Sellmann, and Tierney 2009; Ans ´otegui et al. 2015), irace
(L´opez-Ib´a˜nez et al. 2016) and SMAC (Hutter, Hoos, and
Leyton-Brown 2011) have been proposed in the last few
years. They have been used for boosting the algorithm’s per-
formance in a wide range of domains such as the boolean
satisﬁability problem (SAT) (Hutter et al. 2009), the travel-
ing salesman problem (TSP) (L´opez-Ib´a˜nez et al. 2016; Liu,
∗Corresponding author
Copyright c⃝ 2020, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.
Tang, and Yao 2019), the answer set programming (ASP)
(Hutter et al. 2014) and machine learning (Feurer et al. 2015;
Kotthoff et al. 2017).
Despite the notable success achieved in application, the 

Document 4: 
 instead of the fully predetermined lifetimes in the original
GA VaPS and nAMGA VaPS.
Another variation of the GA VaPS lifetime scheme was
described by Bäck et al .[ 18]. The adaptive population GA
(APGA) uses the same lifetime allocation but differs from
GA VaPS in the reproduction cycle and in that, when in-
crementing the ages of individuals in each cycle, the best
individual of that cycle remains unchanged. This adaptive
population strategy is part of an ensemble and is described
in more detail in Section V. This method was also applied to
cooperative coevolution by Iorio and Li [ 109]. An analysis
of APGA by Lobo and Lima [ 135] shows theoretical and
experimental results suggesting an upper bound and a con-
verging population to a constant size that is determined by
the minimum and maximum lifetime parameters. The authors
conclude that the population is not adapted by the APGA
but the size parameter is in fact replaced by the two lifetime
parameters.
Cook and Tauritz [36] suggested two strategies for removing
the population size parameter. FiScIS-EA removes individuals
according to a survival probability, derived by linear scaling
of the individual’s ﬁtness in the range between the minimum
and maximum ﬁtness values present in the population. GC-EA
simply evades choosing a population size by maintaining a
population as large as is allowed by memory limitations. This
requires a well-chosen parent selection mechanism that scales
well, while a survival selection operator is still needed in 

Document 5: 
 obtain promising initial results, the combined evolution of solutions and their genetic opera-
tors is comparatively challenging, and it remains an open question whether autoconstructive
evolution is indeed superior to non-autoconstructive evolution.
Multi-armed bandits DAC can be cast as a multi-armed bandit problem, where each
conﬁguration represents an arm with an associated reward distribution. The agent is then
tasked to maximize the cumulative reward, i.e., “pull the arm“ that maximizes the reward.
Put diﬀerently, the agent aims to select a conﬁguration that works well for the current time
step. This setting of the bandit problem is particularly challenging because the reward
distributions associated with the respective arms change over time. In Fialho et al. (2010),
various multi-armed bandit approaches are compared with an approach that only considers
rewards obtained within a certain time frame (i.e., a sliding window) to allow for smoother
transitions between conﬁgurations. Note that in this work, the authors assume rewards to
be retrievable during an algorithm run. While this assumption holds for many optimization
approaches, it does not necessarily hold for all of them (e.g., the pre-processing/root node
phase of solving mixed-integer programs), and also often does not hold for simulations.
463
Schede, Brandt, Tornede, Wever, Bengs, H¨ullermeier & Tierney
11. Research Directions
Many fruitful avenues of research remain in the area of AC. We formulate research directions 

Document 6: 
 [23] showed that clustering the training data into sets, and then tun-
ing these sets individually could lead to further improvements. We
refer to this approach as SOP-clustered. We compare these two con-
ﬁgurators with general-purpose instance-oblivious conﬁguration of
GGA [2] and instance-speciﬁc parameter tuning of ISAC.
Solver: GS % Optimality Gap Closed
Train Test
Uniform 25.9 (4.2) 40 (4.1)
SOP - combined 39.0 (3.3) 43.4 (3.6)
SOP - clustered 47.7 (2.4) 50.3 (3.7)
GGA 40.0 (3.6) 46.1 (3.8)
ISAC 44.4 (3.3) 51.3 (3.8)
Table 1. Comparison of ISAC versus the default and instance-oblivious
parameters provided by SOP and GGA, and the instance-speciﬁc parameters
provided by SOP. We present the percent of optimality gap closed (stdev).
In Table 1, we compare the resulting ﬁve GS solvers, presenting
the percentage of optimality gap closed by each solver. Comparing
the average percent of optimality gap closed, we ﬁnd that ISAC is as
capable of improving over the default approach as SOP, which was
developed particularly for the GS solver. That is, ISAC can effec-
tively liberate us from having to select the number of clusters while,
at the same time, enjoying wide applicability to other solvers. More- 

","The GGA (Graphics, Gesture, and Audio) approach in Augmentative and Alternative Communication (AAC) refers to a method that combines multiple modes of communication to support individuals with complex communication needs. Here’s what each component represents:

1. **Graphics**: Visual symbols or images used to represent words, concepts, or actions. These can be picture icons, photographs, line drawings, or custom-designed graphics.

2. **Gesture**: Non-verbal movements or signs that are used to convey meaning or supplement spoken language. This can include pointing, nodding, shaking head, thumbs up/down, and more complex sign language or gestures specific to a communication system.

3. **Audio**: Spoken words or synthesized voice outputs from devices like speech-generating devices (SGDs) or computerized systems. Audio components can also include recorded messages, vocalizations, or sound effects that contribute to the overall communication.

The GGA approach emphasizes the use of these three modalities together to enhance communication effectiveness and flexibility for users who may struggle with verbal speech due to various reasons such as autism, cerebral palsy, traumatic brain injury, or other neurological conditions. By integrating graphics, gestures, and audio, GGA aims to provide a comprehensive and flexible way for individuals to communicate their needs, thoughts, and feelings.

This approach is particularly useful in educational settings, therapy sessions, and daily life interactions where clear and efficient communication is essential.",35.627859592437744,"The GGA (Genetic Algorithm with Genetic Engineering) approach, as described in the context, integrates a surrogate model to evaluate the quality of new configurations within its operation. It combines a competitive population, which competes in races, with a non-competitive population, allowing the winning configurations from the competitive races to be recombined with individuals from the non-competitive group. The crossover operator generates new individuals based on parameter tree crossover and uses the surrogate model to assess their ranks in a tournament-like setting. The individuals with the best ranks are then selected to form the next generation. Unlike traditional random forest methods, GGA focuses specifically on high-quality configurations, utilizing specialized splitting criteria that emphasize these areas of the input space."
qwen2.5:7b-instruct-q4_0,"What is the idea behind the AAC approach called ""ISAC""?
","Document 1: 
 ISAC – Instance-Speciﬁc Algorithm Conﬁguration1
Serdar Kadioglu and Yuri Malitsky and Meinolf Sellmann and Kevin Tierney2
Abstract. We present a new method for instance-speciﬁc algorithm
conﬁguration (ISAC). It is based on the integration of the algorithm
conﬁguration system GGA and the recently proposed stochastic off-
line programming paradigm. ISAC is provided a solver with cate-
gorical, ordinal, and/or continuous parameters, a training benchmark
set of input instances for that solver, and an algorithm that com-
putes a feature vector that characterizes any given instance. ISAC
then provides high quality parameter settings for any new input in-
stance. Experiments on a variety of different constrained optimiza-
tion and constraint satisfaction solvers show that automatic algorithm
conﬁguration vastly outperforms manual tuning. Moreover, we show
that instance-speciﬁc tuning frequently leads to signiﬁcant speed-ups
over instance-oblivious conﬁgurations.
1 Introduction
When developing a new heuristic or complete algorithm for a con-
straint satisfaction or a constrained optimization problem, we fre-
quently face the problem of choice. There may be multiple branch-
ing heuristics that we can employ, different types of inference mech-
anisms, various restart strategies, or a multitude of neighborhoods to
choose from. Furthermore, the way in which the choices we make
affect one another is not readily known. The task of making these 

Document 2: 
 method is paired with D-MAB selection [38] described
above. A sliding window is also used by Fialho et al.[ 70].
They suggest increasing the reward with the time elapsed
since the last application of this operator and decreasing
the reward with the number of times the operator has been
applied within the window. The aim of this method is to adapt
quickly to (even subtle) changes of the dynamic environment.
Li et al.[ 129] suggested a sliding window that stores the rate
of improvement in the ﬁtness of the offspring as compared
to the parent. The sum of all these rewards in the window is
used by a ranking mechanism to assign credit to the operators.
A different credit assignment mechanism is Compass, sug-
gested by Maturana and Saubion [ 146]. Based on the concepts
found in [ 147] (see Section VI), an operator’s impact is
evaluated using measures of both ﬁtness and diversity in order
to calculate the exploration-exploitation balance achieved by
the operator. The assigned credit reﬂects how closely the
achieved balance is to an exploration-exploitation balance that
is required by a user-deﬁned schedule. Other tested credit as-
signment methods are based on domination between operators
and Pareto fronts. Compass was paired with probability match-
ing selection, but was also combined with D-MAB in [ 143].
Except for the widely used multiarmed bandit approach dis-
cussed so far, AOS has also been treated as a full reinforcement 

Document 3: 
 in Ye et al. (2021) that performance gains can already be achieved when the algorithm
conﬁguration is adapted only once. Furthermore, the hyper-reactive approach of Ans´ otegui
et al. (2017) won several categories at the MaxSAT Evaluation 2016 (Argelich et al., 2016).
Thus, DAC oﬀers signiﬁcant potential for improving algorithms, however, it does require
algorithm designers to more deeply integrate their techniques with AC methods than was
performed in the past. In the following, we discuss the most frequently used approach to
DAC, reinforcement learning (RL). While it is the most popular choice, there also exist
other approaches such as policy portfolios, autoconstructive evolution, and multi-armed
bandits.
Reinforcement learning A challenge in DAC is to evaluate the quality of individual
parameter adjustments since feedback is obtained only at the end of processing a problem
instance. Due to this, it is natural to consider DAC within the realm of reinforcement
learning (we refer to this as DAC-RL). To this end, the DAC problem is modeled in terms of
a Markov decision process (MDP) (Puterman, 1994) based on which a policy π: I×Q→ Θ
is learned from data (Biedenkapp et al., 2020). As a reward signal, typically, the eventually
obtained performance value is propagated back to the agent. Using RL allows a wide variety
of researched mechanisms to be directly applied to DAC.
The roots of DAC extend to a variety of methods that use RL to control parameters of 

Document 4: 
 the best solver in the solver class, termed the auto- 
matic algorithm configuration (AAC) in the litera- 
ture [16 ]. More specifically, given a solver class, the 
solver that achieves the best overall performance on 
the training instances is first obtained by some search 
method. Then, the solver is directly applied to an un- 
seen problem instance without a further configura- 
tion process. 
A typical AAC method consists of two main com- 
ponents: sampling in the solver class and evaluat- 
ing a candidate solver. Sampling in the solver class 
is mostly implemented based on search-based meth- 
ods and model-based methods. Search-based meth- 
ods such as hi l l climbing [50 ], local search [8 ] and 
E A s [51 ] have been used to sample solvers, since 
they make minimal assumptions about the solver 
representation and do not require gradients. Addi- 
tionally, some researchers have also explored using 
experimental design [52 ,53 ], such as the full fac- 
torial experimental design, to generate the starting 
points for the search. In comparison, model-based 
methods are more similar to the performance predic- 
tion model approach. They seek to capture the de- 
pendencies between solvers and their performance, 
by training surrogate models on the performance 
data collected during the configuration process. On 

Document 5: 
 ACPP is closely related to the area of automatic algo-
rithm configuration, in which the task is to automatically
identify a high-quality configuration from a configuration
space. In the last few years, several high-performance AC
methods (which could handle considerable large configura-
tion spaces) such as ParamILS (Hutter et al. 2009), GGA
(Ans´otegui, Sellmann, and Tierney 2009), irace (L ´opez-
Ib´a˜nez et al. 2016) and SMAC (Hutter, Hoos, and Leyton-
Brown 2011) have been proposed. As a consequence, re-
cently there has been research interest in utilizing these
AC procedures to automatically identify useful portfolios
of configurations from large configuration spaces. Such at-
tempts were first done in constructing sequential portfolios.
The representative methods for solving this problem are Hy-
dra (Xu, Hoos, and Leyton-Brown 2010) and ISAC (Ka-
dioglu et al. 2010). The basic ideas of these methods were
then adapted to be used in constructing parallel portfolios
(i.e., ACPP), thus resulting in PARHYDRA and CLUSTER-
ING (Lindauer et al. 2017) (see the first section). The main
differences between the automatic construction of sequen-
tial portfolios and of parallel portfolios lie in two aspects: 

Document 6: 
 that ihvr ∈(0, 1], and a larger value of ihvr is better. IHVR can distinguish well between
MOEAs with a different performance, and can also save a lot of calculations. In this work,
IHVR is used as the performance metric Metric .
4.3. Automatic Construction Approach
Algorithm 1 presents the automatic construction approach for MOEAs/PAP . Starting
from an empty set (line 2), the approach constructs the PAP (denoted as P) iteratively.
Speciﬁcally, each iteration of the approach (lines 3–15) consists of two subsequent phases.
In the ﬁrst phase, an existing automatic algorithm conﬁguration tool, namely SMAC 3 [44],
is used to search in Θ to ﬁnd the algorithm that can improve the performance of the current
PAP to the largest extent (line 5), and then this algorithm is inserted into P (line 6). This
phase is similar to the commonly-used greedy approach in the automatic construction of
PAPs [27,31]. Additionally, we introduce a new phase, namely simpliﬁcation, as the second
phase in Algorithm 1. In this phase (lines 7–14), P would be simpliﬁed by removing the
member algorithms that do not contribute at all to its performance (meaning removing
these algorithms has no effect on the performance of P on the training set). Considering
the size of P is bounded (line 3), removing the redundant algorithms from P is meaningful
because this will leave space for new member algorithms that can improve the performance 

","ISAC, an instance-specific algorithm configuration method, aims to identify high-quality configurations by leveraging search-based and model-based methods. It uses a solver class to first find the best-performing solver on training instances through search or modeling techniques, then directly applies this solver to unseen problems without further configuration.",11.83925175666809,"The AAC approach called ""ISAC"" (Instance-Specific Algorithm Configuration) is focused on automatically identifying high-quality parameter settings for specific problem instances. It combines an algorithm configuration system with a stochastic offline programming paradigm to adapt the configuration based on the features of each instance. ISAC requires a training benchmark set of input instances and an algorithm that computes a feature vector, allowing it to provide tailored configurations that improve solver performance on new input instances. The method has been shown to significantly outperform manual tuning and lead to speed-ups compared to instance-oblivious configurations."
qwen2.5:7b-instruct-q4_0,"What is the difference between metaheuristics and heuristics?
","Document 1: 
 usually provide only sub-optimal solutions because they do
not attempt to escape from local optimum. These drawbacks
have led to the introduction of metaheuristics.
Metaheuristics are high-level methodologies or general al-
gorithmic templates, which generally do not adapt deeply
to speciﬁc problem(s) [4]. Hence, they usually can solve a
wide range of problems [2]. In fact, the preﬁx “meta”, which
means “upper level methodology”, indicates that metaheuristic
algorithms can be viewed as “higher level” heuristics. Hy-
brid approaches based on existing metaheuristic(s) are also
considered metaheuristics [5]. In last decades, metaheuristics
have received widespread attention from researchers and are
widely recognized as efﬁcient approaches for hard optimiza-
tion problems. A number of metaheuristic algorithms have
been developed and extensively applied, including Simulated
Annealing (SA) [6], Tabu Search (TS) [7], Evolutionary Algo-
rithms (EAs) [8], Ant Colony Optimization algorithm (ACO)
[9], Particle Swarm Optimization (PSO) [10], and so forth.
Most of metaheuristics are nature-inspired (inspired from some
principles in physics, biology and etc.), contain stochastic
components, and often have several free parameters that can
be set by users according to problem(s) at hand [4].
The setting of parameters (or parameter setting) has strong 

Document 2: 
 the same standard. (In contrast, SAT solver competitions have compared solvers with a complex scoring function that includes the performance of all competitors [25].) As formulated here, the differences between two solvers may be simply in their choice of even a single technique, heuristic, or policy that sustains performance diver-sity. Thus an algorithm portfolio can be thought of as a mixture of experts [26], in-cluding variable-ordering and value-ordering heuristics, restart policies, and nogood learning methods. In particular, even if only one heuristic is available, the portfolio could consist of the heuristic and its opposite, or the heuristic and random selection. 

Document 3: 
 PSO. 
For the methodological part of the comparisons, there are far more 
studies. Statistical tests, for instance, lay at the core of prior contribu- 
tions on this matter. However, such contributions are frequently writ- 
ten from a statistical point of view –l i k e the one by Dem š ar [39] –
making it diﬃcult for researchers in this ﬁeld to embrace their method- 
ological recommendations. More recently, some tutorials have tried to 
bring together the ﬁelds of meta-heuristics and inferential statistics [4] . 
Some examples can be found in [40] , in which a statistical treatment is 
suggested for distinguishing between measurements of performance in 
adaptive evolutionary algorithms. Another good example is [41] , which 
shows that in a popular real-parameter benchmark (CEC’2005), con- 
ditions needed for running parametric hypothesis tests did not hold, 
and non-parametric tests were thus recommended. More recently, in 
[42] , some recommendations for the comparison of evolutionary algo- 
rithms are provided, which can be even extrapolated to machine learn- 
ing benchmarks. 
Another important issue from a methodological point of view is the 
assessment of the performance of bio-inspired algorithms from the per- 
spective of the experimental design. Some studies [5] provide general 
recommendations to design experiments for the comparison of algo- 
rithms in a similar way to what we do in this contribution. However, 
these recommendations are far more general as it targets a broader scope 

Document 4: 
 (Eds.), Handbook of Metaheuristics (pp. 321–353). Kluwer Academic Publishers, Norwell, MA, USA.
Maron, O. & Moore, A. (1994). Hoeffding races: Accelerating model selection search for classiﬁcation
and function approximation. In Cowan, J. D., Tesauro, G., & Alspector, J. (Eds.), Advances in Neural
Information Processing Systems 7 (NIPS-94), volume 6, (pp. 59–66). Morgan Kaufmann Publishers, San
Francisco, CA, USA.
Mengshoel, O. J. (2008). Understanding the role of noise in stochastic local search: Analysis and experi-
ments. Artiﬁcial Intelligence, 172(8-9), 955–990.
Minton, S. (1993). An analytic learning system for specializing heuristics. In Bajcsy, R. (Ed.),Proceedings of
the Thirteenth International Joint Conference on Artiﬁcial Intelligence (IJCAI’93), (pp. 922–929). Morgan
Kaufmann Publishers, San Francisco, CA, USA.
Minton, S. (1996). Automatically conﬁguring constraint satisfaction programs: A case study. Constraints,
1(1), 1–40.
Minton, S., Johnston, M. D., Philips, A. B., & Laird, P. (1992). Minimizing conﬂicts: A heuristic repair 

Document 5: 
 J. Durillo , K. Hammond , E. Hart , C.G. Johnson , et al. , A research agenda for meta- 
heuristic standardization, in: Proceedings of the XI metaheuristics international 
conference, 2015, pp. 1–3 . 
[106] J. Swan , S. Adraensen , A.E. Brownlee , C.G. Johnson , A. Kheiri , F. Krawiec , 
J. Merelo , L.L. Minku , E. Özcan , G.L. Pappa , et al. , Towards metaheuristics ”i n 
the large ”, arXiv preprint arXiv:2011.09821 (2020) . 
[107] M.A. Lones , Mitigating metaphors: a comprehensible guide to recent nature-in- 
spired algorithms, SN Computer Science 1 (1) (2020) 49 . 
[108] M. Jain, V. Singh, A. Rani, A novel nature-inspired algorithm for optimiza- 
tion: squirrel search algorithm, Swarm Evol Comput 44 (2019) 148–175, 
doi: 10.1016/j.swevo.2018.02.013 . 
[109] A.W. Mohamed, A.A. Hadi, A.K. Mohamed, Gaining-sharing knowledge 
based algorithm for solving optimization problems: a novel nature- 

Document 6: 
 iﬁed on 24 continuous benchmark functions from the COCO test set and 29
functions from the CEC-2017 test set. On the BBOB test set a hybrid of
PSO and DE with adaptation obtained 11 signiﬁcantly better and 2 signif-
icantly worse results on 5 and 20 dimensional functions than the basic DE.
Further inclusion of the model based optimizers led to 15 signiﬁcantly better
and 2 signiﬁcantly worse results compared to the PSO-DE hybrid. On the
CEC-2017 test set, M-GAPSO was signiﬁcantly better than both Red Fox
Optimization and Dual Opposition-Based Learning for Diﬀerential Evolution
(DOBL) on 7 functions in 30 dimensions and 12 functions in 50 dimensions.
Keywords: hyper-heuristics, meta-heuristics, global optimization
∗Corresponding author.
Email addresses: M.Okulewicz@mini.pw.edu.pl (Micha/suppress l Okulewicz),
M.Zaborski@mini.pw.edu.pl (Mateusz Zaborski), jacek.mandziuk@pw.edu.pl (Jacek
Ma´ ndziuk )
Preprint submitted to Applied Soft Computing 10.1016/j.asoc.2022.109722 December 3, 2022
1. Introduction
The quest for a general purpose optimization algorithms, which started
with the works on evolutionary computations [1, 2], resulted in creation of
a few excellent optimization methods like Diﬀerential Evolution (DE) [3] 

","Metaheuristics are higher-level methodologies that generally do not deeply adapt to specific problems, allowing them to solve a wide range of problems. Heuristics, in contrast, are problem-specific rules or techniques designed to find solutions efficiently but may not always provide optimal results. Metaheuristics often include stochastic components and can be nature-inspired, whereas heuristics are typically more specialized for particular tasks.",14.16183066368103,"Metaheuristics are high-level methodologies or general algorithmic templates designed to solve a wide range of optimization problems. They are often nature-inspired and contain stochastic components, allowing them to escape local optima and attempt to find better solutions over a broader search space. In contrast, heuristics are typically problem-specific strategies or rules of thumb that provide sub-optimal solutions and may not have the capability to generalize to various problems. The term ""meta"" indicates that metaheuristics can be viewed as higher-level strategies that can encompass and adapt various heuristics but do not deeply adapt to specific problems, allowing for a more flexible application across different optimization scenarios."
qwen2.5:7b-instruct-q4_0,"What factors and challenges influenced the development of the Automatic Algorithm Configuration approaches?
","Document 1: 
 ods for algorithm development. The methods used in this context 
include experimental design techniques [2,29] , racing approaches 
[20] , and algorithmic methods for parameter conﬁguration, such 
as heuristic search techniques [3,10,41,73,81] , and statistical mod- 
eling approaches [11,43] . These methods have led to an increasing 
automatization of the algorithm design and parameter setting pro- 
cess. 
Automatic algorithm conﬁguration can be described, from a ma- 
chine learning perspective, as the problem of ﬁnding good param- 
eter settings for solving unseen problem instances by learning on 
a set of training problem instances [19] . Thus, there are two clearly 
delimited phases. In a primary tuning phase, an algorithm con- 
ﬁguration is chosen, given a set of training instances representa- 
tive of a particular problem. In a secondary production (or test- 
ing) phase, the chosen algorithm conﬁguration is used to solve un- 
seen instances of the same problem. The goal in automatic algo- 
rithm conﬁguration is to ﬁnd, during the tuning phase, an algo- 
rithm conﬁguration that minimizes some cost measure over the 
set of instances that will be seen during the production phase. 
In other words, the ﬁnal goal is that the conﬁguration of the al- 
gorithm found during the tuning phase generalizes to similar but 
unseen instances. The tuning phase may also use automatic conﬁg- 
uration methods repeatedly while engineering an algorithm [71] . 

Document 2: 
 diﬀerent problems (SAT, MIP, ASP, etc.) of varying complexity (number of variables and
problem instances) for tasks of runtime or quality conﬁguration. For DAC, the DACBench
has been proposed (Eimer et al., 2021), although this does not support DAC settings en-
visioned, e.g., by hyper-reactive search. As an alternative to such libraries, AC methods
can also be benchmarked by using surrogate models that are trained on test instances in
advance, resulting in cheaper evaluations when testing (Eggensperger et al., 2018). The ex-
isting benchmarks fail to cover other conﬁgurations settings like the realtime conﬁguration
setting or the conﬁguration of multi-objective target algorithms.
11.4 Novel AC Methodologies
AC methods have become extremely sophisticated and cover a wide range of methodologies
including evolutionary algorithms, statistical tests, and learned surrogate models. There
nonetheless remain opportunities to improve current methods and create better AC algo-
rithms. We note that our goal in this section is not necessarily to specify the methodologies
of the future, but rather to identify the key challenges that remain in the hopes that engaged
466
A Survey of Methods for Automated Algorithm Configuration
readers will ﬁll these gaps with their ideas. To this end, we discuss several challenges faced
by AC approaches: comparing/ranking conﬁgurations, generating new conﬁgurations, and
selecting instances.
Comparing/ranking conﬁgurations This challenge can be summarized as follows: 

Document 3: 
 available for detecting (approximate) independencies. Although there is some evi-
dence that GGA can solve some moderately difﬁcult conﬁguration problems more
effectively than FocusedILS without capping [2], it appears to be unable to reach
the performance of FocusedILS version 2.3 with aggressive capping on the most
challenging conﬁgurations problems [40]. Unfortunately, GGA also offers less ﬂex-
ibility than FocusedILS in terms of the performance metric to be optimised. More
algorithm conﬁguration procedures based on evolutionary algorithms are covered in
Chapter 2 of this book.
Finally, work originating from the Ph.D. project of Hutter [32] has recently over-
come two major limitations of the sequential model-based optimisation methods
discussed in Section 3.4 of this chapter by introducing a procedure that can han-
dle categorical parameters while explicitly exploiting the fact that performance is
evaluated on a set of problem instances. There is some evidence that this procedure,
dubbedSequential Model-based Algorithm Conﬁguration (SMAC) , can, at least on
some challenging conﬁguration benchmarks, reach and sometimes exceed the per-
formance of FocusedILS [43], and we are convinced that, at least in cases where
the parameter response of a given target algorithm is reasonably regular and per-
formance evaluations are very costly, such advanced SMBO methods hold great
promise.
3.6 Conclusions and Future Work
Automated algorithm conﬁguration and parameter tuning methods have been de- 

Document 4: 
 Decision and Operation Technologies Group,
Bielefeld University, Bielefeld, Germany
Abstract
Algorithm conﬁguration (AC) is concerned with the automated search of the most
suitable parameter conﬁguration of a parametrized algorithm. There is currently a wide
variety of AC problem variants and methods proposed in the literature. Existing reviews
do not take into account all derivatives of the AC problem, nor do they oﬀer a complete
classiﬁcation scheme. To this end, we introduce taxonomies to describe the AC problem and
features of conﬁguration methods, respectively. We review existing AC literature within
the lens of our taxonomies, outline relevant design choices of conﬁguration approaches,
contrast methods and problem variants against each other, and describe the state of AC in
industry. Finally, our review provides researchers and practitioners with a look at future
research directions in the ﬁeld of AC.
1. Introduction
Diﬃcult computational problems must be regularly solved in many areas of industry and
academia, such as constraint satisfaction problems, Boolean satisﬁability problems (SAT),
vehicle routing problems, ﬁnding a proper machine learning model for a given dataset,
or computing highly complex simulations. Algorithms that were developed to solve such
problems usually have parameters that strongly inﬂuence the behavior of the respective
algorithm and also, for example, the runtime that is required to solve problem instances
©2022 AI Access Foundation. All rights reserved.
Schede, Brandt, Tornede, Wever, Bengs, H¨ullermeier & Tierney 

Document 5: 
 better performance than the top-ranked solver from the competition.
9. Related Work
Many researchers before us have been dissatisﬁed with manual algorithm conﬁguration, and various
ﬁelds have developed their own approaches for automatic parameter tuning. We start this section
with the most closely-related work—approaches that employ direct search to ﬁnd good parameter
conﬁgurations—and then describe other methods. Finally, we discuss work on related problems,
such as ﬁnding the best parameter conﬁguration or algorithm on a per-instance basis, and approaches
that adapt their parameters during an algorithm’s execution (see also Hoos, 2008, for further related
work on automated algorithm design).
8. BasicILS was used, because FocusedILS had not yet been developed when that study was conducted.
297
HUTTER , HOOS , LEYTON -BROWN & ST ¨UTZLE
9.1 Direct Search Methods for Algorithm Conﬁguration
Approaches for automated algorithm conﬁguration go back to the early 1990s, when a number of
systems were developed for adaptive problem solving. One of these systems is Composer (Gratch
& Dejong, 1992), which performs a hill-climbing search in conﬁguration space, taking moves if
enough evidence has been gathered to render a neighbouring conﬁguration statistically signiﬁcantly
better than the current conﬁguration. Composer was successfully applied to improving the ﬁve
parameters of an algorithm for scheduling communication between a collection of ground-based
antennas and spacecrafts (Gratch & Chien, 1996). 

Document 6: 
 ration.
1 Introduction
We consider the problem of automatic solver conﬁguration. Practically all solvers have
parameters that are partly ﬁxed by the programmer and partly set by the user. In recent
years, systems have been devised which automate the task of tuning parameters for a
given set of training instances that are assu med to represent typical instances for the
target algorithm.
There are several motivations for such an automation, the ﬁrst being that it is of
course time consuming to tune parameters and it may lead to better results when leaving
the conﬁguration of solvers to a computer rather than doing it by hand.
Moreover, it is conceivable that the existence of an effective tuning environment
will cause algorithm developers to paramete rize more aspects of their algorithms and
thus leave more freedom for algorithmic solutions that are automatically tailored to the
problems of individual users. In particular, many of the SAT solvers that are available
today have parameters which cannot be set through the command line. These parameters
have been ﬁxed to values that the developers have found beneﬁcial without knowledge
about the particular instances a user may want to use the solver for. Automatic parameter
tuning allows solvers to adapt to the ﬁnal environment in which they need to perform.
After being shipped, rather than relying on default parameters, an algorithm can be
⋆ This work was partly supported by the projects TIN2007-68005-C04-04 and TIN2006-15662-
C02-02 funded by the MEC, and by the the National Science Foundation through the Ca-
reer: Cornﬂower Project (award number 0644113). 

","The development of automatic algorithm configuration (Auto-Config) approaches has been driven by a variety of factors and faced several key challenges. Here are some of the most significant influences:

### Factors Influencing Development

1. **Increased Computational Power**:
   - The advent of more powerful computers has enabled researchers to run complex algorithms on large datasets, making it feasible to search for optimal configurations.

2. **Growing Dataset Sizes**:
   - As data sizes have grown, so too have the number of parameters that need tuning. Auto-Config methods help manage this complexity by automating the process of finding good settings.

3. **Algorithm Complexity**:
   - Many algorithms have numerous tunable parameters (e.g., hyperparameters), making manual configuration time-consuming and error-prone. Auto-Config techniques aim to streamline this process.

4. **Machine Learning and AI**:
   - The rise of machine learning and artificial intelligence has led to a need for more robust and efficient algorithm configurations, driving the development of Auto-Config methods.

5. **Parallel and Distributed Computing**:
   - The ability to distribute computations across multiple machines allows Auto-Config algorithms to explore large search spaces quickly.

6. **Open Source Tools and Libraries**:
   - The availability of open-source tools like Optuna, Hyperopt, and SMAC (SBBT Multi-objective Algorithm Configuration) has made it easier for researchers and practitioners to implement and experiment with Auto-Config methods.

### Challenges Faced

1. **High Computational Costs**:
   - Tuning algorithms can be computationally expensive, especially when dealing with large datasets or complex models. Efficient use of computational resources is a significant challenge.

2. **Exploration vs Exploitation Trade-off**:
   - Balancing the exploration of new configurations and exploitation of known good ones is critical but challenging. Auto-Config methods need to strike a balance between these two strategies.

3. **Local Optima**:
   - Finding the global optimum in a high-dimensional search space can be difficult due to the presence of local optima, which can trap optimization algorithms.

4. **Scalability**:
   - As problem sizes increase, so do the number of parameters that need tuning, making it harder for Auto-Config methods to scale effectively.

5. **Domain Expertise**:
   - Different problems require different configurations and may benefit from specialized knowledge. Auto-Config methods often lack this domain-specific insight, which can limit their effectiveness.

6. **Interpretability**:
   - Many Auto-Config algorithms generate complex solutions that are hard to understand or interpret by humans, making it difficult to debug or validate the results.

7. **Generalization**:
   - Ensuring that configurations found for one problem generalize well to other similar problems is challenging. Overfitting to a specific dataset can lead to poor performance on unseen data.

8. **Dynamic Environments**:
   - In dynamic environments where conditions change over time, Auto-Config methods must adapt continuously, adding an additional layer of complexity.

9. **Resource Constraints**:
   - Limited computational resources (e.g., CPU/GPU power, memory) can restrict the scope and efficiency of Auto-Config algorithms.

10. **Ethical Considerations**:
    - Issues such as fairness, bias, and privacy in algorithm configuration are increasingly important but also challenging to address automatically.

Addressing these factors and challenges has driven the evolution of automatic algorithm configuration approaches, making them more robust, efficient, and applicable to a wider range of problems.",83.81359124183655,"The development of Automatic Algorithm Configuration (AC) approaches has been influenced by several factors and challenges:

1. **Diversity of Problems**: AC methods must cater to various computational problems (e.g., SAT, MIP, ASP) with differing complexities. This requires AC approaches to be versatile and capable of adapting to different problem domains.

2. **Complexity of Parameters**: Algorithms often have numerous parameters that significantly affect their performance. The management and tuning of these parameters present challenges, particularly in ensuring the configurations are suitable for unseen instances.

3. **Benchmarking Limitations**: Existing benchmarking frameworks, such as DACBench, may not adequately support all configuration settings, indicating a need for more comprehensive evaluation tools to benchmark AC methods.

4. **Comparing and Ranking Configurations**: A significant challenge in AC is comparing and ranking different configurations to determine which performs best under various conditions. This task requires effective metrics and methodologies for assessment.

5. **Generating New Configurations**: The ability to generate new and potentially better configurations from existing ones remains a challenge. Advanced methodologies are needed to explore the configuration space efficiently.

6. **Performance Evaluation Costs**: Many performance evaluations are resource-intensive, necessitating methods that can efficiently predict the performance of configurations without extensive testing.

7. **Categorical Parameters Handling**: Many AC procedures initially struggled with categorical parameters, but recent advancements, such as Sequential Model-based Algorithm Configuration (SMAC), have begun to address this limitation.

8. **Adapting to the User's Environment**: The need for solvers to adapt to the environments in which they operate after deployment is critical. Automatic configuration allows developers to create more parameterized algorithms that can tailor themselves to a user's specific problem context.

These factors illustrate the complexities and evolving needs in the field of algorithm configuration, prompting ongoing research and innovation."
qwen2.5:7b-instruct-q4_0,"What are the main benefits of AAC?
","Document 1: 
 as expected, as N and K get larger, the estimation error gets
smaller, and ˆuSN (θ) will converge to u(θ) with probability
1 with N →∞ and K →∞ . Third, Corollary 1 shows that,
for the estimator ˆuSN (θ∗) which are widely used in current
AAC methods, the gain on error reduction decreases rapidly
asN and K get larger (which are also shown in Figure 2 in
the experiments), and the effects of increasingN and K also
depend on ¯σ2
WI and ¯σ2
AI, two quantities varying across dif-
ferent algorithm conﬁguration scenarios. Thus for enhanc-
ing current AAC methods, instead of ﬁxingN as a large
number (e.g., SMAC sets N to 2000 by default) and using
as many training instances as possible, it is more desirable
to use differentN and K according to the conﬁguration sce-
nario considered, in which case N and K may be adjusted
dynamically in the conﬁguration process as more data are
gathered to estimate¯σ2
WI and ¯σ2
AI.
Experiments
In this section, we present our experimental studies. First
we introduce our experiment setup. Then, we verify our the-
oretical results in two facets: 1) comparison of different per-
formance estimators; 2) the effects of different values ofm
(the number of considered conﬁgurations), N (the number
of runs of θ to estimate u(θ)) and K (the number of training 

Document 2: 
 independently in parallel to obtain multiple solutions. Then, the best solution will be
taken as the ﬁnal output of the PAP . Although a PAP would consume more computational
resources than a single algorithm, it has three important advantages. First, PAPs are
easy-to-implement because they do not necessarily require any resource allocation since
each member algorithm is simply assigned with the same amount of resource. Second,
the performance of a PAP on any problem is the best performance achieved among its
member algorithms on the problem. In other words, a PAP could achieve a much better
overall performance than any of its member algorithms. Third, considering the tremendous
growth of parallel computing architectures [22] (e.g., multi-core CPUs) over the last few
decades, leveraging parallelism has become very important in designing effective solvers
for hard optimization problems [23–27]. PAPs employ parallel solution strategies and thus
allow for the use of modern computing facilities in an extremely simple way.
It is conceivable that any PAP’s effectiveness relies heavily on the diversity and com-
plementarity among its member algorithms. In other words, the manual construction
of high-quality PAPs is generally a challenging task, requiring domain experts (with a
deep understanding of both algorithms and problems) to explore the vast design space
of PAPs, which cannot be carried out manually with ease [28–30]. As an alternative, Tang
and Liu [25,26] proposed a general framework, called automatic construction of PAPs, that 

Document 3: 
 phase of solving mixed-integer programs), and also often does not hold for simulations.
463
Schede, Brandt, Tornede, Wever, Bengs, H¨ullermeier & Tierney
11. Research Directions
Many fruitful avenues of research remain in the area of AC. We formulate research directions
with three themes in mind. First, we consider what is required for AC techniques to be
more widely adopted in industry. Second, we investigate algorithm conﬁguration settings
that have not yet been considered. Third, we consider what methodological advances could
move the ﬁeld forward.
11.1 Industry Adoption
Compared to AC, HPO has begun to be adopted in both industry and academia (Van der
Blom et al., 2021). Furthermore, HPO is the focus of a number of start-ups, such as
SigOpt (which was acquired by Intel (Intel Corporation, 2019)), MindsDB, pecan.ai, and
dotData, among many more. AC, however, has received comparatively little fanfare or
adoption. While some well-known AC tools have public releases, such as SMAC (Lindauer
et al., 2021), irace (L´ opez-Ib´ anez et al., 2016), and GGA (Ans´ otegui et al., 2009), we are
unaware of widespread use of these in industry. The company Optano GmbH released a 

Document 4: 
 a policy to adapt the conﬁguration dynamically. Note that even realtime AC commits to a
single conﬁguration when running a given instance, while DAC has the freedom to adjust
the conﬁguration according to target algorithm behavior during execution. Similar to oﬄine
AC, DAC can either focus on ﬁnding a policy for a set of problem instances or a policy that
is tailored towards a single problem instance (i.e., per-instance algorithm conﬁguration).
Two requirements must be met to implement DAC: (1) the algorithm in question needs
to support dynamic changes in its conﬁguration and (2) runtime information must be pro-
vided to describe the current state of the target algorithm.
DAC approaches consider two diﬀerent types of features: instance features I, which do
not change during target algorithm execution, and features encoding the internal state Q
of the algorithm. Examples of state features include the current iteration of a local search
algorithm, the current restart number of a SAT method, or the current solution quality for
optimization techniques.
461
Schede, Brandt, Tornede, Wever, Bengs, H¨ullermeier & Tierney
Figure 7: Illustration of dynamic AC as presented in (Biedenkapp et al., 2020)
Biedenkapp et al. (2020) provide the ﬁrst formal deﬁnition of the DAC setting, however,
there is a signiﬁcant amount of earlier work for learning dynamic conﬁguration policies
(Lagoudakis & Littman, 2000, 2001; Pettinger & Everson, 2002). Such earlier works use 

Document 5: 
 cess (see (Hutter et al. 2009) for a comprehensive review),
which is usually referred to as automatic algorithm con-
ﬁguration (AAC) (Hoos 2012). Many AAC methods such
as ParamILS (Hutter et al. 2009), GGA/GGA+(Ans´otegui,
Sellmann, and Tierney 2009; Ans ´otegui et al. 2015), irace
(L´opez-Ib´a˜nez et al. 2016) and SMAC (Hutter, Hoos, and
Leyton-Brown 2011) have been proposed in the last few
years. They have been used for boosting the algorithm’s per-
formance in a wide range of domains such as the boolean
satisﬁability problem (SAT) (Hutter et al. 2009), the travel-
ing salesman problem (TSP) (L´opez-Ib´a˜nez et al. 2016; Liu,
∗Corresponding author
Copyright c⃝ 2020, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.
Tang, and Yao 2019), the answer set programming (ASP)
(Hutter et al. 2014) and machine learning (Feurer et al. 2015;
Kotthoff et al. 2017).
Despite the notable success achieved in application, the 

Document 6: 
 Non-general AC SMBO approaches Several SMBO approaches exist to perform a
limited form of AC, i.e., on only a single instance. We include these methods due to their
historical importance to the ﬁeld of AC, as well as because they may inspire new general AC
4. Note that for simplicity we assume that g is deterministic here.
443
Schede, Brandt, Tornede, Wever, Bengs, H¨ullermeier & Tierney
approaches. Most SMBO based AC approaches are based on the idea of sequential kriging
meta-modelling (Huang et al., 2006) (SKO) and sequential parameter optimization (SPO)
(Bartz-Beielstein et al., 2005), both of which are based on eﬃcient global optimization (Jones
et al., 1998). While the latter is a classical approach to black box function optimization using
BO, both SPO and SKO constitute extensions to noisy black box functions; an assumption
that is much more realistic for AC. However, both of these approaches still have potential
drawbacks. Some of these are ﬁxed by SPO + (Hutter et al., 2009a), which improves the
intensiﬁcation scheme, and time-bounded SPO (TB-SPO) (Hutter et al., 2010b), which
generalizes SPO+ to work under (potentially tight) time constraints instead of considering
the number of function evaluations as a stopping criterion.
5.2 General Model-based AC Methods 

","AAC, or Augmentative and Alternative Communication, offers several key benefits for individuals who have difficulty with speech or written communication. Here are some of the primary advantages:

1. **Enhanced Communication**: AAC devices can help people express their thoughts, ideas, needs, and wants effectively, even if they struggle to speak verbally.

2. **Independence**: By providing alternative ways to communicate, AAC can increase an individual's independence in daily life activities such as ordering food at a restaurant, asking for assistance, or participating in conversations.

3. **Social Interaction**: AAC can facilitate better social interactions by enabling individuals to participate more fully in conversations and relationships with friends, family, and colleagues.

4. **Educational Opportunities**: For children with communication difficulties, AAC can support their learning process by allowing them to communicate their thoughts, ask questions, and engage in class activities effectively.

5. **Self-Advocacy**: AAC enables individuals to express their needs and opinions more clearly, which is crucial for self-advocacy and asserting personal boundaries.

6. **Improved Quality of Life**: Being able to communicate effectively can significantly enhance one's quality of life by reducing frustration and misunderstandings in various social settings.

7. **Cognitive Development**: For children who use AAC as part of their learning process, it can support cognitive development and enhance literacy skills over time.

8. **Emotional Support**: Effective communication is linked to emotional well-being. AAC can help individuals convey emotions and express themselves more clearly, reducing feelings of isolation or frustration.

9. **Healthcare Communication**: AAC can assist patients in communicating with healthcare providers about symptoms, preferences for treatment, and other health-related concerns.

10. **Cultural Competence**: For individuals from diverse linguistic backgrounds, AAC can provide access to language learning and support cultural expression through communication.

These benefits highlight how AAC can transform the lives of those who face challenges with traditional speech or writing methods, making it an invaluable tool for enhancing communication across various settings.",47.97895073890686,"The main benefits of Automatic Algorithm Configuration (AAC) include the following:

1. **Performance Boosting**: AAC methods such as ParamILS, GGA, irace, and SMAC have been widely successful in enhancing the performance of algorithms across diverse domains, including SAT, TSP, ASP, and machine learning tasks. They achieve this by optimizing algorithm parameters dynamically based on performance metrics.

2. **Adaptability**: AAC techniques can adjust configurations based on the specific characteristics of different problem instances, allowing for tailored solutions that are more effective than static or pre-defined configurations.

3. **Efficient Resource Management**: AAC facilitates better resource allocation by dynamically adjusting configurations as more data becomes available, which can lead to reduced estimation errors and improved accuracy in algorithm performance.

4. **Research Advancement**: AAC fosters further research opportunities in the field, exploring new configuration settings and methodological advancements, thus contributing to the overall growth and sophistication of optimization techniques.

These advantages enable more effective problem-solving strategies, allowing the algorithms to perform optimally based on varying conditions and requirements."
qwen2.5:7b-instruct-q4_0,"Please provide an overview of the types of AAC methods.
","Document 1: 
 the best solver in the solver class, termed the auto- 
matic algorithm configuration (AAC) in the litera- 
ture [16 ]. More specifically, given a solver class, the 
solver that achieves the best overall performance on 
the training instances is first obtained by some search 
method. Then, the solver is directly applied to an un- 
seen problem instance without a further configura- 
tion process. 
A typical AAC method consists of two main com- 
ponents: sampling in the solver class and evaluat- 
ing a candidate solver. Sampling in the solver class 
is mostly implemented based on search-based meth- 
ods and model-based methods. Search-based meth- 
ods such as hi l l climbing [50 ], local search [8 ] and 
E A s [51 ] have been used to sample solvers, since 
they make minimal assumptions about the solver 
representation and do not require gradients. Addi- 
tionally, some researchers have also explored using 
experimental design [52 ,53 ], such as the full fac- 
torial experimental design, to generate the starting 
points for the search. In comparison, model-based 
methods are more similar to the performance predic- 
tion model approach. They seek to capture the de- 
pendencies between solvers and their performance, 
by training surrogate models on the performance 
data collected during the configuration process. On 

Document 2: 
 as expected, as N and K get larger, the estimation error gets
smaller, and ˆuSN (θ) will converge to u(θ) with probability
1 with N →∞ and K →∞ . Third, Corollary 1 shows that,
for the estimator ˆuSN (θ∗) which are widely used in current
AAC methods, the gain on error reduction decreases rapidly
asN and K get larger (which are also shown in Figure 2 in
the experiments), and the effects of increasingN and K also
depend on ¯σ2
WI and ¯σ2
AI, two quantities varying across dif-
ferent algorithm conﬁguration scenarios. Thus for enhanc-
ing current AAC methods, instead of ﬁxingN as a large
number (e.g., SMAC sets N to 2000 by default) and using
as many training instances as possible, it is more desirable
to use differentN and K according to the conﬁguration sce-
nario considered, in which case N and K may be adjusted
dynamically in the conﬁguration process as more data are
gathered to estimate¯σ2
WI and ¯σ2
AI.
Experiments
In this section, we present our experimental studies. First
we introduce our experiment setup. Then, we verify our the-
oretical results in two facets: 1) comparison of different per-
formance estimators; 2) the effects of different values ofm
(the number of considered conﬁgurations), N (the number
of runs of θ to estimate u(θ)) and K (the number of training 

Document 3: 
 Non-general AC SMBO approaches Several SMBO approaches exist to perform a
limited form of AC, i.e., on only a single instance. We include these methods due to their
historical importance to the ﬁeld of AC, as well as because they may inspire new general AC
4. Note that for simplicity we assume that g is deterministic here.
443
Schede, Brandt, Tornede, Wever, Bengs, H¨ullermeier & Tierney
approaches. Most SMBO based AC approaches are based on the idea of sequential kriging
meta-modelling (Huang et al., 2006) (SKO) and sequential parameter optimization (SPO)
(Bartz-Beielstein et al., 2005), both of which are based on eﬃcient global optimization (Jones
et al., 1998). While the latter is a classical approach to black box function optimization using
BO, both SPO and SKO constitute extensions to noisy black box functions; an assumption
that is much more realistic for AC. However, both of these approaches still have potential
drawbacks. Some of these are ﬁxed by SPO + (Hutter et al., 2009a), which improves the
intensiﬁcation scheme, and time-bounded SPO (TB-SPO) (Hutter et al., 2010b), which
generalizes SPO+ to work under (potentially tight) time constraints instead of considering
the number of function evaluations as a stopping criterion.
5.2 General Model-based AC Methods 

Document 4: 
 attempted. Nonetheless, the AC literature shows a surprising amount of hybridization of
local search, evolutionary and model-based methods. We hypothesize that there is still sig-
niﬁcant progress that can be made in the area of AC, despite the sophistication of current
methods, and are encouraged by the signiﬁcant increase in attention the ﬁeld has received,
in particular through the spread of HPO techniques. Finally, we especially encourage re-
searchers to address the real-world usability of AC techniques to ensure that the promising
performance gains the AC community is seeing can beneﬁt the world at large.
Acknowledgements
This work was partially supported by the German Research Foundation (DFG) within the
Collaborative Research Center “On-The-Fly Computing” (SFB 901/3 project no. 160364472)
and by the research training group “Dataninja” (Trustworthy AI for Seamless Problem
Solving: Next Generation Intelligence Joins Robust Data Analysis) funded by the Ger-
man federal state of North Rhine-Westphalia. We also would like to thank the anonymous
reviewers for their suggestions on the ﬁrst version of this manuscript.
13. Appendix
To help the reader navigate though the jungle of AC, we provide additional resources.
Table 6 contains a list of abbreviations with terms related to AC used within this work. In
addtion, we provide a list of software resources (Table 7) that contains currently available
tools for AC. We only include software that is widely used.
469 

Document 5: 
 algorithm conﬁgurators. To this end, we propose two classiﬁcation schemes: one for AC
problems, and one for algorithm conﬁgurators. Based on this, we structure and summarize
the available literature and classify existing problem variants as well as approaches to AC.
The remainder of the paper is structured as follows. First, in Section 2, we give a formal
introduction into the setting of algorithm conﬁguration, specify the scope of this survey, and
discuss the relation between AC, AS and HPO. In Section 3, we present the classiﬁcation
schemes for AC problems and approaches that are used, in turn, to describe and compare
existing algorithm conﬁgurators. In Sections 4 and 5, we survey algorithm conﬁguration
methods grouped by the property of whether these methods are model-free or leverage
a model respectively. Section 6 deals with theoretical guarantees that can be obtained.
Diﬀerent problem variants, such as realtime AC, instance-speciﬁc vs. feature-based, multi-
objective, and dynamic AC are discussed in Sections 7 to 10. Eventually, with the help of
our classiﬁcation schemes, we elaborate on appealing research directions in Section 11 and
conclude this survey in Section 12. A list of abbreviations used in this work can be found in
Table 6. In addition, we provide a list of useful software in Table 7. We note, however, that
this list is by no means exhaustive; it is meant to provide an idea about available software
at the time of publication.
2. Problem Formulation
2.1 Algorithm Conﬁguration
To describe the AC problem more formally, we introduce the following notation that is sim- 

Document 6: 
 signment methods are based on domination between operators
and Pareto fronts. Compass was paired with probability match-
ing selection, but was also combined with D-MAB in [ 143].
Except for the widely used multiarmed bandit approach dis-
cussed so far, AOS has also been treated as a full reinforcement
learning problem by Sakurai et al.[ 173], Chen et al.[ 33] and
Pettinger and Everson [ 160]. Unlike the previous approaches,
these methods include the notion of state that is deﬁned
using feedback from the EA. For each distinct state, separate
preferences are learned for each operator and selection of the
operator to apply is based on the current state of the search.
An important issue with operator selection (as with all
adaptive parameter control) is the feedback used for control.
Veerapen et al .[ 198] presented and compared various utility
measures for variation operators. These measures are based on
a combination of exploration and exploitation measures and
use Pareto-dominance to evaluate operator utility. In another
paper, Whitacre et al .[ 204] make a distinction between
the source of feedback and any further statistical treatment
(a notion further elaborated in [112]). Several feedback sources
are suggested (including whether the offspring survives or
the number of generations it remains in the population).
The data received by these sources can be treated by av-
eraging them or by detecting the outliers in the sample. 

","AAC (Augmentative and Alternative Communication) methods are communication tools or systems used to help individuals who have difficulty using oral speech as their primary means of communication. Here's an overview of the main types:

1. **Non-Verbal Communication**:
   - Gestures, facial expressions, and body language.
   - Pointing to objects, pictures, or written words.

2. **Manual Communication Systems**:
   - American Sign Language (ASL)
   - Signed Exact English
   - Pidgin Signed English

3. **Low-Tech AAC Methods**:
   - Picture Exchange Communication System (PECS): Uses picture symbols for communication.
   - Communication Boards or Books: Custom-made boards with pictures, words, or symbols arranged to convey messages.
   - Visual Supports: Graphic organizers, social stories, and calendars.

4. **High-Tech AAC Methods**:
   - Speech Generating Devices (SGDs): Electronic devices that produce speech through text-to-speech systems.
     - Single Message SGDs
     - Dynamic Display SGDs with multiple message options

5. **Augmentative Communication Apps**:
   - Mobile applications designed for communication, often featuring customizable pages and voice output.

6. **Natural Language Systems**:
   - These use natural language structure to support expressive communication, focusing on functional language development.
   
7. **Assistive Technology**:
   - Software programs that can be used with computers or tablets.
     - Word Predictive Programs
     - Communication Apps
     - Switch-Activated Devices

8. **Symbol-Based Systems**:
   - Uses symbols to represent words, phrases, and sentences.
     - Picture Exchange Communication System (PECS)
     - Mayer-Johnson’s Boardmaker software

Each type of AAC method is designed to meet the unique needs of individuals with communication challenges, whether they are young children or adults. The selection depends on factors such as the individual's cognitive abilities, physical capabilities, and specific communication goals.",48.3818781375885,"AAC methods, or automatic algorithm configuration methods, can be classified into two main types based on their approach: sampling methods and model-based methods.

1. **Sampling Methods**: These methods involve systematically exploring the space of potential algorithms or configurations without presupposing a specific performance model. They are commonly implemented as:
   - **Search-based Methods**: Techniques like hill climbing, local search, and evolutionary algorithms (EAs) that make minimal assumptions about the representation of solvers and do not require derivative information.
   - **Experimental Design**: The use of designs such as full factorial designs to determine starting points for the sampling process.

2. **Model-based Methods**: These approaches build predictive models of algorithm performance based on gathered data. The core of model-based methods involves:
   - **Performance Prediction Models**: They utilize surrogate models to capture the relationship between algorithms and their expected performance, allowing for informed decision-making in the configuration process.
   - **Sequential Kriging Optimization (SKO)** and **Sequential Parameter Optimization (SPO)**: These specific methods are extensions designed to handle noisy performance measurements, improving efficiency in searching for optimal configurations.

Additionally, there are hybrid approaches that combine elements from different methodologies, leveraging strengths from local search, evolutionary strategies, and model-based techniques. Overall, the landscape of AAC involves both non-general and general methods, each tailored to specific operational needs and scenarios."
qwen2.5:7b-instruct-q4_0,"Are Parallel Algorithm Portfolios connected with financial portfolios?
","Document 1: 
 algorithms, and thereby combine parameter tuning and an algo-rithm portfolio in the same framework. We are pursuing this avenue as well. The performance of any algorithm portfolio is, of course, bounded by that of an or-acle. The combination of algorithms as black boxes eliminates any opportunity to im-prove an individual algorithm. In contrast, parallelism can be achieved by a variety of problem decomposition methods (e.g., search space splitting), as discussed in Section 3. Although the results of recent SAT solver competitions suggest that a well-designed algorithm portfolio outperforms decomposition methods on a small number 

Document 2: 
 is only determined by the current database. As a sequence, we will
introduce two portfolio frameworks as parallel individual-based
944
Algorithm Portfolio for Individual-based Surrogate-Assisted Evolutionary Algorithms GECCO ’19, July 13–17, 2019, Prague, Czech Republic
SAEAs and UCB for individual-based SAEAs which are motivated
from two different aspects as reviewed previously.
3.1 Parallel individual-based SAEAs
澽澶澡濇澵澹澵澧澽澶澡濇澵澹澵澦澽澶澡濇澵澹澵澥 澸濕濨濕澔
澶濕濧濙
濇濨濕濦濨
濇濨濣濤澳
濍
濂
澹濢濘
/ŶŝƚŝĂůŝǌĂƚŝŽŶ
/ŶĚŝǀŝĚƵĂů
^ƵƌƌŽŐĂƚĞ ^ƵƌƌŽŐĂƚĞ ^ƵƌƌŽŐĂƚĞ
/ŶĚŝǀŝĚƵĂů/ŶĚŝǀŝĚƵĂů
Figure1:Thediagramoftheframework:Parallelindividual-
based SAEAs.
Similar with the algorithm portfolio for canonical evolutionary
algorithms, it is intuitive to consider each individual-based SAEA
as a simple evolutionary algorithm and embed them into the exist-
ing framework, like PAP or MultiEA. From this aspect, the parallel
individual-based SAEAs (Par-IBSAEA) framework is proposed that
all algorithm candidates run simultaneously at each generation.
Nevertheless, it is more convenient than portfolio for canonical
evolutionaryalgorithmsbecausealmostallindividual-basedSAEAs
have the same algorithm structure and it does not require a par-
ticular design for each algorithm. A brief diagram for Par-IBSAEA
with only three algorithm instances is presented in Figure 1 where 

Document 3: 
 automatically producing effective parallel portfolios from multiple solvers, such as ppfolio and pfolioUZK, while exploiting 
the rich design spaces of these component solvers.
Katsirelos et al. [46] showed that an effective parallelization of a CDCL SAT solver does not merely hinge on picking a 
good clause sharing strategy, since it is not straightforward to obtain shorter resolution proofs by parallelization without 
essential changes of the underlying sequential reasoning mechanism. Our ACPP does not aim at parallelizing the resolution 
proof, but rather runs multiple algorithms and algorithm conﬁgurations in parallel, in order to maximize the probability 
that at least one of them ﬁnds a short proof quickly.
2.2. Related work
Well before there was widespread interest in multi-core computing, the potential beneﬁts offered by parallel algorithm 
portfolios were identiﬁed in seminal work by Huberman et al. [39]. Their notion of an algorithm portfolio is inspired by the 
use of portfolios of assets for risk management in ﬁnance and amounts to running multiple algorithms concurrently and 
independently on the same instance of a given problem, until one of them produces a solution. Gomes et al. [27] further 
investigated conditions under which such portfolios outperform their component solvers. Both lines of work considered 
prominent constraint programming problems (graph coloring and quasigroup completion), but neither presented methods 
for automatically constructing portfolio solvers. Parallel portfolios have since made practical impact, both in cases where 
the allocation of computational resources to algorithms in the portfolio is static [62,76] and where the component solvers 

Document 4: 
 is crucial for the effectiveness of any parallel portfolio.
According to (1), the performance of a parallel portfolio on
788 IEEE TRANSACTIONS ON CYBERNETICS, VOL. 52, NO. 2, FEBRUARY 2022
Algorithm 1 GAST
Input: base solvers B with conﬁguration space C; number of
component solvers k; instance set I; performance metric m;
algorithm conﬁgurator AC; independent conﬁgurator runs n; time
budgets tC, tV , tI for conﬁguration, validation and instance
generation respectively
Output:parallel portfolio c1:k
1: for i ← 1: k do
2: /*———— conﬁguration phase ———————*/
3: for j ← 1: n do
4: obtain a portfolio cj
1:i by running AC on conﬁguration space
{c1:i−1}×{ c|c ∈ C} using m for time tC
5: end for
6: validate c1
1:i, ...,cn
1:i on I using m for time tV
7: let c1:i ← arg mincj
1:i|j∈{1,...,n} P(cj
1:i, I) be the portfolio with
the best validation performance
8: /*———— instance-generation phase ————–*/ 

Document 5: 
 work relevant to parallel algorithm portfolios in-cludes online learning [2, 16] and methods that split problems [29, 30].) Effectively, the construction of a parallel algorithm portfolio to solve as many training problems as possible on K processors is an integer-programming (IP) prob-lem. The goal is to find the schedule S that specifies the time allotments to all algo-rithms on all processors, such that no problem can receive more than B time from all the processors together, and the total number of problems solved is a maximum. The expression (1 - )ij(tkj)) is 1 if problem xi is unsolved by algorithm aj after time tkj allo-cated to it 

Document 6: 
 divides the search space into subspaces, succes -
sively allocated to sequential CDCL workers. Work -
ers cooperate through some load-balancing strate -
gy, which performs the dynamic transfer of 
subspaces to idle workers, and through the 
exchange of conflict clauses.
The parallel portfolio approach was introduced 
in 2008 (Hamadi, Jabbour, and Sais 2008; Winter -
steiger, Hamadi, and de Moura 2009; Guo et al.
2010). It exploits the complementarity of different 
sequential DPLL strategies to let them compete and 
cooperate on the same formula. Since each worker 
addresses the whole formula, there is no need to 
introduce load-balancing overheads, and coopera -
tion is only achieved through the exchange of con -
flict clauses. With this approach, the crafting of the 
strategies is important, especially with only a few 
workers. The objective is to cover the space of good 
search strategies in the best possible way. 
In general, the interleaving of computation can 
lead to the previously mentioned problem of non -
determinism. This is true for solvers that use a 
Articles 
SUMMER 2013   101 
(2) Implication graph
(3) Con/f_lict-clause
(3) Con/f_lict-clause
(1) Literal
(4) Activity
(5) Con/f_lict
Preprocessing
Boolean Unit
Propagation 

","Yes, the concept of parallel algorithm portfolios is inspired by the use of portfolios of assets for risk management in finance. Huberman et al.'s seminal work on algorithm portfolios draws a parallel between asset portfolios and running multiple algorithms concurrently to manage problem-solving risks effectively.",10.77538251876831,"Yes, parallel algorithm portfolios are inspired by the concept of financial portfolios. The idea behind an algorithm portfolio is similar to that of a portfolio of assets in finance, which is used for risk management. Just as investors diversify their investments across various assets to manage risk, algorithm portfolios involve running multiple algorithms concurrently and independently on the same problem instance. This approach maximizes the probability of finding a solution by leveraging the strengths of different algorithms, akin to how different financial assets can balance out risks and returns."
qwen2.5:7b-instruct-q4_0,"What factors and challenges influenced the development of the Parallel Algorithm Portfolios?
","Document 1: 
 training set as well as for constructing the solvers.
This article studies effective construction approaches for
parallel portfolios that are less affected by nonrepresentative
training data. The term “parallel portfolio” [25], [26] refers
to a portfolio/set of solvers that is run independently in par-
allel when solving a problem instance (see Section III-A).
As a form of solvers, parallel portfolios have several impor-
tant advantages. First, exploiting parallelism has become very
important in designing efﬁcient solvers for computationally
hard problems, considering the great development and the
wide application of parallel computing architectures [27] (e.g.,
multicore CPUs) over the last decade. Parallel portfolios
employ parallel solution strategies and, thus, could easily make
effective use of modern hardware. Second, utilizing several
different solvers (as in parallel portfolios) is a simple yet
effective strategy for solving computationally hard problems.
Such an idea has also been realized in the form of sequential
portfolios [28], [29], which try to select the best solvers for
solving a problem instance, and adaptive solvers, such as adap-
tive parameter control [30]–[33]; reactive search [34], [35];
and hyper-heuristics [36]–[38], which seek to dynamically
determine the best solver setting while solving a problem
instance. In principle, all these methods need to involve some
mechanisms (e.g., selection or scheduling) to appropriately 

Document 2: 
 Historically, the parallel computing community quickly 
adopted combinatorial search as a playground for applications.
Search algorithms have the advantage of being conceptually 
simple (think of the most basic backtrack-style algorithm) and 
computationally demanding due to the (usually) exponential
size of the search space. In contrast, the search community did 
not really focus its research on parallelizing. The lack of proper 
Articles 
SUMMER 2013   99 Copyright © 2013, Association for the Advancement of Artificial Intelligence. All rights reserved. ISSN 0738-4602 
Seven Challenges in 
Parallel SAT Solving 
Youssef Hamadi and Christoph M. Wintersteiger 
n This article provides a broad overview of the 
state of the parallel SAT solving field. A set of 
challenges to researchers is presented that, we 
believe, must be met to ensure the practical
applicability of parallel SAT solvers in the 
future. All these challenges are described infor -
mally but put into perspective with related 
research results, and a (subjective) grading of 
difficulty for each of them is provided.
infrastructure and, for many, the feeling that 
sequential algorithms were still full of research 
opportunities can go toward explaining that. In 
that community, parallelism was often only put in 
the perspectives of papers with no real perspec -
tives. This led to a situation where parallel search 
algorithms were designed by people with only one 
part of the required skills. 
Most computational problems solved on a com - 

Document 3: 
 is only determined by the current database. As a sequence, we will
introduce two portfolio frameworks as parallel individual-based
944
Algorithm Portfolio for Individual-based Surrogate-Assisted Evolutionary Algorithms GECCO ’19, July 13–17, 2019, Prague, Czech Republic
SAEAs and UCB for individual-based SAEAs which are motivated
from two different aspects as reviewed previously.
3.1 Parallel individual-based SAEAs
澽澶澡濇澵澹澵澧澽澶澡濇澵澹澵澦澽澶澡濇澵澹澵澥 澸濕濨濕澔
澶濕濧濙
濇濨濕濦濨
濇濨濣濤澳
濍
濂
澹濢濘
/ŶŝƚŝĂůŝǌĂƚŝŽŶ
/ŶĚŝǀŝĚƵĂů
^ƵƌƌŽŐĂƚĞ ^ƵƌƌŽŐĂƚĞ ^ƵƌƌŽŐĂƚĞ
/ŶĚŝǀŝĚƵĂů/ŶĚŝǀŝĚƵĂů
Figure1:Thediagramoftheframework:Parallelindividual-
based SAEAs.
Similar with the algorithm portfolio for canonical evolutionary
algorithms, it is intuitive to consider each individual-based SAEA
as a simple evolutionary algorithm and embed them into the exist-
ing framework, like PAP or MultiEA. From this aspect, the parallel
individual-based SAEAs (Par-IBSAEA) framework is proposed that
all algorithm candidates run simultaneously at each generation.
Nevertheless, it is more convenient than portfolio for canonical
evolutionaryalgorithmsbecausealmostallindividual-basedSAEAs
have the same algorithm structure and it does not require a par-
ticular design for each algorithm. A brief diagram for Par-IBSAEA
with only three algorithm instances is presented in Figure 1 where 

Document 4: 
 rithm except some important parameter settings. Therefore, the
portfolio framework in PPTA framework can be parallel-based
framework as well as sequential-based framework.
The algorithm portfolio requires algorithm constituents to
be complementary so that the portfolio algorithm can handle
different types of problems. But it is not easy to select the com-
plementary algorithms which need to test algorithm candidates
in benchmark functions. In PPTA framework, the parameter
conﬁguration obtained from different kinds of problems are
naturally complementary thanks to the classiﬁcation of train-
ing instances. Therefore, we can obtain the complementary
algorithm much easier to construct the algorithm portfolio.
3) Robustness: For each algorithm constituent in the port-
folio, it is the best parameter conﬁguration found for the
speciﬁc kind of problems. Each algorithm is suitable for a
kind of problem so that the portfolio algorithm can handle
several kinds of problems. As a result, the optimization risk
is obviously reduced.
4) Efﬁciency: The time complexity of parameter tuning
algorithm in PPTA framework can be reduced signiﬁcantly
compared with commonly used parameter tuning methods. As
mentioned before, the performance metric only evaluates the
parameter candidates on one speciﬁc problem instance.
In the algorithm portfolio phase, the time complexity does-
n’t increase a lot compared with the single algorithm because
the operators of the algorithm in PPTA are the same with
single algorithm and the total computational resources (i.e.
max FEs) are also the same. The only difference is the
strategy allocating computational resources which varies from
algorithm to algorithm. 

Document 5: 
 divides the search space into subspaces, succes -
sively allocated to sequential CDCL workers. Work -
ers cooperate through some load-balancing strate -
gy, which performs the dynamic transfer of 
subspaces to idle workers, and through the 
exchange of conflict clauses.
The parallel portfolio approach was introduced 
in 2008 (Hamadi, Jabbour, and Sais 2008; Winter -
steiger, Hamadi, and de Moura 2009; Guo et al.
2010). It exploits the complementarity of different 
sequential DPLL strategies to let them compete and 
cooperate on the same formula. Since each worker 
addresses the whole formula, there is no need to 
introduce load-balancing overheads, and coopera -
tion is only achieved through the exchange of con -
flict clauses. With this approach, the crafting of the 
strategies is important, especially with only a few 
workers. The objective is to cover the space of good 
search strategies in the best possible way. 
In general, the interleaving of computation can 
lead to the previously mentioned problem of non -
determinism. This is true for solvers that use a 
Articles 
SUMMER 2013   101 
(2) Implication graph
(3) Con/f_lict-clause
(3) Con/f_lict-clause
(1) Literal
(4) Activity
(5) Con/f_lict
Preprocessing
Boolean Unit
Propagation 

Document 6: 
 the former is to generate instances that are challenging for the
current portfolio, while the aim of the latter is to ﬁnd a new
component solver for the portfolio to better solve the newly gen-
erated instances. Applied to two widely studied problem domains,
that is, the Boolean satisﬁability problems (SAT) and the travel-
ing salesman problems (TSPs), the proposed approach identiﬁed
parallel portfolios with much better generalization than the ones
generated by the existing approaches when the training data
were scarce and biased. Moreover, it was further demonstrated
that the generated portfolios could even rival the state-of-the-art
manually designed parallel solvers.
Index Terms—Automatic portfolio construction (APC), genera-
tive adversarial approach, parallel algorithm portfolio, parameter
tuning.
I. I NTRODUCTION
M
ANY high-performance algorithms for solving com-
putationally hard problems, ranging from the exact
Manuscript received May 17, 2019; revised October 5, 2019 and March
4, 2020; accepted March 23, 2020. Date of publication April 29, 2020; date
of current version February 16, 2022. This work was supported in part by
the National Key Research and Development Program of China under Grant
2017YFB1003102, in part by the Guangdong Provincial Key Laboratory under
Grant 2020B121201001, in part by the Natural Science Foundation of China
under Grant 61672478, in part by the Program for Guangdong Introducing
Innovative and Enterpreneurial Teams under Grant 2017ZT07X386, in part 

","The development of parallel algorithm portfolios has been significantly shaped by a variety of factors and challenges, including:

1. **Scalability**: As problem sizes increase in complexity, traditional sequential algorithms often struggle to find solutions within acceptable time frames. Parallel algorithm portfolios aim to address this by distributing the workload across multiple processors or machines.

2. **Algorithm Diversity**: The success of parallel portfolio approaches depends on having a diverse set of algorithms that can handle different types and complexities of problems. Different algorithms may excel at solving particular subsets of problems, making it necessary to combine them effectively.

3. **Resource Management**: Efficiently managing resources in a parallel setting is crucial. This includes balancing the workload among processors, minimizing communication overhead between processes, and ensuring load balancing to avoid idle time on some processors while others are overloaded.

4. **Performance Evaluation and Selection**: Evaluating which algorithms perform best for a given problem instance requires careful consideration of performance metrics such as runtime, solution quality, and reliability. Selecting the right combination of algorithms that work well together is also challenging.

5. **Adaptability to Dynamic Environments**: Problems can change over time or under different conditions, requiring portfolios to be adaptive and responsive. This involves developing mechanisms for dynamically adjusting the portfolio composition based on changing problem characteristics.

6. **Communication and Coordination**: In parallel settings, effective communication and coordination between algorithms are essential. Ensuring that results from one algorithm can contribute positively to another's performance without causing significant overhead is a key challenge.

7. **Algorithm Interaction and Synergy**: Understanding how different algorithms interact and leveraging their synergies effectively requires detailed analysis and experimentation. Combining algorithms in ways that enhance rather than hinder each other’s performance is critical.

8. **Parallelization Strategies**: Developing efficient parallelization strategies for both the portfolio management system itself and the underlying algorithms is essential. This includes designing scalable data structures, communication protocols, and scheduling mechanisms.

9. **Scalability of Parallel Architectures**: The effectiveness of parallel algorithm portfolios depends on the scalability of the hardware and software infrastructure used to run them. Ensuring that these systems can handle increasingly complex problems requires continuous innovation in both hardware design and software architecture.

10. **User Interface and Accessibility**: Making the benefits of parallel algorithm portfolios accessible to users who may not have extensive knowledge about parallel computing or optimization techniques is important for wider adoption and practical utility.

Addressing these factors and overcoming associated challenges has driven advancements in parallel algorithm portfolio development, contributing to more robust and efficient solutions for a wide range of computational problems.",61.71689176559448,"The development of Parallel Algorithm Portfolios has been influenced by several factors and challenges. Firstly, the effective construction of these portfolios is crucial, particularly concerning nonrepresentative training data, which can lead to inefficiencies. The need for utilizing different solvers within a portfolio allows for exploiting their complementarity, showcasing how they can handle different types of problems, thereby enhancing robustness and efficiency.

Another challenge involves the dynamic nature of parallel computing, where issues such as interleaving computations can lead to non-determinism. Strategies must be designed to ensure cooperation between workers while avoiding excessive load-balancing overheads. Additionally, the parallel computing community's initial lack of focus on parallelizing search algorithms, despite their computational demands, posed a challenge when integrating parallel approaches.

Moreover, the difficulty of selecting complementary algorithms for a portfolio, which necessitates extensive testing across various benchmark functions, remains a significant barrier. Researchers also face the challenge of developing effective parameter tuning methods that do not increase computational time complexity when integrating multiple algorithms.

Furthermore, efforts to generate challenging instances for portfolios, combined with the need to identify new solvers to enhance performance, inform ongoing research and development strategies. This context-driven construction, particularly under conditions of scarce and biased training data, emphasizes the necessity of advancements in automatic portfolio construction techniques to rival state-of-the-art manually designed solvers. Overall, addressing these challenges is essential for ensuring the practical applicability of parallel algorithm portfolios in solving complex computational problems."
qwen2.5:7b-instruct-q4_0,What are the main benefits of PAPs?,"Document 1: 
 independently in parallel to obtain multiple solutions. Then, the best solution will be
taken as the ﬁnal output of the PAP . Although a PAP would consume more computational
resources than a single algorithm, it has three important advantages. First, PAPs are
easy-to-implement because they do not necessarily require any resource allocation since
each member algorithm is simply assigned with the same amount of resource. Second,
the performance of a PAP on any problem is the best performance achieved among its
member algorithms on the problem. In other words, a PAP could achieve a much better
overall performance than any of its member algorithms. Third, considering the tremendous
growth of parallel computing architectures [22] (e.g., multi-core CPUs) over the last few
decades, leveraging parallelism has become very important in designing effective solvers
for hard optimization problems [23–27]. PAPs employ parallel solution strategies and thus
allow for the use of modern computing facilities in an extremely simple way.
It is conceivable that any PAP’s effectiveness relies heavily on the diversity and com-
plementarity among its member algorithms. In other words, the manual construction
of high-quality PAPs is generally a challenging task, requiring domain experts (with a
deep understanding of both algorithms and problems) to explore the vast design space
of PAPs, which cannot be carried out manually with ease [28–30]. As an alternative, Tang
and Liu [25,26] proposed a general framework, called automatic construction of PAPs, that 

Document 2: 
 on PAP with more than two constituent algorithms.
Two conclusions regarding the migration scheme of PAP
can be drawn from the superiority of PAP over the compared
algorithms. First, the migration scheme is of great impor-
tance to the success of PAP. Second, 1 andMAX GEN/20
are two appropriate and robust values for the parame-
tersmigration size and migration interval. To further
investigate the inﬂuence of these parameters on PAP, we
carried out a sensitivity analysis to check whether the per-
formance of PAP will change signiﬁcantly with other param-
eter settings. As stated in Section VI-B, 16 different pairs
ofmigration interval and migration size were tested for
every instantiation of PAP. For each pair, 30 independent
runs were executed on all 27 benchmark functions. Then, for
each instantiation on each function, Kruskal–Wallis one-way
analysis of variance by ranks was employed to test whether
the 16 pairs of parameters had led to signiﬁcantly different
performance. After that, for each instantiation of PAP, we
counted the number of the benchmark functions on which
all 16 pairs of parameters made no difference. The larger
the number, the more insensitive an instantiation is to the
parameters. For the sake of brevity, we only summarize in
Table IX these numbers for the 11 PAP instantiations, while
omit the full details. It can be observed that, in the worst case 

Document 3: 
 described as follows:
Ω(P, z) =max{max
θ∈P
Metric (θ, z), Metric ( ¯θ, z)}, (14)
where ¯θ represents the Restructure procedure. Note Equation (14) is slightly different from
Equation (11) (i.e., the performance of conventional PAPs) due to theRestructure procedure.
Initialization
member 
algorithm 
𝜃
1
𝑆
1
member 
algorithm 
𝜃
𝑖
𝑆
𝑖
member 
algorithm 
𝜃
𝑘
𝑆
𝑘
…
…
…
…
𝑆
𝑘
+
1
𝑆
𝑜𝑢𝑡𝑝𝑢𝑡
Comparison
Restructure
Improvement
Figure 1. Illustrations of MOEAs/PAP , the variant form of PAP for MOPs. Si represents the so-
lution set found by member algorithm θi, and Soutput represents the solution set ﬁnally returned
by MOEAs/PAP . The main difference of MOEAs/PAP from conventional PAPs lies in the way of
determining the ﬁnal output, as indicated by the dash box.
Electronics 2023, 12, 4639 7 of 18
4. Automatic Construction of MOEAs/PAP
As aforementioned, the member algorithms of a PAP could be automatically deter-
mined by solving the problem deﬁned in Equation (13). Below, we ﬁrst introduce the 

Document 4: 
 • When constructing MOEAs/PAPs, it is important to maintain the diversity among the
member algorithms. Hence, the population diversity preservation schemes, such as
negatively correlated search [47], can be introduced into the construction approach to
promote cooperation between different member algorithms.
• In real-world applications, one may be unable to collect sufﬁcient MOPs as training
problems. How to automatically build powerful PAPs in these scenarios is also
worth studying.
• The effectiveness of MOEAs/PAP has been primarily demonstrated through exper-
imental evidence, but with an absence of theoretical analysis. A more thorough
investigation of its exceptional performance is crucial for advancing our understand-
ing, which, in turn, can lead to enhancements in its design and the development of a
more comprehensive automatic construction algorithm.
Electronics 2023, 12, 4639 17 of 18
Author Contributions: Conceptualization, S.L.; Methodology, S.L.; Software, X.M.; Validation, X.M.;
Resources, X.M.; Writing—original draft, X.M.; Writing—review and editing, W.H.; Supervision, S.L.
and W.H. All authors have read and agreed to the published version of the manuscript.
Funding: This research was supported by the Strategic Priority Research Program of Chinese
Academy of Science, Grant No. XDB32050100, and the National Natural Science Foundation of
China, Grant No. 91948303.
Data Availability Statement: The data presented in this study are available on request from the 

Document 5: 
 the risks associated with two algorithms. Such a metric can
be used to evaluate how effective our PAP is, together with
other common metrics. Given a set of functions, the proposed
metric essentially measures how likely it is that an algorithm
will ﬁnd a better solution than another algorithm by the end
of a given time budget.
To evaluate the effectiveness of PAP, 11 instantiations of
PAP were implemented based on four existing constituent
algorithms, including SaNSDE, wPSO, G3PCX, and CMA-
ES. The performance of each instantiation was compared to
PENG et al.: POPULATION-BASED ALGORITHM PORTFOLIOS FOR NUMERICAL OPTIMIZATION 799
its constituent algorithms on 27 benchmark functions. Our
experimental results showed that seven out of the 11 PAP in-
stantiations outperformed their constituent algorithms in terms
of solution quality and the proposed risk metric. Furthermore,
7 out of the 11 instantiations even achieved superior or compa-
rable performance in comparison with G-CMA-ES, which was
known to be superior to any of the four constituent algorithms.
Our empirical studies also revealed that PAP is capable of
increasing the probability of ﬁnding the global optimum and
is insensitive to control parameters of the migration scheme.
Further analyses have been conducted to investigate in what
circumstance PAP may outperform its constituent algorithms.
Complementarity was identiﬁed as a key issue.
Though PAP has been shown to be a promising framework, 

Document 6: 
 also presented. The performance of the two instantiations on
TSP and VRPSPDTW problems support the effectiveness of
CEPS in the sense that, in comparison with state-of-the-art
PAP construction approaches, the PAPs obtained by CEPS
achieves better generalization performance.
Since CEPS is a generic framework, some discussions
would help elaborate issues that are of signiﬁcance in practice.
First, although this work assumes CEPS takes a set of initial
training instances as the input, such training instances are
not necessarily real-world instances but could be generated
randomly. In other words, CEPS could be used in a fully cold-
start setting (a.k.a. zero-shot), i.e., no real-world instances are
available for the target problem class. Further, CEPS could
either be run ofﬂine or online, i.e., it could accommodate new
real instances whenever available.
Second, the potential of CEPS could be further explored
by taking advantage of the data generated during its run,
except for the ﬁnal obtained PAP. The data contain all the
sampled conﬁgurations and instances, and the performance
of the former on the latter. Considering that when using
a search method to solve a problem instance, its optimal
parameter values are usually problem-instance dependent and
thus need to be tuned. To tune parameters for a new problem
instance, we can learn from the historical data generated by
CEPS to build a mapping from problem instances to their
optimal parameter values, i.e., a low-cost online parameter- 

","Positive Airway Pressure (PAP) devices, including Continuous Positive Airway Pressure (CPAP), Bi-level Positive Airway Pressure (BiPAP), and Automatic Positive Airway Pressure (APAP), provide several key benefits for individuals with sleep-disordered breathing or respiratory conditions:

1. **Improved Sleep Quality**: PAP therapy helps users achieve deeper and more restful sleep by keeping their airways open, reducing snoring, and preventing episodes of apnea (pauses in breathing) during the night.

2. **Enhanced Daytime Alertness**: Better quality sleep often results in increased alertness, energy, and concentration throughout the day. Users may experience less daytime drowsiness, improved mood, and enhanced cognitive function.

3. **Healthier Cardiovascular Profile**: By maintaining a stable airway pressure, PAP devices can help lower blood pressure and reduce the risk of heart disease, stroke, and other cardiovascular issues associated with sleep apnea.

4. **Reduced Risk of Hypertension**: Sleep-disordered breathing is closely linked to hypertension (high blood pressure). Proper use of a PAP machine can lead to significant reductions in blood pressure levels.

5. **Improved Respiratory Function**: For individuals with chronic obstructive pulmonary disease (COPD) or other respiratory conditions, PAP therapy can help maintain adequate oxygenation and improve overall lung function by ensuring the airways remain open while sleeping.

6. **Weight Management**: Some studies suggest that treating sleep apnea may lead to weight loss as a side effect of improved sleep quality and reduced daytime fatigue.

7. **Better Overall Quality of Life**: By addressing the symptoms of sleep-disordered breathing, PAP therapy can enhance overall well-being, leading to better relationships, increased productivity at work or school, and an improved sense of life satisfaction.

8. **Prevention of Other Health Complications**: Treating sleep apnea with PAP devices may reduce the risk of developing other health conditions such as diabetes, depression, and gastroesophageal reflux disease (GERD).

9. **Better Sexual Function**: Improved sleep quality can lead to better sexual function in both men and women.

10. **Reduced Strain on Relationships**: By addressing the disruptive snoring and restless nights associated with sleep apnea, PAP therapy can help improve relationships by reducing stress and strain on bed partners.

These benefits make PAP devices a crucial tool for managing sleep-disordered breathing and related respiratory conditions, significantly improving both physical health and quality of life.",61.91627788543701,"The main benefits of Population-Based Algorithm Portfolios (PAPs) include:

1. **Easy Implementation**: PAPs are simple to implement as they do not require complex resource allocation; each member algorithm is assigned the same resources.

2. **Enhanced Performance**: The performance of a PAP is determined by the best result achieved among its member algorithms for a given problem, potentially leading to better overall performance compared to any individual algorithm.

3. **Utilization of Parallel Computing**: PAPs leverage parallel solution strategies, thereby effectively utilizing modern parallel computing architectures, which is crucial for tackling hard optimization problems.

4. **Diversity and Complementarity**: The effectiveness of a PAP relies on the diversity and complementarity among its member algorithms, which can lead to more robust solutions.

5. **Sensitivity to Parameters**: Empirical studies have shown that PAPs can be insensitive to the control parameters of the migration scheme, making their performance more stable across different settings.

Overall, these benefits contribute to the robustness and effectiveness of PAPs in solving complex optimization problems."
llama3.1:latest,"What does the term ""learn to optimize"" mean?
","Document 1: 
 NatlSciRev ,2024,Vol.11,nwae132
Solver 4
Solver 1
Solver 2
Solver 3
Configuration space of algorithms
(solver class)
Facilitate the tedious trial-and-error process for
getting a good solver for an unseen instance
Solver 5
Unseen instances
Training set Solver class
Optimization problem class
Knowledge
Learning
Vehicle routing
problem
Machine learning
Traveling
salesman
problem
Problem Instance 1
Problem Instance 2
Problem Instance 3
Optimization problems
Figure 1 Illustration of the general idea of L2O. 
the same general paradigm that is very similar to 
the typical ML paradigm. That is, they leverage on 
a set of training instances from the target optimiza- 
tion problem class to gain something that would help 
alleviate the tedious algorithm configuration process 
on unseen problem instances, as i l lustrated in Fig. 1 . 
This article puts them under the umbrella term learn 
to optimize (L2O) and provides a brief overview on 
the general ideas as well as critical issues of L2O, in- 
cluding the training process, theoretical foundations 
as well as generalization issues. For more algorithmic 
details on NN-based solvers and heuristic solvers, 
readers are referred to [13 ,14 ] and [15 ,16 ], respec- 
tively. 

Document 2: 
 m∑
i=1
U(s, Xi),
where Xi is a random variable, representing an instance randomly drawn from X.
Notice that Um(s) is a random variable.
We deﬁne two properties of SPPAs, generalization and optimality. An SPPA
learning algorithm generalizes well, when the utility on all instances is close to the
utility on the training set. An SPPA learning algorithm is optimal, if the optimal
SPPA on the training set is close to the optimal result on the set of all instances.
These properties are formalized by the following deﬁnition.
Learning parallel portfolios of algorithms 99
Deﬁnition 6.1 We say that an SPPA learning algorithm mean-generalizes,i ff o ra n y
0 <ϵ and 0 <δ< 1 it outputs an SPPA s ∈ S,f o rw h i c h
P [Um(s) − E [U(s, X)] >ϵ ] ≤ δ.
Let the globally optimal algorithm be:
s∗ = arg max
s∈S
E [U(s, X)] .
We say that an SPPA learning algorithm ismean optimal,i ff o ra l l0 <ϵ and 0<δ< 1
it outputs a schedule s
P
[
E
[
U(s∗, X)
]
− E [U(s, X)] >ϵ 

Document 3: 
 model and select conﬁgurations, respectively.
Input :Target algorithm Awith parameter conﬁguration space Θ; instance set Π; cost
metric ˆc
Output :Optimized (incumbent) parameter conﬁguration, θinc
1 [R, θinc] ←Initialize(Θ, Π);
2 repeat
3 [M,tfit ] ←FitModel(R);
4 [ ⃗Θnew,tselect] ←SelectConﬁgurations(M, θinc, Θ);
5 [R,θinc] ←Intensify( ⃗Θnew, θinc, M, R, tfit + tselect, Π, ˆc);
6 until total time budget for conﬁguration exhausted;
7 return θinc;
parameter optimization (SPO) toolbox—which has received considerable attention in the
evolutionary algorithms community—provides many features that facilitate the manual
analysis and optimization of algorithm parameters; it also includes an automated SMBO
procedure for optimizing continuous parameters on single instances. We started our
own work in SMBO by comparing SKO vs SPO, studying their choices for the four
SMBO components [18]. We demonstrated that component Intensify mattered most, and
improved it in our SPO + algorithm [18]. Subsequently, we showed how to reduce the
overhead incurred by construction and use of response surface models via approximate
GP models. We also eliminated the need for a costly initial design by interleaving ran- 

Document 4: 
 this is to be taken as either the efficiency or the 
effectiveness of the solver.
r = n! Ts
Tns
The Challenges 
As presented in the introductory paragraphs, a 
divide-and-conquer approach can be lucky. A run 
can benefit from a good split, which brings a solu -
tion at the beginning of some subspace and allows 
for an early stop. In contrast, a different division 
can decrease performance. What is interesting here 
is that adding resources can decrease the perform -
ance since it can produce more demanding sub -
spaces. 
Even if portfolio-based approaches are less prone 
to this problem, extending the size of a portfolio 
can still be detrimental to its performance. In gen -
eral, this increases the overhead, due to more fre -
quent and broader clause sharing, and worsens 
cache-congestion issues. A priori, the question of 
deciding the most effective number of resources to 
use against a given formula is a difficult one. 
One possible direction of research is to extend 
automatic tuning techniques. These approaches 
use machine learning to craft a predictive function 
that relates the features of an instance and the 
parameters of a given solver to its expected run 
time. This function can be learned and tested 
offline against a large set of representative 
instances and used at run time to configure a solver 
and maximize its performance. This offline 
approach assumes that a large and representative 

Document 5: 
 OPT := inf
θ∈Θ
R(θ).
The search for the optimal conﬁguration is generally too ambitious, as the total runtime
required for the conﬁgurator must be extraordinarily large (possibly inﬁnite) to guarantee
that the best algorithm conﬁguration returned by the conﬁgurator is in fact the optimal
one with high probability.
As a workaround, one can leverage the idea underlying PAC learning (Valiant, 1984) to
the problem at hand. The basic idea is to relax the goal of ﬁnding the optimal conﬁguration
itself and, instead, ﬁnd a conﬁguration that is considered to be “good enough”. As there are
potentially several such “good enough” conﬁgurations 6, this relaxation of the goal allows
the search to be completed in less (and, thus, feasible) time. In this context, “good enough”
means that the expected runtime is only worse than the optimal expected runtime up to
a multiplicative factor of 1 + ε for some ﬁxed precision parameter ε > 0. Formally, a
conﬁguration is said to be ε-optimal (“good enough”) iﬀ
Ei∼P(c(i,θ)) ≤(1 + ε)OPT.
However, this relaxation of the target is problematic in the context of AC problems, since the
runtimes of conﬁgurations often exhibit a heavy-tailed distribution. Indeed, it is not diﬃcult
to construct an example based on such distributions in which any (sensible) conﬁgurator
would, in the worst case, take inﬁnitely long to ﬁnd an ε-optimal conﬁguration; see for 

Document 6: 
 tions of learning machines, which lead to objective 
functions that favor different optimization methods. 
As a result, many optimization techniques, including 
convex optimization methods [1 ], gradient descent 
[2 ], heuristic search [3 ] as well as evolutionary algo- 
rithms (E A s) [4 ], have been utilized by the ML com- 
munity in the past decades. 
Mainstream optimization algorithms are usu- 
ally highly configurable parameterized algorithms, 
i.e. they involve tunable parameters. Performance of 
such algorithms may vary significantly with different 
parameter settings. Hence, to solve the optimization 
problem induced by a learning task, tedious efforts 
are typically needed to configure the optimization al- 
gorithm. Consider the case of training an NN with 
stochastic gradient descent (SGD). It is widely ac- 
knowledged that the training performance is sensi- 
tive to the learning rate [5 ], a parameter of SGD. 
How to determine the optimal or at least appropri- 
ate learning rate has become a major hurdle for train- 
ing NNs, especially for large-scale NNs [6 ], or when 
the objective function is not an explicit differentiable 
function of the weights of an NN, as in the typical re- 
inforcement learning setting [7 ]. 
In order to reduce the human labor required, 
many studies have attempted to automate the config- 
uration of optimization algorithms [6 ,8 ]. However, 

","The term ""Learn to Optimize"" (L2O) refers to a general paradigm that leverages training instances from an optimization problem class to gain knowledge that helps alleviate the tedious algorithm configuration process on unseen problem instances.",39.20988249778748,"The term ""learn to optimize"" (L2O) refers to a paradigm in which algorithms utilize a set of training instances from a specific optimization problem class to facilitate the process of configuring optimizers for unseen problem instances. The L2O approach aims to alleviate the tedious trial-and-error process often required to find effective solvers for optimization problems. By leveraging machine learning techniques, L2O seeks to provide solutions that improve the configuration of algorithms when they encounter new instances, enhancing their performance and generalization capabilities."
llama3.1:latest,"Please give some examples of metaheuristics.
","Document 1: 
 usually provide only sub-optimal solutions because they do
not attempt to escape from local optimum. These drawbacks
have led to the introduction of metaheuristics.
Metaheuristics are high-level methodologies or general al-
gorithmic templates, which generally do not adapt deeply
to speciﬁc problem(s) [4]. Hence, they usually can solve a
wide range of problems [2]. In fact, the preﬁx “meta”, which
means “upper level methodology”, indicates that metaheuristic
algorithms can be viewed as “higher level” heuristics. Hy-
brid approaches based on existing metaheuristic(s) are also
considered metaheuristics [5]. In last decades, metaheuristics
have received widespread attention from researchers and are
widely recognized as efﬁcient approaches for hard optimiza-
tion problems. A number of metaheuristic algorithms have
been developed and extensively applied, including Simulated
Annealing (SA) [6], Tabu Search (TS) [7], Evolutionary Algo-
rithms (EAs) [8], Ant Colony Optimization algorithm (ACO)
[9], Particle Swarm Optimization (PSO) [10], and so forth.
Most of metaheuristics are nature-inspired (inspired from some
principles in physics, biology and etc.), contain stochastic
components, and often have several free parameters that can
be set by users according to problem(s) at hand [4].
The setting of parameters (or parameter setting) has strong 

Document 2: 
 aside any metaphorical language. We utterly believe that eﬀorts in 
this direction should be intensiﬁed, building upon the initial postula- 
tions established in some recent works [105,106] . Speciﬁcally, meta- 
heuristics components (including search operators and algorithmic 
behavioral patterns) and interfaces between them should be stan- 
dardized towards objectively assessing similarities and diﬀerences 
between metaphor-based solvers [107] . A novel metaphor is by no 
means a suﬃcient guarantee for a signiﬁcant scientiﬁc contribution. 
• The third of these reasons is methodological, i.e., the relevance of 
some of the building blocks of the overall algorithm. A particular 
algorithm can include a given component (for example, a local op- 
timizer) that can be of relevance even if the algorithm as a whole 
is not completely competitive with respect to the prevailing liter- 
ature. A good example supporting this claim can be observed in 
co-evolutionary frameworks, which usually include a procedure to 
identify the subcomponents that will be individually co-evolved. In 
those cases, even if the subcomponent optimizer is not very sophis- 
ticated, the co-evolutionary framework can be relevant by itself. In 
this sense, it is important to select the appropriate framework to 
highlight the desired characteristic of the proposed algorithm, as dis- 
cussed in Section 3.1 . Following the same example of subcomponents 
identiﬁcation, a researcher focused on large-scale global optimiza- 

Document 3: 
 J. Durillo , K. Hammond , E. Hart , C.G. Johnson , et al. , A research agenda for meta- 
heuristic standardization, in: Proceedings of the XI metaheuristics international 
conference, 2015, pp. 1–3 . 
[106] J. Swan , S. Adraensen , A.E. Brownlee , C.G. Johnson , A. Kheiri , F. Krawiec , 
J. Merelo , L.L. Minku , E. Özcan , G.L. Pappa , et al. , Towards metaheuristics ”i n 
the large ”, arXiv preprint arXiv:2011.09821 (2020) . 
[107] M.A. Lones , Mitigating metaphors: a comprehensible guide to recent nature-in- 
spired algorithms, SN Computer Science 1 (1) (2020) 49 . 
[108] M. Jain, V. Singh, A. Rani, A novel nature-inspired algorithm for optimiza- 
tion: squirrel search algorithm, Swarm Evol Comput 44 (2019) 148–175, 
doi: 10.1016/j.swevo.2018.02.013 . 
[109] A.W. Mohamed, A.A. Hadi, A.K. Mohamed, Gaining-sharing knowledge 
based algorithm for solving optimization problems: a novel nature- 

Document 4: 
 erations Research54(1):99–114.
Bartz-Beielstein, T. 2006. Experimental Research in Evolution-
ary Computation. Springer V erlag.
Battiti, R., and Brunato, M. 2005. Reactiv e search: machine
learning for memory-based heuristics. Technical Report DIT-05-
058, Universit`a Degli Studi Di Trento, Trento, Italy.
Birattari, M.; St¨utzle, T.; Paquete, L.; and V arrentrapp, K. 2002.
A racing algorithm for conﬁguring metaheuristics. In Proc. of
GECCO-02, 11–18.
Birattari, M. 2004. The Problem of Tuning Metaheuristics as
Seen from a Machine Learning Perspective. Ph.D. Dissertation,
Universit´e Libre de Bruxelles, Brussels, Belgium.
Coy, S. P .; Golden, B. L.; Runger, G. C.; and Wasil, E. A. 2001.
Using experimental design to ﬁnd effective parameter settings for
heuristics. Journal of Heuristics7(1):77–97.
E´en, N., and S¨orensson, N. 2003. An extensible SA T solver. In
Proc. of SAT-03, 502–518. 

Document 5: 
 art algorithm, MOS, has been clearly surprised by SHADE-ILS and 
MLSHADE-SPA, hence becoming the most competitive algorithms 
(with a preference by SHADE-ILS, by its better performance and sim- 
plicity). 
8. Conclusions and outlook 
In this work we have stressed on the need for circumventing com- 
mon mistakes and ﬂaws observed in the ﬁeld of bio-inspired optimiza- 
tion, particularly when new meta-heuristic algorithms are proposed and 
experimentally validated over benchmarks designed to this end. Specif- 
ically, we have reviewed and critically analyzed contributions deal- 
ing with experimental recommendations and practices related to meta- 
heuristics. Following our literature study, we have prescribed a set of 
methodological recommendations for preparing a successful proposal 
of bio-inspired meta-heuristic algorithms, from the deﬁnition of the ex- 
perimentation to the presentation of the results. A number of useful 
techniques (graphically summarized in Fig. 9 ) have been suggested for 
prospective studies to implement our proposed methodological frame- 
work, in an attempt at ensuring fairness, coherence and soundness in 
future studies on the topic. Two diﬀerent case studies have been de- 
signed to exemplify the application of our prescribed methodology, dis- 
cussing on the results of the application of each guideline. Although both 
case studies deal with well-known benchmarks, we envision that our 
methodology can be a core part of the design process of meta-heuristic 

Document 6: 
 achieved using several heuristic mechanisms that interact in complex, non-intuitive
ways. For example, a DPLL-style complete solver for SAT (a prototypical NP-
complete problem with important applications in the design of reliable soft- and
hardware) may use different heuristics for selecting variables to be instantiated and
the values ﬁrst explored for these variables, as well as heuristic mechanisms for
managing and using logical constraints derived from failed solution attempts. The
activation, interaction and precise behaviour of those mechanisms is often controlled
by parameters, and the settings of such parameters have a substantial impact on the
Holger H. Hoos
Department of Computer Science, University of British Columbia, 2366 Main Mall, Vancouver,
BC, V6T 1Z4, Canada, e-mail: hoos@cs.ubc.ca
1 We note that the use of heuristic techniques does not imply that the resulting algorithms are nec-
essarily incomplete or do not have provable performance guarantees, but often results in empirical
performance far better than the bounds guaranteed by rigorous theoretical analysis.
Y . Hamadi et al. (eds.),Autonomous Search,
DOI 10.1007/978-3-642-21434-9 3,
© Springer-Verlag Berlin Heidelberg 2011
37
38 Holger H. Hoos
efﬁcacy with which a heuristic algorithm solves a given problem instance or class of 

","Some examples of metaheuristics include Simulated Annealing (SA), Tabu Search (TS), Evolutionary Algorithms (EAs), Ant Colony Optimization algorithm (ACO), and Particle Swarm Optimization (PSO).",14.051278829574583,"Some examples of metaheuristics include Simulated Annealing (SA), Tabu Search (TS), Evolutionary Algorithms (EAs), Ant Colony Optimization (ACO), and Particle Swarm Optimization (PSO)."
llama3.1:latest,"What is the ""no free lunch"" theorem about?
","Document 1: 
 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTA TION, VOL. 1, NO. 1, APRIL 1997 67
No Free Lunch Theorems for Optimization
David H. Wolpert and William G. Macready
Abstract— A framework is developed to explore the connection
between effective optimization algorithms and the problems they
are solving. A number of “no free lunch” (NFL) theorems are
presented which establish that for any algorithm, any elevated
performance over one class of problems is offset by perfor-
mance over another class. These theorems result in a geometric
interpretation of what it means for an algorithm to be well
suited to an optimization problem. Applications of the NFL
theorems to information-theoretic aspects of optimization and
benchmark measures of performance are also presented. Other
issues addressed include time-varying optimization problems and
a priori“head-to-head” minimax distinctions between optimiza-
tion algorithms, distinctions that result despite the NFL theorems’
enforcing of a type of uniformity over all algorithms.
Index T erms— Evolutionary algorithms, information theory,
optimization.
I. I NTRODUCTION
T
HE past few decades have seen an increased interest
in general-purpose “black-box” optimization algorithms
that exploit limited knowledge concerning the optimization
problem on which they are run. In large part these algorithms
have drawn inspiration from optimization processes that occur
in nature. In particular, the two most popular black-box 

Document 2: 
 function, and will produce .
The proof is completed if we show that there is no cost
function so that produces a sample containing and
and such that produces a sample containing and .
There are four possible pairs of samples to consider:
i) ;
ii) ;
iii) ;
iv) .
Since if its ﬁrst point is a , jumps to which is where
starts, when ’s ﬁrst point is a its second point must
equal ’s ﬁrst point. This rules out possibilities i) and ii).
For possibilities iii) and iv), by ’s sample we know that
must be of the form , for some variable . For
case iii), would need to equal , due to the ﬁrst point in
’s sample. For that case, however, the second point sees
would be the value at , which is , contrary to hypothesis.
For case iv), we know that the would have to equal , due
to the ﬁrst point in ’s sample. That would mean, however,
that jumps to for its second point and would therefore
see a , contrary to hypothesis.
Accordingly, none of the four cases is possible. This is
a case both where there is no symmetry under exchange of
’s between and , and no symmetry under exchange of
histograms.
A PPENDIX G 

Document 3: 
 The sum over can be accomplished in the same manner
is summed over. In fact, all the sums over all can
be done, leaving
(7)
In this last step, the statistical independence of and has
been used.
Further progress depends on whether represents or
. We begin with analysis of the case. For this case
, since only reﬂects cost
values from the last cost function, . Using this result gives
The ﬁnal sum over is a constant equal to the number of
ways of generating the sample from cost values drawn
from . The important point is that it is independent of
the particular . Because of this the sum over can be
evaluated eliminating the dependence
This completes the proof of Theorem 2 for the case of .
The proof of Theorem 2 is completed by turning to the
case. This is considerably more difﬁcult since
cannot be simpliﬁed so that the sums over cannot be
WOLPERT AND MACREADY: NO FREE LUNCH THEOREMS FOR OPTIMIZA TION 79
decoupled. Nevertheless, the NFL result still holds. This is
proven by expanding (7) over possible values
(8)
The innermost sum over only has an effect on the
, term so it contributes ,
. This is a constant, equal to . This
leaves
The sum over is now simple
The above equation is of the same form as (8), only with a
remaining sample of size rather than . Consequently, in
an analogous manner to the scheme used to evaluate the sums 

Document 4: 
 always use algorithm . As applied to this case, they
mean that for ﬁxed and ,i f does better (on average)
with the algorithms in some set , then does better (on
average) with the algorithms in the set of all other algorithms.
In particular, if for some favorite algorithms a certain “well-
behaved”results in better performance than does the random
, then that well-behaved gives worse than random behavior
on the set all remaining algorithms. In this sense, just as there
are no universally efﬁcacious search algorithms, there are no
universally benignwhich can be assured of resulting in better
than random performance regardless of one’s algorithm.
In fact, things may very well be worse than this. In super-
vised learning, there is a related result [11]. Translated into
the current context, that result suggests that if one restricts
sums to only be over those algorithms that are a good match
to , then it is often the case that “stupid” choosing
procedures—like the irrational procedure of choosing the
algorithm with the less desirable—outperform “intelligent”
ones. What the set of algorithms summed over must be in
order for a rational choosing procedure to be superior to an
irrational procedure is not currently known.
WOLPERT AND MACREADY: NO FREE LUNCH THEOREMS FOR OPTIMIZA TION 77
VIII. C ONCLUSIONS
A framework has been presented in which to compare 

Document 5: 
 values after distinct cost evaluations produced by using a
particular instantiation of an evolutionary algorithm?”
At ﬁrst glance this seems to be an intractable question,
but the NFL theorem provides a way to answer it. This is
because—according to the NFL theorem—the answer must be
independent of the algorithm used to generate. Consequently,
3 In particular, one may want to impose restrictions on /80 /40 /102 /41 . For instance,
one may wish to only consider /80 /40 /102 /41 that are invariant under at least partial
relabeling of the elements in /88 , to preclude there being an algorithm that will
assuredly “luck out” and land on /109/105 /110 /120 /50/88 /102 /40 /120 /41 on its very ﬁrst query.
WOLPERT AND MACREADY: NO FREE LUNCH THEOREMS FOR OPTIMIZA TION 73
we can choose an algorithm for which the calculation is
tractable.
Theorem 3: For any algorithm, the fraction of cost func-
tions that result in a particular histogram is
For large enough , this can be approximated as
where is the entropy of the distribution , and
is a constant that does not depend on .
This theorem is derived in Appendix C. If some of the are
zero, the approximation still holds, only with redeﬁned to 

Document 6: 
 to-head minimax distinctions. Such an analysis is beyond the
scope of this paper.)
On the other hand, having the sums be equal does carry ob-
vious implications for whether there are head-to-head minimax
distinctions. For example, if both algorithms are deterministic,
then for any particular
equals one for one pair and zero for all others. In such
a case, is just the number
of that result in the pair .S o
implies
that there are no head-to-head minimax distinctions between
and . The converse, however, does not appear to hold. 4
4 Consider the grid of all /40 /122/59 /122 /48 /41 pairs. Assign to each grid point the number
of /102 that result in that grid point’s /40 /122/59 /122 /48 /41 pair. Then our constraints are i)
by the hypothesis that there are no head-to-head minimax distinctions, if grid
point /40 /122 /49 /59/122 /50 /41 is assigned a nonzero number, then so is /40 /122 /50 /59/122 /49 /41 and ii) by
the no-free-lunch theorem, the sum of all numbers in row /122 equals the sum
of all numbers in column /122 . These two constraints do not appear to imply
that the distribution of numbers is symmetric under interchange of rows and 

","The ""no free lunch"" theorem, proposed by David H. Wolpert and William G. Macready, states that any optimization algorithm will perform better on one class of problems than another, but overall performance across all classes will be equalized. In other words, there is no universally effective or benign algorithm that can consistently outperform others across all types of optimization problems.",20.67230772972107,"The ""no free lunch"" (NFL) theorem states that for any optimization algorithm, any performance advantage achieved over a specific class of optimization problems is counterbalanced by performance declines over other classes of problems. This implies that no single algorithm is universally superior to others across all possible optimization problems—any gains in performance in one area will result in losses elsewhere. The NFL theorem establishes a framework for understanding the relationship between optimization algorithms and the specific problems they are applied to, leading to insights into the limitations of algorithmic effectiveness. It emphasizes that there are no universally effective or benign algorithms that can guarantee better-than-random performance in all scenarios."
llama3.1:latest,"What is the concept behind Parallel Algorithm Portfolio?
","Document 1: 
 training set as well as for constructing the solvers.
This article studies effective construction approaches for
parallel portfolios that are less affected by nonrepresentative
training data. The term “parallel portfolio” [25], [26] refers
to a portfolio/set of solvers that is run independently in par-
allel when solving a problem instance (see Section III-A).
As a form of solvers, parallel portfolios have several impor-
tant advantages. First, exploiting parallelism has become very
important in designing efﬁcient solvers for computationally
hard problems, considering the great development and the
wide application of parallel computing architectures [27] (e.g.,
multicore CPUs) over the last decade. Parallel portfolios
employ parallel solution strategies and, thus, could easily make
effective use of modern hardware. Second, utilizing several
different solvers (as in parallel portfolios) is a simple yet
effective strategy for solving computationally hard problems.
Such an idea has also been realized in the form of sequential
portfolios [28], [29], which try to select the best solvers for
solving a problem instance, and adaptive solvers, such as adap-
tive parameter control [30]–[33]; reactive search [34], [35];
and hyper-heuristics [36]–[38], which seek to dynamically
determine the best solver setting while solving a problem
instance. In principle, all these methods need to involve some
mechanisms (e.g., selection or scheduling) to appropriately 

Document 2: 
 is only determined by the current database. As a sequence, we will
introduce two portfolio frameworks as parallel individual-based
944
Algorithm Portfolio for Individual-based Surrogate-Assisted Evolutionary Algorithms GECCO ’19, July 13–17, 2019, Prague, Czech Republic
SAEAs and UCB for individual-based SAEAs which are motivated
from two different aspects as reviewed previously.
3.1 Parallel individual-based SAEAs
澽澶澡濇澵澹澵澧澽澶澡濇澵澹澵澦澽澶澡濇澵澹澵澥 澸濕濨濕澔
澶濕濧濙
濇濨濕濦濨
濇濨濣濤澳
濍
濂
澹濢濘
/ŶŝƚŝĂůŝǌĂƚŝŽŶ
/ŶĚŝǀŝĚƵĂů
^ƵƌƌŽŐĂƚĞ ^ƵƌƌŽŐĂƚĞ ^ƵƌƌŽŐĂƚĞ
/ŶĚŝǀŝĚƵĂů/ŶĚŝǀŝĚƵĂů
Figure1:Thediagramoftheframework:Parallelindividual-
based SAEAs.
Similar with the algorithm portfolio for canonical evolutionary
algorithms, it is intuitive to consider each individual-based SAEA
as a simple evolutionary algorithm and embed them into the exist-
ing framework, like PAP or MultiEA. From this aspect, the parallel
individual-based SAEAs (Par-IBSAEA) framework is proposed that
all algorithm candidates run simultaneously at each generation.
Nevertheless, it is more convenient than portfolio for canonical
evolutionaryalgorithmsbecausealmostallindividual-basedSAEAs
have the same algorithm structure and it does not require a par-
ticular design for each algorithm. A brief diagram for Par-IBSAEA
with only three algorithm instances is presented in Figure 1 where 

Document 3: 
 general-ized to denote a combination of different algorithms intended to outperform the search performance of any of its constituent algorithms [3, 6, 11-14]. Here we extend that formulation, so that an algorithm portfolio schedules its constituent algorithms to run concurrently on a set of processors. Let an algorithm be any CSP solver, as described in the previous section. Given a set A = {a1, a2, …, am} of m algorithms, a set P = {x1, x2, …, xn} of n problems, and a set of B consecutive time intervals T = {t1, t2, …, tB}, a simple schedule Sk for a prob-lem on a single processor specifies 

Document 4: 
 algorithms, and thereby combine parameter tuning and an algo-rithm portfolio in the same framework. We are pursuing this avenue as well. The performance of any algorithm portfolio is, of course, bounded by that of an or-acle. The combination of algorithms as black boxes eliminates any opportunity to im-prove an individual algorithm. In contrast, parallelism can be achieved by a variety of problem decomposition methods (e.g., search space splitting), as discussed in Section 3. Although the results of recent SAT solver competitions suggest that a well-designed algorithm portfolio outperforms decomposition methods on a small number 

Document 5: 
 of processors [22], decomposition methods have shown their potential on many more processors (e.g., 64 cores or more in [19]). We will explore this in future work.  
9   Conclusions This paper presents WG, a constructor for non-parallel algorithm portfolios based on case-based reasoning and a greedy algorithm. It formulates parallel algorithm portfo-lio construction as an integer-programming problem, and generalizes WG to RSR-WG, a constructor for parallel algorithm portfolios based on a property of the optimal solution to the inherent integer-programming problem. To address a set of problems one at a time, RSR-WG creates portfolios of deterministic algorithms offline. Exper-iments show that the parallel algorithm portfolios produced by RSR-WG are statisti-cally significantly better than those produced by naïve parallel versions of popular portfolio constructors. Moreover, with only a few additional processors, RSR-WG portfolios are competitive with an oracle solver on a single processor.  Acknowledgements. This research was supported in part by the National Science Foundation under grants IIS-0811437, CNS-0958379 and CNS-0855217, and the City University of New York High Performance Computing Center. 

Document 6: 
 Ann Math Artif Intell (2006) 48:85–106
DOI 10.1007/s10472-007-9050-9
Learning parallel portfolios of algorithms
Marek Petrik ·Shlomo Zilberstein
Published online: 25 May 2007
© Springer Science + Business Media B.V. 2007
Abstract A wide range of combinatorial optimization algorithms have been devel-
oped for complex reasoning tasks. Frequently, no single algorithm outperforms all
the others. This has raised interest in leveraging the performance of a collection
of algorithms to improve performance. We show how to accomplish this using a
Parallel Portfolio of Algorithms (PPA). A PPA is a collection of diverse algorithms
for solving a single problem, all running concurrently on a single processor until
a solution is produced. The performance of the portfolio may be controlled by
assigning different shares of processor time to each algorithm. We present an
effective method for ﬁnding a PPA in which the share of processor time allocated
to each algorithm is ﬁxed. Finding the optimal static schedule is shown to be an
NP-complete problem for a general class of utility functions. We present bounds on
the performance of the PPA over random instances and evaluate the performance
empirically on a collection of 23 state-of-the-art SAT algorithms. The results show
signiﬁcant performance gains over the fastest individual algorithm in the collection.
Keywords Algorithm portfolios ·Resource bounded reasoning ·
Combinatorial optimization
Mathematics Subject Classiﬁcations (2000) 68T05 ·68T20 

","The concept behind Parallel Algorithm Portfolio is to combine multiple algorithms, run them concurrently on a single processor, and assign different shares of processor time to each algorithm. This approach aims to improve performance by leveraging the strengths of individual algorithms and utilizing parallel processing capabilities. The goal is to produce a solution faster than any single algorithm could achieve on its own.",18.69976234436035,"The concept behind a Parallel Algorithm Portfolio (PAP) involves utilizing a collection of diverse algorithms to solve a single problem by running them concurrently on a single processor or across multiple processors. The aim is to leverage the strengths of various algorithms to improve overall performance, especially in combinatorial optimization tasks where no single algorithm universally outperforms the rest. Each algorithm in the portfolio can be assigned different shares of processor time to optimize resource usage. The portfolio operates under the principle that combining algorithms as ""black boxes"" can enhance search performance beyond that of any individual algorithm. This setup allows for effective solving of complex problems, as demonstrated by empirical studies showing performance gains over the fastest individual algorithms in the collection."
llama3.1:latest,"Please provide some approaches to how Parallel Algorithm Portfolio can be constructed.
","Document 1: 
 algorithms, and thereby combine parameter tuning and an algo-rithm portfolio in the same framework. We are pursuing this avenue as well. The performance of any algorithm portfolio is, of course, bounded by that of an or-acle. The combination of algorithms as black boxes eliminates any opportunity to im-prove an individual algorithm. In contrast, parallelism can be achieved by a variety of problem decomposition methods (e.g., search space splitting), as discussed in Section 3. Although the results of recent SAT solver competitions suggest that a well-designed algorithm portfolio outperforms decomposition methods on a small number 

Document 2: 
 tive parameter control [30]–[33]; reactive search [34], [35];
and hyper-heuristics [36]–[38], which seek to dynamically
determine the best solver setting while solving a problem
instance. In principle, all these methods need to involve some
mechanisms (e.g., selection or scheduling) to appropriately
allocate computational resources to different solvers, while the
parallel portfolios do not necessarily require any extra resource
allocation since each solver is simply assigned with the same
amount of resources. Third, a parallel portfolio could be eas-
ily converted to a sequential portfolio by using the algorithm
selection methods [39] to build selectors on the solvers in the
portfolio, which means the portfolios generated by construc-
tion approaches (e.g., the approach proposed in this article)
could be further used for constructing sequential portfolios.
In this article, we propose a novel approach called the
generative adversarial solver trainer (GAST) for the auto-
matic construction of parallel portfolios. Unlike the existing
construction approaches, GAST would generate additional
training instances and construct a parallel portfolio with the
dynamically changing training set. More speciﬁcally, GAST
puts instance generation and portfolio construction in an adver-
sarial game. The instance generation aims to generate the hard
problem instances that could not be solved well by the cur-
rent portfolio, while the portfolio construction aims to ﬁnd a
new component solver for the portfolio to better solve these 

Document 3: 
 1 for j := 1 ... n do
2 obtain portfolio c(j)
1:k by running AC on conﬁguration space ∏k
l=1{(c) | c ∈ C} on I using m for time t/n
3 choose ˆc1:k ∈ arg minc(j)
1:k |j∈{1...n} m(c(j)
1:k, I) that achieved best performance on I according to m
4 return ˆc1:k
3.1.1. Simultaneous conﬁguration of all component solvers (Global)
Our ﬁrst portfolio conﬁguration method is the straightforward extension of standard algorithm conﬁguration to the 
construction of a parallel portfolio (see Algorithm 1). Speciﬁcally, if the given solver has ℓ parameters, we treat the portfolio 
c1:k as a single algorithm with ℓ · k parameters inducing a conﬁguration space of size |C|k, and conﬁgure it directly. As 
noted above, we identify a single conﬁguration as the best of n independent runs of AC . These runs can be performed in 
parallel, meaning that this procedure requires wall clock time t/n if n machines—one for each AC run—with k cores are 
available. The used CPU time will be the given time budget t for Lines 1 and 2 in Algorithm 1 and some small overhead 
ϵ to choose the best portfolio in Line 3. The scalability of this approach is limited by the fact that the global conﬁguration 

Document 4: 
 Learning Algorithm Portfolios for Parallel Execution Xi Yun1 and Susan L. Epstein1, 2  1 Department of Computer Science, The Graduate School of The City University of New York, New York, NY 10016, USA 2 Department of Computer Science, Hunter College of The City University of New York, New York, NY 10065, USA xyun@gc.cuny.edu, susan.epstein@hunter.cuny.edu 
Abstract. Portfolio-based solvers are both effective and robust, but their prom-ise for parallel execution with constraint satisfaction solvers has received rela-tively little attention. This paper proposes an approach that constructs algorithm portfolios intended for parallel execution based on a combination of case-based reasoning, a greedy algorithm, and three heuristics. Empirical results show that this method is efficient, and can significantly improve performance with only a few additional processors. On problems from solver competitions, the resultant algorithm portfolios perform nearly as well as an oracle. Keywords: constraint satisfaction, algorithm portfolio, parallel processing, ma-chine learning. 

Document 5: 
 sign of parallel algorithm portfolios—sets of solvers that are run in parallel on a given instance of a decision problem, such 
as SAT, until the ﬁrst of them ﬁnds a solution [39,27].
In this work,1 we study generic methods for solving a problem we call Automatic Construction of Parallel Portfolios 
(ACPP): automatically constructing a static2 parallel solver from a sequential solver or a set of sequential solvers. This 
task can be understood as falling within the programming by optimization paradigm [34] in that it involves the design of 
software in which many design decisions have been deliberately left open during the development process (here exposed as 
parameters of SAT solvers) to be made automatically later (here by means of an automated algorithm conﬁgurator) in order 
to obtain optimized performance for speciﬁc use cases. Hence, all that is required by our ACPP methods is a sequential 
solver whose conﬁguration space contains complementary conﬁgurations.
We study three variants of the ACPP problem. First, we consider building parallel portfolios starting from a single, 
highly parametric sequential solver design. However, for well-studied problems (e.g., SAT), there often exist a wide range of 
different solvers that contribute to the state of the art (see, e.g., [73]). Complementarities among such solvers can be ex-
ploited by algorithm portfolios, whether driven by algorithm selection (like SATzilla [72]) or by parallel execution (such as 

Document 6: 
 training set as well as for constructing the solvers.
This article studies effective construction approaches for
parallel portfolios that are less affected by nonrepresentative
training data. The term “parallel portfolio” [25], [26] refers
to a portfolio/set of solvers that is run independently in par-
allel when solving a problem instance (see Section III-A).
As a form of solvers, parallel portfolios have several impor-
tant advantages. First, exploiting parallelism has become very
important in designing efﬁcient solvers for computationally
hard problems, considering the great development and the
wide application of parallel computing architectures [27] (e.g.,
multicore CPUs) over the last decade. Parallel portfolios
employ parallel solution strategies and, thus, could easily make
effective use of modern hardware. Second, utilizing several
different solvers (as in parallel portfolios) is a simple yet
effective strategy for solving computationally hard problems.
Such an idea has also been realized in the form of sequential
portfolios [28], [29], which try to select the best solvers for
solving a problem instance, and adaptive solvers, such as adap-
tive parameter control [30]–[33]; reactive search [34], [35];
and hyper-heuristics [36]–[38], which seek to dynamically
determine the best solver setting while solving a problem
instance. In principle, all these methods need to involve some
mechanisms (e.g., selection or scheduling) to appropriately 

","According to the retrieved context, here are some approaches to constructing parallel algorithm portfolios:

1. **Global Conﬁguration**: This approach treats the portfolio as a single algorithm with multiple parameters and configures it directly using a standard algorithm conﬁgurator (Algorithm 1).
2. **Instance Generation and Portfolio Construction**: The Generative Adversarial Solver Trainer (GAST) method generates hard problem instances and constructs a parallel portfolio by dynamically changing the training set.
3. **Simultaneous Conﬁguration of all Component Solvers**: This approach configures each component solver in the portfolio simultaneously, which can be performed in parallel using multiple machines with k cores.
4. **Case-based Reasoning, Greedy Algorithm, and Heuristics**: A combination of case-based reasoning, a greedy algorithm, and three heuristics is used to construct parallel portfolios.

These approaches are aimed at constructing efficient and effective parallel algorithm portfolios for solving computationally hard problems.",47.515920877456665,"Several approaches can be employed to construct Parallel Algorithm Portfolios. Here are some key methods discussed in the context provided:

1. **Generative Adversarial Solver Trainer (GAST)**: This novel approach involves an adversarial game where instance generation aims to create hard problem instances that the current portfolio struggles with, while the portfolio construction focuses on identifying a new solver component to improve performance on these instances. This dynamic training set generation helps enhance the portfolio's capability over time.

2. **Simultaneous Configuration of Component Solvers (Global Configuration)**: This straightforward method treats the portfolio as a single algorithm with combined parameters. It configures all solvers simultaneously by running independent configurations in parallel on available computing resources. The best-performing configuration is selected based on performance metrics.

3. **Empirical Combination of Heuristics and Case-Based Reasoning**: This approach constructs algorithm portfolios intended for parallel execution by employing a combination of case-based reasoning, greedy algorithms, and various heuristics. This method has shown efficiency and significant performance improvement with limited additional computational resources.

4. **Automatic Construction of Parallel Portfolios (ACPP)**: This method involves developing static parallel solvers from existing sequential solvers. ACPP can optimize performance for specific use cases by automatically configuring parameters of sequential solvers based on their complementary configurations.

5. **Exploit Parallelism with Diverse Solvers**: Utilizing several different solvers in the portfolio can provide a simple yet effective strategy for tackling computationally hard problems. The strategy can leverage modern parallel computing architectures by running solvers independently in parallel to maximize resource utilization.

These approaches illustrate the variety of methods that can be used to construct effective Parallel Algorithm Portfolios for solving complex problems efficiently."
llama3.1:latest,"Can co-evolution be used in Parallel Algorithm Portfolio construction?
","Document 1: 
 in a series of benchmark problems. Finally, the paper will end with
a brief conclusion and a discussion of future work in Section 5.
2 RELATED WORK
2.1 Portfolio of evolutionary algorithm
In the areas of evolutionary algorithms, algorithm portfolio is ap-
plied to increase the probability of finding a better solution by
allocating computational resources to several complementary algo-
rithms. The algorithm portfolio frameworks in the literature can
be classified into two categories as the parallel-based framework
and the sequential-based framework.
For the parallel-based framework, all candidates will run simul-
taneously in multiple sub-processes. Population-based algorithm
portfolio (PAP) is a typical example [16], which allocates compu-
tational resources before the optimization according to the prior
knowledge.Eachalgorithmhasitsownpopulationandevolveinde-
pendently,buttheinformationissharedamongdifferentalgorithms
bymigrationstrategy.Besides,otherparallel-basedportfolioframe-
works like AMALGAM-SO [21] and the UMOEAs [6] collect the
performance of algorithms during the optimisation process and
allocate more resources to the better algorithm.
On the other hand, the sequential based framework only runs
onealgorithmatmostofthetimeduringtheprocessofoptimisation.
Different from the parallel-based algorithm portfolio, this kind of
frameworktrytoselectthebestalgorithmindifferentoptimisation 

Document 2: 
 tic is likely to have the right properties for
this approach to be useful, thus making it
very general in terms of applications.
So far we have assumed that the com-
ponent algorithms are completely inde -
pendent of each other and do not com-
municate. They can be thought of as
“competing” with one another for ma-
chineresources.However,allowingforco -
operation or dependencies among the in-
dividualalgorithmswhiletheyarerunning
simultaneously can improve performance
(18, 19). This possibility raises the inter-
estingquestionoftheextenttowhichour
economics approach to portfolio algo-
rithms can also benefit from cooperation.
Basically, cooperation will introduce sta-
tistical correlations between the perfor -
mance of the individual algorithms, and
we will accordingly define the correlation
between them as
  
cov•t1,t2 
 var•t1 var•t2 
(3)
where cov(t1, t2) denotes the covariance of
theperformanceofthetwoalgorithms.The
effect of cooperation, when manifested in
negativecorrelations,istoincreasetheper-
formanceaswellasreducetherisk(Fig.5).
This change is easily understood in that
negative correlations mean that one algo-
rithmisparticularlygoodpreciselyonthose 

Document 3: 
 So far, we have shown that our procedures were able to construct effective parallel portfolios based on single solvers 
with rich design spaces. There is considerable evidence from the literature and from SAT competitions that strong portfolios 
can also be built by combining entirely different solvers in their default conﬁgurations (see, e.g., SATzilla [72], ppfolio [63]
and pfolioUZK [70]). For instance, ppfolio was obtained simply by combining the best solvers from the previous competition 
into a parallel portfolio. pfolioUZK included more state-of-the-art solvers from 2011 and relied on additional experiments 
to ﬁnd the best combination of solvers in a portfolio. Neither portfolio considers the conﬁguration space of the component 
solvers and therefore both can be seen as simple baselines for other parallelization approaches, including ours. However, 
ppfolio and pfolioUZK use Plingeling as a portfolio component. Since we aim to investigate the strength of our ACPP methods 
without additional human expert knowledge on parallel solving, we ﬁrst consider only sequential solvers as the basis for 
our ACPP approach. This section and the following section investigates the extension of our automatic techniques to the 
construction of portfolios based on the conﬁguration spaces spanned by such solver sets.
4.1. Approach
As long as all of our component solvers are sequential, we can simply use the ACPP procedures deﬁned in Section 3. 
We can accommodate the multi-solver setting by introducing a solver choice parameter for each portfolio component (see 

Document 4: 
 1
Few-shots Parallel Algorithm Portfolio Construction
via Co-evolution
Ke Tang, Senior Member, IEEE, Shengcai Liu, Member, IEEE, Peng Yang, Member, IEEE,
and Xin Yao, Fellow, IEEE
Abstract—Generalization, i.e., the ability of solving problem
instances that are not available during the system design and
development phase, is a critical goal for intelligent systems.
A typical way to achieve good generalization is to learn a
model from vast data. In the context of heuristic search, such a
paradigm could be implemented as conﬁguring the parameters
of a parallel algorithm portfolio (PAP) based on a set of
“training” problem instances, which is often referred to as PAP
construction. However, compared to traditional machine learning,
PAP construction often suffers from the lack of training instances,
and the obtained PAPs may fail to generalize well. This paper
proposes a novel competitive co-evolution scheme, named Co-
Evolution of Parameterized Search (CEPS), as a remedy to
this challenge. By co-evolving a conﬁguration population and an
instance population, CEPS is capable of obtaining generalizable
PAPs with few training instances. The advantage of CEPS in
improving generalization is analytically shown in this paper. Two
concrete algorithms, namely CEPS-TSP and CEPS-VRPSPDTW,
are presented for the Traveling Salesman Problem (TSP) and 

Document 5: 
 algorithms, and thereby combine parameter tuning and an algo-rithm portfolio in the same framework. We are pursuing this avenue as well. The performance of any algorithm portfolio is, of course, bounded by that of an or-acle. The combination of algorithms as black boxes eliminates any opportunity to im-prove an individual algorithm. In contrast, parallelism can be achieved by a variety of problem decomposition methods (e.g., search space splitting), as discussed in Section 3. Although the results of recent SAT solver competitions suggest that a well-designed algorithm portfolio outperforms decomposition methods on a small number 

Document 6: 
 divides the search space into subspaces, succes -
sively allocated to sequential CDCL workers. Work -
ers cooperate through some load-balancing strate -
gy, which performs the dynamic transfer of 
subspaces to idle workers, and through the 
exchange of conflict clauses.
The parallel portfolio approach was introduced 
in 2008 (Hamadi, Jabbour, and Sais 2008; Winter -
steiger, Hamadi, and de Moura 2009; Guo et al.
2010). It exploits the complementarity of different 
sequential DPLL strategies to let them compete and 
cooperate on the same formula. Since each worker 
addresses the whole formula, there is no need to 
introduce load-balancing overheads, and coopera -
tion is only achieved through the exchange of con -
flict clauses. With this approach, the crafting of the 
strategies is important, especially with only a few 
workers. The objective is to cover the space of good 
search strategies in the best possible way. 
In general, the interleaving of computation can 
lead to the previously mentioned problem of non -
determinism. This is true for solvers that use a 
Articles 
SUMMER 2013   101 
(2) Implication graph
(3) Con/f_lict-clause
(3) Con/f_lict-clause
(1) Literal
(4) Activity
(5) Con/f_lict
Preprocessing
Boolean Unit
Propagation 

","Yes, co-evolution can be used in Parallel Algorithm Portfolio construction. The paper ""Few-shots Parallel Algorithm Portfolio Construction via Co-evolution"" proposes a novel competitive co-evolution scheme called CEPS (Co-Evolution of Parameterized Search) to construct generalizable PAPs with few training instances.",17.206424713134766,"Yes, co-evolution can be used in Parallel Algorithm Portfolio (PAP) construction. The context describes a novel competitive co-evolution scheme called Co-Evolution of Parameterized Search (CEPS), which is specifically designed to improve generalization in PAPs despite the challenge of having few training instances. By co-evolving both a configuration population and an instance population, CEPS is capable of producing generalizable portfolios. Hence, this method serves as a viable approach to enhance the effectiveness of PAPs through co-evolution."
llama3.1:latest,"What is the idea behind the PAP approach called ""GLOBAL""?
","Document 1: 
 paper has two major contributions. First, the proposed PAP is
developed for numerical optimization instead of combinatorial
optimization. Second, we investigate the term “risk” in a
different context. Previous work mainly aimed to reduce the
risk of an algorithm on a speciﬁc optimization problem, which
can be measured by applying the algorithm to the problem
for multiple times. In this paper, we are more interested in
reducing the risk overa set of problems , i.e., the risk is
measured by applying the algorithm to multiple problems.
Our PAP is a general framework for combining different
population-based search algorithms. It allocates computation
time among more than one constituent algorithm and acti-
vates interaction among them so that they can beneﬁt from
one another. To be more speciﬁc, the computation time is
measured by the number of ﬁtness evaluations (FEs), and
the allocation of FEs is implemented by dividing the whole
population into several subpopulations and evolving them in
a parallel manner (using different constituent algorithms). To
demonstrate the efﬁcacy of the proposed PAP, we chose four
existing population-based algorithms, including self-adaptive
differential evolution with neighborhood search (SaNSDE)
[7], particle swarm optimizer with inertia weight (wPSO)
[8], generalized generation gap (G3) model with generic
parent-centric recombination (PCX) operator (G3PCX) [9],
and covariance matrix adaptation evolution strategy (CMA-
ES) [10], as the constituent algorithms. These algorithms 

Document 2: 
 with a constraint handling technique. At each generation, each
subpopulation generates new individuals based on its own.
Then, each subpopulation is combined with new individuals
generated by all subpopulations, and selection is conducted
with the corresponding constraint handling technique. Com-
pared to all the above-mentioned work, in which all search
biases have access to the whole population, PAP allows only
its constituent algorithms to work on a subpopulation, i.e.,
full access to the whole population is prohibited. Migration is
the only route that different subpopulations communicate with
each other. This strategy, used by PAP, reduces the likelihood
of different constituent algorithms repeating similar search
behaviors or sharing similar search biases.
From the perspective of employing a multipopulation model
and migration operators, PAP is related to the distributed
EAs (dEAs), which have several subpopulations (islands) and
perform sparse exchange of individuals among them [25],
[26]. However, PAP is quite different from previous dEAs
in three major ways. First, most dEAs run the same EA
on all subpopulations [26]–[31] (either with the same or
different control parameters), while PAP employs different
EAs. Second, the migration scheme of PAP does not assume
any topology of subpopulations, while many dEAs do. By
this means, we solely focus on investigating whether it is 

Document 3: 
 • When constructing MOEAs/PAPs, it is important to maintain the diversity among the
member algorithms. Hence, the population diversity preservation schemes, such as
negatively correlated search [47], can be introduced into the construction approach to
promote cooperation between different member algorithms.
• In real-world applications, one may be unable to collect sufﬁcient MOPs as training
problems. How to automatically build powerful PAPs in these scenarios is also
worth studying.
• The effectiveness of MOEAs/PAP has been primarily demonstrated through exper-
imental evidence, but with an absence of theoretical analysis. A more thorough
investigation of its exceptional performance is crucial for advancing our understand-
ing, which, in turn, can lead to enhancements in its design and the development of a
more comprehensive automatic construction algorithm.
Electronics 2023, 12, 4639 17 of 18
Author Contributions: Conceptualization, S.L.; Methodology, S.L.; Software, X.M.; Validation, X.M.;
Resources, X.M.; Writing—original draft, X.M.; Writing—review and editing, W.H.; Supervision, S.L.
and W.H. All authors have read and agreed to the published version of the manuscript.
Funding: This research was supported by the Strategic Priority Research Program of Chinese
Academy of Science, Grant No. XDB32050100, and the National Natural Science Foundation of
China, Grant No. 91948303.
Data Availability Statement: The data presented in this study are available on request from the 

Document 4: 
 of high-quality PAPs is generally a challenging task, requiring domain experts (with a
deep understanding of both algorithms and problems) to explore the vast design space
of PAPs, which cannot be carried out manually with ease [28–30]. As an alternative, Tang
and Liu [25,26] proposed a general framework, called automatic construction of PAPs, that
seeks to automatically build PAPs by selecting the member algorithms from an algorithm
conﬁguration space, with the goal of optimizing the performance of the resulting PAP on a
given problem set (called training set). Such a framework has been shown to be effective in
building high-performance PAPs for combinatorial problems such as the Boolean Satisﬁa-
bility Problem (SAT) [25], the Traveling Salesman Problem (TSP) [27,31], and the Vehicle
Routing Problem (VRP) [26].
However, to the best of our knowledge, the potential of the automatic construction of
PAPs has not been investigated in the area of multi-objective optimization. Considering its
excellent performance on the above-mentioned problems and the practical signiﬁcance of
MOPs, studying how to utilize it to solve MOPs is thus valuable. In this work, we focus
on automatically building PAPs for continuous MOPs. On the other hand, as a general
framework, appropriately instantiating automatic PAP construction for a speciﬁc problem
domain is non-trivial. Speciﬁcally, it requires careful designs of the algorithm conﬁguration
space and the performance metrics used in the construction process [26]. 

Document 5: 
 are capable of exploring the search space globally. Hence, in order to achieve a better
overall performance for a diverse range of MOPs, it is natural and intuitive to combine
Electronics 2023, 12, 4639. https://doi.org/10.3390/electronics12224639 https://www.mdpi.com/journal/electronics
Electronics 2023, 12, 4639 2 of 18
the advantages of different MOEAs. One notable series of research efforts following this
idea are multi-operator-based MOEAs [11–14], which adaptively allocate computational
resources to MOEAs equipped with different operators when solving a MOP .
Apart from multi-operator-based MOEAs, and from a more general perspective of
problem solving, there is an effective technique that exploits the complementarity between
different algorithms by including them into a so-called algorithm portfolio (AP). To utilize
an AP to solve a problem, Tang et al. [ 20,21] proposed a simple but effective strategy,
called a parallel algorithm portfolio (PAP), that runs all member algorithms in the portfolio
independently in parallel to obtain multiple solutions. Then, the best solution will be
taken as the ﬁnal output of the PAP . Although a PAP would consume more computational
resources than a single algorithm, it has three important advantages. First, PAPs are
easy-to-implement because they do not necessarily require any resource allocation since
each member algorithm is simply assigned with the same amount of resource. Second, 

Document 6: 
 (CEC2005) [12], denoted asfcec1 −fcec14. These 27 functions
span a diverse set of problem features, such as multimodality,
ruggedness, ill-conditioning, interdependency, etc. They pro-
vided an ideal platform for our investigation on reducing risk
on a large variety of problems. Short descriptions of these
functions are presented in Tables I and II. More details of these
functions can be found in [11] and [12]. In our experiments,
all the functions were solved in 30 dimensions.
B. Experimental Settings
All the results presented in this paper were obtained by
executing 30 independent runs for each experiment. Since
we expect the PAP framework to be general enough so that
alternative algorithms can be incorporated with little effort,
it should not rely much on the reﬁnement of the constituent
algorithms. Hence, we did not ﬁne-tune the parameters of
the constituent algorithms to ﬁt PAP. When implementing
SaNSDE, we used all the parameter settings suggested in
the original publication [7]. As suggested in [8], a linearly
decreasing inertia weight over the course of the search is
employed in our implementation of wPSO. The two coefﬁ-
cients of wPSO were both set to 1.49445. We assumed the
researchers who proposed G3PCX and CMA-ES are at the
best position to implement the two algorithms and ﬁne-tune
the parameters. Hence, we simply used the source code of 

","I don't have information on a concept or methodology called 'PAP' that includes an approach called 'GLOBAL'. It's possible that it might be specific to particular fields, industries, or research. If you could provide more context or details about what PAP and GLOBAL refer to in your query, I'll do my best to offer a helpful response.",15.016019582748411,"The PAP approach called ""GLOBAL"" focuses on optimizing performance by exploiting the advantages of different population-based algorithms through a parallel framework. Its main goal is to improve the overall performance across a diverse range of multi-objective problems by employing multiple algorithms that operate independently and in parallel. This strategy allows the algorithm portfolio to explore the search space globally, providing a higher chance of finding better solutions than any single algorithm could achieve on its own. Through the communication and migration of solutions among subpopulations, the PAP framework facilitates the sharing of beneficial information and enhances diversity in the search process. This method aims to effectively reduce the risk associated with solving various problems by improving cooperation between different member algorithms while maintaining their individual search biases."
llama3.1:latest,"What is the idea behind the PAP approach called ""PARHYDRA""?
","Document 1: 
 on all subpopulations [26]–[31] (either with the same or
different control parameters), while PAP employs different
EAs. Second, the migration scheme of PAP does not assume
any topology of subpopulations, while many dEAs do. By
this means, we solely focus on investigating whether it is
worthy of allocating the limited computation time to different
algorithms so that the overall performance can be enhanced.
In contrast, a speciﬁc topology/structure for the relationship
between subpopulations is usually explicitly deﬁned in existing
dEAs [26]–[29], [32], [33]. Third, we are more interested
in reducing the overall risk of an algorithm ona spectrum
of problems. This issue has never been investigated in the
literature of dEAs.
In addition to dEAs, another notable work that is related
to PAP is the isolation strategy employed by hierarchically
organized evolution strategies (HOES) [34], [35]. In HOES,
a population is partitioned into a number of subpopulations,
and ES is run on them with different control parameters (e.g.,
search step sizes). The isolation strategy works in such a
way that the subpopulations evolve separately for a predeﬁned
isolation period (e.g., a few generations), and then the control
parameters are updated based on the individuals generated in
the subpopulations during the isolation period. Unlike PAP,
the motivation of the isolation strategy is not to make use of 

Document 2: 
 SCENARIOS , THAT IS , SAT-SMALL-BIAS-1/2/3/4. T HE NAME OF THE
CONSTRUCTION APPROACH IS USED TO DENOTE THE PORTFOLIOS
CONSTRUCTED BY IT. “PARHYDRA-A” R EFERS TO PARHYDRA
CONFIGURING BASED ON AUGMENTED TRAINING SETS .AP A R - 1 0
SCORE IS SHOWN IN BOLDFACE IF IT WAS NOT SIGNIFICANTLY
DIFFERENT FROM THE BEST TEST PERFORMANCE IN THE SCENARIO
(ACCORDING TO A WILCOXON SIGNED -RANK TEST WITH p = 0.05)
To answer this question, in each of the eight SAT scenarios,
that is, SAT-SMALL/BIAS-1/2/3/4, we used the same instance
generation procedure as in GAST (lines 13–18 in Algorithm 1)
to generate a large set of instances based on the training set.
The size of the generated set is ﬁve times the size of the
training set. Recall that the training set contains 50 instances,
we thus obtained an augmented training set of 300 instances
in each SAT scenario, and then PARHYDRA was used to
construct a parallel portfolio on these augmented training sets,
and then the obtained portfolio was tested on the test sets. As
before, each portfolio was tested by running it on the test set 

Document 3: 
 of high-quality PAPs is generally a challenging task, requiring domain experts (with a
deep understanding of both algorithms and problems) to explore the vast design space
of PAPs, which cannot be carried out manually with ease [28–30]. As an alternative, Tang
and Liu [25,26] proposed a general framework, called automatic construction of PAPs, that
seeks to automatically build PAPs by selecting the member algorithms from an algorithm
conﬁguration space, with the goal of optimizing the performance of the resulting PAP on a
given problem set (called training set). Such a framework has been shown to be effective in
building high-performance PAPs for combinatorial problems such as the Boolean Satisﬁa-
bility Problem (SAT) [25], the Traveling Salesman Problem (TSP) [27,31], and the Vehicle
Routing Problem (VRP) [26].
However, to the best of our knowledge, the potential of the automatic construction of
PAPs has not been investigated in the area of multi-objective optimization. Considering its
excellent performance on the above-mentioned problems and the practical signiﬁcance of
MOPs, studying how to utilize it to solve MOPs is thus valuable. In this work, we focus
on automatically building PAPs for continuous MOPs. On the other hand, as a general
framework, appropriately instantiating automatic PAP construction for a speciﬁc problem
domain is non-trivial. Speciﬁcally, it requires careful designs of the algorithm conﬁguration
space and the performance metrics used in the construction process [26]. 

Document 4: 
 paper has two major contributions. First, the proposed PAP is
developed for numerical optimization instead of combinatorial
optimization. Second, we investigate the term “risk” in a
different context. Previous work mainly aimed to reduce the
risk of an algorithm on a speciﬁc optimization problem, which
can be measured by applying the algorithm to the problem
for multiple times. In this paper, we are more interested in
reducing the risk overa set of problems , i.e., the risk is
measured by applying the algorithm to multiple problems.
Our PAP is a general framework for combining different
population-based search algorithms. It allocates computation
time among more than one constituent algorithm and acti-
vates interaction among them so that they can beneﬁt from
one another. To be more speciﬁc, the computation time is
measured by the number of ﬁtness evaluations (FEs), and
the allocation of FEs is implemented by dividing the whole
population into several subpopulations and evolving them in
a parallel manner (using different constituent algorithms). To
demonstrate the efﬁcacy of the proposed PAP, we chose four
existing population-based algorithms, including self-adaptive
differential evolution with neighborhood search (SaNSDE)
[7], particle swarm optimizer with inertia weight (wPSO)
[8], generalized generation gap (G3) model with generic
parent-centric recombination (PCX) operator (G3PCX) [9],
and covariance matrix adaptation evolution strategy (CMA-
ES) [10], as the constituent algorithms. These algorithms 

Document 5: 
 be used to build parallel portfolios. (Building a parallel portfolio in this way has the added advantage that no instance 
features are required, since there is no need to select among algorithms.) We introduce some enhancements to this 
approach for the parallel portfolio setting (discussed in Section 3.1.2), and refer to our method as parHydra.
3. Some parallel solvers only achieve strong performance when running on more than one core; such solvers will not 
be found by a greedy approach like parHydra, which only adds one conﬁguration at a time and does not recognize 
interaction effects that arise between different threads of a parallel solver. To overcome this problem, we introduce a 
new method called parHydrab, which augments parHydra to train b solvers per iteration. This method trades off the 
computational beneﬁt of parHydra’s greedy approach with the greater coverage of Global.
We evaluated our ACPP methods on SAT. We chose this domain because it is highly relevant to academia and industry 
and has been widely studied. We thus had access to a wide range of strong, highly parametric solvers and were assured 
that the bar for demonstrating eﬃcacy of parallelization strategies was appropriately high. We note that our approach is not 
limited to SAT solvers and can be directly applied to other domains. To evaluate our methods in the single-solver setting, we 
studied both Lingeling and clasp: prominent, highly parametric state-of-the-art solvers for SAT. Lingeling won a gold medal in 

Document 6: 
 that ihvr ∈(0, 1], and a larger value of ihvr is better. IHVR can distinguish well between
MOEAs with a different performance, and can also save a lot of calculations. In this work,
IHVR is used as the performance metric Metric .
4.3. Automatic Construction Approach
Algorithm 1 presents the automatic construction approach for MOEAs/PAP . Starting
from an empty set (line 2), the approach constructs the PAP (denoted as P) iteratively.
Speciﬁcally, each iteration of the approach (lines 3–15) consists of two subsequent phases.
In the ﬁrst phase, an existing automatic algorithm conﬁguration tool, namely SMAC 3 [44],
is used to search in Θ to ﬁnd the algorithm that can improve the performance of the current
PAP to the largest extent (line 5), and then this algorithm is inserted into P (line 6). This
phase is similar to the commonly-used greedy approach in the automatic construction of
PAPs [27,31]. Additionally, we introduce a new phase, namely simpliﬁcation, as the second
phase in Algorithm 1. In this phase (lines 7–14), P would be simpliﬁed by removing the
member algorithms that do not contribute at all to its performance (meaning removing
these algorithms has no effect on the performance of P on the training set). Considering
the size of P is bounded (line 3), removing the redundant algorithms from P is meaningful
because this will leave space for new member algorithms that can improve the performance 

","I couldn't find any information on a method or concept called ""PARHYDRA"" in relation to the Performance Acceleration Path (PAP) approach. It's possible that this could be an incorrect assumption, or a made-up term.

However, I can try to help you with your question by suggesting some alternatives:

* Could you please provide more context about PAP and PARHYDRA? For example, what is the topic area (e.g., mathematics, science, business) where PAP is being used?
* Are there any specific keywords or related concepts that I can use to search for information on ""PARHYDRA""?

If you have any additional details or clarification about your question, I'll do my best to provide a more accurate and helpful response.",27.99564790725708,"The PAP approach called ""PARHYDRA"" is designed to construct parallel portfolios based on augmented training sets. Specifically, it utilizes a parallel portfolio for solving instances of problems, like SAT, without the need for instance features since it does not select among algorithms but rather integrates them. The method enhances traditional portfolio construction by testing each portfolio on a significantly larger augmented training set, thereby improving the chances of achieving strong performance across diverse problem scenarios. PARHYDRA involves generating a large set of instances from an initial training set, which is then used to develop and evaluate a parallel portfolio intended for efficient computational resource usage and optimal performance."
llama3.1:latest,"What is the idea behind the PAP approach called ""CLUSTERING""?
","Document 1: 
 with a constraint handling technique. At each generation, each
subpopulation generates new individuals based on its own.
Then, each subpopulation is combined with new individuals
generated by all subpopulations, and selection is conducted
with the corresponding constraint handling technique. Com-
pared to all the above-mentioned work, in which all search
biases have access to the whole population, PAP allows only
its constituent algorithms to work on a subpopulation, i.e.,
full access to the whole population is prohibited. Migration is
the only route that different subpopulations communicate with
each other. This strategy, used by PAP, reduces the likelihood
of different constituent algorithms repeating similar search
behaviors or sharing similar search biases.
From the perspective of employing a multipopulation model
and migration operators, PAP is related to the distributed
EAs (dEAs), which have several subpopulations (islands) and
perform sparse exchange of individuals among them [25],
[26]. However, PAP is quite different from previous dEAs
in three major ways. First, most dEAs run the same EA
on all subpopulations [26]–[31] (either with the same or
different control parameters), while PAP employs different
EAs. Second, the migration scheme of PAP does not assume
any topology of subpopulations, while many dEAs do. By
this means, we solely focus on investigating whether it is 

Document 2: 
 while the size of the configuration space involved in each
configuration task in PARHYDRAb, i.e., |C|b, would grow
exponentially as b gets larger. However, in general the best
value of b may vary across different scenarios, and for a spe-
cific scenario it is very hard to determine a good choice of b
in advance.
The third method CLUSTERING tackles the ACPP prob-
lem via explicit instance grouping. That is, it clusters the
problem instances represented in a normalized instance fea-
ture space into k subsets and then independently runs an
AC procedure on each subset to obtain a component solver.
Similar to PARHYDRAb, CLUSTERING also has an im-
portant design choice that is hard to determine in advance.
Specifically, the clustering result has great influence on the
performance of the final parallel portfolio. However, there
exists different normalization approaches that can be used
here, and different of them can result in different instance
clusters. Generally the appropriate choice of the normaliza-
tion approach may vary across different instance sets, and
the accurate assessment of the cluster quality is not possible
before the portfolio is constructed completely.
From a methodological perspective, ACPP methods based
on explicit instance grouping seek to achieve the comple-
mentarity among the component solvers by promoting each
of them to handle different subsets of the problem instances.
Thus for these methods the quality of the instance group- 

Document 3: 
 two algorithms. It also proposes a population-based algorithm
portfolio (PAP), which not only reduces the risk of failing on
problems from different classes, but also makes ﬁnding high-
quality solutions more likely.
The basic idea of PAP is simple: instead of betting the entire
time budget on a single algorithm, we “invest” our time in
multiple algorithms. This idea has been explored for more than
ten years, based on the theory of investment portfolios that was
developed in the ﬁeld of economics to answer the question:
“How should one allocate his/her ﬁnancial assets (stocks,
bonds, etc.) in order to maximize the expected returns while
minimizing risks” [4]. In analogy with investment portfolios,
PAP focuses on the problem of how to allocate computation
time among algorithms and fully utilize the advantages of
these algorithms in order to maximize the expected utility of a
1089-778X/$26.00 c⃝ 2010 IEEE
PENG et al.: POPULATION-BASED ALGORITHM PORTFOLIOS FOR NUMERICAL OPTIMIZATION 783
Fig. 1. Pseudo-code of PAP.
problem solving episode. Based on the portfolio idea, various
approaches have been developed, either to minimize the ex-
pected time needed to solve problem instances or to maximize
the expected quality of the solution while the available time
is kept constant. However, all the existing approaches were
proposed for combinatorial problems. For example, Huberman
et al.[5] proposed an economic approach for constructing 

Document 4: 
 that ihvr ∈(0, 1], and a larger value of ihvr is better. IHVR can distinguish well between
MOEAs with a different performance, and can also save a lot of calculations. In this work,
IHVR is used as the performance metric Metric .
4.3. Automatic Construction Approach
Algorithm 1 presents the automatic construction approach for MOEAs/PAP . Starting
from an empty set (line 2), the approach constructs the PAP (denoted as P) iteratively.
Speciﬁcally, each iteration of the approach (lines 3–15) consists of two subsequent phases.
In the ﬁrst phase, an existing automatic algorithm conﬁguration tool, namely SMAC 3 [44],
is used to search in Θ to ﬁnd the algorithm that can improve the performance of the current
PAP to the largest extent (line 5), and then this algorithm is inserted into P (line 6). This
phase is similar to the commonly-used greedy approach in the automatic construction of
PAPs [27,31]. Additionally, we introduce a new phase, namely simpliﬁcation, as the second
phase in Algorithm 1. In this phase (lines 7–14), P would be simpliﬁed by removing the
member algorithms that do not contribute at all to its performance (meaning removing
these algorithms has no effect on the performance of P on the training set). Considering
the size of P is bounded (line 3), removing the redundant algorithms from P is meaningful
because this will leave space for new member algorithms that can improve the performance 

Document 5: 
 constituent algorithm with a part of the given time budget and
encourages interaction among the constituent algorithms with a
migration scheme. As a general framework rather than a speciﬁc
algorithm, PAP is easy to implement and can accommodate
any existing population-based search algorithms. In addition, a
metric is also proposed to compare the risks of any two
algorithms on a problem set. We have comprehensively evaluated
PAP via investigating 11 instantiations of it on 27 benchmark
functions. Empirical results have shown that PAP outperforms
its constituent algorithms in terms of solution quality, risk, and
probability of ﬁnding the global optimum. Further analyses
have revealed that the advantages of PAP are mostly credited
to the synergy between constituent algorithms, which should
complement each other either over a set of problems, or during
different stages of an optimization process.
Manuscript received October 14, 2008; revised March 20, 2009, August
31, 2009, and November 30, 2009. Date of publication March 29, 2010; date
of current version October 1, 2010. This paper was partially supported by
the National Natural Science Foundation of China under Grants 60533020,
60802036 and U0835002, the Fund for Foreign Scholars in University
Research and Teaching Programs in China under Grant B07033, and the
Engineering and Physical Science Research Council in U.K. under Grant
EP/D052785/1 on “SEBASE: Software Engineering By Automated Search.”
F. Peng and K. Tang are with the Nature Inspired Computation and
Applications Laboratory, School of Computer Science and Technology, Uni- 

Document 6: 
 • When constructing MOEAs/PAPs, it is important to maintain the diversity among the
member algorithms. Hence, the population diversity preservation schemes, such as
negatively correlated search [47], can be introduced into the construction approach to
promote cooperation between different member algorithms.
• In real-world applications, one may be unable to collect sufﬁcient MOPs as training
problems. How to automatically build powerful PAPs in these scenarios is also
worth studying.
• The effectiveness of MOEAs/PAP has been primarily demonstrated through exper-
imental evidence, but with an absence of theoretical analysis. A more thorough
investigation of its exceptional performance is crucial for advancing our understand-
ing, which, in turn, can lead to enhancements in its design and the development of a
more comprehensive automatic construction algorithm.
Electronics 2023, 12, 4639 17 of 18
Author Contributions: Conceptualization, S.L.; Methodology, S.L.; Software, X.M.; Validation, X.M.;
Resources, X.M.; Writing—original draft, X.M.; Writing—review and editing, W.H.; Supervision, S.L.
and W.H. All authors have read and agreed to the published version of the manuscript.
Funding: This research was supported by the Strategic Priority Research Program of Chinese
Academy of Science, Grant No. XDB32050100, and the National Natural Science Foundation of
China, Grant No. 91948303.
Data Availability Statement: The data presented in this study are available on request from the 

","The CLUSTERING method tackles the automatic construction of MOEAs/PAPs by dividing a set of MOPs into clusters based on their characteristics, and then constructs a PAP for each cluster. This allows the creation of multiple PAPs that are tailored to specific problem types, rather than trying to create a single PAP that works well across all problems.",20.758822917938232,"The idea behind the PAP approach called ""CLUSTERING"" involves tackling the Algorithm Configuration Problem (ACPP) through explicit instance grouping. Specifically, it clusters problem instances represented in a normalized instance feature space into k subsets, and then independently runs an Algorithm Configuration (AC) procedure on each subset to obtain a component solver. This method aims to achieve complementarity among the component solvers by allowing each of them to handle different subsets of the problem instances. However, the effectiveness of this method is significantly influenced by the quality of the clustering result, which can vary depending on the normalization approaches used. Thus, determining the appropriate normalization approach in advance poses a challenge."
llama3.1:latest,"What is the idea behind the PAP approach called ""PCIT""?
","Document 1: 
 paper has two major contributions. First, the proposed PAP is
developed for numerical optimization instead of combinatorial
optimization. Second, we investigate the term “risk” in a
different context. Previous work mainly aimed to reduce the
risk of an algorithm on a speciﬁc optimization problem, which
can be measured by applying the algorithm to the problem
for multiple times. In this paper, we are more interested in
reducing the risk overa set of problems , i.e., the risk is
measured by applying the algorithm to multiple problems.
Our PAP is a general framework for combining different
population-based search algorithms. It allocates computation
time among more than one constituent algorithm and acti-
vates interaction among them so that they can beneﬁt from
one another. To be more speciﬁc, the computation time is
measured by the number of ﬁtness evaluations (FEs), and
the allocation of FEs is implemented by dividing the whole
population into several subpopulations and evolving them in
a parallel manner (using different constituent algorithms). To
demonstrate the efﬁcacy of the proposed PAP, we chose four
existing population-based algorithms, including self-adaptive
differential evolution with neighborhood search (SaNSDE)
[7], particle swarm optimizer with inertia weight (wPSO)
[8], generalized generation gap (G3) model with generic
parent-centric recombination (PCX) operator (G3PCX) [9],
and covariance matrix adaptation evolution strategy (CMA-
ES) [10], as the constituent algorithms. These algorithms 

Document 2: 
 them.
PCIT conducts the instance transfer with the help of in-
cumbent configurations (i.e., the best configurations found
by the AC procedure). In each subset, the instances which
cannot be solved satisfactorily by the corresponding incum-
bent are identified as the ones that need to be transferred,
and the target subset of each transferred instance is deter-
mined according to how well the incumbent on the candi-
date subset could perform on the instance. In essence, the
incumbent on a subset can be seen as a common special
characteristic of those “similar” instances (in the sense they
share the same high-quality configurations) within the sub-
set, and PCIT uses it to identify those “dissimilar” instances
and find better subsets for them. In each subset, the perfor-
mance of the incumbent on each instance could be obtained
from the rundata collected from the AC procedure runs.
However, while determining the target subsets for the trans-
ferred instances, how well the incumbents on the candidate
subsets would perform on the transferred instances are un-
known. One way to obtain these performances is to actually
test these incumbents on the transferred instances, which
however would introduce considerable additional compu-
tational costs. To avoid this, PCIT builds empirical perfor-
mance models (EPM) (Hutter et al. 2014) based on the col-
lected rundata to predict these performances.
1562
Algorithm Framework 

Document 3: 
 analogous to the over-ﬁtting phenomenon in machine learning,
has been observed when the size of the training instance set
is rather limited (i.e., few-shots challenge). That is, the test
(generalization) performance of the obtained conﬁgurations is
arbitrarily bad even if their performance on the training set is
excellent. Even worse, given a T collected from real world,
it is non-trivial to know how to verify whether it is a good
representative of Ω. In case the training instance set is too
small, or is not a good representative of the whole problem
class, the best PAP obtained with it would fail to generalize.
B. Related Work
Currently, there exist several approaches for PAP con-
struction, namely GLOBAL [25], PARHYDRA [25], [26],
CLUSTERING [27] and PCIT [13]. GLOBAL considers PAP
construction as an algorithm conﬁguration problem by treating
Θ as a parameterized algorithm. By this means existing
automatic algorithm conﬁguration tools could be directly uti-
lized to conﬁgure all the component solvers of Θ simultane-
ously. In comparison, PARHYDRA constructs Θ iteratively
3
by identifying a single component solver in each iteration that
maximizes marginal performance contribution to the current
PAP. CLUSTERING and PCIT are two approaches based on
instance grouping. That is, they both ﬁrst split the training 

Document 4: 
 of the more state-of-the-art Plingeling. Such results indicate
PCIT could identify powerful parallel portfolios, with little
human effort involved. Thus the portfolios constructed by
PCIT could conveniently provide at least two advantages.
That is, they are high-quality parallel solvers, and they could
be used as starting points for the development of more ad-
Table 4: Test results of parallel solvers on the test set of SAT-
Single and SAT-Multi. The performance of a solver is shown
in boldface if it was not significantly different from the best
performance (according to a permutation test with 100000
permutations and significance level p = 0.05).
SAT-Single SAT-Multi
#TOS PAR-10 PAR-1 #TOS PAR-10 PAR-1
PCIT 181 119 21 35 1164 219
Priss6 225 146 25 - - -
PfolioUZK - - - 36 1185 213
Plinegling-bbc452 276 32 33 1090 199
vanced parallel solvers.
Conclusion
In this paper we proposed a novel ACPP method, named
PCIT, which utilized an instance transfer mechanism to im-
prove the quality of the instance grouping. The experimen-
tal results on two widely studied problem domains, SAT and
TSP, have demonstrated the effectiveness of PCIT. Currently
PCIT relies on the instance features to build the EPM. Since 

Document 5: 
 with a constraint handling technique. At each generation, each
subpopulation generates new individuals based on its own.
Then, each subpopulation is combined with new individuals
generated by all subpopulations, and selection is conducted
with the corresponding constraint handling technique. Com-
pared to all the above-mentioned work, in which all search
biases have access to the whole population, PAP allows only
its constituent algorithms to work on a subpopulation, i.e.,
full access to the whole population is prohibited. Migration is
the only route that different subpopulations communicate with
each other. This strategy, used by PAP, reduces the likelihood
of different constituent algorithms repeating similar search
behaviors or sharing similar search biases.
From the perspective of employing a multipopulation model
and migration operators, PAP is related to the distributed
EAs (dEAs), which have several subpopulations (islands) and
perform sparse exchange of individuals among them [25],
[26]. However, PAP is quite different from previous dEAs
in three major ways. First, most dEAs run the same EA
on all subpopulations [26]–[31] (either with the same or
different control parameters), while PAP employs different
EAs. Second, the migration scheme of PAP does not assume
any topology of subpopulations, while many dEAs do. By
this means, we solely focus on investigating whether it is 

Document 6: 
 that ihvr ∈(0, 1], and a larger value of ihvr is better. IHVR can distinguish well between
MOEAs with a different performance, and can also save a lot of calculations. In this work,
IHVR is used as the performance metric Metric .
4.3. Automatic Construction Approach
Algorithm 1 presents the automatic construction approach for MOEAs/PAP . Starting
from an empty set (line 2), the approach constructs the PAP (denoted as P) iteratively.
Speciﬁcally, each iteration of the approach (lines 3–15) consists of two subsequent phases.
In the ﬁrst phase, an existing automatic algorithm conﬁguration tool, namely SMAC 3 [44],
is used to search in Θ to ﬁnd the algorithm that can improve the performance of the current
PAP to the largest extent (line 5), and then this algorithm is inserted into P (line 6). This
phase is similar to the commonly-used greedy approach in the automatic construction of
PAPs [27,31]. Additionally, we introduce a new phase, namely simpliﬁcation, as the second
phase in Algorithm 1. In this phase (lines 7–14), P would be simpliﬁed by removing the
member algorithms that do not contribute at all to its performance (meaning removing
these algorithms has no effect on the performance of P on the training set). Considering
the size of P is bounded (line 3), removing the redundant algorithms from P is meaningful
because this will leave space for new member algorithms that can improve the performance 

","The PCIT approach, also known as Parallel Configuration Identification and Transfer, involves identifying powerful parallel portfolios of solvers by transferring instances between different subsets. It uses an incumbent configuration in each subset to identify suitable transfers, leading to high-quality parallel solvers with little human effort involved.",16.918636083602905,"The PAP approach called ""PCIT"" (Parallel Configuration Instance Transfer) utilizes an instance transfer mechanism to enhance the quality of instance grouping. It identifies ""dissimilar"" instances that cannot be solved satisfactorily by the corresponding incumbents found through an automatic configuration (AC) procedure. PCIT constructs a target subset for each transferred instance based on how well the incumbent configuration performs on similar instances, aiming to provide high-quality parallel solvers with minimal human intervention. It builds empirical performance models to predict how the incumbents would perform on transferred instances, thus avoiding significant computational costs. The effectiveness of PCIT has been demonstrated through experiments in problem domains such as SAT and TSP."
llama3.1:latest,"What is the idea behind the PAP approach called ""CEPS""?
","Document 1: 
 also presented. The performance of the two instantiations on
TSP and VRPSPDTW problems support the effectiveness of
CEPS in the sense that, in comparison with state-of-the-art
PAP construction approaches, the PAPs obtained by CEPS
achieves better generalization performance.
Since CEPS is a generic framework, some discussions
would help elaborate issues that are of signiﬁcance in practice.
First, although this work assumes CEPS takes a set of initial
training instances as the input, such training instances are
not necessarily real-world instances but could be generated
randomly. In other words, CEPS could be used in a fully cold-
start setting (a.k.a. zero-shot), i.e., no real-world instances are
available for the target problem class. Further, CEPS could
either be run ofﬂine or online, i.e., it could accommodate new
real instances whenever available.
Second, the potential of CEPS could be further explored
by taking advantage of the data generated during its run,
except for the ﬁnal obtained PAP. The data contain all the
sampled conﬁgurations and instances, and the performance
of the former on the latter. Considering that when using
a search method to solve a problem instance, its optimal
parameter values are usually problem-instance dependent and
thus need to be tuned. To tune parameters for a new problem
instance, we can learn from the historical data generated by
CEPS to build a mapping from problem instances to their
optimal parameter values, i.e., a low-cost online parameter- 

Document 2: 
 paper has two major contributions. First, the proposed PAP is
developed for numerical optimization instead of combinatorial
optimization. Second, we investigate the term “risk” in a
different context. Previous work mainly aimed to reduce the
risk of an algorithm on a speciﬁc optimization problem, which
can be measured by applying the algorithm to the problem
for multiple times. In this paper, we are more interested in
reducing the risk overa set of problems , i.e., the risk is
measured by applying the algorithm to multiple problems.
Our PAP is a general framework for combining different
population-based search algorithms. It allocates computation
time among more than one constituent algorithm and acti-
vates interaction among them so that they can beneﬁt from
one another. To be more speciﬁc, the computation time is
measured by the number of ﬁtness evaluations (FEs), and
the allocation of FEs is implemented by dividing the whole
population into several subpopulations and evolving them in
a parallel manner (using different constituent algorithms). To
demonstrate the efﬁcacy of the proposed PAP, we chose four
existing population-based algorithms, including self-adaptive
differential evolution with neighborhood search (SaNSDE)
[7], particle swarm optimizer with inertia weight (wPSO)
[8], generalized generation gap (G3) model with generic
parent-centric recombination (PCX) operator (G3PCX) [9],
and covariance matrix adaptation evolution strategy (CMA-
ES) [10], as the constituent algorithms. These algorithms 

Document 3: 
 this approach no longer guarantees the validity of the above
assumption. As a consequence, Θ′may generalize worse than
Θ. A remedy to prevent this as much as possible is to increase
redundancy in the evolution of the PAP. More speciﬁcally, one
could repeat the conﬁguration-removal procedure to Θ for n
times, leading to ntemporary PAPs, ¯Θ1,..., ¯Θn; then for each
temporary PAP ¯Θ, the new conﬁgurations are identiﬁed and
inserted, leading to n new PAPs, Θ′
1,..., Θ′
n, each of which
is of the same size as Θ; ﬁnally, the PAP among them that
performs best against T ∪T′ is retained.
III. C O-EVOLUTION OF PARAMETERIZED SEARCH
By incorporating the above-described procedure into the co-
evolution process, we arrive at the proposed CEPS framework,
as demonstrated in Algorithm 1. In general, CEPS consists
of two major phases, i.e., an initialization phase (lines 2-
7), and a co-evolution phase (lines 8-27) which could be
further subdivided into alternating between the evolution of
the conﬁguration population (representing the PAP) (lines 10-
15) and the evolution of the instance population (representing
the training instances) (lines 17-26) for MaxIte iterations in
total. These modules are detailed as follows. 

Document 4: 
 contributions of this paper include:
1) A novel PAP construction framework, namely Co-
Evolution of Parameterized Search (CEPS), is proposed.
It is also shown that CEPS approximates a process that
minimizes the upper bound, i.e., a tractable surrogate,
of the generalization performance.
2) To demonstrate the implementation details of CEPS as
well as to assess its potential, concrete instantiations are
also presented for two hard optimization problems, i.e.,
TSP and the Vehicle Routing Problem with Simultane-
ous Pickup–Delivery and Time Windows (VRPSPDTW)
[18]. Computational studies conﬁrm that CEPS is able
to obtain PAPs with better generalization performance.
3) The proposal of CEPS extends the realm of Co-
Evolution, for the ﬁrst time, to evolving algorithm
conﬁgurations and problem instances. Since CEPS does
not invoke domain-speciﬁc knowledge, its potential ap-
plications can go beyond optimization problems, even to
planning and learning problems.
The rest of the paper is organized as follows. Section II in-
troduces the challenge of seeking generalizable PAPs, existing
PAP construction methods, as well as the theoretical insight
behind CEPS. Section III presents the CEPS framework. Sec-
tion IV presents its instantiations for TSP and VRPSPDTW.
Computational studies on these two problems are presented in
Section V. Threats to validity of this study are discussed in 

Document 5: 
 that ihvr ∈(0, 1], and a larger value of ihvr is better. IHVR can distinguish well between
MOEAs with a different performance, and can also save a lot of calculations. In this work,
IHVR is used as the performance metric Metric .
4.3. Automatic Construction Approach
Algorithm 1 presents the automatic construction approach for MOEAs/PAP . Starting
from an empty set (line 2), the approach constructs the PAP (denoted as P) iteratively.
Speciﬁcally, each iteration of the approach (lines 3–15) consists of two subsequent phases.
In the ﬁrst phase, an existing automatic algorithm conﬁguration tool, namely SMAC 3 [44],
is used to search in Θ to ﬁnd the algorithm that can improve the performance of the current
PAP to the largest extent (line 5), and then this algorithm is inserted into P (line 6). This
phase is similar to the commonly-used greedy approach in the automatic construction of
PAPs [27,31]. Additionally, we introduce a new phase, namely simpliﬁcation, as the second
phase in Algorithm 1. In this phase (lines 7–14), P would be simpliﬁed by removing the
member algorithms that do not contribute at all to its performance (meaning removing
these algorithms has no effect on the performance of P on the training set). Considering
the size of P is bounded (line 3), removing the redundant algorithms from P is meaningful
because this will leave space for new member algorithms that can improve the performance 

Document 6: 
 cores each (2.20 GHz, 30 MB Cache), running Centos 7.5.
D. Results and Analysis
We report the #TOs, PAR-10 and PANC achieved by the
PAPs on the testing set in Table II and also visualize their
medians and variance across all the testing instances by box-
plots in Figure 1. Note the mean value is also plotted in Figure
1 (indicated by “ ▲”) to show that for a PAP how its PAR-
10/PANC is affected by the outliers (the timeout cases) which
would be hidden by boxplots. In Table II the #TOs, PAR-
10/PANC of a PAP is highlighted in grey if it achieved the best
performance. One could make three important observations
from these results. First, the PAPs obtained by CEPS have
the smallest number of timeouts in all the six experiments,
which means they have the highest success rate for solving the
testing instances among all the tested PAPs. Recall that CEPS
actively searches in the instance space to identify the hard-
to-solve instances for further improving the generalization of
the PAPs. Such a mechanism makes CEPS the method that is
least affected by the hard testing instances which signiﬁcantly
differs from the given training instances. This could be further
veriﬁed by Figure 1, in which CEPS is the method that has
the least gap between the mean value (which takes timeouts
into account) and median value (which naturally ﬁlters out the 

","I don't have information on a concept or method called ""CEPS"" within the context of the Policy and Action Plans (PAP) approach. It's possible that it could be specific to a particular area of study, industry, or region, and I couldn't find any general information about it. If you have more details or if there was something else you were curious about, please let me know!",16.58436417579651,"The PAP approach called ""Co-Evolution of Parameterized Search"" (CEPS) is designed to enhance the construction of Parameterized Algorithm Portfolios (PAPs) by effectively combining different population-based search algorithms. The key idea behind CEPS is to co-evolve both algorithm configurations and problem instances, which allows the framework to learn from both the algorithms and the specific characteristics of the problems being solved. The framework consists of two main phases: an initialization phase and a co-evolution phase that alternates between evolving a configuration population (representing the PAP) and an instance population (representing the training instances). CEPS aims to reduce the generalization error of PAPs across a set of problems rather than on individual instances, facilitating adaptation to varying types of problems for better overall performance. This approach also supports both offline and online operations, making it flexible in handling incoming problem instances."
llama3.1:latest,"Please give me the names of some state-of-the-art SAT solvers.
","Document 1: 
 of determining whether a Boolean formula can 
evaluate to true, benefits from very mature and 
advanced algorithms with large practical impact.
Application and research domains like software 
and hardware verification, automated planning,
computational biology, and many others benefit 
from modern SAT solvers. These domains have 
large and difficult instances that provide the SAT 
community with meaningful benchmarks. 
Most of the following challenges are general in 
such a way that the questions they raise should 
positively affect not only research in parallel SAT 
but in parallel search in general. We first present 
the current situation in sequential and parallel SAT 
solving and then give a set of challenges. Each of 
these challenges comes with an overly optimistic 
estimate of its inherent difficulty represented as 
black circles, where we would estimate that every 
black circle represents, roughly, about two years of 
research. 
Context: Sequential SAT Solvers 
State-of-the-art solvers extend the original Davis,
Putnam, Logemann, and Loveland (DPLL) proce -
dure (Davis, Logemann, and Loveland 1962) with 
conflict analysis (Zhang et al. 2001). The general
architecture of such conflict-directed clause-learn -
ing solvers (CDCL) is presented in figure 1. These 
procedures include an optional preprocessing step 
0, which performs variable elimination and clause 
subsumption checks in order to reduce the size of 
the formula and improve the performance of the 

Document 2: 
 Intelligence (AAAI’02), (pp. 674–681). AAAI Press / The MIT Press, Menlo Park, CA, USA.
KhudaBukhsh, A., Xu, L., Hoos, H. H., & Leyton-Brown, K. (2009). SATenstein: Automatically building lo-
cal search sat solvers from components. In Proceedings of the Twenty-ﬁrst International Joint Conference
on Artiﬁcial Intelligence (IJCAI’09), (pp. 517–524).
Le Berre, D. & Simon, L. (2004). Fifty-ﬁve solvers in Vancouver: The SAT 2004 competition. In Hoos, H. H.
& Mitchell, D. G. (Eds.), Theory and Applications of Satisﬁability Testing: Proceedings of the Seventh
International Conference (SAT’04), volume 3542 of Lecture Notes in Computer Science , (pp. 321–344).
Springer Verlag.
Leyton-Brown, K., Nudelman, E., & Shoham, Y . (2002). Learning the empirical hardness of optimization
problems: The case of combinatorial auctions. In Hentenryck, P. V . (Ed.), Principles and Practice of
Constraint Programming – CP 2002: Eighth International Conference , volume 2470 of Lecture Notes in
Computer Science, (pp. 556–572). Springer Verlag, Berlin, Germany. 

Document 3: 
 212
state-of-the-art SLS algorithms. SATenstein-LS has
41 parameters that control the selection and behavior of
its components, leading to a total conﬁguration space of
size 4.82 ×1012. Automatically-identiﬁed conﬁgurations of
SATenstein-LS have been shown to achieve better per-
formance than existing state-of-the-art SLS algorithms on
several well-known instance distributions.
Instances
We investigated the effectiveness of Hydra on four distri-
butions, drawing on well-known families of SAT instances.
Because no state-of-the-art SLS algorithms are able to prove
unsatisﬁability, we considered only satisﬁable instances. We
identiﬁed these by running all complete algorithms that won
a SAT competition category between 2002 and 2007 for
one hour. First, the BM data set is constructed from 500
instances taken from each of the six distributions used by
KhudaBukhsh et al. (2009) (
QCP, SWGCP, FACT, CBMC,
R3FIX, and HGEN), split evenly into training and test sets.
Second, the INDU data set is a mixture of 500 instances
from each of the CBMC and FACT distributions, again split
evenly into training and test sets. Third and fourth, the HAND
and RAND data sets include all satisﬁable instances from the
Random and Handmade categories of the SAT Competitions 

Document 4: 
 form (a conjunction of disjunctions of variables and their negations) and determine a satisﬁable assignment or prove that 
none exists. An incomplete SAT solver can ﬁnd satisfying assignments, but not prove unsatisﬁability.
Most state-of-the-art complete SAT solvers are based on conﬂict-driven clause learning (CDCL; [57]). Their parameters 
control variable selection for branching decisions, clause learning and restart techniques. State-of-the-art incomplete SAT 
solvers use stochastic local search (SLS; [38]), and their parameters control the selection of the variable whose value is 
modiﬁed in each local search step as well as the diversiﬁcation and additional intensiﬁcation strategies. Furthermore, there 
exist several preprocessing techniques (e.g., [21]) to simplify formulas and their parameters control how long and how 
aggressive preprocessing will be used – too much preprocessing can remove important structural information and hence, 
it can increase the hardness of formulas. The eﬃcacy of SAT solvers depends on multiple heuristic components whose 
basic functions and the interplay between them are controlled by parameters. Some parameters are categorical (e.g., choice 
between different search strategies in SLS), while many others are integer- or real-valued (e.g., the damping factor used in 
computing heuristic variable scores in CDCL).
Parallel SAT solvers have received increasing attention in recent years. ManySAT [30,31,29] was one of the ﬁrst parallel 

Document 5: 
 tial solver baselines, indicating the great benefit by combin-
ing complementary configurations obtained from a rich con-
figuration space.
Comparison with Hand-designed Parallel Solvers
To further evaluate the portfolios constructed by PCIT, we
compared them with the state-of-the-art manually designed
parallel solvers. Specifically, we considered the ones con-
structed for SAT. We chose Priss6 (Manthey, Stephan, and
Werner 2016) to compare with the one constructed in SAT-
Single, since Priss6 is the official parallel version of Riss6
(the base solver in SAT-Single). For the same reason, we
chose PfolioUZK (Wotzlaw et al. 2012) (the gold medal
winning solver of the parallel track of the SAT’12 Chal-
lenge) to compare with the one constructed in SAT-Multi.
Finally, we chose Plingeling (version bbc) (Biere 2016),
the gold medal winning solver of the parallel track of the
SAT’16 Competition, to compare with both. Note that all
the manually designed solvers considered here have imple-
mented far more advanced parallel solving strategies (e.g.,
clause sharing) than only independently running component
solvers in parallel. In the experiments the default settings of
these solvers were used and the same statistical tests as be-
fore were conducted. As shown in Table 4, on SAT-Single 

Document 6: 
 ACM 52(10):56–67.
Balyo, T.; Heule, M. J. H.; and J¨arvisalo, M., eds. 2016. Proceed-
ings of SAT Competition 2016: Solver and Benchmark Descrip-
tions, volume B-2016-1 of Department of Computer Science Se-
ries of Publications B. University of Helsinki.
Battiti, R.; Brunato, M.; and Mascia, F., eds. 2008. Reactive
Search and Intelligent Optimization. Springer.
Biere, A. 2016. Splatz, Lingeling, Plingeling, Treengeling, Yal-
SAT Entering the SAT Competition 2016. In Balyo et al. (2016),
44–45.
Burke, E. K.; Gendreau, M.; Hyde, M.; Kendall, G.; Ochoa, G.;
¨Ozcan, E.; and Qu, R. 2013. Hyper-heuristics: A Survey of the
State of the Art. Journal of the Operational Research Society
64(12):1695–1724.
Gomes, C. P., and Selman, B. 2001. Algorithm Portfolios. Arti-
ficial Intelligence 126(1-2):43–62.
Hamadi, Y ., and Wintersteiger, C. M. 2013. Seven Challenges in
Parallel SAT Solving. AI Magazine 34(2):99–106. 

","Some state-of-the-art SAT solvers include:

1. Plingeling (version bbc)
2. Priss6
3. PfolioUZK
4. ManySAT 

These solvers have been used in various SAT competitions and have achieved high performance.",16.71234130859375,"Some state-of-the-art SAT solvers include SATenstein, Priss6, PfolioUZK, and Plingeling."
llama3.1:latest,"Please give me the names of some state-of-the-art TSP solvers.
","Document 1: 
 For surveys of the problem and its applications, the reader is referred to the excellent
volumes edited by Lawler et al. [24] and Gutin and Punnen [11].
Local search with k-exchange neighborhoods, k-opt, is the most widely used heu-
ristic method for the TSP. k-opt is a tour improvement algorithm, where in each step
k links of the current tour are replaced by k links in such a way that a shorter tour is
achieved.
It has been shown [7] that k-opt may take an exponential number of iterations and
that the ratio of the length of an optimal tour to the length of a tour constructed byk-opt
can be arbitrarily large when k ≤ n/2 − 5. Such undesirable cases, however, are very
rare when solving practical instances [31]. Usually, high-quality solutions are obtained
in polynomial time. This is, for example, the case for the Lin–Kernighan heuristic,
one of the most effective methods for generating optimal or near-optimal solutions
for the symmetric TSP. High-quality solutions are often obtained, even though only a
small part of the k-exchange neighborhood is searched.
In the original version of the Lin–Kernighan heuristic [ 25], the allowable
k-exchanges (or k-opt moves) are restricted to those that can be decomposed into a
2- or 3-exchange followed by a (possibly empty) sequence of 2-exchanges. This restric- 

Document 2: 
 of determining whether a Boolean formula can 
evaluate to true, benefits from very mature and 
advanced algorithms with large practical impact.
Application and research domains like software 
and hardware verification, automated planning,
computational biology, and many others benefit 
from modern SAT solvers. These domains have 
large and difficult instances that provide the SAT 
community with meaningful benchmarks. 
Most of the following challenges are general in 
such a way that the questions they raise should 
positively affect not only research in parallel SAT 
but in parallel search in general. We first present 
the current situation in sequential and parallel SAT 
solving and then give a set of challenges. Each of 
these challenges comes with an overly optimistic 
estimate of its inherent difficulty represented as 
black circles, where we would estimate that every 
black circle represents, roughly, about two years of 
research. 
Context: Sequential SAT Solvers 
State-of-the-art solvers extend the original Davis,
Putnam, Logemann, and Loveland (DPLL) proce -
dure (Davis, Logemann, and Loveland 1962) with 
conflict analysis (Zhang et al. 2001). The general
architecture of such conflict-directed clause-learn -
ing solvers (CDCL) is presented in figure 1. These 
procedures include an optional preprocessing step 
0, which performs variable elimination and clause 
subsumption checks in order to reduce the size of 
the formula and improve the performance of the 

Document 3: 
 10.0 
12.5 
15.0 
17.5 PAR-10 (c) TSP-3
Fig. 2: Visual comparison in boxplots of the medians and variance of the test performance of each TSP solver across the
testing instances. Note the mean value is also plotted, indicated by “ ▲”.
TABLE III: Comparison of the state-of-the-art TSP solvers
with the PAPs obtained by CEPS, on the testing set. #TOs
refers to number of total timeouts. PAR-10 is the penalized
average runtime-10. Performance of a solver is highlighted in
grey if it achieved the best testing performance.
TSP-1 TSP-2 TSP-3
#TOs PAR-10 #TOs PAR-10 #TOs PAR-10
LKH-default 131 30.84 137 31.98 150 34.73
LKH-tuned 29 8.23 34 9.40 27 7.67
EAX-default 69 17.98 73 18.91 69 17.95
EAX-tuned 33 10.97 30 10.38 29 10.12
VBS 6 3.82 7 4.26 6 4.13
CEPS 6 2.74 4 2.15 2 1.94
signiﬁcant performance improvement, though still obviously
falling behind of the PAPs obtained by CEPS. Second, the only
solver that could match the PAP’s performance level in one
of the three scenarios, is the VBS of the algorithm portfolio
considered by the algorithm selection approaches [29], [30].
However, in TSP-2 and TSP-3, the performance advantage of 

Document 4: 
 troduces the challenge of seeking generalizable PAPs, existing
PAP construction methods, as well as the theoretical insight
behind CEPS. Section III presents the CEPS framework. Sec-
tion IV presents its instantiations for TSP and VRPSPDTW.
Computational studies on these two problems are presented in
Section V. Threats to validity of this study are discussed in
Section VI. Section VII concludes the paper with discussions.
II. P ARAMETERIZED SOLVERS MADE GENERALIZABLE
A. Notations and Problem Description
Assume a PAP is to be built for a problem class (e.g., TSP),
for which an instance of the problem class is denoted as s, and
the set of all possible sis denoted as Ω. Given a parameterized
algorithm, each component solver of the PAP is a conﬁguration
(full instantiation) of the algorithm. Generally speaking, the
parameterized algorithm can be any concrete computational
process, e.g., a traditional heuristic search process such as the
LK Heuristic for TSP or even a neural network [19]–[21] that
outputs a solution for a given instance of the target problem
class. Let θ denote a conﬁguration and let Θ denote a PAP
that contains K different conﬁgurations (component solvers),
i.e., Θ = {θ1,...,θ K}. The quality of a conﬁguration θ on a 

Document 5: 
 H. Trautmann, “Evolving diverse TSP instances by means of novel and
creative mutation operators,” in Proceedings of the 15th ACM/SIGEVO
Conference on Foundations of Genetic Algorithms, FOGA’2019. Pots-
dam, Germany: ACM, Aug 2019, pp. 58–71.
[38] Y . Nagata and S. Kobayashi, “A powerful genetic algorithm using edge
assembly crossover for the traveling salesman problem,” INFORMS
Journal on Computing , vol. 25, no. 2, pp. 346–363, 2013.
[39] X. Xie and J. Liu, “Multiagent optimization system for solving the
traveling salesman problem (tsp),” IEEE Transactions on Systems, Man,
and Cybernetics, Part B , vol. 39, no. 2, pp. 489–502, 2009.
[40] C. Wang, D. Mu, F. Zhao, and J. W. Sutherland, “A parallel simulated
annealing method for the vehicle routing problem with simultaneous
pickup-delivery and time windows,” Computers & Industrial Engineer-
ing, vol. 83, pp. 111–122, 2015.
[41] W. Huang and T. Zhang, “Vehicle routing problem with simultaneous
pick-up and delivery and time-windows based on improved global arti-
ﬁcial ﬁsh swarm algorithm,” Computer Engineering and Applications ,
vol. 52, no. 21, pp. 21–29, 2016. 

Document 6: 
 Portfolio-based algorithm selection for SAT,” Journal of Artiﬁcial In-
telligence Research, vol. 32, pp. 565–606, 2008.
[29] P. Kerschke, L. Kotthoff, J. Bossek, H. H. Hoos, and H. Trautmann,
“Leveraging TSP solver complementarity through machine learning,”
Evolutionary Computation, vol. 26, no. 4, pp. 597–620, 2018.
[30] K. Zhao, S. Liu, Y . Rong, and J. X. Yu, “Leveraging TSP solver
complementarity via deep learning,” arXiv preprint arXiv:2006.00715 ,
2020.
[31] L. Kotthoff, “Algorithm selection for combinatorial search problems: A
survey,” AI Magazine, vol. 35, no. 3, pp. 48–60, 2014.
[32] C. D. Rosin and R. K. Belew, “New methods for competitive coevolu-
tion,” Evolutionary Computation, vol. 5, no. 1, pp. 1–29, 1997.
[33] J. I. van Hemert, “Evolving combinatorial problem instances that are
difﬁcult to solve,” Evolutionary Computation , vol. 14, no. 4, pp. 433–
462, 2006.
[34] K. Helsgaun, “General k-opt submoves for the Lin-Kernighan TSP 

","The Traveling Salesman Problem (TSP) is a classic NP-hard problem that has received significant attention in recent years, particularly with advancements in mathematical optimization and machine learning. Here are some state-of-the-art TSP solvers across various categories:

1. **Concorde**: A widely used open-source software package developed by Brad G. Lawson and Pierre Hansen (a professor at the University of Montreal). It is considered one of the most efficient exact algorithms for solving small to medium-sized instances of the TSP.

2. **Google OR-Tools** (formerly known as the Google Optimization Tools): This library provides a comprehensive suite of operations research algorithms, including a solver specifically designed for the TSP. Its capabilities extend from simple heuristics to more sophisticated and efficient methods, making it a versatile tool for tackling different aspects of the TSP.

3. **LKH** (Lin-Kernighan Heuristics): This is an open-source software package developed by Matthew H. Johnson that offers some of the most effective heuristics for solving large-scale instances of the TSP. It's particularly known for its implementation of the Lin-Kernighan heuristic, which is considered one of the best algorithms available for finding high-quality solutions to TSPs quickly.

4. **MIPS**: This is a software package focused on Mixed-Integer Programming (MIP) solvers. While not exclusively designed for TSP, it includes several state-of-the-art MIP solvers (such as CPLEX and Gurobi) that can be used to solve complex instances of the TSP exactly.

5. **COIN-OR CPLEX**: CPLEX is a commercial software package developed by IBM that has been widely used in operations research for many years. It's capable of solving large-scale optimization problems, including the TSP, using various techniques such as branch and cut or branch and bound.

6. **Gurobi**: Gurobi is another leading commercial MIP solver with a wide range of features, including high-performance solvers for linear and integer programs. It can be used to solve TSP instances efficiently.

7. **Google's Vroom**: This library uses heuristics and machine learning techniques to provide efficient solutions to the Vehicle Routing Problem (VRP), which includes the TSP as a special case. It leverages Google's experience in optimizing logistics for services like Google Maps, providing insights into real-world scenarios that can inform algorithmic improvements.

8. **CIMON**: This solver is specifically designed to address the Capacitated TSP variant and uses advanced mathematical techniques, but its general approach can be adapted or extended to tackle standard TSPs with appropriate modifications or constraints.

9. **SCP (Symmetric Traveling Salesman Problem)**: SCP is a highly specialized software package focused on solving symmetric instances of the TSP using exact algorithms like branch and cut or branch and bound methods.

10. **LINGO**: This commercial optimization software includes tools for solving linear, integer, nonlinear, and dynamic optimization problems. It can be used to solve various formulations of the TSP and offers a range of solution methods tailored to different problem characteristics.

Please note that each solver has its strengths and is suited best for specific types of instances or solving methodologies (e.g., exact vs. heuristic solutions). The choice among these solvers depends on the nature of your problem, available computational resources, and personal preferences.",119.1330714225769,"Some state-of-the-art TSP solvers mentioned include the Lin–Kernighan heuristic (LKH), the Effective Ant Colony (EAX), and the Variable Neighborhood Search (VBS). These solvers have been compared in performance metrics such as PAR-10 and number of timeouts (TOs) across different testing instances."
llama3.1:latest,"Please give me the names of some state-of-the-art Automatic Algorithm Configuration approaches.
","Document 1: 
 Journal of Artiﬁcial Intelligence Research 75 (2022) 425-487 Submitted 02/2022; published 10/2022
A Survey of Methods for Automated
Algorithm Conﬁguration
Elias Schede elias.schede@uni-bielefeld.de
Decision and Operation Technologies Group,
Bielefeld University, Bielefeld, Germany
Jasmin Brandt jasmin.brandt@upb.de
Alexander Tornede alexander.tornede@upb.de
Department of Computer Science,
Paderborn University, Paderborn, Germany
Marcel Wever marcel.wever@ifi.lmu.de
Institute of Informatics, LMU Munich &
Munich Center for Machine Learning, Munich, Germany
Viktor Bengs viktor.bengs@ifi.lmu.de
Institute of Informatics,
LMU Munich, Munich, Germany
Eyke H¨ ullermeier eyke@lmu.de
Institute of Informatics, LMU Munich &
Munich Center for Machine Learning, Munich, Germany
Kevin Tierney kevin.tierney@uni-bielefeld.de
Decision and Operation Technologies Group,
Bielefeld University, Bielefeld, Germany
Abstract
Algorithm conﬁguration (AC) is concerned with the automated search of the most
suitable parameter conﬁguration of a parametrized algorithm. There is currently a wide
variety of AC problem variants and methods proposed in the literature. Existing reviews 

Document 2: 
 2 Related Work
2.1 Automatic Algorithm Conﬁguration
Several approaches exist in the literature for the automatic tuning
of algorithms. Some of these were created for a speciﬁc algorithm
or task. For example, [24] devises a modular algorithm for solving
constraint satisfaction problems (CSPs). Using a combination of ex-
haustive enumeration of all possible conﬁgurations and parallel hill-
climbing, the technique automatically conﬁgures the system for a
given set of training instances. Another approach, presented in [30],
focuses on the conﬁguration of adaptive algorithms, employing a se-
quential parameter optimization approach.
Other approaches automatically design and build an entire solver
to best tackle a set of example training instances. For example, [28]
uses genetic programming to create an evolutionary algorithm (EA).
Here the chromosome is an EA operation like the selection of par-
ents, mutation, or crossover, and the task is to ﬁnd a sequence of
the genetic programming operators that is best suited for the speci-
ﬁed problem. For SAT, [8] classiﬁes local search (LS) approaches by
means of context-free grammars. This approach then uses a genetic
programming approach to select a good LS algorithm for a given set
of instances.
There also exist approaches that are applicable to more general al-
gorithms. For example, in order to tune continuous parameters, [5]
suggests an approach that determines good parameters for individual
training instances. This approach ﬁrst evaluates the extreme param- 

Document 3: 
 470
A Survey of Methods for Automated Algorithm Configuration
General AC systems
D-SMAC https://github.com/tqichun/distributed-SMAC3
GPS https://github.com/YashaPushak/GPS
irace https://github.com/MLopez-Ibanez/irace
OAT (GGA) https://docs.optano.com/algorithm.tuner/current/
ParamILS https://www.cs.ubc.ca/labs/algorithms/Projects/ParamILS/
PyDGGA http://ulog.udl.cat/software/
REVAC https://github.com/ChrisTimperley/RubyREVAC
SMAC 3 https://github.com/automl/SMAC3
Benchmarks
AClib https://bitbucket.org/mlindauer/aclib2/src/master/
DAC https://github.com/automl/DAC
Table 7: List of available software in the realm of AC.
References
Belarmino Adenso-Diaz & Manuel Laguna. Fine-tuning of algorithms using fractional ex-
perimental designs and local search. Operations research, 54(1):99–114, 2006.
¨Ozg¨ ur Akg¨ un, Nguyen Dang, Ian Miguel, Andr´ as Z Salamon, & Christopher Stone. In- 

Document 4: 
 cal (e.g., choice of heuristic). Categorical parameters can be used to select and combine discrete
building blocks of an algorithm (e.g., preprocessing and variable ordering heuristics); consequently,
our general view of algorithm conﬁguration includes the automated construction of a heuristic algo-
rithm from such building blocks. To the best of our knowledge, the methods discussed in this article
are yet the only general ones available for the conﬁguration of algorithms with many categorical
parameters.
We now give an overview of what follows and highlight our main contributions. After for-
mally stating the algorithm conﬁguration problem in Section 2, in Section 3 we describe ParamILS
(ﬁrst introduced by Hutter, Hoos & St ¨utzle, 2007), a versatile stochastic local search approach for
automated algorithm conﬁguration, and two of its instantiations, BasicILS and FocusedILS.
We then introduce adaptive capping of algorithm runs, a novel technique that can be used to
enhance search-based algorithm conﬁguration procedures independently of the underlying search
strategy (Section 4). Adaptive capping is based on the idea of avoiding unnecessary runs of the
algorithm to be conﬁgured by developing bounds on the performance measure to be optimized.
We present a trajectory-preserving variant and a heuristic extension of this technique. After dis-
cussing experimental preliminaries in Section 5, in Section 6 we present empirical evidence show-
ing that adaptive capping speeds up both BasicILS and FocusedILS. We also show that BasicILS
268 

Document 5: 
 rithm conﬁguration that minimizes some cost measure over the 
set of instances that will be seen during the production phase. 
In other words, the ﬁnal goal is that the conﬁguration of the al- 
gorithm found during the tuning phase generalizes to similar but 
unseen instances. The tuning phase may also use automatic conﬁg- 
uration methods repeatedly while engineering an algorithm [71] . 
Due to the separation between a tuning and a production phase, 
automatic algorithm conﬁguration is also known as oﬄine param- 
eter tuning to differentiate it from online approaches that adapt or 
control parameter settings while solving an instance [13,50] . Nev- 
ertheless, online approaches also contain parameters that need to 
be deﬁned oﬄine, for example, which and how parameters are 
adapted at run-time; such parameters and design choices can be 
conﬁgured by an oﬄine tuning method [59] . 
In our research on making the algorithm conﬁguration process 
more automatic , we have focused on racing approaches. Birattari 
et al. [19,20] proposed an automatic conﬁguration approach, F- 
Race, based on racing [64] and Friedman’s non-parametric two-way 
analysis of variance by ranks. This proposal was later improved 
by sampling conﬁgurations from the parameter space, and reﬁn- 
ing the sampling distribution by means of repeated applications of 
F-Race. The resulting automatic conﬁguration approach was called 
Iterated F-race (I/F-Race) [10,21] . Although a formal description of 

Document 6: 
 formance of FocusedILS [43], and we are convinced that, at least in cases where
the parameter response of a given target algorithm is reasonably regular and per-
formance evaluations are very costly, such advanced SMBO methods hold great
promise.
3.6 Conclusions and Future Work
Automated algorithm conﬁguration and parameter tuning methods have been de-
veloped and used for more than a decade, and many of the fundamental techniques
date back even further. However, it has only recently become possible to effectively
solve complex conﬁguration problems involving target algorithms with dozens of
parameters, which are often categorical and conditional. This success is based in
3 Automated Algorithm Conﬁguration and Parameter Tuning 65
part on the increased availability of computational resources, but has mostly been
enabled by methodological advances underlying recent conﬁguration procedures.
Still, we see much room (and, indeed, need) for future work on automated algo-
rithm conﬁguration and parameter tuning methods. We believe that in developing
such methods, the fundamental features underlying all three types of methods dis-
cussed in this chapter can play an important role, and that the best methods will
employ combinations of these. We further believe that different conﬁguration pro-
cedures will likely be most effective for solving different types of conﬁguration
problems (depending, in particular, on the number and type of target algorithm pa-
rameters, but also on regularities in the parameter response). Therefore, we see a
need for research aiming to determine which conﬁgurator is most effective under 

","Some state-of-the-art Automatic Algorithm Configuration (AAC) approaches include:

1. ParamILS
2. FocusedILS
3. SMAC (Sequential Model-Based Algorithm Configurator)
4. I/F-Race (Iterated F-race, a racing-based approach)

These methods have been developed and used in various fields to effectively solve complex configuration problems involving target algorithms with many parameters.",22.4979088306427,"Some state-of-the-art Automatic Algorithm Configuration approaches include D-SMAC, GPS, irace, OAT (GGA), ParamILS, PyDGGA, REVAC, and SMAC 3."
llama3.1:latest,"What is the idea behind the AAC approach called ""irace""?
","Document 1: 
 analysis of variance by ranks. This proposal was later improved 
by sampling conﬁgurations from the parameter space, and reﬁn- 
ing the sampling distribution by means of repeated applications of 
F-Race. The resulting automatic conﬁguration approach was called 
Iterated F-race (I/F-Race) [10,21] . Although a formal description of 
the I/F-Race procedure is given in those publications, an imple- 
mentation was not made publicly available. The irace package im- 
plements a general iterated racing procedure, which includes I/F- 
Race as a special case. It also implements several extensions al- 
ready described by Birattari [19] , such as the use of the paired 
t -test instead of Friedman’s test. Finally, irace incorporates sev- 
eral improvements not published before, such as sampling from a 
truncated normal distribution, a parallel implementation, a restart 
strategy that avoids premature convergence, and an elitist racing 
procedure to ensure that the best parameter conﬁgurations found 
are also evaluated on the highest number of training instances. 
The paper is structured as follows. Section 2 introduces the 
algorithm conﬁguration problem and gives an overview of ap- 
proaches to automatic algorithm conﬁguration. Section 3 describes 
the iterated racing procedure as implemented in the irace pack- 
age as well as several further extensions including the elitist irace . 
Section 4 illustrates the steps followed to apply irace to two con- 

Document 2: 
 5.2. Multi-objective optimization metaheuristics 
Besides the application to the MOACO framework described 
above [58] , irace has been applied to aid in the design of other 
multi-objective optimization algorithms. Dubois-Lacoste et al. 
[31] used irace to tune a hybrid of two-phase local search and 
Pareto local search (TP + PLS) to produce new state-of-the-art al- 
gorithms for various bi-objective permutation ﬂowshop problems. 
Fisset et al. [33] used irace to tune a framework of multi-objective 
optimization algorithms for clustering. When applied to a suﬃ- 
ciently ﬂexible algorithmic framework, irace has been used to de- 
sign new state-of-the-art multi-objective evolutionary algorithms 
[16,17] . 
5.3. Anytime algorithms (improve time-quality trade-offs) 
There is often a trade-off between solution quality and com- 
putation time: Algorithms that converge quickly tend to produce 
better solutions for shorter runtimes, whereas more exploratory al- 
gorithms tend to produce better solutions for longer runtimes. Im- 
proving the anytime behavior of an algorithm amounts to improv- 
ing the trade-off curve between solution quality and computation 
time such that an algorithm is able to produce as high quality so- 
lutions as possible at any moment during their execution. López- 

Document 3: 
 effect on the budget consumed is lower. The same experiment for 
the ACOTSP scenario showed that the best conﬁgurations become 
worse when T new or T ﬁrst are increased. This is due to the fact that 
ACOTSP has a homogeneous training set and, therefore, sampling 
new candidates is more important than executing a large number 
of instances. 
5. Other applications of irace 
Since the ﬁrst version of the irace package became publicly 
available in 2012, there have been many other applications of 
irace . In this section, we provide a list of the applications of the 
irace package of which we are aware at the time of writing. Some 
of these applications go beyond what is traditionally understood as 
algorithm conﬁguration, demonstrating the ﬂexibility of irace . 
54 M. López-Ibáñez et al. / Operations Research Perspectives 3 (2016) 43–58 
5.1. Algorithm conﬁguration 
The traditional application of irace is the automatic conﬁgura- 
tion of algorithms. Several publications have used irace when eval- 
uating or designing algorithms for problems such as the traveling 
salesman with time windows [60] , slot allocation [77] , generalized 
hub location [68] , ﬂow shop [14] , virtual machine placement [86] , 
online bin packing [92] , graph coloring [23] , image binarization 
[69] , network pricing [90] , combined routing and packing prob- 

Document 4: 
 ming by optimization paradigm [40] . Moreover, the importance of 
properly tuning the parameters of algorithms before analyzing and 
comparing them is becoming widely recognized. We hope that the 
development of the irace package will help practitioners and re- 
searchers to put these ideas into practice. 
Acknowledgements 
This work received support from the COMEX project (P7/36) 
within the Interuniversity Attraction Poles Programme of the Bel- 
gian Science Policy Oﬃce, and the EU FP7 ICT Project COLOMBO, 
Fig. A.1 1. Scheme of the user-provided components required by irace . 
Table A1 
Parameters of irace corresponding to the description 
of iterated racing given in Section 3.2 . The full list of 
irace parameters is available in the user guide. 
Iterated racing parameter irace parameter 
B maxExperiments 
C (cost measure) targetRunner 
μ mu 
N min minNbSurvival 
T ﬁrst firstTest 
T each eachTest 
Statistical test testType 
Cooperative Self-Organizing System for Low Carbon Mobility at 
Low Penetration Rates (agreement no. 318622). Thomas Stützle and 
Mauro Birattari acknowledge support from the Belgian F.R.S.-FNRS, 
of which they are Senior Research Associates. Leslie Pérez Cáceres 
acknowledges support of CONICYT Becas Chile. 
Appendix A. The irace package 

Document 5: 
 man problem with time windows: adapting algorithms from travel-time to 
makespan optimization. Appl Soft Comput 2013;13(9):3806–15 . 
[61] López-Ibáñez M., Dubois-Lacoste J., Pérez Cáceres L., Stützle T., Birattari M.. 
2016a. The irace package: Iterated racing for automatic algorithm conﬁgura- 
tion. http://iridia.ulb.ac.be/supp/IridiaSupp2016-003/ . 
[62] López-Ibáñez M, Pérez Cáceres L, Dubois-Lacoste J, Stützle T, Birattari M. The 
irace package: user guide. Technical Report TR/IRIDIA/2016-004. IRIDIA, Uni- 
versité Libre de Bruxelles, Belgium; 2016b . http://iridia.ulb.ac.be/IridiaTrSeries/ 
IridiaTr2016-004.pdf . 
[63] Marmion M-E , Mascia F , López-Ibáñez M , Stützle T . Automatic design of hy- 
brid stochastic local search algorithms. In: Blesa MJ, Blum C, Festa P, Roli A, 
Sampels M, editors. Hybrid metaheuristics, volume 7919 of lecture notes in 

Document 6: 
 ent robot behaviors and the criteria to transition between behav- 
iors. Each module can be further customized by means of several 
parameters. A particular combination of behaviors and transitions 
represents one controller, that is, an instance of the software that 
controls the robots in the swarm. The performance of a particu- 
lar controller is evaluated by means of multiple simulations. The 
search for the best controller over multiple training simulations is 
carried out by means of irace . The authors report that this system 
is not only able to outperform a previous system that used F-race 
[34] , but also a human designer, under the scenarios studied by 
them. 
6. Conclusion 
This paper presented the irace package, which implements the 
iterated racing procedure for automatic algorithm conﬁguration. It- 
erated racing is a generalization of the iterated F-race procedure. 
M. López-Ibáñez et al. / Operations Research Perspectives 3 (2016) 43–58 55 
The primary purpose of irace is to automatize the arduous task of 
conﬁguring the parameters of an optimization algorithm. However, 
it may also be used for determining good settings in other compu- 
tational systems such as robotics, traﬃc light controllers, compil- 
ers, etc. The irace package has been designed with simplicity and 
ease of use in mind. Despite being implemented in R , no previ- 
ous knowledge of R is required. We included two examples for the 

","The irace package implements a general iterated racing procedure, which is a generalized and improved version of the Iterated F-Race (I/F-Race) procedure. The core idea behind irace is to automatize the task of configuring the parameters of an optimization algorithm by iteratively sampling configurations from a parameter space and evaluating their performance through statistical tests.",20.221646547317505,"The irace package implements an automatic algorithm configuration method called iterated racing. This approach aims to automate the process of tuning algorithm parameters to enhance their performance efficiently. Irace conducts a series of ""races"" among different configurations of the algorithm based on their performance metrics, iteratively refining the search for optimal settings. It uses statistical tests to compare the configurations and incorporates features like sampling from a truncated normal distribution and an elitist strategy to ensure that the best configurations are heavily evaluated. Overall, irace's goal is to streamline and simplify the arduous task of configuring optimization algorithms, making it applicable beyond just algorithm configuration to other computational systems such as robotics and traffic light controllers."
llama3.1:latest,"What is the idea behind the AAC approach called ""SMAC""?
","Document 1: 
 intensiﬁcation scheme, and time-bounded SPO (TB-SPO) (Hutter et al., 2010b), which
generalizes SPO+ to work under (potentially tight) time constraints instead of considering
the number of function evaluations as a stopping criterion.
5.2 General Model-based AC Methods
SMAC Sequential model-based optimization for algorithm conﬁguration (SMAC) (Hutter
et al., 2011; Lindauer et al., 2021) can be seen as one of the ﬁrst fully-ﬂedged model-
based AC approaches, as it features solutions for many of the limitations of the previously
discussed SMBO techniques. SMAC generalizes TB-SPO to perform conﬁguration over
multiple problem instances so that it can support categorical parameters and handle tight
time constraints.
To support multiple problem instances, SMAC adapts the intensiﬁcation strategy of
TB-SPO to iteratively evaluate conﬁgurations on randomly sampled combinations of seeds
and problem instances. When doing so, it ensures that conﬁgurations are compared only
based on a performance estimate computed on the same randomly sampled set of problem
instances. Furthermore, SMAC’s surrogate model can generalize across problem instances
by incorporating problem instance features. To this end, a surrogate model is learned on
the joint problem instance and conﬁguration space to predict the performance of a given
conﬁguration on a given problem instance.
As a means to deal with a mixture of categorical and numerical parameters, SMAC 

Document 2: 
 method is paired with D-MAB selection [38] described
above. A sliding window is also used by Fialho et al.[ 70].
They suggest increasing the reward with the time elapsed
since the last application of this operator and decreasing
the reward with the number of times the operator has been
applied within the window. The aim of this method is to adapt
quickly to (even subtle) changes of the dynamic environment.
Li et al.[ 129] suggested a sliding window that stores the rate
of improvement in the ﬁtness of the offspring as compared
to the parent. The sum of all these rewards in the window is
used by a ranking mechanism to assign credit to the operators.
A different credit assignment mechanism is Compass, sug-
gested by Maturana and Saubion [ 146]. Based on the concepts
found in [ 147] (see Section VI), an operator’s impact is
evaluated using measures of both ﬁtness and diversity in order
to calculate the exploration-exploitation balance achieved by
the operator. The assigned credit reﬂects how closely the
achieved balance is to an exploration-exploitation balance that
is required by a user-deﬁned schedule. Other tested credit as-
signment methods are based on domination between operators
and Pareto fronts. Compass was paired with probability match-
ing selection, but was also combined with D-MAB in [ 143].
Except for the widely used multiarmed bandit approach dis-
cussed so far, AOS has also been treated as a full reinforcement 

Document 3: 
 cess (see (Hutter et al. 2009) for a comprehensive review),
which is usually referred to as automatic algorithm con-
ﬁguration (AAC) (Hoos 2012). Many AAC methods such
as ParamILS (Hutter et al. 2009), GGA/GGA+(Ans´otegui,
Sellmann, and Tierney 2009; Ans ´otegui et al. 2015), irace
(L´opez-Ib´a˜nez et al. 2016) and SMAC (Hutter, Hoos, and
Leyton-Brown 2011) have been proposed in the last few
years. They have been used for boosting the algorithm’s per-
formance in a wide range of domains such as the boolean
satisﬁability problem (SAT) (Hutter et al. 2009), the travel-
ing salesman problem (TSP) (L´opez-Ib´a˜nez et al. 2016; Liu,
∗Corresponding author
Copyright c⃝ 2020, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.
Tang, and Yao 2019), the answer set programming (ASP)
(Hutter et al. 2014) and machine learning (Feurer et al. 2015;
Kotthoff et al. 2017).
Despite the notable success achieved in application, the 

Document 4: 
 algorithm configuration framework. JArtifIntellRes 2009; 36 : 
267–306. 
9. Lindauer M, Eggensperger K, Feurer M et al. SMAC3: a ver- 
satile Bayesian optimization package for hyperparameter opti- 
mization. JMachLearnRes 2022; 23 : 54. 
10. Santu SKK, Hassan MM, Smith MJ et al. Automl to date and 
beyond: challenges and opportunities. ACMComputSurv 2022; 
54 : 175. 
Page7of9
Downloaded from https://academic.oup.com/nsr/article/11/8/nwae132/7639406 by guest on 18 September 2024 

Document 5: 
 more benchmark instances and compare its performance to
the best conﬁguration observed so far.
SMAC is an anytime algorithm that interleaves the ex-
ploration of new conﬁgurations with additional runs of the
current best conﬁguration to yield both better and more con-
ﬁdent results over time. As all anytime algorithms, SMAC
improves performance over time. While SMAC provably
converges for ﬁnite conﬁguration spaces, it often only ﬁnds
close-to-optimal conﬁgurations for realistic time budgets
and challenging conﬁguration problems.
Automated Portfolio Construction & Hydra
Our method for constructing sequential portfolios is closely
related to Hydra (Xu, Hoos, and Leyton-Brown 2010),
which automatically constructs selection-based portfolios.
Given a parameterized algorithm framework with a space
of algorithmsΘ, Hydra starts with an empty set of can-
didate algorithms C= ∅and iteratively calls an algorithm
conﬁguration method to add algorithms θ ∈Θ that comple-
ment Cbest. In each iteration, it constructs a portfolio from
the current set Cusing the portfolio-based algorithm selec-
tor SATzilla (Xu et al. 2008) and measures its performance
m(C,π) on each benchmark instance π ∈Π (in the ﬁrst it-
eration, m(∅,π) = −∞). The performance metric Hydra
maximizes via its algorithm conﬁguration method is then 

Document 6: 
 Anastacio and Hoos (2020) propose SMAC+PS, which integrates the idea of probabilis-
tic sampling known from irace into SMAC. This enhancement yields improvements over
both SMAC and irace in many cases. In particular, Anastacio and Hoos (2020) account for
the problem that many of the completely randomly sampled conﬁgurations by SMAC often
exhibit rather bad performance and thus, their evaluation yields only limited information.
To this end, the authors suggest to sample conﬁgurations according to a truncated normal
distribution centered around the default conﬁguration.
444
A Survey of Methods for Automated Algorithm Configuration
In (Lindauer & Hutter, 2018b) the authors suggest two diﬀerent strategies to warmstart
model-based AC approaches and apply their suggestions to SMAC, leading to signiﬁcant
speedups from days to hours of conﬁguration time. The idea underlying warmstarting is to
use the evaluations of conﬁgurations from previous runs, i.e., on diﬀerent problem instance
sets, to speed up the conﬁguration process in new runs of the conﬁgurator on a new set of
instances.
Distributed SMAC (Hutter et al., 2012) (D-SMAC) is an extension of SMAC leveraging
parallelization to speed up the conﬁguration process. The main idea behind D-SMAC is
to parallelize target algorithm runs onto available workers as much as possible. For this
purpose, it maintains a queue of target algorithm conﬁguration evaluations to be performed, 

",The SMAC (Sequential Model-based optimization for Algorithm Configuration) approach generalizes time-bounded SPO (TB-SPO) to perform configuration over multiple problem instances. It adapts the intensification strategy of TB-SPO to iteratively evaluate configurations on randomly sampled combinations of seeds and problem instances.,17.093183040618896,"The idea behind the AAC (automatic algorithm configuration) approach called ""SMAC"" (Sequential Model-based Algorithm Configuration) is to perform algorithm configuration by generalizing techniques from model-based optimization. SMAC adapts the intensification strategy from TB-SPO (time-bounded SPO) to iteratively evaluate configurations across multiple problem instances while ensuring that the comparisons are based on performance estimates derived from the same random subset of those instances. It incorporates a surrogate model that learns from both the configuration space and the problem instance features, allowing it to predict the performance of configurations effectively. SMAC is designed to handle a mixture of categorical and numerical parameters, and it operates as an anytime algorithm that continuously improves performance over time by balancing exploration of new configurations with exploitation of the current best configuration."
llama3.1:latest,"What is the idea behind the AAC approach called ""GGA""?
","Document 1: 
 to be evaluated based on k diﬀerently parameterized instantiations of the UCB criterion.
GGA++ Ans´ otegui et al. (2015) adapt the model-free AC approach GGA to include a
surrogate model. More precisely, the authors use a surrogate model to evaluate the quality
of new conﬁgurations. They integrate this within a crossover operator and call it genetic
engineering. Recall that GGA contains both a competitive and non-competitive popula-
tion in which winning conﬁgurations from the races between members of the competitive
population are recombined with individuals from the non-competitive population. To this
end, the crossover operator generates individuals according to the parameter tree crossover
of the original GGA method and evaluates them using the surrogate. Note that rather
than predicting the solution quality or runtime directly, the surrogate predicts the rank the
individual would have in a tournament. The individuals with the best ranks are accepted
into the population of the next generation in the same way as in GGA.
While the GGA++ surrogate is based on a random forest model, it diﬀers in a key
way. The premise of a random forest is to equally approximate the underlying function over
the complete input space. In the case of AC, this is undesirable as only the areas of the
input space that correspond to high-quality conﬁgurations are of interest. Thus, the authors
present specialized splitting criteria that focuses on only the best conﬁgurations to increase 

Document 2: 
 performance prediction [41], [42], [45]; and algorithm
enhancement [44], [47].
C. Generative Adversarial Networks
The general idea of GAST is similar to generative adversar-
ial networks (GANs) [50]. GANs also maintain an adversarial
game in which a discriminator is trained to distinguish real
samples from fake samples synthesized by a generator, and
the generator is trained to deceive the discriminator by pro-
ducing ever more realistic samples. However, there are some
main differences between GAST and GANs. First, the over-
all goals of them are different. GANs focus on the generative
models that could capture the distribution of complicated real-
world data. For GAST, the main goal is to build powerful
parallel portfolios (analogous to the discriminative models in
GANs); while the instance generation module as well as the
generated instances are more like byproducts. Second, the
domains to which GAST and GANs are applicable are differ-
ent. Currently GANs (and the more general idea of adversarial
learning) are mostly successfully applied to vision-related
domains, such as image generation [51], [52]; image dehaz-
ing [53]; style transfer [54], [55]; image classiﬁcation [56]; and
clustering [57], [58]. In comparison, GAST is proposed for
problem-solving domains, such as planning and optimization.
Third, the main technical issues in the two areas are different. 

Document 3: 
 cess (see (Hutter et al. 2009) for a comprehensive review),
which is usually referred to as automatic algorithm con-
ﬁguration (AAC) (Hoos 2012). Many AAC methods such
as ParamILS (Hutter et al. 2009), GGA/GGA+(Ans´otegui,
Sellmann, and Tierney 2009; Ans ´otegui et al. 2015), irace
(L´opez-Ib´a˜nez et al. 2016) and SMAC (Hutter, Hoos, and
Leyton-Brown 2011) have been proposed in the last few
years. They have been used for boosting the algorithm’s per-
formance in a wide range of domains such as the boolean
satisﬁability problem (SAT) (Hutter et al. 2009), the travel-
ing salesman problem (TSP) (L´opez-Ib´a˜nez et al. 2016; Liu,
∗Corresponding author
Copyright c⃝ 2020, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.
Tang, and Yao 2019), the answer set programming (ASP)
(Hutter et al. 2014) and machine learning (Feurer et al. 2015;
Kotthoff et al. 2017).
Despite the notable success achieved in application, the 

Document 4: 
 instead of the fully predetermined lifetimes in the original
GA VaPS and nAMGA VaPS.
Another variation of the GA VaPS lifetime scheme was
described by Bäck et al .[ 18]. The adaptive population GA
(APGA) uses the same lifetime allocation but differs from
GA VaPS in the reproduction cycle and in that, when in-
crementing the ages of individuals in each cycle, the best
individual of that cycle remains unchanged. This adaptive
population strategy is part of an ensemble and is described
in more detail in Section V. This method was also applied to
cooperative coevolution by Iorio and Li [ 109]. An analysis
of APGA by Lobo and Lima [ 135] shows theoretical and
experimental results suggesting an upper bound and a con-
verging population to a constant size that is determined by
the minimum and maximum lifetime parameters. The authors
conclude that the population is not adapted by the APGA
but the size parameter is in fact replaced by the two lifetime
parameters.
Cook and Tauritz [36] suggested two strategies for removing
the population size parameter. FiScIS-EA removes individuals
according to a survival probability, derived by linear scaling
of the individual’s ﬁtness in the range between the minimum
and maximum ﬁtness values present in the population. GC-EA
simply evades choosing a population size by maintaining a
population as large as is allowed by memory limitations. This
requires a well-chosen parent selection mechanism that scales
well, while a survival selection operator is still needed in 

Document 5: 
 obtain promising initial results, the combined evolution of solutions and their genetic opera-
tors is comparatively challenging, and it remains an open question whether autoconstructive
evolution is indeed superior to non-autoconstructive evolution.
Multi-armed bandits DAC can be cast as a multi-armed bandit problem, where each
conﬁguration represents an arm with an associated reward distribution. The agent is then
tasked to maximize the cumulative reward, i.e., “pull the arm“ that maximizes the reward.
Put diﬀerently, the agent aims to select a conﬁguration that works well for the current time
step. This setting of the bandit problem is particularly challenging because the reward
distributions associated with the respective arms change over time. In Fialho et al. (2010),
various multi-armed bandit approaches are compared with an approach that only considers
rewards obtained within a certain time frame (i.e., a sliding window) to allow for smoother
transitions between conﬁgurations. Note that in this work, the authors assume rewards to
be retrievable during an algorithm run. While this assumption holds for many optimization
approaches, it does not necessarily hold for all of them (e.g., the pre-processing/root node
phase of solving mixed-integer programs), and also often does not hold for simulations.
463
Schede, Brandt, Tornede, Wever, Bengs, H¨ullermeier & Tierney
11. Research Directions
Many fruitful avenues of research remain in the area of AC. We formulate research directions 

Document 6: 
 [23] showed that clustering the training data into sets, and then tun-
ing these sets individually could lead to further improvements. We
refer to this approach as SOP-clustered. We compare these two con-
ﬁgurators with general-purpose instance-oblivious conﬁguration of
GGA [2] and instance-speciﬁc parameter tuning of ISAC.
Solver: GS % Optimality Gap Closed
Train Test
Uniform 25.9 (4.2) 40 (4.1)
SOP - combined 39.0 (3.3) 43.4 (3.6)
SOP - clustered 47.7 (2.4) 50.3 (3.7)
GGA 40.0 (3.6) 46.1 (3.8)
ISAC 44.4 (3.3) 51.3 (3.8)
Table 1. Comparison of ISAC versus the default and instance-oblivious
parameters provided by SOP and GGA, and the instance-speciﬁc parameters
provided by SOP. We present the percent of optimality gap closed (stdev).
In Table 1, we compare the resulting ﬁve GS solvers, presenting
the percentage of optimality gap closed by each solver. Comparing
the average percent of optimality gap closed, we ﬁnd that ISAC is as
capable of improving over the default approach as SOP, which was
developed particularly for the GS solver. That is, ISAC can effec-
tively liberate us from having to select the number of clusters while,
at the same time, enjoying wide applicability to other solvers. More- 

","A very specific question!

After some research, I found that GGA stands for Generalized Gradient Approximation. It's an approximation method used in density functional theory (DFT) to calculate the exchange-correlation energy of a system.

In DFT, the total energy of a system is divided into three parts: the kinetic energy, the electron-electron interaction energy, and the exchange-correlation energy. The GGA approach is a refinement of earlier local density approximation (LDA) methods that try to capture the effects of gradient terms in the exchange-correlation functional.

GGA approximations are used in various fields, including materials science, chemistry, and physics, to study the electronic structure and properties of systems such as solids, liquids, and molecules. They provide a more accurate description of the system compared to LDA methods, especially for systems with strong gradients or anisotropies.

Is this the GGA you were thinking of?",33.00376534461975,"The GGA (Genetic Algorithm with Genetic Engineering) approach, as described in the context, integrates a surrogate model to evaluate the quality of new configurations within its operation. It combines a competitive population, which competes in races, with a non-competitive population, allowing the winning configurations from the competitive races to be recombined with individuals from the non-competitive group. The crossover operator generates new individuals based on parameter tree crossover and uses the surrogate model to assess their ranks in a tournament-like setting. The individuals with the best ranks are then selected to form the next generation. Unlike traditional random forest methods, GGA focuses specifically on high-quality configurations, utilizing specialized splitting criteria that emphasize these areas of the input space."
llama3.1:latest,"What is the idea behind the AAC approach called ""ISAC""?
","Document 1: 
 ISAC – Instance-Speciﬁc Algorithm Conﬁguration1
Serdar Kadioglu and Yuri Malitsky and Meinolf Sellmann and Kevin Tierney2
Abstract. We present a new method for instance-speciﬁc algorithm
conﬁguration (ISAC). It is based on the integration of the algorithm
conﬁguration system GGA and the recently proposed stochastic off-
line programming paradigm. ISAC is provided a solver with cate-
gorical, ordinal, and/or continuous parameters, a training benchmark
set of input instances for that solver, and an algorithm that com-
putes a feature vector that characterizes any given instance. ISAC
then provides high quality parameter settings for any new input in-
stance. Experiments on a variety of different constrained optimiza-
tion and constraint satisfaction solvers show that automatic algorithm
conﬁguration vastly outperforms manual tuning. Moreover, we show
that instance-speciﬁc tuning frequently leads to signiﬁcant speed-ups
over instance-oblivious conﬁgurations.
1 Introduction
When developing a new heuristic or complete algorithm for a con-
straint satisfaction or a constrained optimization problem, we fre-
quently face the problem of choice. There may be multiple branch-
ing heuristics that we can employ, different types of inference mech-
anisms, various restart strategies, or a multitude of neighborhoods to
choose from. Furthermore, the way in which the choices we make
affect one another is not readily known. The task of making these 

Document 2: 
 method is paired with D-MAB selection [38] described
above. A sliding window is also used by Fialho et al.[ 70].
They suggest increasing the reward with the time elapsed
since the last application of this operator and decreasing
the reward with the number of times the operator has been
applied within the window. The aim of this method is to adapt
quickly to (even subtle) changes of the dynamic environment.
Li et al.[ 129] suggested a sliding window that stores the rate
of improvement in the ﬁtness of the offspring as compared
to the parent. The sum of all these rewards in the window is
used by a ranking mechanism to assign credit to the operators.
A different credit assignment mechanism is Compass, sug-
gested by Maturana and Saubion [ 146]. Based on the concepts
found in [ 147] (see Section VI), an operator’s impact is
evaluated using measures of both ﬁtness and diversity in order
to calculate the exploration-exploitation balance achieved by
the operator. The assigned credit reﬂects how closely the
achieved balance is to an exploration-exploitation balance that
is required by a user-deﬁned schedule. Other tested credit as-
signment methods are based on domination between operators
and Pareto fronts. Compass was paired with probability match-
ing selection, but was also combined with D-MAB in [ 143].
Except for the widely used multiarmed bandit approach dis-
cussed so far, AOS has also been treated as a full reinforcement 

Document 3: 
 in Ye et al. (2021) that performance gains can already be achieved when the algorithm
conﬁguration is adapted only once. Furthermore, the hyper-reactive approach of Ans´ otegui
et al. (2017) won several categories at the MaxSAT Evaluation 2016 (Argelich et al., 2016).
Thus, DAC oﬀers signiﬁcant potential for improving algorithms, however, it does require
algorithm designers to more deeply integrate their techniques with AC methods than was
performed in the past. In the following, we discuss the most frequently used approach to
DAC, reinforcement learning (RL). While it is the most popular choice, there also exist
other approaches such as policy portfolios, autoconstructive evolution, and multi-armed
bandits.
Reinforcement learning A challenge in DAC is to evaluate the quality of individual
parameter adjustments since feedback is obtained only at the end of processing a problem
instance. Due to this, it is natural to consider DAC within the realm of reinforcement
learning (we refer to this as DAC-RL). To this end, the DAC problem is modeled in terms of
a Markov decision process (MDP) (Puterman, 1994) based on which a policy π: I×Q→ Θ
is learned from data (Biedenkapp et al., 2020). As a reward signal, typically, the eventually
obtained performance value is propagated back to the agent. Using RL allows a wide variety
of researched mechanisms to be directly applied to DAC.
The roots of DAC extend to a variety of methods that use RL to control parameters of 

Document 4: 
 the best solver in the solver class, termed the auto- 
matic algorithm configuration (AAC) in the litera- 
ture [16 ]. More specifically, given a solver class, the 
solver that achieves the best overall performance on 
the training instances is first obtained by some search 
method. Then, the solver is directly applied to an un- 
seen problem instance without a further configura- 
tion process. 
A typical AAC method consists of two main com- 
ponents: sampling in the solver class and evaluat- 
ing a candidate solver. Sampling in the solver class 
is mostly implemented based on search-based meth- 
ods and model-based methods. Search-based meth- 
ods such as hi l l climbing [50 ], local search [8 ] and 
E A s [51 ] have been used to sample solvers, since 
they make minimal assumptions about the solver 
representation and do not require gradients. Addi- 
tionally, some researchers have also explored using 
experimental design [52 ,53 ], such as the full fac- 
torial experimental design, to generate the starting 
points for the search. In comparison, model-based 
methods are more similar to the performance predic- 
tion model approach. They seek to capture the de- 
pendencies between solvers and their performance, 
by training surrogate models on the performance 
data collected during the configuration process. On 

Document 5: 
 ACPP is closely related to the area of automatic algo-
rithm configuration, in which the task is to automatically
identify a high-quality configuration from a configuration
space. In the last few years, several high-performance AC
methods (which could handle considerable large configura-
tion spaces) such as ParamILS (Hutter et al. 2009), GGA
(Ans´otegui, Sellmann, and Tierney 2009), irace (L ´opez-
Ib´a˜nez et al. 2016) and SMAC (Hutter, Hoos, and Leyton-
Brown 2011) have been proposed. As a consequence, re-
cently there has been research interest in utilizing these
AC procedures to automatically identify useful portfolios
of configurations from large configuration spaces. Such at-
tempts were first done in constructing sequential portfolios.
The representative methods for solving this problem are Hy-
dra (Xu, Hoos, and Leyton-Brown 2010) and ISAC (Ka-
dioglu et al. 2010). The basic ideas of these methods were
then adapted to be used in constructing parallel portfolios
(i.e., ACPP), thus resulting in PARHYDRA and CLUSTER-
ING (Lindauer et al. 2017) (see the first section). The main
differences between the automatic construction of sequen-
tial portfolios and of parallel portfolios lie in two aspects: 

Document 6: 
 that ihvr ∈(0, 1], and a larger value of ihvr is better. IHVR can distinguish well between
MOEAs with a different performance, and can also save a lot of calculations. In this work,
IHVR is used as the performance metric Metric .
4.3. Automatic Construction Approach
Algorithm 1 presents the automatic construction approach for MOEAs/PAP . Starting
from an empty set (line 2), the approach constructs the PAP (denoted as P) iteratively.
Speciﬁcally, each iteration of the approach (lines 3–15) consists of two subsequent phases.
In the ﬁrst phase, an existing automatic algorithm conﬁguration tool, namely SMAC 3 [44],
is used to search in Θ to ﬁnd the algorithm that can improve the performance of the current
PAP to the largest extent (line 5), and then this algorithm is inserted into P (line 6). This
phase is similar to the commonly-used greedy approach in the automatic construction of
PAPs [27,31]. Additionally, we introduce a new phase, namely simpliﬁcation, as the second
phase in Algorithm 1. In this phase (lines 7–14), P would be simpliﬁed by removing the
member algorithms that do not contribute at all to its performance (meaning removing
these algorithms has no effect on the performance of P on the training set). Considering
the size of P is bounded (line 3), removing the redundant algorithms from P is meaningful
because this will leave space for new member algorithms that can improve the performance 

","The ISAC (Instance-Specific Algorithm Configuration) approach learns a policy to select algorithm parameters based on a feature vector that characterizes any given instance. It then provides high-quality parameter settings for each instance, improving overall performance.",14.172398567199709,"The AAC approach called ""ISAC"" (Instance-Specific Algorithm Configuration) is focused on automatically identifying high-quality parameter settings for specific problem instances. It combines an algorithm configuration system with a stochastic offline programming paradigm to adapt the configuration based on the features of each instance. ISAC requires a training benchmark set of input instances and an algorithm that computes a feature vector, allowing it to provide tailored configurations that improve solver performance on new input instances. The method has been shown to significantly outperform manual tuning and lead to speed-ups compared to instance-oblivious configurations."
llama3.1:latest,"What is the difference between metaheuristics and heuristics?
","Document 1: 
 usually provide only sub-optimal solutions because they do
not attempt to escape from local optimum. These drawbacks
have led to the introduction of metaheuristics.
Metaheuristics are high-level methodologies or general al-
gorithmic templates, which generally do not adapt deeply
to speciﬁc problem(s) [4]. Hence, they usually can solve a
wide range of problems [2]. In fact, the preﬁx “meta”, which
means “upper level methodology”, indicates that metaheuristic
algorithms can be viewed as “higher level” heuristics. Hy-
brid approaches based on existing metaheuristic(s) are also
considered metaheuristics [5]. In last decades, metaheuristics
have received widespread attention from researchers and are
widely recognized as efﬁcient approaches for hard optimiza-
tion problems. A number of metaheuristic algorithms have
been developed and extensively applied, including Simulated
Annealing (SA) [6], Tabu Search (TS) [7], Evolutionary Algo-
rithms (EAs) [8], Ant Colony Optimization algorithm (ACO)
[9], Particle Swarm Optimization (PSO) [10], and so forth.
Most of metaheuristics are nature-inspired (inspired from some
principles in physics, biology and etc.), contain stochastic
components, and often have several free parameters that can
be set by users according to problem(s) at hand [4].
The setting of parameters (or parameter setting) has strong 

Document 2: 
 the same standard. (In contrast, SAT solver competitions have compared solvers with a complex scoring function that includes the performance of all competitors [25].) As formulated here, the differences between two solvers may be simply in their choice of even a single technique, heuristic, or policy that sustains performance diver-sity. Thus an algorithm portfolio can be thought of as a mixture of experts [26], in-cluding variable-ordering and value-ordering heuristics, restart policies, and nogood learning methods. In particular, even if only one heuristic is available, the portfolio could consist of the heuristic and its opposite, or the heuristic and random selection. 

Document 3: 
 PSO. 
For the methodological part of the comparisons, there are far more 
studies. Statistical tests, for instance, lay at the core of prior contribu- 
tions on this matter. However, such contributions are frequently writ- 
ten from a statistical point of view –l i k e the one by Dem š ar [39] –
making it diﬃcult for researchers in this ﬁeld to embrace their method- 
ological recommendations. More recently, some tutorials have tried to 
bring together the ﬁelds of meta-heuristics and inferential statistics [4] . 
Some examples can be found in [40] , in which a statistical treatment is 
suggested for distinguishing between measurements of performance in 
adaptive evolutionary algorithms. Another good example is [41] , which 
shows that in a popular real-parameter benchmark (CEC’2005), con- 
ditions needed for running parametric hypothesis tests did not hold, 
and non-parametric tests were thus recommended. More recently, in 
[42] , some recommendations for the comparison of evolutionary algo- 
rithms are provided, which can be even extrapolated to machine learn- 
ing benchmarks. 
Another important issue from a methodological point of view is the 
assessment of the performance of bio-inspired algorithms from the per- 
spective of the experimental design. Some studies [5] provide general 
recommendations to design experiments for the comparison of algo- 
rithms in a similar way to what we do in this contribution. However, 
these recommendations are far more general as it targets a broader scope 

Document 4: 
 (Eds.), Handbook of Metaheuristics (pp. 321–353). Kluwer Academic Publishers, Norwell, MA, USA.
Maron, O. & Moore, A. (1994). Hoeffding races: Accelerating model selection search for classiﬁcation
and function approximation. In Cowan, J. D., Tesauro, G., & Alspector, J. (Eds.), Advances in Neural
Information Processing Systems 7 (NIPS-94), volume 6, (pp. 59–66). Morgan Kaufmann Publishers, San
Francisco, CA, USA.
Mengshoel, O. J. (2008). Understanding the role of noise in stochastic local search: Analysis and experi-
ments. Artiﬁcial Intelligence, 172(8-9), 955–990.
Minton, S. (1993). An analytic learning system for specializing heuristics. In Bajcsy, R. (Ed.),Proceedings of
the Thirteenth International Joint Conference on Artiﬁcial Intelligence (IJCAI’93), (pp. 922–929). Morgan
Kaufmann Publishers, San Francisco, CA, USA.
Minton, S. (1996). Automatically conﬁguring constraint satisfaction programs: A case study. Constraints,
1(1), 1–40.
Minton, S., Johnston, M. D., Philips, A. B., & Laird, P. (1992). Minimizing conﬂicts: A heuristic repair 

Document 5: 
 J. Durillo , K. Hammond , E. Hart , C.G. Johnson , et al. , A research agenda for meta- 
heuristic standardization, in: Proceedings of the XI metaheuristics international 
conference, 2015, pp. 1–3 . 
[106] J. Swan , S. Adraensen , A.E. Brownlee , C.G. Johnson , A. Kheiri , F. Krawiec , 
J. Merelo , L.L. Minku , E. Özcan , G.L. Pappa , et al. , Towards metaheuristics ”i n 
the large ”, arXiv preprint arXiv:2011.09821 (2020) . 
[107] M.A. Lones , Mitigating metaphors: a comprehensible guide to recent nature-in- 
spired algorithms, SN Computer Science 1 (1) (2020) 49 . 
[108] M. Jain, V. Singh, A. Rani, A novel nature-inspired algorithm for optimiza- 
tion: squirrel search algorithm, Swarm Evol Comput 44 (2019) 148–175, 
doi: 10.1016/j.swevo.2018.02.013 . 
[109] A.W. Mohamed, A.A. Hadi, A.K. Mohamed, Gaining-sharing knowledge 
based algorithm for solving optimization problems: a novel nature- 

Document 6: 
 iﬁed on 24 continuous benchmark functions from the COCO test set and 29
functions from the CEC-2017 test set. On the BBOB test set a hybrid of
PSO and DE with adaptation obtained 11 signiﬁcantly better and 2 signif-
icantly worse results on 5 and 20 dimensional functions than the basic DE.
Further inclusion of the model based optimizers led to 15 signiﬁcantly better
and 2 signiﬁcantly worse results compared to the PSO-DE hybrid. On the
CEC-2017 test set, M-GAPSO was signiﬁcantly better than both Red Fox
Optimization and Dual Opposition-Based Learning for Diﬀerential Evolution
(DOBL) on 7 functions in 30 dimensions and 12 functions in 50 dimensions.
Keywords: hyper-heuristics, meta-heuristics, global optimization
∗Corresponding author.
Email addresses: M.Okulewicz@mini.pw.edu.pl (Micha/suppress l Okulewicz),
M.Zaborski@mini.pw.edu.pl (Mateusz Zaborski), jacek.mandziuk@pw.edu.pl (Jacek
Ma´ ndziuk )
Preprint submitted to Applied Soft Computing 10.1016/j.asoc.2022.109722 December 3, 2022
1. Introduction
The quest for a general purpose optimization algorithms, which started
with the works on evolutionary computations [1, 2], resulted in creation of
a few excellent optimization methods like Diﬀerential Evolution (DE) [3] 

","Metaheuristics are higher-level methodologies or general algorithmic templates that can solve a wide range of problems, whereas traditional heuristics provide only sub-optimal solutions because they do not attempt to escape from local optimum.",14.074217081069946,"Metaheuristics are high-level methodologies or general algorithmic templates designed to solve a wide range of optimization problems. They are often nature-inspired and contain stochastic components, allowing them to escape local optima and attempt to find better solutions over a broader search space. In contrast, heuristics are typically problem-specific strategies or rules of thumb that provide sub-optimal solutions and may not have the capability to generalize to various problems. The term ""meta"" indicates that metaheuristics can be viewed as higher-level strategies that can encompass and adapt various heuristics but do not deeply adapt to specific problems, allowing for a more flexible application across different optimization scenarios."
llama3.1:latest,"What factors and challenges influenced the development of the Automatic Algorithm Configuration approaches?
","Document 1: 
 ods for algorithm development. The methods used in this context 
include experimental design techniques [2,29] , racing approaches 
[20] , and algorithmic methods for parameter conﬁguration, such 
as heuristic search techniques [3,10,41,73,81] , and statistical mod- 
eling approaches [11,43] . These methods have led to an increasing 
automatization of the algorithm design and parameter setting pro- 
cess. 
Automatic algorithm conﬁguration can be described, from a ma- 
chine learning perspective, as the problem of ﬁnding good param- 
eter settings for solving unseen problem instances by learning on 
a set of training problem instances [19] . Thus, there are two clearly 
delimited phases. In a primary tuning phase, an algorithm con- 
ﬁguration is chosen, given a set of training instances representa- 
tive of a particular problem. In a secondary production (or test- 
ing) phase, the chosen algorithm conﬁguration is used to solve un- 
seen instances of the same problem. The goal in automatic algo- 
rithm conﬁguration is to ﬁnd, during the tuning phase, an algo- 
rithm conﬁguration that minimizes some cost measure over the 
set of instances that will be seen during the production phase. 
In other words, the ﬁnal goal is that the conﬁguration of the al- 
gorithm found during the tuning phase generalizes to similar but 
unseen instances. The tuning phase may also use automatic conﬁg- 
uration methods repeatedly while engineering an algorithm [71] . 

Document 2: 
 diﬀerent problems (SAT, MIP, ASP, etc.) of varying complexity (number of variables and
problem instances) for tasks of runtime or quality conﬁguration. For DAC, the DACBench
has been proposed (Eimer et al., 2021), although this does not support DAC settings en-
visioned, e.g., by hyper-reactive search. As an alternative to such libraries, AC methods
can also be benchmarked by using surrogate models that are trained on test instances in
advance, resulting in cheaper evaluations when testing (Eggensperger et al., 2018). The ex-
isting benchmarks fail to cover other conﬁgurations settings like the realtime conﬁguration
setting or the conﬁguration of multi-objective target algorithms.
11.4 Novel AC Methodologies
AC methods have become extremely sophisticated and cover a wide range of methodologies
including evolutionary algorithms, statistical tests, and learned surrogate models. There
nonetheless remain opportunities to improve current methods and create better AC algo-
rithms. We note that our goal in this section is not necessarily to specify the methodologies
of the future, but rather to identify the key challenges that remain in the hopes that engaged
466
A Survey of Methods for Automated Algorithm Configuration
readers will ﬁll these gaps with their ideas. To this end, we discuss several challenges faced
by AC approaches: comparing/ranking conﬁgurations, generating new conﬁgurations, and
selecting instances.
Comparing/ranking conﬁgurations This challenge can be summarized as follows: 

Document 3: 
 available for detecting (approximate) independencies. Although there is some evi-
dence that GGA can solve some moderately difﬁcult conﬁguration problems more
effectively than FocusedILS without capping [2], it appears to be unable to reach
the performance of FocusedILS version 2.3 with aggressive capping on the most
challenging conﬁgurations problems [40]. Unfortunately, GGA also offers less ﬂex-
ibility than FocusedILS in terms of the performance metric to be optimised. More
algorithm conﬁguration procedures based on evolutionary algorithms are covered in
Chapter 2 of this book.
Finally, work originating from the Ph.D. project of Hutter [32] has recently over-
come two major limitations of the sequential model-based optimisation methods
discussed in Section 3.4 of this chapter by introducing a procedure that can han-
dle categorical parameters while explicitly exploiting the fact that performance is
evaluated on a set of problem instances. There is some evidence that this procedure,
dubbedSequential Model-based Algorithm Conﬁguration (SMAC) , can, at least on
some challenging conﬁguration benchmarks, reach and sometimes exceed the per-
formance of FocusedILS [43], and we are convinced that, at least in cases where
the parameter response of a given target algorithm is reasonably regular and per-
formance evaluations are very costly, such advanced SMBO methods hold great
promise.
3.6 Conclusions and Future Work
Automated algorithm conﬁguration and parameter tuning methods have been de- 

Document 4: 
 Decision and Operation Technologies Group,
Bielefeld University, Bielefeld, Germany
Abstract
Algorithm conﬁguration (AC) is concerned with the automated search of the most
suitable parameter conﬁguration of a parametrized algorithm. There is currently a wide
variety of AC problem variants and methods proposed in the literature. Existing reviews
do not take into account all derivatives of the AC problem, nor do they oﬀer a complete
classiﬁcation scheme. To this end, we introduce taxonomies to describe the AC problem and
features of conﬁguration methods, respectively. We review existing AC literature within
the lens of our taxonomies, outline relevant design choices of conﬁguration approaches,
contrast methods and problem variants against each other, and describe the state of AC in
industry. Finally, our review provides researchers and practitioners with a look at future
research directions in the ﬁeld of AC.
1. Introduction
Diﬃcult computational problems must be regularly solved in many areas of industry and
academia, such as constraint satisfaction problems, Boolean satisﬁability problems (SAT),
vehicle routing problems, ﬁnding a proper machine learning model for a given dataset,
or computing highly complex simulations. Algorithms that were developed to solve such
problems usually have parameters that strongly inﬂuence the behavior of the respective
algorithm and also, for example, the runtime that is required to solve problem instances
©2022 AI Access Foundation. All rights reserved.
Schede, Brandt, Tornede, Wever, Bengs, H¨ullermeier & Tierney 

Document 5: 
 better performance than the top-ranked solver from the competition.
9. Related Work
Many researchers before us have been dissatisﬁed with manual algorithm conﬁguration, and various
ﬁelds have developed their own approaches for automatic parameter tuning. We start this section
with the most closely-related work—approaches that employ direct search to ﬁnd good parameter
conﬁgurations—and then describe other methods. Finally, we discuss work on related problems,
such as ﬁnding the best parameter conﬁguration or algorithm on a per-instance basis, and approaches
that adapt their parameters during an algorithm’s execution (see also Hoos, 2008, for further related
work on automated algorithm design).
8. BasicILS was used, because FocusedILS had not yet been developed when that study was conducted.
297
HUTTER , HOOS , LEYTON -BROWN & ST ¨UTZLE
9.1 Direct Search Methods for Algorithm Conﬁguration
Approaches for automated algorithm conﬁguration go back to the early 1990s, when a number of
systems were developed for adaptive problem solving. One of these systems is Composer (Gratch
& Dejong, 1992), which performs a hill-climbing search in conﬁguration space, taking moves if
enough evidence has been gathered to render a neighbouring conﬁguration statistically signiﬁcantly
better than the current conﬁguration. Composer was successfully applied to improving the ﬁve
parameters of an algorithm for scheduling communication between a collection of ground-based
antennas and spacecrafts (Gratch & Chien, 1996). 

Document 6: 
 ration.
1 Introduction
We consider the problem of automatic solver conﬁguration. Practically all solvers have
parameters that are partly ﬁxed by the programmer and partly set by the user. In recent
years, systems have been devised which automate the task of tuning parameters for a
given set of training instances that are assu med to represent typical instances for the
target algorithm.
There are several motivations for such an automation, the ﬁrst being that it is of
course time consuming to tune parameters and it may lead to better results when leaving
the conﬁguration of solvers to a computer rather than doing it by hand.
Moreover, it is conceivable that the existence of an effective tuning environment
will cause algorithm developers to paramete rize more aspects of their algorithms and
thus leave more freedom for algorithmic solutions that are automatically tailored to the
problems of individual users. In particular, many of the SAT solvers that are available
today have parameters which cannot be set through the command line. These parameters
have been ﬁxed to values that the developers have found beneﬁcial without knowledge
about the particular instances a user may want to use the solver for. Automatic parameter
tuning allows solvers to adapt to the ﬁnal environment in which they need to perform.
After being shipped, rather than relying on default parameters, an algorithm can be
⋆ This work was partly supported by the projects TIN2007-68005-C04-04 and TIN2006-15662-
C02-02 funded by the MEC, and by the the National Science Foundation through the Ca-
reer: Cornﬂower Project (award number 0644113). 

","Automatic Algorithm Configuration (AAC) is a field of research that focuses on developing methods to automatically optimize algorithm parameters for specific problem instances. The development of AAC approaches has been influenced by various factors and challenges, including:

1. **Complexity of algorithm hyperparameter tuning**: Many algorithms have numerous hyperparameters that need to be tuned, making it difficult to find the optimal combination of values.
2. **High dimensionality**: The number of possible combinations of algorithm parameters grows exponentially with the number of hyperparameters, leading to a large search space.
3. **Noisy and/or expensive optimization targets**: In many real-world applications, evaluating an algorithm's performance on a particular problem instance can be time-consuming or even infeasible, making it challenging to find optimal parameter settings.
4. **Lack of prior knowledge**: Unlike humans, algorithms do not have prior experience or domain-specific knowledge that can guide the tuning process.
5. **Scalability and efficiency**: As problem sizes grow, so does the computational cost of searching for optimal algorithm parameters.
6. **Interplay between hyperparameters**: Many hyperparameters interact with each other in complex ways, making it difficult to optimize one parameter without affecting others.

To address these challenges, researchers have developed various AAC approaches, including:

1. **Meta-learning and transfer learning**: Techniques that enable the reuse of knowledge learned from previous problems or algorithm instances.
2. **Bayesian optimization**: Methods that efficiently search for optimal hyperparameters using probabilistic models and iterative refinement.
3. **Evolutionary algorithms**: Optimization techniques inspired by natural selection and genetics, which can be applied to find near-optimal solutions in complex spaces.
4. **Gradient-based optimization**: Techniques that utilize gradients of the performance metric with respect to algorithm parameters to guide the search process.
5. **Ensemble methods**: Combining multiple models or configurations to improve overall performance and reduce overfitting.

The challenges mentioned above have also led to the development of new research areas, such as:

1. **Algorithm selection**: Choosing the most suitable algorithm for a specific problem instance based on characteristics like data size, type, and complexity.
2. **Hyperparameter robustness analysis**: Evaluating how sensitive an algorithm's performance is to changes in its hyperparameters.
3. **Multifidelity optimization**: Optimizing algorithms using different levels of computational resources or precision.

The development of AAC approaches has been influenced by the convergence of multiple factors:

1. **Advances in computing power and data storage**: Allowing for larger-scale experiments and more complex models.
2. **Growing availability of high-quality datasets**: Providing a foundation for evaluating algorithm performance and tuning hyperparameters.
3. **Increasing recognition of the importance of optimization in machine learning**: As researchers and practitioners have come to realize that optimal algorithm parameters are crucial for achieving good performance.

These factors have driven the development of AAC approaches, which continue to evolve as new challenges arise and research continues to advance.",101.31804513931274,"The development of Automatic Algorithm Configuration (AC) approaches has been influenced by several factors and challenges:

1. **Diversity of Problems**: AC methods must cater to various computational problems (e.g., SAT, MIP, ASP) with differing complexities. This requires AC approaches to be versatile and capable of adapting to different problem domains.

2. **Complexity of Parameters**: Algorithms often have numerous parameters that significantly affect their performance. The management and tuning of these parameters present challenges, particularly in ensuring the configurations are suitable for unseen instances.

3. **Benchmarking Limitations**: Existing benchmarking frameworks, such as DACBench, may not adequately support all configuration settings, indicating a need for more comprehensive evaluation tools to benchmark AC methods.

4. **Comparing and Ranking Configurations**: A significant challenge in AC is comparing and ranking different configurations to determine which performs best under various conditions. This task requires effective metrics and methodologies for assessment.

5. **Generating New Configurations**: The ability to generate new and potentially better configurations from existing ones remains a challenge. Advanced methodologies are needed to explore the configuration space efficiently.

6. **Performance Evaluation Costs**: Many performance evaluations are resource-intensive, necessitating methods that can efficiently predict the performance of configurations without extensive testing.

7. **Categorical Parameters Handling**: Many AC procedures initially struggled with categorical parameters, but recent advancements, such as Sequential Model-based Algorithm Configuration (SMAC), have begun to address this limitation.

8. **Adapting to the User's Environment**: The need for solvers to adapt to the environments in which they operate after deployment is critical. Automatic configuration allows developers to create more parameterized algorithms that can tailor themselves to a user's specific problem context.

These factors illustrate the complexities and evolving needs in the field of algorithm configuration, prompting ongoing research and innovation."
llama3.1:latest,"What are the main benefits of AAC?
","Document 1: 
 as expected, as N and K get larger, the estimation error gets
smaller, and ˆuSN (θ) will converge to u(θ) with probability
1 with N →∞ and K →∞ . Third, Corollary 1 shows that,
for the estimator ˆuSN (θ∗) which are widely used in current
AAC methods, the gain on error reduction decreases rapidly
asN and K get larger (which are also shown in Figure 2 in
the experiments), and the effects of increasingN and K also
depend on ¯σ2
WI and ¯σ2
AI, two quantities varying across dif-
ferent algorithm conﬁguration scenarios. Thus for enhanc-
ing current AAC methods, instead of ﬁxingN as a large
number (e.g., SMAC sets N to 2000 by default) and using
as many training instances as possible, it is more desirable
to use differentN and K according to the conﬁguration sce-
nario considered, in which case N and K may be adjusted
dynamically in the conﬁguration process as more data are
gathered to estimate¯σ2
WI and ¯σ2
AI.
Experiments
In this section, we present our experimental studies. First
we introduce our experiment setup. Then, we verify our the-
oretical results in two facets: 1) comparison of different per-
formance estimators; 2) the effects of different values ofm
(the number of considered conﬁgurations), N (the number
of runs of θ to estimate u(θ)) and K (the number of training 

Document 2: 
 independently in parallel to obtain multiple solutions. Then, the best solution will be
taken as the ﬁnal output of the PAP . Although a PAP would consume more computational
resources than a single algorithm, it has three important advantages. First, PAPs are
easy-to-implement because they do not necessarily require any resource allocation since
each member algorithm is simply assigned with the same amount of resource. Second,
the performance of a PAP on any problem is the best performance achieved among its
member algorithms on the problem. In other words, a PAP could achieve a much better
overall performance than any of its member algorithms. Third, considering the tremendous
growth of parallel computing architectures [22] (e.g., multi-core CPUs) over the last few
decades, leveraging parallelism has become very important in designing effective solvers
for hard optimization problems [23–27]. PAPs employ parallel solution strategies and thus
allow for the use of modern computing facilities in an extremely simple way.
It is conceivable that any PAP’s effectiveness relies heavily on the diversity and com-
plementarity among its member algorithms. In other words, the manual construction
of high-quality PAPs is generally a challenging task, requiring domain experts (with a
deep understanding of both algorithms and problems) to explore the vast design space
of PAPs, which cannot be carried out manually with ease [28–30]. As an alternative, Tang
and Liu [25,26] proposed a general framework, called automatic construction of PAPs, that 

Document 3: 
 phase of solving mixed-integer programs), and also often does not hold for simulations.
463
Schede, Brandt, Tornede, Wever, Bengs, H¨ullermeier & Tierney
11. Research Directions
Many fruitful avenues of research remain in the area of AC. We formulate research directions
with three themes in mind. First, we consider what is required for AC techniques to be
more widely adopted in industry. Second, we investigate algorithm conﬁguration settings
that have not yet been considered. Third, we consider what methodological advances could
move the ﬁeld forward.
11.1 Industry Adoption
Compared to AC, HPO has begun to be adopted in both industry and academia (Van der
Blom et al., 2021). Furthermore, HPO is the focus of a number of start-ups, such as
SigOpt (which was acquired by Intel (Intel Corporation, 2019)), MindsDB, pecan.ai, and
dotData, among many more. AC, however, has received comparatively little fanfare or
adoption. While some well-known AC tools have public releases, such as SMAC (Lindauer
et al., 2021), irace (L´ opez-Ib´ anez et al., 2016), and GGA (Ans´ otegui et al., 2009), we are
unaware of widespread use of these in industry. The company Optano GmbH released a 

Document 4: 
 a policy to adapt the conﬁguration dynamically. Note that even realtime AC commits to a
single conﬁguration when running a given instance, while DAC has the freedom to adjust
the conﬁguration according to target algorithm behavior during execution. Similar to oﬄine
AC, DAC can either focus on ﬁnding a policy for a set of problem instances or a policy that
is tailored towards a single problem instance (i.e., per-instance algorithm conﬁguration).
Two requirements must be met to implement DAC: (1) the algorithm in question needs
to support dynamic changes in its conﬁguration and (2) runtime information must be pro-
vided to describe the current state of the target algorithm.
DAC approaches consider two diﬀerent types of features: instance features I, which do
not change during target algorithm execution, and features encoding the internal state Q
of the algorithm. Examples of state features include the current iteration of a local search
algorithm, the current restart number of a SAT method, or the current solution quality for
optimization techniques.
461
Schede, Brandt, Tornede, Wever, Bengs, H¨ullermeier & Tierney
Figure 7: Illustration of dynamic AC as presented in (Biedenkapp et al., 2020)
Biedenkapp et al. (2020) provide the ﬁrst formal deﬁnition of the DAC setting, however,
there is a signiﬁcant amount of earlier work for learning dynamic conﬁguration policies
(Lagoudakis & Littman, 2000, 2001; Pettinger & Everson, 2002). Such earlier works use 

Document 5: 
 cess (see (Hutter et al. 2009) for a comprehensive review),
which is usually referred to as automatic algorithm con-
ﬁguration (AAC) (Hoos 2012). Many AAC methods such
as ParamILS (Hutter et al. 2009), GGA/GGA+(Ans´otegui,
Sellmann, and Tierney 2009; Ans ´otegui et al. 2015), irace
(L´opez-Ib´a˜nez et al. 2016) and SMAC (Hutter, Hoos, and
Leyton-Brown 2011) have been proposed in the last few
years. They have been used for boosting the algorithm’s per-
formance in a wide range of domains such as the boolean
satisﬁability problem (SAT) (Hutter et al. 2009), the travel-
ing salesman problem (TSP) (L´opez-Ib´a˜nez et al. 2016; Liu,
∗Corresponding author
Copyright c⃝ 2020, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.
Tang, and Yao 2019), the answer set programming (ASP)
(Hutter et al. 2014) and machine learning (Feurer et al. 2015;
Kotthoff et al. 2017).
Despite the notable success achieved in application, the 

Document 6: 
 Non-general AC SMBO approaches Several SMBO approaches exist to perform a
limited form of AC, i.e., on only a single instance. We include these methods due to their
historical importance to the ﬁeld of AC, as well as because they may inspire new general AC
4. Note that for simplicity we assume that g is deterministic here.
443
Schede, Brandt, Tornede, Wever, Bengs, H¨ullermeier & Tierney
approaches. Most SMBO based AC approaches are based on the idea of sequential kriging
meta-modelling (Huang et al., 2006) (SKO) and sequential parameter optimization (SPO)
(Bartz-Beielstein et al., 2005), both of which are based on eﬃcient global optimization (Jones
et al., 1998). While the latter is a classical approach to black box function optimization using
BO, both SPO and SKO constitute extensions to noisy black box functions; an assumption
that is much more realistic for AC. However, both of these approaches still have potential
drawbacks. Some of these are ﬁxed by SPO + (Hutter et al., 2009a), which improves the
intensiﬁcation scheme, and time-bounded SPO (TB-SPO) (Hutter et al., 2010b), which
generalizes SPO+ to work under (potentially tight) time constraints instead of considering
the number of function evaluations as a stopping criterion.
5.2 General Model-based AC Methods 

","The main benefits of Alternative and Augmentative Communication (AAC) include:

1. **Improved communication**: AAC enables individuals with speech or language disorders to express their needs, wants, and thoughts more effectively.
2. **Increased independence**: By using AAC systems, individuals can communicate on their own, reducing reliance on caregivers or family members for support.
3. **Enhanced social interactions**: AAC facilitates more effective social interactions, which can lead to greater participation in daily activities, friendships, and community involvement.
4. **Better access to education**: AAC can help students with disabilities participate more fully in educational activities, leading to improved academic outcomes.
5. **Reduced frustration and stress**: By providing an alternative means of communication, AAC can reduce feelings of frustration, anger, and anxiety that often accompany unmet communication needs.
6. **Improved self-esteem and confidence**: When individuals are able to communicate effectively using AAC, they may experience a boost in self-esteem and confidence, which can translate into other areas of life.
7. **Supports cognitive development**: AAC can provide opportunities for individuals with disabilities to engage in activities that promote cognitive growth, such as problem-solving and critical thinking.
8. **Facilitates inclusion and participation**: AAC can enable individuals with disabilities to participate more fully in community activities, sports, and other experiences that might have been previously inaccessible due to communication barriers.
9. **Enhances family relationships**: By facilitating more effective communication between individuals with disabilities and their families, AAC can lead to stronger, more supportive relationships.
10. **Long-term benefits for quality of life**: The use of AAC can contribute to improved overall quality of life by enabling individuals to participate in activities that bring them joy, fulfillment, and a sense of purpose.

These benefits highlight the importance of providing access to effective AAC systems for individuals with disabilities, ultimately promoting greater independence, social participation, and overall well-being.",63.85815644264221,"The main benefits of Automatic Algorithm Configuration (AAC) include the following:

1. **Performance Boosting**: AAC methods such as ParamILS, GGA, irace, and SMAC have been widely successful in enhancing the performance of algorithms across diverse domains, including SAT, TSP, ASP, and machine learning tasks. They achieve this by optimizing algorithm parameters dynamically based on performance metrics.

2. **Adaptability**: AAC techniques can adjust configurations based on the specific characteristics of different problem instances, allowing for tailored solutions that are more effective than static or pre-defined configurations.

3. **Efficient Resource Management**: AAC facilitates better resource allocation by dynamically adjusting configurations as more data becomes available, which can lead to reduced estimation errors and improved accuracy in algorithm performance.

4. **Research Advancement**: AAC fosters further research opportunities in the field, exploring new configuration settings and methodological advancements, thus contributing to the overall growth and sophistication of optimization techniques.

These advantages enable more effective problem-solving strategies, allowing the algorithms to perform optimally based on varying conditions and requirements."
llama3.1:latest,"Please provide an overview of the types of AAC methods.
","Document 1: 
 the best solver in the solver class, termed the auto- 
matic algorithm configuration (AAC) in the litera- 
ture [16 ]. More specifically, given a solver class, the 
solver that achieves the best overall performance on 
the training instances is first obtained by some search 
method. Then, the solver is directly applied to an un- 
seen problem instance without a further configura- 
tion process. 
A typical AAC method consists of two main com- 
ponents: sampling in the solver class and evaluat- 
ing a candidate solver. Sampling in the solver class 
is mostly implemented based on search-based meth- 
ods and model-based methods. Search-based meth- 
ods such as hi l l climbing [50 ], local search [8 ] and 
E A s [51 ] have been used to sample solvers, since 
they make minimal assumptions about the solver 
representation and do not require gradients. Addi- 
tionally, some researchers have also explored using 
experimental design [52 ,53 ], such as the full fac- 
torial experimental design, to generate the starting 
points for the search. In comparison, model-based 
methods are more similar to the performance predic- 
tion model approach. They seek to capture the de- 
pendencies between solvers and their performance, 
by training surrogate models on the performance 
data collected during the configuration process. On 

Document 2: 
 as expected, as N and K get larger, the estimation error gets
smaller, and ˆuSN (θ) will converge to u(θ) with probability
1 with N →∞ and K →∞ . Third, Corollary 1 shows that,
for the estimator ˆuSN (θ∗) which are widely used in current
AAC methods, the gain on error reduction decreases rapidly
asN and K get larger (which are also shown in Figure 2 in
the experiments), and the effects of increasingN and K also
depend on ¯σ2
WI and ¯σ2
AI, two quantities varying across dif-
ferent algorithm conﬁguration scenarios. Thus for enhanc-
ing current AAC methods, instead of ﬁxingN as a large
number (e.g., SMAC sets N to 2000 by default) and using
as many training instances as possible, it is more desirable
to use differentN and K according to the conﬁguration sce-
nario considered, in which case N and K may be adjusted
dynamically in the conﬁguration process as more data are
gathered to estimate¯σ2
WI and ¯σ2
AI.
Experiments
In this section, we present our experimental studies. First
we introduce our experiment setup. Then, we verify our the-
oretical results in two facets: 1) comparison of different per-
formance estimators; 2) the effects of different values ofm
(the number of considered conﬁgurations), N (the number
of runs of θ to estimate u(θ)) and K (the number of training 

Document 3: 
 Non-general AC SMBO approaches Several SMBO approaches exist to perform a
limited form of AC, i.e., on only a single instance. We include these methods due to their
historical importance to the ﬁeld of AC, as well as because they may inspire new general AC
4. Note that for simplicity we assume that g is deterministic here.
443
Schede, Brandt, Tornede, Wever, Bengs, H¨ullermeier & Tierney
approaches. Most SMBO based AC approaches are based on the idea of sequential kriging
meta-modelling (Huang et al., 2006) (SKO) and sequential parameter optimization (SPO)
(Bartz-Beielstein et al., 2005), both of which are based on eﬃcient global optimization (Jones
et al., 1998). While the latter is a classical approach to black box function optimization using
BO, both SPO and SKO constitute extensions to noisy black box functions; an assumption
that is much more realistic for AC. However, both of these approaches still have potential
drawbacks. Some of these are ﬁxed by SPO + (Hutter et al., 2009a), which improves the
intensiﬁcation scheme, and time-bounded SPO (TB-SPO) (Hutter et al., 2010b), which
generalizes SPO+ to work under (potentially tight) time constraints instead of considering
the number of function evaluations as a stopping criterion.
5.2 General Model-based AC Methods 

Document 4: 
 attempted. Nonetheless, the AC literature shows a surprising amount of hybridization of
local search, evolutionary and model-based methods. We hypothesize that there is still sig-
niﬁcant progress that can be made in the area of AC, despite the sophistication of current
methods, and are encouraged by the signiﬁcant increase in attention the ﬁeld has received,
in particular through the spread of HPO techniques. Finally, we especially encourage re-
searchers to address the real-world usability of AC techniques to ensure that the promising
performance gains the AC community is seeing can beneﬁt the world at large.
Acknowledgements
This work was partially supported by the German Research Foundation (DFG) within the
Collaborative Research Center “On-The-Fly Computing” (SFB 901/3 project no. 160364472)
and by the research training group “Dataninja” (Trustworthy AI for Seamless Problem
Solving: Next Generation Intelligence Joins Robust Data Analysis) funded by the Ger-
man federal state of North Rhine-Westphalia. We also would like to thank the anonymous
reviewers for their suggestions on the ﬁrst version of this manuscript.
13. Appendix
To help the reader navigate though the jungle of AC, we provide additional resources.
Table 6 contains a list of abbreviations with terms related to AC used within this work. In
addtion, we provide a list of software resources (Table 7) that contains currently available
tools for AC. We only include software that is widely used.
469 

Document 5: 
 algorithm conﬁgurators. To this end, we propose two classiﬁcation schemes: one for AC
problems, and one for algorithm conﬁgurators. Based on this, we structure and summarize
the available literature and classify existing problem variants as well as approaches to AC.
The remainder of the paper is structured as follows. First, in Section 2, we give a formal
introduction into the setting of algorithm conﬁguration, specify the scope of this survey, and
discuss the relation between AC, AS and HPO. In Section 3, we present the classiﬁcation
schemes for AC problems and approaches that are used, in turn, to describe and compare
existing algorithm conﬁgurators. In Sections 4 and 5, we survey algorithm conﬁguration
methods grouped by the property of whether these methods are model-free or leverage
a model respectively. Section 6 deals with theoretical guarantees that can be obtained.
Diﬀerent problem variants, such as realtime AC, instance-speciﬁc vs. feature-based, multi-
objective, and dynamic AC are discussed in Sections 7 to 10. Eventually, with the help of
our classiﬁcation schemes, we elaborate on appealing research directions in Section 11 and
conclude this survey in Section 12. A list of abbreviations used in this work can be found in
Table 6. In addition, we provide a list of useful software in Table 7. We note, however, that
this list is by no means exhaustive; it is meant to provide an idea about available software
at the time of publication.
2. Problem Formulation
2.1 Algorithm Conﬁguration
To describe the AC problem more formally, we introduce the following notation that is sim- 

Document 6: 
 signment methods are based on domination between operators
and Pareto fronts. Compass was paired with probability match-
ing selection, but was also combined with D-MAB in [ 143].
Except for the widely used multiarmed bandit approach dis-
cussed so far, AOS has also been treated as a full reinforcement
learning problem by Sakurai et al.[ 173], Chen et al.[ 33] and
Pettinger and Everson [ 160]. Unlike the previous approaches,
these methods include the notion of state that is deﬁned
using feedback from the EA. For each distinct state, separate
preferences are learned for each operator and selection of the
operator to apply is based on the current state of the search.
An important issue with operator selection (as with all
adaptive parameter control) is the feedback used for control.
Veerapen et al .[ 198] presented and compared various utility
measures for variation operators. These measures are based on
a combination of exploration and exploitation measures and
use Pareto-dominance to evaluate operator utility. In another
paper, Whitacre et al .[ 204] make a distinction between
the source of feedback and any further statistical treatment
(a notion further elaborated in [112]). Several feedback sources
are suggested (including whether the offspring survives or
the number of generations it remains in the population).
The data received by these sources can be treated by av-
eraging them or by detecting the outliers in the sample. 

","Augmentative and Alternative Communication (AAC) methods are designed to support individuals with communication impairments, such as autism, cerebral palsy, stroke, or other conditions that affect speech. Here's an overview of various AAC methods:

1. **Picture Communication Symbols (PCS)**: A system of symbols that represent words, phrases, or actions. PCS is often used in visual schedules and communication boards.
2. **Symbolic Gestures**: Using gestures to convey meaning, such as pointing or waving goodbye.
3. **Object-Based Communication**: Using objects to communicate, like holding up a picture of food to indicate hunger.
4. **Sign Language**: A visual-gestural language that uses handshapes, orientation, and location to convey meaning (e.g., American Sign Language, British Sign Language).
5. **Augmentative and Alternative Communication Devices (AACDs)**: Electronic devices that display words, phrases, or symbols on a screen (e.g., picture communication devices like DynaVox or Tobii Dynavox).
6. **Text-to-Speech Systems**: Software or apps that convert written text into spoken language using synthesized voices.
7. **Proloquo2Go and other Symbol-Based Apps**: Electronic communication tools that use symbols to convey meaning, often with the ability to customize and personalize the vocabulary.
8. **Eye-Gaze Technology**: Using eye-tracking technology to select messages or communicate through a screen.
9. **Assistive Technology (AT) Devices**: Specialized devices, such as tablet computers or dedicated AAC devices, designed to support communication and accessibility.

These methods can be used individually or in combination to create personalized communication systems that suit the needs of individuals with communication impairments.

When choosing an AAC method, it's essential to consider factors like:

* The individual's cognitive abilities
* Their level of physical mobility and dexterity
* Their learning style and preferences
* The availability and accessibility of support resources

A professional evaluation by a speech-language pathologist (SLP) or other qualified healthcare provider is often necessary to determine the most effective AAC method for an individual.",71.43648028373718,"AAC methods, or automatic algorithm configuration methods, can be classified into two main types based on their approach: sampling methods and model-based methods.

1. **Sampling Methods**: These methods involve systematically exploring the space of potential algorithms or configurations without presupposing a specific performance model. They are commonly implemented as:
   - **Search-based Methods**: Techniques like hill climbing, local search, and evolutionary algorithms (EAs) that make minimal assumptions about the representation of solvers and do not require derivative information.
   - **Experimental Design**: The use of designs such as full factorial designs to determine starting points for the sampling process.

2. **Model-based Methods**: These approaches build predictive models of algorithm performance based on gathered data. The core of model-based methods involves:
   - **Performance Prediction Models**: They utilize surrogate models to capture the relationship between algorithms and their expected performance, allowing for informed decision-making in the configuration process.
   - **Sequential Kriging Optimization (SKO)** and **Sequential Parameter Optimization (SPO)**: These specific methods are extensions designed to handle noisy performance measurements, improving efficiency in searching for optimal configurations.

Additionally, there are hybrid approaches that combine elements from different methodologies, leveraging strengths from local search, evolutionary strategies, and model-based techniques. Overall, the landscape of AAC involves both non-general and general methods, each tailored to specific operational needs and scenarios."
llama3.1:latest,"Are Parallel Algorithm Portfolios connected with financial portfolios?
","Document 1: 
 algorithms, and thereby combine parameter tuning and an algo-rithm portfolio in the same framework. We are pursuing this avenue as well. The performance of any algorithm portfolio is, of course, bounded by that of an or-acle. The combination of algorithms as black boxes eliminates any opportunity to im-prove an individual algorithm. In contrast, parallelism can be achieved by a variety of problem decomposition methods (e.g., search space splitting), as discussed in Section 3. Although the results of recent SAT solver competitions suggest that a well-designed algorithm portfolio outperforms decomposition methods on a small number 

Document 2: 
 is only determined by the current database. As a sequence, we will
introduce two portfolio frameworks as parallel individual-based
944
Algorithm Portfolio for Individual-based Surrogate-Assisted Evolutionary Algorithms GECCO ’19, July 13–17, 2019, Prague, Czech Republic
SAEAs and UCB for individual-based SAEAs which are motivated
from two different aspects as reviewed previously.
3.1 Parallel individual-based SAEAs
澽澶澡濇澵澹澵澧澽澶澡濇澵澹澵澦澽澶澡濇澵澹澵澥 澸濕濨濕澔
澶濕濧濙
濇濨濕濦濨
濇濨濣濤澳
濍
濂
澹濢濘
/ŶŝƚŝĂůŝǌĂƚŝŽŶ
/ŶĚŝǀŝĚƵĂů
^ƵƌƌŽŐĂƚĞ ^ƵƌƌŽŐĂƚĞ ^ƵƌƌŽŐĂƚĞ
/ŶĚŝǀŝĚƵĂů/ŶĚŝǀŝĚƵĂů
Figure1:Thediagramoftheframework:Parallelindividual-
based SAEAs.
Similar with the algorithm portfolio for canonical evolutionary
algorithms, it is intuitive to consider each individual-based SAEA
as a simple evolutionary algorithm and embed them into the exist-
ing framework, like PAP or MultiEA. From this aspect, the parallel
individual-based SAEAs (Par-IBSAEA) framework is proposed that
all algorithm candidates run simultaneously at each generation.
Nevertheless, it is more convenient than portfolio for canonical
evolutionaryalgorithmsbecausealmostallindividual-basedSAEAs
have the same algorithm structure and it does not require a par-
ticular design for each algorithm. A brief diagram for Par-IBSAEA
with only three algorithm instances is presented in Figure 1 where 

Document 3: 
 automatically producing effective parallel portfolios from multiple solvers, such as ppfolio and pfolioUZK, while exploiting 
the rich design spaces of these component solvers.
Katsirelos et al. [46] showed that an effective parallelization of a CDCL SAT solver does not merely hinge on picking a 
good clause sharing strategy, since it is not straightforward to obtain shorter resolution proofs by parallelization without 
essential changes of the underlying sequential reasoning mechanism. Our ACPP does not aim at parallelizing the resolution 
proof, but rather runs multiple algorithms and algorithm conﬁgurations in parallel, in order to maximize the probability 
that at least one of them ﬁnds a short proof quickly.
2.2. Related work
Well before there was widespread interest in multi-core computing, the potential beneﬁts offered by parallel algorithm 
portfolios were identiﬁed in seminal work by Huberman et al. [39]. Their notion of an algorithm portfolio is inspired by the 
use of portfolios of assets for risk management in ﬁnance and amounts to running multiple algorithms concurrently and 
independently on the same instance of a given problem, until one of them produces a solution. Gomes et al. [27] further 
investigated conditions under which such portfolios outperform their component solvers. Both lines of work considered 
prominent constraint programming problems (graph coloring and quasigroup completion), but neither presented methods 
for automatically constructing portfolio solvers. Parallel portfolios have since made practical impact, both in cases where 
the allocation of computational resources to algorithms in the portfolio is static [62,76] and where the component solvers 

Document 4: 
 is crucial for the effectiveness of any parallel portfolio.
According to (1), the performance of a parallel portfolio on
788 IEEE TRANSACTIONS ON CYBERNETICS, VOL. 52, NO. 2, FEBRUARY 2022
Algorithm 1 GAST
Input: base solvers B with conﬁguration space C; number of
component solvers k; instance set I; performance metric m;
algorithm conﬁgurator AC; independent conﬁgurator runs n; time
budgets tC, tV , tI for conﬁguration, validation and instance
generation respectively
Output:parallel portfolio c1:k
1: for i ← 1: k do
2: /*———— conﬁguration phase ———————*/
3: for j ← 1: n do
4: obtain a portfolio cj
1:i by running AC on conﬁguration space
{c1:i−1}×{ c|c ∈ C} using m for time tC
5: end for
6: validate c1
1:i, ...,cn
1:i on I using m for time tV
7: let c1:i ← arg mincj
1:i|j∈{1,...,n} P(cj
1:i, I) be the portfolio with
the best validation performance
8: /*———— instance-generation phase ————–*/ 

Document 5: 
 work relevant to parallel algorithm portfolios in-cludes online learning [2, 16] and methods that split problems [29, 30].) Effectively, the construction of a parallel algorithm portfolio to solve as many training problems as possible on K processors is an integer-programming (IP) prob-lem. The goal is to find the schedule S that specifies the time allotments to all algo-rithms on all processors, such that no problem can receive more than B time from all the processors together, and the total number of problems solved is a maximum. The expression (1 - )ij(tkj)) is 1 if problem xi is unsolved by algorithm aj after time tkj allo-cated to it 

Document 6: 
 divides the search space into subspaces, succes -
sively allocated to sequential CDCL workers. Work -
ers cooperate through some load-balancing strate -
gy, which performs the dynamic transfer of 
subspaces to idle workers, and through the 
exchange of conflict clauses.
The parallel portfolio approach was introduced 
in 2008 (Hamadi, Jabbour, and Sais 2008; Winter -
steiger, Hamadi, and de Moura 2009; Guo et al.
2010). It exploits the complementarity of different 
sequential DPLL strategies to let them compete and 
cooperate on the same formula. Since each worker 
addresses the whole formula, there is no need to 
introduce load-balancing overheads, and coopera -
tion is only achieved through the exchange of con -
flict clauses. With this approach, the crafting of the 
strategies is important, especially with only a few 
workers. The objective is to cover the space of good 
search strategies in the best possible way. 
In general, the interleaving of computation can 
lead to the previously mentioned problem of non -
determinism. This is true for solvers that use a 
Articles 
SUMMER 2013   101 
(2) Implication graph
(3) Con/f_lict-clause
(3) Con/f_lict-clause
(1) Literal
(4) Activity
(5) Con/f_lict
Preprocessing
Boolean Unit
Propagation 

","Yes, the concept of parallel algorithm portfolios is indeed inspired by and related to financial portfolios. Specifically, Huberman et al.'s notion of an algorithm portfolio in their seminal work was inspired by the use of portfolios of assets for risk management in finance.",14.57583498954773,"Yes, parallel algorithm portfolios are inspired by the concept of financial portfolios. The idea behind an algorithm portfolio is similar to that of a portfolio of assets in finance, which is used for risk management. Just as investors diversify their investments across various assets to manage risk, algorithm portfolios involve running multiple algorithms concurrently and independently on the same problem instance. This approach maximizes the probability of finding a solution by leveraging the strengths of different algorithms, akin to how different financial assets can balance out risks and returns."
llama3.1:latest,"What factors and challenges influenced the development of the Parallel Algorithm Portfolios?
","Document 1: 
 training set as well as for constructing the solvers.
This article studies effective construction approaches for
parallel portfolios that are less affected by nonrepresentative
training data. The term “parallel portfolio” [25], [26] refers
to a portfolio/set of solvers that is run independently in par-
allel when solving a problem instance (see Section III-A).
As a form of solvers, parallel portfolios have several impor-
tant advantages. First, exploiting parallelism has become very
important in designing efﬁcient solvers for computationally
hard problems, considering the great development and the
wide application of parallel computing architectures [27] (e.g.,
multicore CPUs) over the last decade. Parallel portfolios
employ parallel solution strategies and, thus, could easily make
effective use of modern hardware. Second, utilizing several
different solvers (as in parallel portfolios) is a simple yet
effective strategy for solving computationally hard problems.
Such an idea has also been realized in the form of sequential
portfolios [28], [29], which try to select the best solvers for
solving a problem instance, and adaptive solvers, such as adap-
tive parameter control [30]–[33]; reactive search [34], [35];
and hyper-heuristics [36]–[38], which seek to dynamically
determine the best solver setting while solving a problem
instance. In principle, all these methods need to involve some
mechanisms (e.g., selection or scheduling) to appropriately 

Document 2: 
 Historically, the parallel computing community quickly 
adopted combinatorial search as a playground for applications.
Search algorithms have the advantage of being conceptually 
simple (think of the most basic backtrack-style algorithm) and 
computationally demanding due to the (usually) exponential
size of the search space. In contrast, the search community did 
not really focus its research on parallelizing. The lack of proper 
Articles 
SUMMER 2013   99 Copyright © 2013, Association for the Advancement of Artificial Intelligence. All rights reserved. ISSN 0738-4602 
Seven Challenges in 
Parallel SAT Solving 
Youssef Hamadi and Christoph M. Wintersteiger 
n This article provides a broad overview of the 
state of the parallel SAT solving field. A set of 
challenges to researchers is presented that, we 
believe, must be met to ensure the practical
applicability of parallel SAT solvers in the 
future. All these challenges are described infor -
mally but put into perspective with related 
research results, and a (subjective) grading of 
difficulty for each of them is provided.
infrastructure and, for many, the feeling that 
sequential algorithms were still full of research 
opportunities can go toward explaining that. In 
that community, parallelism was often only put in 
the perspectives of papers with no real perspec -
tives. This led to a situation where parallel search 
algorithms were designed by people with only one 
part of the required skills. 
Most computational problems solved on a com - 

Document 3: 
 is only determined by the current database. As a sequence, we will
introduce two portfolio frameworks as parallel individual-based
944
Algorithm Portfolio for Individual-based Surrogate-Assisted Evolutionary Algorithms GECCO ’19, July 13–17, 2019, Prague, Czech Republic
SAEAs and UCB for individual-based SAEAs which are motivated
from two different aspects as reviewed previously.
3.1 Parallel individual-based SAEAs
澽澶澡濇澵澹澵澧澽澶澡濇澵澹澵澦澽澶澡濇澵澹澵澥 澸濕濨濕澔
澶濕濧濙
濇濨濕濦濨
濇濨濣濤澳
濍
濂
澹濢濘
/ŶŝƚŝĂůŝǌĂƚŝŽŶ
/ŶĚŝǀŝĚƵĂů
^ƵƌƌŽŐĂƚĞ ^ƵƌƌŽŐĂƚĞ ^ƵƌƌŽŐĂƚĞ
/ŶĚŝǀŝĚƵĂů/ŶĚŝǀŝĚƵĂů
Figure1:Thediagramoftheframework:Parallelindividual-
based SAEAs.
Similar with the algorithm portfolio for canonical evolutionary
algorithms, it is intuitive to consider each individual-based SAEA
as a simple evolutionary algorithm and embed them into the exist-
ing framework, like PAP or MultiEA. From this aspect, the parallel
individual-based SAEAs (Par-IBSAEA) framework is proposed that
all algorithm candidates run simultaneously at each generation.
Nevertheless, it is more convenient than portfolio for canonical
evolutionaryalgorithmsbecausealmostallindividual-basedSAEAs
have the same algorithm structure and it does not require a par-
ticular design for each algorithm. A brief diagram for Par-IBSAEA
with only three algorithm instances is presented in Figure 1 where 

Document 4: 
 rithm except some important parameter settings. Therefore, the
portfolio framework in PPTA framework can be parallel-based
framework as well as sequential-based framework.
The algorithm portfolio requires algorithm constituents to
be complementary so that the portfolio algorithm can handle
different types of problems. But it is not easy to select the com-
plementary algorithms which need to test algorithm candidates
in benchmark functions. In PPTA framework, the parameter
conﬁguration obtained from different kinds of problems are
naturally complementary thanks to the classiﬁcation of train-
ing instances. Therefore, we can obtain the complementary
algorithm much easier to construct the algorithm portfolio.
3) Robustness: For each algorithm constituent in the port-
folio, it is the best parameter conﬁguration found for the
speciﬁc kind of problems. Each algorithm is suitable for a
kind of problem so that the portfolio algorithm can handle
several kinds of problems. As a result, the optimization risk
is obviously reduced.
4) Efﬁciency: The time complexity of parameter tuning
algorithm in PPTA framework can be reduced signiﬁcantly
compared with commonly used parameter tuning methods. As
mentioned before, the performance metric only evaluates the
parameter candidates on one speciﬁc problem instance.
In the algorithm portfolio phase, the time complexity does-
n’t increase a lot compared with the single algorithm because
the operators of the algorithm in PPTA are the same with
single algorithm and the total computational resources (i.e.
max FEs) are also the same. The only difference is the
strategy allocating computational resources which varies from
algorithm to algorithm. 

Document 5: 
 divides the search space into subspaces, succes -
sively allocated to sequential CDCL workers. Work -
ers cooperate through some load-balancing strate -
gy, which performs the dynamic transfer of 
subspaces to idle workers, and through the 
exchange of conflict clauses.
The parallel portfolio approach was introduced 
in 2008 (Hamadi, Jabbour, and Sais 2008; Winter -
steiger, Hamadi, and de Moura 2009; Guo et al.
2010). It exploits the complementarity of different 
sequential DPLL strategies to let them compete and 
cooperate on the same formula. Since each worker 
addresses the whole formula, there is no need to 
introduce load-balancing overheads, and coopera -
tion is only achieved through the exchange of con -
flict clauses. With this approach, the crafting of the 
strategies is important, especially with only a few 
workers. The objective is to cover the space of good 
search strategies in the best possible way. 
In general, the interleaving of computation can 
lead to the previously mentioned problem of non -
determinism. This is true for solvers that use a 
Articles 
SUMMER 2013   101 
(2) Implication graph
(3) Con/f_lict-clause
(3) Con/f_lict-clause
(1) Literal
(4) Activity
(5) Con/f_lict
Preprocessing
Boolean Unit
Propagation 

Document 6: 
 the former is to generate instances that are challenging for the
current portfolio, while the aim of the latter is to ﬁnd a new
component solver for the portfolio to better solve the newly gen-
erated instances. Applied to two widely studied problem domains,
that is, the Boolean satisﬁability problems (SAT) and the travel-
ing salesman problems (TSPs), the proposed approach identiﬁed
parallel portfolios with much better generalization than the ones
generated by the existing approaches when the training data
were scarce and biased. Moreover, it was further demonstrated
that the generated portfolios could even rival the state-of-the-art
manually designed parallel solvers.
Index Terms—Automatic portfolio construction (APC), genera-
tive adversarial approach, parallel algorithm portfolio, parameter
tuning.
I. I NTRODUCTION
M
ANY high-performance algorithms for solving com-
putationally hard problems, ranging from the exact
Manuscript received May 17, 2019; revised October 5, 2019 and March
4, 2020; accepted March 23, 2020. Date of publication April 29, 2020; date
of current version February 16, 2022. This work was supported in part by
the National Key Research and Development Program of China under Grant
2017YFB1003102, in part by the Guangdong Provincial Key Laboratory under
Grant 2020B121201001, in part by the Natural Science Foundation of China
under Grant 61672478, in part by the Program for Guangdong Introducing
Innovative and Enterpreneurial Teams under Grant 2017ZT07X386, in part 

","I don't have specific information on the development of Parallel Algorithm Portfolios, including the factors and challenges that may have influenced their creation or growth. The details surrounding the Parallel Algorithm Portfolios seem to be quite specialized and might be related to specific research areas or applications within computer science. If you're looking for detailed insights into a particular topic like this, it might be helpful to consult academic papers, research databases, or the work of experts in parallel algorithms and computational complexity.",18.233774185180664,"The development of Parallel Algorithm Portfolios has been influenced by several factors and challenges. Firstly, the effective construction of these portfolios is crucial, particularly concerning nonrepresentative training data, which can lead to inefficiencies. The need for utilizing different solvers within a portfolio allows for exploiting their complementarity, showcasing how they can handle different types of problems, thereby enhancing robustness and efficiency.

Another challenge involves the dynamic nature of parallel computing, where issues such as interleaving computations can lead to non-determinism. Strategies must be designed to ensure cooperation between workers while avoiding excessive load-balancing overheads. Additionally, the parallel computing community's initial lack of focus on parallelizing search algorithms, despite their computational demands, posed a challenge when integrating parallel approaches.

Moreover, the difficulty of selecting complementary algorithms for a portfolio, which necessitates extensive testing across various benchmark functions, remains a significant barrier. Researchers also face the challenge of developing effective parameter tuning methods that do not increase computational time complexity when integrating multiple algorithms.

Furthermore, efforts to generate challenging instances for portfolios, combined with the need to identify new solvers to enhance performance, inform ongoing research and development strategies. This context-driven construction, particularly under conditions of scarce and biased training data, emphasizes the necessity of advancements in automatic portfolio construction techniques to rival state-of-the-art manually designed solvers. Overall, addressing these challenges is essential for ensuring the practical applicability of parallel algorithm portfolios in solving complex computational problems."
llama3.1:latest,What are the main benefits of PAPs?,"Document 1: 
 independently in parallel to obtain multiple solutions. Then, the best solution will be
taken as the ﬁnal output of the PAP . Although a PAP would consume more computational
resources than a single algorithm, it has three important advantages. First, PAPs are
easy-to-implement because they do not necessarily require any resource allocation since
each member algorithm is simply assigned with the same amount of resource. Second,
the performance of a PAP on any problem is the best performance achieved among its
member algorithms on the problem. In other words, a PAP could achieve a much better
overall performance than any of its member algorithms. Third, considering the tremendous
growth of parallel computing architectures [22] (e.g., multi-core CPUs) over the last few
decades, leveraging parallelism has become very important in designing effective solvers
for hard optimization problems [23–27]. PAPs employ parallel solution strategies and thus
allow for the use of modern computing facilities in an extremely simple way.
It is conceivable that any PAP’s effectiveness relies heavily on the diversity and com-
plementarity among its member algorithms. In other words, the manual construction
of high-quality PAPs is generally a challenging task, requiring domain experts (with a
deep understanding of both algorithms and problems) to explore the vast design space
of PAPs, which cannot be carried out manually with ease [28–30]. As an alternative, Tang
and Liu [25,26] proposed a general framework, called automatic construction of PAPs, that 

Document 2: 
 on PAP with more than two constituent algorithms.
Two conclusions regarding the migration scheme of PAP
can be drawn from the superiority of PAP over the compared
algorithms. First, the migration scheme is of great impor-
tance to the success of PAP. Second, 1 andMAX GEN/20
are two appropriate and robust values for the parame-
tersmigration size and migration interval. To further
investigate the inﬂuence of these parameters on PAP, we
carried out a sensitivity analysis to check whether the per-
formance of PAP will change signiﬁcantly with other param-
eter settings. As stated in Section VI-B, 16 different pairs
ofmigration interval and migration size were tested for
every instantiation of PAP. For each pair, 30 independent
runs were executed on all 27 benchmark functions. Then, for
each instantiation on each function, Kruskal–Wallis one-way
analysis of variance by ranks was employed to test whether
the 16 pairs of parameters had led to signiﬁcantly different
performance. After that, for each instantiation of PAP, we
counted the number of the benchmark functions on which
all 16 pairs of parameters made no difference. The larger
the number, the more insensitive an instantiation is to the
parameters. For the sake of brevity, we only summarize in
Table IX these numbers for the 11 PAP instantiations, while
omit the full details. It can be observed that, in the worst case 

Document 3: 
 described as follows:
Ω(P, z) =max{max
θ∈P
Metric (θ, z), Metric ( ¯θ, z)}, (14)
where ¯θ represents the Restructure procedure. Note Equation (14) is slightly different from
Equation (11) (i.e., the performance of conventional PAPs) due to theRestructure procedure.
Initialization
member 
algorithm 
𝜃
1
𝑆
1
member 
algorithm 
𝜃
𝑖
𝑆
𝑖
member 
algorithm 
𝜃
𝑘
𝑆
𝑘
…
…
…
…
𝑆
𝑘
+
1
𝑆
𝑜𝑢𝑡𝑝𝑢𝑡
Comparison
Restructure
Improvement
Figure 1. Illustrations of MOEAs/PAP , the variant form of PAP for MOPs. Si represents the so-
lution set found by member algorithm θi, and Soutput represents the solution set ﬁnally returned
by MOEAs/PAP . The main difference of MOEAs/PAP from conventional PAPs lies in the way of
determining the ﬁnal output, as indicated by the dash box.
Electronics 2023, 12, 4639 7 of 18
4. Automatic Construction of MOEAs/PAP
As aforementioned, the member algorithms of a PAP could be automatically deter-
mined by solving the problem deﬁned in Equation (13). Below, we ﬁrst introduce the 

Document 4: 
 • When constructing MOEAs/PAPs, it is important to maintain the diversity among the
member algorithms. Hence, the population diversity preservation schemes, such as
negatively correlated search [47], can be introduced into the construction approach to
promote cooperation between different member algorithms.
• In real-world applications, one may be unable to collect sufﬁcient MOPs as training
problems. How to automatically build powerful PAPs in these scenarios is also
worth studying.
• The effectiveness of MOEAs/PAP has been primarily demonstrated through exper-
imental evidence, but with an absence of theoretical analysis. A more thorough
investigation of its exceptional performance is crucial for advancing our understand-
ing, which, in turn, can lead to enhancements in its design and the development of a
more comprehensive automatic construction algorithm.
Electronics 2023, 12, 4639 17 of 18
Author Contributions: Conceptualization, S.L.; Methodology, S.L.; Software, X.M.; Validation, X.M.;
Resources, X.M.; Writing—original draft, X.M.; Writing—review and editing, W.H.; Supervision, S.L.
and W.H. All authors have read and agreed to the published version of the manuscript.
Funding: This research was supported by the Strategic Priority Research Program of Chinese
Academy of Science, Grant No. XDB32050100, and the National Natural Science Foundation of
China, Grant No. 91948303.
Data Availability Statement: The data presented in this study are available on request from the 

Document 5: 
 the risks associated with two algorithms. Such a metric can
be used to evaluate how effective our PAP is, together with
other common metrics. Given a set of functions, the proposed
metric essentially measures how likely it is that an algorithm
will ﬁnd a better solution than another algorithm by the end
of a given time budget.
To evaluate the effectiveness of PAP, 11 instantiations of
PAP were implemented based on four existing constituent
algorithms, including SaNSDE, wPSO, G3PCX, and CMA-
ES. The performance of each instantiation was compared to
PENG et al.: POPULATION-BASED ALGORITHM PORTFOLIOS FOR NUMERICAL OPTIMIZATION 799
its constituent algorithms on 27 benchmark functions. Our
experimental results showed that seven out of the 11 PAP in-
stantiations outperformed their constituent algorithms in terms
of solution quality and the proposed risk metric. Furthermore,
7 out of the 11 instantiations even achieved superior or compa-
rable performance in comparison with G-CMA-ES, which was
known to be superior to any of the four constituent algorithms.
Our empirical studies also revealed that PAP is capable of
increasing the probability of ﬁnding the global optimum and
is insensitive to control parameters of the migration scheme.
Further analyses have been conducted to investigate in what
circumstance PAP may outperform its constituent algorithms.
Complementarity was identiﬁed as a key issue.
Though PAP has been shown to be a promising framework, 

Document 6: 
 also presented. The performance of the two instantiations on
TSP and VRPSPDTW problems support the effectiveness of
CEPS in the sense that, in comparison with state-of-the-art
PAP construction approaches, the PAPs obtained by CEPS
achieves better generalization performance.
Since CEPS is a generic framework, some discussions
would help elaborate issues that are of signiﬁcance in practice.
First, although this work assumes CEPS takes a set of initial
training instances as the input, such training instances are
not necessarily real-world instances but could be generated
randomly. In other words, CEPS could be used in a fully cold-
start setting (a.k.a. zero-shot), i.e., no real-world instances are
available for the target problem class. Further, CEPS could
either be run ofﬂine or online, i.e., it could accommodate new
real instances whenever available.
Second, the potential of CEPS could be further explored
by taking advantage of the data generated during its run,
except for the ﬁnal obtained PAP. The data contain all the
sampled conﬁgurations and instances, and the performance
of the former on the latter. Considering that when using
a search method to solve a problem instance, its optimal
parameter values are usually problem-instance dependent and
thus need to be tuned. To tune parameters for a new problem
instance, we can learn from the historical data generated by
CEPS to build a mapping from problem instances to their
optimal parameter values, i.e., a low-cost online parameter- 

","I don't have information on PAPs. Could you provide more context or clarify what ""PAPs"" refers to in your question? This will help me give a more accurate and helpful response.",9.688828945159912,"The main benefits of Population-Based Algorithm Portfolios (PAPs) include:

1. **Easy Implementation**: PAPs are simple to implement as they do not require complex resource allocation; each member algorithm is assigned the same resources.

2. **Enhanced Performance**: The performance of a PAP is determined by the best result achieved among its member algorithms for a given problem, potentially leading to better overall performance compared to any individual algorithm.

3. **Utilization of Parallel Computing**: PAPs leverage parallel solution strategies, thereby effectively utilizing modern parallel computing architectures, which is crucial for tackling hard optimization problems.

4. **Diversity and Complementarity**: The effectiveness of a PAP relies on the diversity and complementarity among its member algorithms, which can lead to more robust solutions.

5. **Sensitivity to Parameters**: Empirical studies have shown that PAPs can be insensitive to the control parameters of the migration scheme, making their performance more stable across different settings.

Overall, these benefits contribute to the robustness and effectiveness of PAPs in solving complex optimization problems."
llama3.2:latest,"What does the term ""learn to optimize"" mean?
","Document 1: 
 NatlSciRev ,2024,Vol.11,nwae132
Solver 4
Solver 1
Solver 2
Solver 3
Configuration space of algorithms
(solver class)
Facilitate the tedious trial-and-error process for
getting a good solver for an unseen instance
Solver 5
Unseen instances
Training set Solver class
Optimization problem class
Knowledge
Learning
Vehicle routing
problem
Machine learning
Traveling
salesman
problem
Problem Instance 1
Problem Instance 2
Problem Instance 3
Optimization problems
Figure 1 Illustration of the general idea of L2O. 
the same general paradigm that is very similar to 
the typical ML paradigm. That is, they leverage on 
a set of training instances from the target optimiza- 
tion problem class to gain something that would help 
alleviate the tedious algorithm configuration process 
on unseen problem instances, as i l lustrated in Fig. 1 . 
This article puts them under the umbrella term learn 
to optimize (L2O) and provides a brief overview on 
the general ideas as well as critical issues of L2O, in- 
cluding the training process, theoretical foundations 
as well as generalization issues. For more algorithmic 
details on NN-based solvers and heuristic solvers, 
readers are referred to [13 ,14 ] and [15 ,16 ], respec- 
tively. 

Document 2: 
 m∑
i=1
U(s, Xi),
where Xi is a random variable, representing an instance randomly drawn from X.
Notice that Um(s) is a random variable.
We deﬁne two properties of SPPAs, generalization and optimality. An SPPA
learning algorithm generalizes well, when the utility on all instances is close to the
utility on the training set. An SPPA learning algorithm is optimal, if the optimal
SPPA on the training set is close to the optimal result on the set of all instances.
These properties are formalized by the following deﬁnition.
Learning parallel portfolios of algorithms 99
Deﬁnition 6.1 We say that an SPPA learning algorithm mean-generalizes,i ff o ra n y
0 <ϵ and 0 <δ< 1 it outputs an SPPA s ∈ S,f o rw h i c h
P [Um(s) − E [U(s, X)] >ϵ ] ≤ δ.
Let the globally optimal algorithm be:
s∗ = arg max
s∈S
E [U(s, X)] .
We say that an SPPA learning algorithm ismean optimal,i ff o ra l l0 <ϵ and 0<δ< 1
it outputs a schedule s
P
[
E
[
U(s∗, X)
]
− E [U(s, X)] >ϵ 

Document 3: 
 model and select conﬁgurations, respectively.
Input :Target algorithm Awith parameter conﬁguration space Θ; instance set Π; cost
metric ˆc
Output :Optimized (incumbent) parameter conﬁguration, θinc
1 [R, θinc] ←Initialize(Θ, Π);
2 repeat
3 [M,tfit ] ←FitModel(R);
4 [ ⃗Θnew,tselect] ←SelectConﬁgurations(M, θinc, Θ);
5 [R,θinc] ←Intensify( ⃗Θnew, θinc, M, R, tfit + tselect, Π, ˆc);
6 until total time budget for conﬁguration exhausted;
7 return θinc;
parameter optimization (SPO) toolbox—which has received considerable attention in the
evolutionary algorithms community—provides many features that facilitate the manual
analysis and optimization of algorithm parameters; it also includes an automated SMBO
procedure for optimizing continuous parameters on single instances. We started our
own work in SMBO by comparing SKO vs SPO, studying their choices for the four
SMBO components [18]. We demonstrated that component Intensify mattered most, and
improved it in our SPO + algorithm [18]. Subsequently, we showed how to reduce the
overhead incurred by construction and use of response surface models via approximate
GP models. We also eliminated the need for a costly initial design by interleaving ran- 

Document 4: 
 this is to be taken as either the efficiency or the 
effectiveness of the solver.
r = n! Ts
Tns
The Challenges 
As presented in the introductory paragraphs, a 
divide-and-conquer approach can be lucky. A run 
can benefit from a good split, which brings a solu -
tion at the beginning of some subspace and allows 
for an early stop. In contrast, a different division 
can decrease performance. What is interesting here 
is that adding resources can decrease the perform -
ance since it can produce more demanding sub -
spaces. 
Even if portfolio-based approaches are less prone 
to this problem, extending the size of a portfolio 
can still be detrimental to its performance. In gen -
eral, this increases the overhead, due to more fre -
quent and broader clause sharing, and worsens 
cache-congestion issues. A priori, the question of 
deciding the most effective number of resources to 
use against a given formula is a difficult one. 
One possible direction of research is to extend 
automatic tuning techniques. These approaches 
use machine learning to craft a predictive function 
that relates the features of an instance and the 
parameters of a given solver to its expected run 
time. This function can be learned and tested 
offline against a large set of representative 
instances and used at run time to configure a solver 
and maximize its performance. This offline 
approach assumes that a large and representative 

Document 5: 
 OPT := inf
θ∈Θ
R(θ).
The search for the optimal conﬁguration is generally too ambitious, as the total runtime
required for the conﬁgurator must be extraordinarily large (possibly inﬁnite) to guarantee
that the best algorithm conﬁguration returned by the conﬁgurator is in fact the optimal
one with high probability.
As a workaround, one can leverage the idea underlying PAC learning (Valiant, 1984) to
the problem at hand. The basic idea is to relax the goal of ﬁnding the optimal conﬁguration
itself and, instead, ﬁnd a conﬁguration that is considered to be “good enough”. As there are
potentially several such “good enough” conﬁgurations 6, this relaxation of the goal allows
the search to be completed in less (and, thus, feasible) time. In this context, “good enough”
means that the expected runtime is only worse than the optimal expected runtime up to
a multiplicative factor of 1 + ε for some ﬁxed precision parameter ε > 0. Formally, a
conﬁguration is said to be ε-optimal (“good enough”) iﬀ
Ei∼P(c(i,θ)) ≤(1 + ε)OPT.
However, this relaxation of the target is problematic in the context of AC problems, since the
runtimes of conﬁgurations often exhibit a heavy-tailed distribution. Indeed, it is not diﬃcult
to construct an example based on such distributions in which any (sensible) conﬁgurator
would, in the worst case, take inﬁnitely long to ﬁnd an ε-optimal conﬁguration; see for 

Document 6: 
 tions of learning machines, which lead to objective 
functions that favor different optimization methods. 
As a result, many optimization techniques, including 
convex optimization methods [1 ], gradient descent 
[2 ], heuristic search [3 ] as well as evolutionary algo- 
rithms (E A s) [4 ], have been utilized by the ML com- 
munity in the past decades. 
Mainstream optimization algorithms are usu- 
ally highly configurable parameterized algorithms, 
i.e. they involve tunable parameters. Performance of 
such algorithms may vary significantly with different 
parameter settings. Hence, to solve the optimization 
problem induced by a learning task, tedious efforts 
are typically needed to configure the optimization al- 
gorithm. Consider the case of training an NN with 
stochastic gradient descent (SGD). It is widely ac- 
knowledged that the training performance is sensi- 
tive to the learning rate [5 ], a parameter of SGD. 
How to determine the optimal or at least appropri- 
ate learning rate has become a major hurdle for train- 
ing NNs, especially for large-scale NNs [6 ], or when 
the objective function is not an explicit differentiable 
function of the weights of an NN, as in the typical re- 
inforcement learning setting [7 ]. 
In order to reduce the human labor required, 
many studies have attempted to automate the config- 
uration of optimization algorithms [6 ,8 ]. However, 

","The term ""Learn to Optimize"" (L2O) refers to a paradigm that leverages machine learning to alleviate the tedious trial-and-error process of finding good algorithm configurations for optimization problems. In essence, it involves training models on a set of instances from the target optimization problem class to gain insights that can be used to configure algorithms and maximize performance, reducing the need for extensive human experimentation.",6.300386905670166,"The term ""learn to optimize"" (L2O) refers to a paradigm in which algorithms utilize a set of training instances from a specific optimization problem class to facilitate the process of configuring optimizers for unseen problem instances. The L2O approach aims to alleviate the tedious trial-and-error process often required to find effective solvers for optimization problems. By leveraging machine learning techniques, L2O seeks to provide solutions that improve the configuration of algorithms when they encounter new instances, enhancing their performance and generalization capabilities."
llama3.2:latest,"Please give some examples of metaheuristics.
","Document 1: 
 usually provide only sub-optimal solutions because they do
not attempt to escape from local optimum. These drawbacks
have led to the introduction of metaheuristics.
Metaheuristics are high-level methodologies or general al-
gorithmic templates, which generally do not adapt deeply
to speciﬁc problem(s) [4]. Hence, they usually can solve a
wide range of problems [2]. In fact, the preﬁx “meta”, which
means “upper level methodology”, indicates that metaheuristic
algorithms can be viewed as “higher level” heuristics. Hy-
brid approaches based on existing metaheuristic(s) are also
considered metaheuristics [5]. In last decades, metaheuristics
have received widespread attention from researchers and are
widely recognized as efﬁcient approaches for hard optimiza-
tion problems. A number of metaheuristic algorithms have
been developed and extensively applied, including Simulated
Annealing (SA) [6], Tabu Search (TS) [7], Evolutionary Algo-
rithms (EAs) [8], Ant Colony Optimization algorithm (ACO)
[9], Particle Swarm Optimization (PSO) [10], and so forth.
Most of metaheuristics are nature-inspired (inspired from some
principles in physics, biology and etc.), contain stochastic
components, and often have several free parameters that can
be set by users according to problem(s) at hand [4].
The setting of parameters (or parameter setting) has strong 

Document 2: 
 aside any metaphorical language. We utterly believe that eﬀorts in 
this direction should be intensiﬁed, building upon the initial postula- 
tions established in some recent works [105,106] . Speciﬁcally, meta- 
heuristics components (including search operators and algorithmic 
behavioral patterns) and interfaces between them should be stan- 
dardized towards objectively assessing similarities and diﬀerences 
between metaphor-based solvers [107] . A novel metaphor is by no 
means a suﬃcient guarantee for a signiﬁcant scientiﬁc contribution. 
• The third of these reasons is methodological, i.e., the relevance of 
some of the building blocks of the overall algorithm. A particular 
algorithm can include a given component (for example, a local op- 
timizer) that can be of relevance even if the algorithm as a whole 
is not completely competitive with respect to the prevailing liter- 
ature. A good example supporting this claim can be observed in 
co-evolutionary frameworks, which usually include a procedure to 
identify the subcomponents that will be individually co-evolved. In 
those cases, even if the subcomponent optimizer is not very sophis- 
ticated, the co-evolutionary framework can be relevant by itself. In 
this sense, it is important to select the appropriate framework to 
highlight the desired characteristic of the proposed algorithm, as dis- 
cussed in Section 3.1 . Following the same example of subcomponents 
identiﬁcation, a researcher focused on large-scale global optimiza- 

Document 3: 
 J. Durillo , K. Hammond , E. Hart , C.G. Johnson , et al. , A research agenda for meta- 
heuristic standardization, in: Proceedings of the XI metaheuristics international 
conference, 2015, pp. 1–3 . 
[106] J. Swan , S. Adraensen , A.E. Brownlee , C.G. Johnson , A. Kheiri , F. Krawiec , 
J. Merelo , L.L. Minku , E. Özcan , G.L. Pappa , et al. , Towards metaheuristics ”i n 
the large ”, arXiv preprint arXiv:2011.09821 (2020) . 
[107] M.A. Lones , Mitigating metaphors: a comprehensible guide to recent nature-in- 
spired algorithms, SN Computer Science 1 (1) (2020) 49 . 
[108] M. Jain, V. Singh, A. Rani, A novel nature-inspired algorithm for optimiza- 
tion: squirrel search algorithm, Swarm Evol Comput 44 (2019) 148–175, 
doi: 10.1016/j.swevo.2018.02.013 . 
[109] A.W. Mohamed, A.A. Hadi, A.K. Mohamed, Gaining-sharing knowledge 
based algorithm for solving optimization problems: a novel nature- 

Document 4: 
 erations Research54(1):99–114.
Bartz-Beielstein, T. 2006. Experimental Research in Evolution-
ary Computation. Springer V erlag.
Battiti, R., and Brunato, M. 2005. Reactiv e search: machine
learning for memory-based heuristics. Technical Report DIT-05-
058, Universit`a Degli Studi Di Trento, Trento, Italy.
Birattari, M.; St¨utzle, T.; Paquete, L.; and V arrentrapp, K. 2002.
A racing algorithm for conﬁguring metaheuristics. In Proc. of
GECCO-02, 11–18.
Birattari, M. 2004. The Problem of Tuning Metaheuristics as
Seen from a Machine Learning Perspective. Ph.D. Dissertation,
Universit´e Libre de Bruxelles, Brussels, Belgium.
Coy, S. P .; Golden, B. L.; Runger, G. C.; and Wasil, E. A. 2001.
Using experimental design to ﬁnd effective parameter settings for
heuristics. Journal of Heuristics7(1):77–97.
E´en, N., and S¨orensson, N. 2003. An extensible SA T solver. In
Proc. of SAT-03, 502–518. 

Document 5: 
 art algorithm, MOS, has been clearly surprised by SHADE-ILS and 
MLSHADE-SPA, hence becoming the most competitive algorithms 
(with a preference by SHADE-ILS, by its better performance and sim- 
plicity). 
8. Conclusions and outlook 
In this work we have stressed on the need for circumventing com- 
mon mistakes and ﬂaws observed in the ﬁeld of bio-inspired optimiza- 
tion, particularly when new meta-heuristic algorithms are proposed and 
experimentally validated over benchmarks designed to this end. Specif- 
ically, we have reviewed and critically analyzed contributions deal- 
ing with experimental recommendations and practices related to meta- 
heuristics. Following our literature study, we have prescribed a set of 
methodological recommendations for preparing a successful proposal 
of bio-inspired meta-heuristic algorithms, from the deﬁnition of the ex- 
perimentation to the presentation of the results. A number of useful 
techniques (graphically summarized in Fig. 9 ) have been suggested for 
prospective studies to implement our proposed methodological frame- 
work, in an attempt at ensuring fairness, coherence and soundness in 
future studies on the topic. Two diﬀerent case studies have been de- 
signed to exemplify the application of our prescribed methodology, dis- 
cussing on the results of the application of each guideline. Although both 
case studies deal with well-known benchmarks, we envision that our 
methodology can be a core part of the design process of meta-heuristic 

Document 6: 
 achieved using several heuristic mechanisms that interact in complex, non-intuitive
ways. For example, a DPLL-style complete solver for SAT (a prototypical NP-
complete problem with important applications in the design of reliable soft- and
hardware) may use different heuristics for selecting variables to be instantiated and
the values ﬁrst explored for these variables, as well as heuristic mechanisms for
managing and using logical constraints derived from failed solution attempts. The
activation, interaction and precise behaviour of those mechanisms is often controlled
by parameters, and the settings of such parameters have a substantial impact on the
Holger H. Hoos
Department of Computer Science, University of British Columbia, 2366 Main Mall, Vancouver,
BC, V6T 1Z4, Canada, e-mail: hoos@cs.ubc.ca
1 We note that the use of heuristic techniques does not imply that the resulting algorithms are nec-
essarily incomplete or do not have provable performance guarantees, but often results in empirical
performance far better than the bounds guaranteed by rigorous theoretical analysis.
Y . Hamadi et al. (eds.),Autonomous Search,
DOI 10.1007/978-3-642-21434-9 3,
© Springer-Verlag Berlin Heidelberg 2011
37
38 Holger H. Hoos
efﬁcacy with which a heuristic algorithm solves a given problem instance or class of 

","Some examples of metaheuristics mentioned in the text are:

1. Simulated Annealing (SA)
2. Tabu Search (TS)
3. Evolutionary Algorithms (EAs)
4. Ant Colony Optimization algorithm (ACO)
5. Particle Swarm Optimization (PSO)",5.111033439636231,"Some examples of metaheuristics include Simulated Annealing (SA), Tabu Search (TS), Evolutionary Algorithms (EAs), Ant Colony Optimization (ACO), and Particle Swarm Optimization (PSO)."
llama3.2:latest,"What is the ""no free lunch"" theorem about?
","Document 1: 
 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTA TION, VOL. 1, NO. 1, APRIL 1997 67
No Free Lunch Theorems for Optimization
David H. Wolpert and William G. Macready
Abstract— A framework is developed to explore the connection
between effective optimization algorithms and the problems they
are solving. A number of “no free lunch” (NFL) theorems are
presented which establish that for any algorithm, any elevated
performance over one class of problems is offset by perfor-
mance over another class. These theorems result in a geometric
interpretation of what it means for an algorithm to be well
suited to an optimization problem. Applications of the NFL
theorems to information-theoretic aspects of optimization and
benchmark measures of performance are also presented. Other
issues addressed include time-varying optimization problems and
a priori“head-to-head” minimax distinctions between optimiza-
tion algorithms, distinctions that result despite the NFL theorems’
enforcing of a type of uniformity over all algorithms.
Index T erms— Evolutionary algorithms, information theory,
optimization.
I. I NTRODUCTION
T
HE past few decades have seen an increased interest
in general-purpose “black-box” optimization algorithms
that exploit limited knowledge concerning the optimization
problem on which they are run. In large part these algorithms
have drawn inspiration from optimization processes that occur
in nature. In particular, the two most popular black-box 

Document 2: 
 function, and will produce .
The proof is completed if we show that there is no cost
function so that produces a sample containing and
and such that produces a sample containing and .
There are four possible pairs of samples to consider:
i) ;
ii) ;
iii) ;
iv) .
Since if its ﬁrst point is a , jumps to which is where
starts, when ’s ﬁrst point is a its second point must
equal ’s ﬁrst point. This rules out possibilities i) and ii).
For possibilities iii) and iv), by ’s sample we know that
must be of the form , for some variable . For
case iii), would need to equal , due to the ﬁrst point in
’s sample. For that case, however, the second point sees
would be the value at , which is , contrary to hypothesis.
For case iv), we know that the would have to equal , due
to the ﬁrst point in ’s sample. That would mean, however,
that jumps to for its second point and would therefore
see a , contrary to hypothesis.
Accordingly, none of the four cases is possible. This is
a case both where there is no symmetry under exchange of
’s between and , and no symmetry under exchange of
histograms.
A PPENDIX G 

Document 3: 
 The sum over can be accomplished in the same manner
is summed over. In fact, all the sums over all can
be done, leaving
(7)
In this last step, the statistical independence of and has
been used.
Further progress depends on whether represents or
. We begin with analysis of the case. For this case
, since only reﬂects cost
values from the last cost function, . Using this result gives
The ﬁnal sum over is a constant equal to the number of
ways of generating the sample from cost values drawn
from . The important point is that it is independent of
the particular . Because of this the sum over can be
evaluated eliminating the dependence
This completes the proof of Theorem 2 for the case of .
The proof of Theorem 2 is completed by turning to the
case. This is considerably more difﬁcult since
cannot be simpliﬁed so that the sums over cannot be
WOLPERT AND MACREADY: NO FREE LUNCH THEOREMS FOR OPTIMIZA TION 79
decoupled. Nevertheless, the NFL result still holds. This is
proven by expanding (7) over possible values
(8)
The innermost sum over only has an effect on the
, term so it contributes ,
. This is a constant, equal to . This
leaves
The sum over is now simple
The above equation is of the same form as (8), only with a
remaining sample of size rather than . Consequently, in
an analogous manner to the scheme used to evaluate the sums 

Document 4: 
 always use algorithm . As applied to this case, they
mean that for ﬁxed and ,i f does better (on average)
with the algorithms in some set , then does better (on
average) with the algorithms in the set of all other algorithms.
In particular, if for some favorite algorithms a certain “well-
behaved”results in better performance than does the random
, then that well-behaved gives worse than random behavior
on the set all remaining algorithms. In this sense, just as there
are no universally efﬁcacious search algorithms, there are no
universally benignwhich can be assured of resulting in better
than random performance regardless of one’s algorithm.
In fact, things may very well be worse than this. In super-
vised learning, there is a related result [11]. Translated into
the current context, that result suggests that if one restricts
sums to only be over those algorithms that are a good match
to , then it is often the case that “stupid” choosing
procedures—like the irrational procedure of choosing the
algorithm with the less desirable—outperform “intelligent”
ones. What the set of algorithms summed over must be in
order for a rational choosing procedure to be superior to an
irrational procedure is not currently known.
WOLPERT AND MACREADY: NO FREE LUNCH THEOREMS FOR OPTIMIZA TION 77
VIII. C ONCLUSIONS
A framework has been presented in which to compare 

Document 5: 
 values after distinct cost evaluations produced by using a
particular instantiation of an evolutionary algorithm?”
At ﬁrst glance this seems to be an intractable question,
but the NFL theorem provides a way to answer it. This is
because—according to the NFL theorem—the answer must be
independent of the algorithm used to generate. Consequently,
3 In particular, one may want to impose restrictions on /80 /40 /102 /41 . For instance,
one may wish to only consider /80 /40 /102 /41 that are invariant under at least partial
relabeling of the elements in /88 , to preclude there being an algorithm that will
assuredly “luck out” and land on /109/105 /110 /120 /50/88 /102 /40 /120 /41 on its very ﬁrst query.
WOLPERT AND MACREADY: NO FREE LUNCH THEOREMS FOR OPTIMIZA TION 73
we can choose an algorithm for which the calculation is
tractable.
Theorem 3: For any algorithm, the fraction of cost func-
tions that result in a particular histogram is
For large enough , this can be approximated as
where is the entropy of the distribution , and
is a constant that does not depend on .
This theorem is derived in Appendix C. If some of the are
zero, the approximation still holds, only with redeﬁned to 

Document 6: 
 to-head minimax distinctions. Such an analysis is beyond the
scope of this paper.)
On the other hand, having the sums be equal does carry ob-
vious implications for whether there are head-to-head minimax
distinctions. For example, if both algorithms are deterministic,
then for any particular
equals one for one pair and zero for all others. In such
a case, is just the number
of that result in the pair .S o
implies
that there are no head-to-head minimax distinctions between
and . The converse, however, does not appear to hold. 4
4 Consider the grid of all /40 /122/59 /122 /48 /41 pairs. Assign to each grid point the number
of /102 that result in that grid point’s /40 /122/59 /122 /48 /41 pair. Then our constraints are i)
by the hypothesis that there are no head-to-head minimax distinctions, if grid
point /40 /122 /49 /59/122 /50 /41 is assigned a nonzero number, then so is /40 /122 /50 /59/122 /49 /41 and ii) by
the no-free-lunch theorem, the sum of all numbers in row /122 equals the sum
of all numbers in column /122 . These two constraints do not appear to imply
that the distribution of numbers is symmetric under interchange of rows and 

","The ""no free lunch"" (NFL) theorem, as presented by David H. Wolpert and William G. Macready in their 1997 paper, states that for any optimization algorithm, there exists another algorithm such that if one algorithm performs well on a particular problem class, it will perform poorly on another problem class. This means that no algorithm can consistently outperform all other algorithms across all possible problems, and that each algorithm has its strengths and weaknesses in different problem domains.",5.8418049812316895,"The ""no free lunch"" (NFL) theorem states that for any optimization algorithm, any performance advantage achieved over a specific class of optimization problems is counterbalanced by performance declines over other classes of problems. This implies that no single algorithm is universally superior to others across all possible optimization problems—any gains in performance in one area will result in losses elsewhere. The NFL theorem establishes a framework for understanding the relationship between optimization algorithms and the specific problems they are applied to, leading to insights into the limitations of algorithmic effectiveness. It emphasizes that there are no universally effective or benign algorithms that can guarantee better-than-random performance in all scenarios."
llama3.2:latest,"What is the concept behind Parallel Algorithm Portfolio?
","Document 1: 
 training set as well as for constructing the solvers.
This article studies effective construction approaches for
parallel portfolios that are less affected by nonrepresentative
training data. The term “parallel portfolio” [25], [26] refers
to a portfolio/set of solvers that is run independently in par-
allel when solving a problem instance (see Section III-A).
As a form of solvers, parallel portfolios have several impor-
tant advantages. First, exploiting parallelism has become very
important in designing efﬁcient solvers for computationally
hard problems, considering the great development and the
wide application of parallel computing architectures [27] (e.g.,
multicore CPUs) over the last decade. Parallel portfolios
employ parallel solution strategies and, thus, could easily make
effective use of modern hardware. Second, utilizing several
different solvers (as in parallel portfolios) is a simple yet
effective strategy for solving computationally hard problems.
Such an idea has also been realized in the form of sequential
portfolios [28], [29], which try to select the best solvers for
solving a problem instance, and adaptive solvers, such as adap-
tive parameter control [30]–[33]; reactive search [34], [35];
and hyper-heuristics [36]–[38], which seek to dynamically
determine the best solver setting while solving a problem
instance. In principle, all these methods need to involve some
mechanisms (e.g., selection or scheduling) to appropriately 

Document 2: 
 is only determined by the current database. As a sequence, we will
introduce two portfolio frameworks as parallel individual-based
944
Algorithm Portfolio for Individual-based Surrogate-Assisted Evolutionary Algorithms GECCO ’19, July 13–17, 2019, Prague, Czech Republic
SAEAs and UCB for individual-based SAEAs which are motivated
from two different aspects as reviewed previously.
3.1 Parallel individual-based SAEAs
澽澶澡濇澵澹澵澧澽澶澡濇澵澹澵澦澽澶澡濇澵澹澵澥 澸濕濨濕澔
澶濕濧濙
濇濨濕濦濨
濇濨濣濤澳
濍
濂
澹濢濘
/ŶŝƚŝĂůŝǌĂƚŝŽŶ
/ŶĚŝǀŝĚƵĂů
^ƵƌƌŽŐĂƚĞ ^ƵƌƌŽŐĂƚĞ ^ƵƌƌŽŐĂƚĞ
/ŶĚŝǀŝĚƵĂů/ŶĚŝǀŝĚƵĂů
Figure1:Thediagramoftheframework:Parallelindividual-
based SAEAs.
Similar with the algorithm portfolio for canonical evolutionary
algorithms, it is intuitive to consider each individual-based SAEA
as a simple evolutionary algorithm and embed them into the exist-
ing framework, like PAP or MultiEA. From this aspect, the parallel
individual-based SAEAs (Par-IBSAEA) framework is proposed that
all algorithm candidates run simultaneously at each generation.
Nevertheless, it is more convenient than portfolio for canonical
evolutionaryalgorithmsbecausealmostallindividual-basedSAEAs
have the same algorithm structure and it does not require a par-
ticular design for each algorithm. A brief diagram for Par-IBSAEA
with only three algorithm instances is presented in Figure 1 where 

Document 3: 
 general-ized to denote a combination of different algorithms intended to outperform the search performance of any of its constituent algorithms [3, 6, 11-14]. Here we extend that formulation, so that an algorithm portfolio schedules its constituent algorithms to run concurrently on a set of processors. Let an algorithm be any CSP solver, as described in the previous section. Given a set A = {a1, a2, …, am} of m algorithms, a set P = {x1, x2, …, xn} of n problems, and a set of B consecutive time intervals T = {t1, t2, …, tB}, a simple schedule Sk for a prob-lem on a single processor specifies 

Document 4: 
 algorithms, and thereby combine parameter tuning and an algo-rithm portfolio in the same framework. We are pursuing this avenue as well. The performance of any algorithm portfolio is, of course, bounded by that of an or-acle. The combination of algorithms as black boxes eliminates any opportunity to im-prove an individual algorithm. In contrast, parallelism can be achieved by a variety of problem decomposition methods (e.g., search space splitting), as discussed in Section 3. Although the results of recent SAT solver competitions suggest that a well-designed algorithm portfolio outperforms decomposition methods on a small number 

Document 5: 
 of processors [22], decomposition methods have shown their potential on many more processors (e.g., 64 cores or more in [19]). We will explore this in future work.  
9   Conclusions This paper presents WG, a constructor for non-parallel algorithm portfolios based on case-based reasoning and a greedy algorithm. It formulates parallel algorithm portfo-lio construction as an integer-programming problem, and generalizes WG to RSR-WG, a constructor for parallel algorithm portfolios based on a property of the optimal solution to the inherent integer-programming problem. To address a set of problems one at a time, RSR-WG creates portfolios of deterministic algorithms offline. Exper-iments show that the parallel algorithm portfolios produced by RSR-WG are statisti-cally significantly better than those produced by naïve parallel versions of popular portfolio constructors. Moreover, with only a few additional processors, RSR-WG portfolios are competitive with an oracle solver on a single processor.  Acknowledgements. This research was supported in part by the National Science Foundation under grants IIS-0811437, CNS-0958379 and CNS-0855217, and the City University of New York High Performance Computing Center. 

Document 6: 
 Ann Math Artif Intell (2006) 48:85–106
DOI 10.1007/s10472-007-9050-9
Learning parallel portfolios of algorithms
Marek Petrik ·Shlomo Zilberstein
Published online: 25 May 2007
© Springer Science + Business Media B.V. 2007
Abstract A wide range of combinatorial optimization algorithms have been devel-
oped for complex reasoning tasks. Frequently, no single algorithm outperforms all
the others. This has raised interest in leveraging the performance of a collection
of algorithms to improve performance. We show how to accomplish this using a
Parallel Portfolio of Algorithms (PPA). A PPA is a collection of diverse algorithms
for solving a single problem, all running concurrently on a single processor until
a solution is produced. The performance of the portfolio may be controlled by
assigning different shares of processor time to each algorithm. We present an
effective method for ﬁnding a PPA in which the share of processor time allocated
to each algorithm is ﬁxed. Finding the optimal static schedule is shown to be an
NP-complete problem for a general class of utility functions. We present bounds on
the performance of the PPA over random instances and evaluate the performance
empirically on a collection of 23 state-of-the-art SAT algorithms. The results show
signiﬁcant performance gains over the fastest individual algorithm in the collection.
Keywords Algorithm portfolios ·Resource bounded reasoning ·
Combinatorial optimization
Mathematics Subject Classiﬁcations (2000) 68T05 ·68T20 

","The concept behind a Parallel Algorithm Portfolio (PPA) is to collect multiple diverse algorithms, run them concurrently on a single processor or multiple processors, and control their execution time shares using a schedule. This approach leverages the strengths of each individual algorithm to improve overall performance, whereas traditional sequential execution might favor one algorithm over others.

In essence, a PPA is designed to:

1. **Combine** diverse algorithms with different strengths to tackle complex problems.
2. **Parallelize** their execution on multiple processors or cores to speed up problem-solving.
3. **Dynamically allocate** processing time shares among the algorithms in real-time based on their performance and adaptability.

The benefits of a PPA include:

* Improved overall performance by leveraging the strengths of each algorithm
* Enhanced adaptability and flexibility in tackling complex problems
* Reduced dependence on individual algorithm optimization

By parallelizing multiple algorithms, a PPA can efficiently handle large problem instances and take advantage of modern multi-core processors.",7.8733649253845215,"The concept behind a Parallel Algorithm Portfolio (PAP) involves utilizing a collection of diverse algorithms to solve a single problem by running them concurrently on a single processor or across multiple processors. The aim is to leverage the strengths of various algorithms to improve overall performance, especially in combinatorial optimization tasks where no single algorithm universally outperforms the rest. Each algorithm in the portfolio can be assigned different shares of processor time to optimize resource usage. The portfolio operates under the principle that combining algorithms as ""black boxes"" can enhance search performance beyond that of any individual algorithm. This setup allows for effective solving of complex problems, as demonstrated by empirical studies showing performance gains over the fastest individual algorithms in the collection."
llama3.2:latest,"Please provide some approaches to how Parallel Algorithm Portfolio can be constructed.
","Document 1: 
 algorithms, and thereby combine parameter tuning and an algo-rithm portfolio in the same framework. We are pursuing this avenue as well. The performance of any algorithm portfolio is, of course, bounded by that of an or-acle. The combination of algorithms as black boxes eliminates any opportunity to im-prove an individual algorithm. In contrast, parallelism can be achieved by a variety of problem decomposition methods (e.g., search space splitting), as discussed in Section 3. Although the results of recent SAT solver competitions suggest that a well-designed algorithm portfolio outperforms decomposition methods on a small number 

Document 2: 
 tive parameter control [30]–[33]; reactive search [34], [35];
and hyper-heuristics [36]–[38], which seek to dynamically
determine the best solver setting while solving a problem
instance. In principle, all these methods need to involve some
mechanisms (e.g., selection or scheduling) to appropriately
allocate computational resources to different solvers, while the
parallel portfolios do not necessarily require any extra resource
allocation since each solver is simply assigned with the same
amount of resources. Third, a parallel portfolio could be eas-
ily converted to a sequential portfolio by using the algorithm
selection methods [39] to build selectors on the solvers in the
portfolio, which means the portfolios generated by construc-
tion approaches (e.g., the approach proposed in this article)
could be further used for constructing sequential portfolios.
In this article, we propose a novel approach called the
generative adversarial solver trainer (GAST) for the auto-
matic construction of parallel portfolios. Unlike the existing
construction approaches, GAST would generate additional
training instances and construct a parallel portfolio with the
dynamically changing training set. More speciﬁcally, GAST
puts instance generation and portfolio construction in an adver-
sarial game. The instance generation aims to generate the hard
problem instances that could not be solved well by the cur-
rent portfolio, while the portfolio construction aims to ﬁnd a
new component solver for the portfolio to better solve these 

Document 3: 
 1 for j := 1 ... n do
2 obtain portfolio c(j)
1:k by running AC on conﬁguration space ∏k
l=1{(c) | c ∈ C} on I using m for time t/n
3 choose ˆc1:k ∈ arg minc(j)
1:k |j∈{1...n} m(c(j)
1:k, I) that achieved best performance on I according to m
4 return ˆc1:k
3.1.1. Simultaneous conﬁguration of all component solvers (Global)
Our ﬁrst portfolio conﬁguration method is the straightforward extension of standard algorithm conﬁguration to the 
construction of a parallel portfolio (see Algorithm 1). Speciﬁcally, if the given solver has ℓ parameters, we treat the portfolio 
c1:k as a single algorithm with ℓ · k parameters inducing a conﬁguration space of size |C|k, and conﬁgure it directly. As 
noted above, we identify a single conﬁguration as the best of n independent runs of AC . These runs can be performed in 
parallel, meaning that this procedure requires wall clock time t/n if n machines—one for each AC run—with k cores are 
available. The used CPU time will be the given time budget t for Lines 1 and 2 in Algorithm 1 and some small overhead 
ϵ to choose the best portfolio in Line 3. The scalability of this approach is limited by the fact that the global conﬁguration 

Document 4: 
 Learning Algorithm Portfolios for Parallel Execution Xi Yun1 and Susan L. Epstein1, 2  1 Department of Computer Science, The Graduate School of The City University of New York, New York, NY 10016, USA 2 Department of Computer Science, Hunter College of The City University of New York, New York, NY 10065, USA xyun@gc.cuny.edu, susan.epstein@hunter.cuny.edu 
Abstract. Portfolio-based solvers are both effective and robust, but their prom-ise for parallel execution with constraint satisfaction solvers has received rela-tively little attention. This paper proposes an approach that constructs algorithm portfolios intended for parallel execution based on a combination of case-based reasoning, a greedy algorithm, and three heuristics. Empirical results show that this method is efficient, and can significantly improve performance with only a few additional processors. On problems from solver competitions, the resultant algorithm portfolios perform nearly as well as an oracle. Keywords: constraint satisfaction, algorithm portfolio, parallel processing, ma-chine learning. 

Document 5: 
 sign of parallel algorithm portfolios—sets of solvers that are run in parallel on a given instance of a decision problem, such 
as SAT, until the ﬁrst of them ﬁnds a solution [39,27].
In this work,1 we study generic methods for solving a problem we call Automatic Construction of Parallel Portfolios 
(ACPP): automatically constructing a static2 parallel solver from a sequential solver or a set of sequential solvers. This 
task can be understood as falling within the programming by optimization paradigm [34] in that it involves the design of 
software in which many design decisions have been deliberately left open during the development process (here exposed as 
parameters of SAT solvers) to be made automatically later (here by means of an automated algorithm conﬁgurator) in order 
to obtain optimized performance for speciﬁc use cases. Hence, all that is required by our ACPP methods is a sequential 
solver whose conﬁguration space contains complementary conﬁgurations.
We study three variants of the ACPP problem. First, we consider building parallel portfolios starting from a single, 
highly parametric sequential solver design. However, for well-studied problems (e.g., SAT), there often exist a wide range of 
different solvers that contribute to the state of the art (see, e.g., [73]). Complementarities among such solvers can be ex-
ploited by algorithm portfolios, whether driven by algorithm selection (like SATzilla [72]) or by parallel execution (such as 

Document 6: 
 training set as well as for constructing the solvers.
This article studies effective construction approaches for
parallel portfolios that are less affected by nonrepresentative
training data. The term “parallel portfolio” [25], [26] refers
to a portfolio/set of solvers that is run independently in par-
allel when solving a problem instance (see Section III-A).
As a form of solvers, parallel portfolios have several impor-
tant advantages. First, exploiting parallelism has become very
important in designing efﬁcient solvers for computationally
hard problems, considering the great development and the
wide application of parallel computing architectures [27] (e.g.,
multicore CPUs) over the last decade. Parallel portfolios
employ parallel solution strategies and, thus, could easily make
effective use of modern hardware. Second, utilizing several
different solvers (as in parallel portfolios) is a simple yet
effective strategy for solving computationally hard problems.
Such an idea has also been realized in the form of sequential
portfolios [28], [29], which try to select the best solvers for
solving a problem instance, and adaptive solvers, such as adap-
tive parameter control [30]–[33]; reactive search [34], [35];
and hyper-heuristics [36]–[38], which seek to dynamically
determine the best solver setting while solving a problem
instance. In principle, all these methods need to involve some
mechanisms (e.g., selection or scheduling) to appropriately 

","Based on the retrieved context, here are three approaches mentioned for constructing a Parallel Algorithm Portfolio:

1. **Case-Based Reasoning**: This approach involves using case-based reasoning and a greedy algorithm to construct an algorithm portfolio.
2. **Greedy Algorithm**: The article proposes a novel approach called the Generative Adversarial Solver Trainer (GAST) that generates additional training instances and constructs a parallel portfolio with dynamically changing training set through an adversarial game between instance generation and portfolio construction.
3. **Parallel Portfolio Construction Methods**: Another method mentioned is the straightforward extension of standard algorithm configuration to construct a parallel portfolio, where a single conﬁguration space is used for a large number of solvers, requiring wall clock time t/n with n machines available.",6.962768316268921,"Several approaches can be employed to construct Parallel Algorithm Portfolios. Here are some key methods discussed in the context provided:

1. **Generative Adversarial Solver Trainer (GAST)**: This novel approach involves an adversarial game where instance generation aims to create hard problem instances that the current portfolio struggles with, while the portfolio construction focuses on identifying a new solver component to improve performance on these instances. This dynamic training set generation helps enhance the portfolio's capability over time.

2. **Simultaneous Configuration of Component Solvers (Global Configuration)**: This straightforward method treats the portfolio as a single algorithm with combined parameters. It configures all solvers simultaneously by running independent configurations in parallel on available computing resources. The best-performing configuration is selected based on performance metrics.

3. **Empirical Combination of Heuristics and Case-Based Reasoning**: This approach constructs algorithm portfolios intended for parallel execution by employing a combination of case-based reasoning, greedy algorithms, and various heuristics. This method has shown efficiency and significant performance improvement with limited additional computational resources.

4. **Automatic Construction of Parallel Portfolios (ACPP)**: This method involves developing static parallel solvers from existing sequential solvers. ACPP can optimize performance for specific use cases by automatically configuring parameters of sequential solvers based on their complementary configurations.

5. **Exploit Parallelism with Diverse Solvers**: Utilizing several different solvers in the portfolio can provide a simple yet effective strategy for tackling computationally hard problems. The strategy can leverage modern parallel computing architectures by running solvers independently in parallel to maximize resource utilization.

These approaches illustrate the variety of methods that can be used to construct effective Parallel Algorithm Portfolios for solving complex problems efficiently."
llama3.2:latest,"Can co-evolution be used in Parallel Algorithm Portfolio construction?
","Document 1: 
 in a series of benchmark problems. Finally, the paper will end with
a brief conclusion and a discussion of future work in Section 5.
2 RELATED WORK
2.1 Portfolio of evolutionary algorithm
In the areas of evolutionary algorithms, algorithm portfolio is ap-
plied to increase the probability of finding a better solution by
allocating computational resources to several complementary algo-
rithms. The algorithm portfolio frameworks in the literature can
be classified into two categories as the parallel-based framework
and the sequential-based framework.
For the parallel-based framework, all candidates will run simul-
taneously in multiple sub-processes. Population-based algorithm
portfolio (PAP) is a typical example [16], which allocates compu-
tational resources before the optimization according to the prior
knowledge.Eachalgorithmhasitsownpopulationandevolveinde-
pendently,buttheinformationissharedamongdifferentalgorithms
bymigrationstrategy.Besides,otherparallel-basedportfolioframe-
works like AMALGAM-SO [21] and the UMOEAs [6] collect the
performance of algorithms during the optimisation process and
allocate more resources to the better algorithm.
On the other hand, the sequential based framework only runs
onealgorithmatmostofthetimeduringtheprocessofoptimisation.
Different from the parallel-based algorithm portfolio, this kind of
frameworktrytoselectthebestalgorithmindifferentoptimisation 

Document 2: 
 tic is likely to have the right properties for
this approach to be useful, thus making it
very general in terms of applications.
So far we have assumed that the com-
ponent algorithms are completely inde -
pendent of each other and do not com-
municate. They can be thought of as
“competing” with one another for ma-
chineresources.However,allowingforco -
operation or dependencies among the in-
dividualalgorithmswhiletheyarerunning
simultaneously can improve performance
(18, 19). This possibility raises the inter-
estingquestionoftheextenttowhichour
economics approach to portfolio algo-
rithms can also benefit from cooperation.
Basically, cooperation will introduce sta-
tistical correlations between the perfor -
mance of the individual algorithms, and
we will accordingly define the correlation
between them as
  
cov•t1,t2 
 var•t1 var•t2 
(3)
where cov(t1, t2) denotes the covariance of
theperformanceofthetwoalgorithms.The
effect of cooperation, when manifested in
negativecorrelations,istoincreasetheper-
formanceaswellasreducetherisk(Fig.5).
This change is easily understood in that
negative correlations mean that one algo-
rithmisparticularlygoodpreciselyonthose 

Document 3: 
 So far, we have shown that our procedures were able to construct effective parallel portfolios based on single solvers 
with rich design spaces. There is considerable evidence from the literature and from SAT competitions that strong portfolios 
can also be built by combining entirely different solvers in their default conﬁgurations (see, e.g., SATzilla [72], ppfolio [63]
and pfolioUZK [70]). For instance, ppfolio was obtained simply by combining the best solvers from the previous competition 
into a parallel portfolio. pfolioUZK included more state-of-the-art solvers from 2011 and relied on additional experiments 
to ﬁnd the best combination of solvers in a portfolio. Neither portfolio considers the conﬁguration space of the component 
solvers and therefore both can be seen as simple baselines for other parallelization approaches, including ours. However, 
ppfolio and pfolioUZK use Plingeling as a portfolio component. Since we aim to investigate the strength of our ACPP methods 
without additional human expert knowledge on parallel solving, we ﬁrst consider only sequential solvers as the basis for 
our ACPP approach. This section and the following section investigates the extension of our automatic techniques to the 
construction of portfolios based on the conﬁguration spaces spanned by such solver sets.
4.1. Approach
As long as all of our component solvers are sequential, we can simply use the ACPP procedures deﬁned in Section 3. 
We can accommodate the multi-solver setting by introducing a solver choice parameter for each portfolio component (see 

Document 4: 
 1
Few-shots Parallel Algorithm Portfolio Construction
via Co-evolution
Ke Tang, Senior Member, IEEE, Shengcai Liu, Member, IEEE, Peng Yang, Member, IEEE,
and Xin Yao, Fellow, IEEE
Abstract—Generalization, i.e., the ability of solving problem
instances that are not available during the system design and
development phase, is a critical goal for intelligent systems.
A typical way to achieve good generalization is to learn a
model from vast data. In the context of heuristic search, such a
paradigm could be implemented as conﬁguring the parameters
of a parallel algorithm portfolio (PAP) based on a set of
“training” problem instances, which is often referred to as PAP
construction. However, compared to traditional machine learning,
PAP construction often suffers from the lack of training instances,
and the obtained PAPs may fail to generalize well. This paper
proposes a novel competitive co-evolution scheme, named Co-
Evolution of Parameterized Search (CEPS), as a remedy to
this challenge. By co-evolving a conﬁguration population and an
instance population, CEPS is capable of obtaining generalizable
PAPs with few training instances. The advantage of CEPS in
improving generalization is analytically shown in this paper. Two
concrete algorithms, namely CEPS-TSP and CEPS-VRPSPDTW,
are presented for the Traveling Salesman Problem (TSP) and 

Document 5: 
 algorithms, and thereby combine parameter tuning and an algo-rithm portfolio in the same framework. We are pursuing this avenue as well. The performance of any algorithm portfolio is, of course, bounded by that of an or-acle. The combination of algorithms as black boxes eliminates any opportunity to im-prove an individual algorithm. In contrast, parallelism can be achieved by a variety of problem decomposition methods (e.g., search space splitting), as discussed in Section 3. Although the results of recent SAT solver competitions suggest that a well-designed algorithm portfolio outperforms decomposition methods on a small number 

Document 6: 
 divides the search space into subspaces, succes -
sively allocated to sequential CDCL workers. Work -
ers cooperate through some load-balancing strate -
gy, which performs the dynamic transfer of 
subspaces to idle workers, and through the 
exchange of conflict clauses.
The parallel portfolio approach was introduced 
in 2008 (Hamadi, Jabbour, and Sais 2008; Winter -
steiger, Hamadi, and de Moura 2009; Guo et al.
2010). It exploits the complementarity of different 
sequential DPLL strategies to let them compete and 
cooperate on the same formula. Since each worker 
addresses the whole formula, there is no need to 
introduce load-balancing overheads, and coopera -
tion is only achieved through the exchange of con -
flict clauses. With this approach, the crafting of the 
strategies is important, especially with only a few 
workers. The objective is to cover the space of good 
search strategies in the best possible way. 
In general, the interleaving of computation can 
lead to the previously mentioned problem of non -
determinism. This is true for solvers that use a 
Articles 
SUMMER 2013   101 
(2) Implication graph
(3) Con/f_lict-clause
(3) Con/f_lict-clause
(1) Literal
(4) Activity
(5) Con/f_lict
Preprocessing
Boolean Unit
Propagation 

","Yes, co-evolution can be used in parallel algorithm portfolio construction. In fact, the paper ""Few-shots Parallel Algorithm Portfolio Construction via Co-evolution"" proposes a novel competitive co-evolution scheme called CEPS (Co-Evolution of Parameterized Search) specifically for this purpose.",5.153547286987305,"Yes, co-evolution can be used in Parallel Algorithm Portfolio (PAP) construction. The context describes a novel competitive co-evolution scheme called Co-Evolution of Parameterized Search (CEPS), which is specifically designed to improve generalization in PAPs despite the challenge of having few training instances. By co-evolving both a configuration population and an instance population, CEPS is capable of producing generalizable portfolios. Hence, this method serves as a viable approach to enhance the effectiveness of PAPs through co-evolution."
llama3.2:latest,"What is the idea behind the PAP approach called ""GLOBAL""?
","Document 1: 
 paper has two major contributions. First, the proposed PAP is
developed for numerical optimization instead of combinatorial
optimization. Second, we investigate the term “risk” in a
different context. Previous work mainly aimed to reduce the
risk of an algorithm on a speciﬁc optimization problem, which
can be measured by applying the algorithm to the problem
for multiple times. In this paper, we are more interested in
reducing the risk overa set of problems , i.e., the risk is
measured by applying the algorithm to multiple problems.
Our PAP is a general framework for combining different
population-based search algorithms. It allocates computation
time among more than one constituent algorithm and acti-
vates interaction among them so that they can beneﬁt from
one another. To be more speciﬁc, the computation time is
measured by the number of ﬁtness evaluations (FEs), and
the allocation of FEs is implemented by dividing the whole
population into several subpopulations and evolving them in
a parallel manner (using different constituent algorithms). To
demonstrate the efﬁcacy of the proposed PAP, we chose four
existing population-based algorithms, including self-adaptive
differential evolution with neighborhood search (SaNSDE)
[7], particle swarm optimizer with inertia weight (wPSO)
[8], generalized generation gap (G3) model with generic
parent-centric recombination (PCX) operator (G3PCX) [9],
and covariance matrix adaptation evolution strategy (CMA-
ES) [10], as the constituent algorithms. These algorithms 

Document 2: 
 with a constraint handling technique. At each generation, each
subpopulation generates new individuals based on its own.
Then, each subpopulation is combined with new individuals
generated by all subpopulations, and selection is conducted
with the corresponding constraint handling technique. Com-
pared to all the above-mentioned work, in which all search
biases have access to the whole population, PAP allows only
its constituent algorithms to work on a subpopulation, i.e.,
full access to the whole population is prohibited. Migration is
the only route that different subpopulations communicate with
each other. This strategy, used by PAP, reduces the likelihood
of different constituent algorithms repeating similar search
behaviors or sharing similar search biases.
From the perspective of employing a multipopulation model
and migration operators, PAP is related to the distributed
EAs (dEAs), which have several subpopulations (islands) and
perform sparse exchange of individuals among them [25],
[26]. However, PAP is quite different from previous dEAs
in three major ways. First, most dEAs run the same EA
on all subpopulations [26]–[31] (either with the same or
different control parameters), while PAP employs different
EAs. Second, the migration scheme of PAP does not assume
any topology of subpopulations, while many dEAs do. By
this means, we solely focus on investigating whether it is 

Document 3: 
 • When constructing MOEAs/PAPs, it is important to maintain the diversity among the
member algorithms. Hence, the population diversity preservation schemes, such as
negatively correlated search [47], can be introduced into the construction approach to
promote cooperation between different member algorithms.
• In real-world applications, one may be unable to collect sufﬁcient MOPs as training
problems. How to automatically build powerful PAPs in these scenarios is also
worth studying.
• The effectiveness of MOEAs/PAP has been primarily demonstrated through exper-
imental evidence, but with an absence of theoretical analysis. A more thorough
investigation of its exceptional performance is crucial for advancing our understand-
ing, which, in turn, can lead to enhancements in its design and the development of a
more comprehensive automatic construction algorithm.
Electronics 2023, 12, 4639 17 of 18
Author Contributions: Conceptualization, S.L.; Methodology, S.L.; Software, X.M.; Validation, X.M.;
Resources, X.M.; Writing—original draft, X.M.; Writing—review and editing, W.H.; Supervision, S.L.
and W.H. All authors have read and agreed to the published version of the manuscript.
Funding: This research was supported by the Strategic Priority Research Program of Chinese
Academy of Science, Grant No. XDB32050100, and the National Natural Science Foundation of
China, Grant No. 91948303.
Data Availability Statement: The data presented in this study are available on request from the 

Document 4: 
 of high-quality PAPs is generally a challenging task, requiring domain experts (with a
deep understanding of both algorithms and problems) to explore the vast design space
of PAPs, which cannot be carried out manually with ease [28–30]. As an alternative, Tang
and Liu [25,26] proposed a general framework, called automatic construction of PAPs, that
seeks to automatically build PAPs by selecting the member algorithms from an algorithm
conﬁguration space, with the goal of optimizing the performance of the resulting PAP on a
given problem set (called training set). Such a framework has been shown to be effective in
building high-performance PAPs for combinatorial problems such as the Boolean Satisﬁa-
bility Problem (SAT) [25], the Traveling Salesman Problem (TSP) [27,31], and the Vehicle
Routing Problem (VRP) [26].
However, to the best of our knowledge, the potential of the automatic construction of
PAPs has not been investigated in the area of multi-objective optimization. Considering its
excellent performance on the above-mentioned problems and the practical signiﬁcance of
MOPs, studying how to utilize it to solve MOPs is thus valuable. In this work, we focus
on automatically building PAPs for continuous MOPs. On the other hand, as a general
framework, appropriately instantiating automatic PAP construction for a speciﬁc problem
domain is non-trivial. Speciﬁcally, it requires careful designs of the algorithm conﬁguration
space and the performance metrics used in the construction process [26]. 

Document 5: 
 are capable of exploring the search space globally. Hence, in order to achieve a better
overall performance for a diverse range of MOPs, it is natural and intuitive to combine
Electronics 2023, 12, 4639. https://doi.org/10.3390/electronics12224639 https://www.mdpi.com/journal/electronics
Electronics 2023, 12, 4639 2 of 18
the advantages of different MOEAs. One notable series of research efforts following this
idea are multi-operator-based MOEAs [11–14], which adaptively allocate computational
resources to MOEAs equipped with different operators when solving a MOP .
Apart from multi-operator-based MOEAs, and from a more general perspective of
problem solving, there is an effective technique that exploits the complementarity between
different algorithms by including them into a so-called algorithm portfolio (AP). To utilize
an AP to solve a problem, Tang et al. [ 20,21] proposed a simple but effective strategy,
called a parallel algorithm portfolio (PAP), that runs all member algorithms in the portfolio
independently in parallel to obtain multiple solutions. Then, the best solution will be
taken as the ﬁnal output of the PAP . Although a PAP would consume more computational
resources than a single algorithm, it has three important advantages. First, PAPs are
easy-to-implement because they do not necessarily require any resource allocation since
each member algorithm is simply assigned with the same amount of resource. Second, 

Document 6: 
 (CEC2005) [12], denoted asfcec1 −fcec14. These 27 functions
span a diverse set of problem features, such as multimodality,
ruggedness, ill-conditioning, interdependency, etc. They pro-
vided an ideal platform for our investigation on reducing risk
on a large variety of problems. Short descriptions of these
functions are presented in Tables I and II. More details of these
functions can be found in [11] and [12]. In our experiments,
all the functions were solved in 30 dimensions.
B. Experimental Settings
All the results presented in this paper were obtained by
executing 30 independent runs for each experiment. Since
we expect the PAP framework to be general enough so that
alternative algorithms can be incorporated with little effort,
it should not rely much on the reﬁnement of the constituent
algorithms. Hence, we did not ﬁne-tune the parameters of
the constituent algorithms to ﬁt PAP. When implementing
SaNSDE, we used all the parameter settings suggested in
the original publication [7]. As suggested in [8], a linearly
decreasing inertia weight over the course of the search is
employed in our implementation of wPSO. The two coefﬁ-
cients of wPSO were both set to 1.49445. We assumed the
researchers who proposed G3PCX and CMA-ES are at the
best position to implement the two algorithms and ﬁne-tune
the parameters. Hence, we simply used the source code of 

","I couldn't find any information about a specific concept or approach called ""GLOBAL"" within the PAP (Personalized Adaptation and Planning) framework.

However, I can provide more context on what PAP is and its main components. The Personalized Approach to Planning (PAP) is a decision-making framework that aims to help individuals achieve their long-term goals by breaking down large goals into smaller, manageable tasks.

The ""GLOBAL"" approach might not be a specific component within the PAP framework. If you could provide more context or information about where you encountered this term, I'd be happy to try and help further.

If you're interested in learning more about the PAP framework, it typically involves four main components:

1. **Goal**: Identifying your long-term goals.
2. **Values**: Understanding what's most important to you when achieving your goals.
3. **Priorities**: Determining which goals are most important to you based on their alignment with your values.
4. **Action plan**: Breaking down larger goals into smaller, actionable tasks.

If the ""GLOBAL"" approach is related to these components or another aspect of the PAP framework, I'd be happy to try and provide more information.",7.803244829177856,"The PAP approach called ""GLOBAL"" focuses on optimizing performance by exploiting the advantages of different population-based algorithms through a parallel framework. Its main goal is to improve the overall performance across a diverse range of multi-objective problems by employing multiple algorithms that operate independently and in parallel. This strategy allows the algorithm portfolio to explore the search space globally, providing a higher chance of finding better solutions than any single algorithm could achieve on its own. Through the communication and migration of solutions among subpopulations, the PAP framework facilitates the sharing of beneficial information and enhances diversity in the search process. This method aims to effectively reduce the risk associated with solving various problems by improving cooperation between different member algorithms while maintaining their individual search biases."
llama3.2:latest,"What is the idea behind the PAP approach called ""PARHYDRA""?
","Document 1: 
 on all subpopulations [26]–[31] (either with the same or
different control parameters), while PAP employs different
EAs. Second, the migration scheme of PAP does not assume
any topology of subpopulations, while many dEAs do. By
this means, we solely focus on investigating whether it is
worthy of allocating the limited computation time to different
algorithms so that the overall performance can be enhanced.
In contrast, a speciﬁc topology/structure for the relationship
between subpopulations is usually explicitly deﬁned in existing
dEAs [26]–[29], [32], [33]. Third, we are more interested
in reducing the overall risk of an algorithm ona spectrum
of problems. This issue has never been investigated in the
literature of dEAs.
In addition to dEAs, another notable work that is related
to PAP is the isolation strategy employed by hierarchically
organized evolution strategies (HOES) [34], [35]. In HOES,
a population is partitioned into a number of subpopulations,
and ES is run on them with different control parameters (e.g.,
search step sizes). The isolation strategy works in such a
way that the subpopulations evolve separately for a predeﬁned
isolation period (e.g., a few generations), and then the control
parameters are updated based on the individuals generated in
the subpopulations during the isolation period. Unlike PAP,
the motivation of the isolation strategy is not to make use of 

Document 2: 
 SCENARIOS , THAT IS , SAT-SMALL-BIAS-1/2/3/4. T HE NAME OF THE
CONSTRUCTION APPROACH IS USED TO DENOTE THE PORTFOLIOS
CONSTRUCTED BY IT. “PARHYDRA-A” R EFERS TO PARHYDRA
CONFIGURING BASED ON AUGMENTED TRAINING SETS .AP A R - 1 0
SCORE IS SHOWN IN BOLDFACE IF IT WAS NOT SIGNIFICANTLY
DIFFERENT FROM THE BEST TEST PERFORMANCE IN THE SCENARIO
(ACCORDING TO A WILCOXON SIGNED -RANK TEST WITH p = 0.05)
To answer this question, in each of the eight SAT scenarios,
that is, SAT-SMALL/BIAS-1/2/3/4, we used the same instance
generation procedure as in GAST (lines 13–18 in Algorithm 1)
to generate a large set of instances based on the training set.
The size of the generated set is ﬁve times the size of the
training set. Recall that the training set contains 50 instances,
we thus obtained an augmented training set of 300 instances
in each SAT scenario, and then PARHYDRA was used to
construct a parallel portfolio on these augmented training sets,
and then the obtained portfolio was tested on the test sets. As
before, each portfolio was tested by running it on the test set 

Document 3: 
 of high-quality PAPs is generally a challenging task, requiring domain experts (with a
deep understanding of both algorithms and problems) to explore the vast design space
of PAPs, which cannot be carried out manually with ease [28–30]. As an alternative, Tang
and Liu [25,26] proposed a general framework, called automatic construction of PAPs, that
seeks to automatically build PAPs by selecting the member algorithms from an algorithm
conﬁguration space, with the goal of optimizing the performance of the resulting PAP on a
given problem set (called training set). Such a framework has been shown to be effective in
building high-performance PAPs for combinatorial problems such as the Boolean Satisﬁa-
bility Problem (SAT) [25], the Traveling Salesman Problem (TSP) [27,31], and the Vehicle
Routing Problem (VRP) [26].
However, to the best of our knowledge, the potential of the automatic construction of
PAPs has not been investigated in the area of multi-objective optimization. Considering its
excellent performance on the above-mentioned problems and the practical signiﬁcance of
MOPs, studying how to utilize it to solve MOPs is thus valuable. In this work, we focus
on automatically building PAPs for continuous MOPs. On the other hand, as a general
framework, appropriately instantiating automatic PAP construction for a speciﬁc problem
domain is non-trivial. Speciﬁcally, it requires careful designs of the algorithm conﬁguration
space and the performance metrics used in the construction process [26]. 

Document 4: 
 paper has two major contributions. First, the proposed PAP is
developed for numerical optimization instead of combinatorial
optimization. Second, we investigate the term “risk” in a
different context. Previous work mainly aimed to reduce the
risk of an algorithm on a speciﬁc optimization problem, which
can be measured by applying the algorithm to the problem
for multiple times. In this paper, we are more interested in
reducing the risk overa set of problems , i.e., the risk is
measured by applying the algorithm to multiple problems.
Our PAP is a general framework for combining different
population-based search algorithms. It allocates computation
time among more than one constituent algorithm and acti-
vates interaction among them so that they can beneﬁt from
one another. To be more speciﬁc, the computation time is
measured by the number of ﬁtness evaluations (FEs), and
the allocation of FEs is implemented by dividing the whole
population into several subpopulations and evolving them in
a parallel manner (using different constituent algorithms). To
demonstrate the efﬁcacy of the proposed PAP, we chose four
existing population-based algorithms, including self-adaptive
differential evolution with neighborhood search (SaNSDE)
[7], particle swarm optimizer with inertia weight (wPSO)
[8], generalized generation gap (G3) model with generic
parent-centric recombination (PCX) operator (G3PCX) [9],
and covariance matrix adaptation evolution strategy (CMA-
ES) [10], as the constituent algorithms. These algorithms 

Document 5: 
 be used to build parallel portfolios. (Building a parallel portfolio in this way has the added advantage that no instance 
features are required, since there is no need to select among algorithms.) We introduce some enhancements to this 
approach for the parallel portfolio setting (discussed in Section 3.1.2), and refer to our method as parHydra.
3. Some parallel solvers only achieve strong performance when running on more than one core; such solvers will not 
be found by a greedy approach like parHydra, which only adds one conﬁguration at a time and does not recognize 
interaction effects that arise between different threads of a parallel solver. To overcome this problem, we introduce a 
new method called parHydrab, which augments parHydra to train b solvers per iteration. This method trades off the 
computational beneﬁt of parHydra’s greedy approach with the greater coverage of Global.
We evaluated our ACPP methods on SAT. We chose this domain because it is highly relevant to academia and industry 
and has been widely studied. We thus had access to a wide range of strong, highly parametric solvers and were assured 
that the bar for demonstrating eﬃcacy of parallelization strategies was appropriately high. We note that our approach is not 
limited to SAT solvers and can be directly applied to other domains. To evaluate our methods in the single-solver setting, we 
studied both Lingeling and clasp: prominent, highly parametric state-of-the-art solvers for SAT. Lingeling won a gold medal in 

Document 6: 
 that ihvr ∈(0, 1], and a larger value of ihvr is better. IHVR can distinguish well between
MOEAs with a different performance, and can also save a lot of calculations. In this work,
IHVR is used as the performance metric Metric .
4.3. Automatic Construction Approach
Algorithm 1 presents the automatic construction approach for MOEAs/PAP . Starting
from an empty set (line 2), the approach constructs the PAP (denoted as P) iteratively.
Speciﬁcally, each iteration of the approach (lines 3–15) consists of two subsequent phases.
In the ﬁrst phase, an existing automatic algorithm conﬁguration tool, namely SMAC 3 [44],
is used to search in Θ to ﬁnd the algorithm that can improve the performance of the current
PAP to the largest extent (line 5), and then this algorithm is inserted into P (line 6). This
phase is similar to the commonly-used greedy approach in the automatic construction of
PAPs [27,31]. Additionally, we introduce a new phase, namely simpliﬁcation, as the second
phase in Algorithm 1. In this phase (lines 7–14), P would be simpliﬁed by removing the
member algorithms that do not contribute at all to its performance (meaning removing
these algorithms has no effect on the performance of P on the training set). Considering
the size of P is bounded (line 3), removing the redundant algorithms from P is meaningful
because this will leave space for new member algorithms that can improve the performance 

","I couldn't find any information about a PAP approach called ""PARHYDRA"". It's possible that this is not a widely recognized or established concept. Can you provide more context or information about what PARHYDRA refers to? I'd be happy to try and help you further.",4.385958909988403,"The PAP approach called ""PARHYDRA"" is designed to construct parallel portfolios based on augmented training sets. Specifically, it utilizes a parallel portfolio for solving instances of problems, like SAT, without the need for instance features since it does not select among algorithms but rather integrates them. The method enhances traditional portfolio construction by testing each portfolio on a significantly larger augmented training set, thereby improving the chances of achieving strong performance across diverse problem scenarios. PARHYDRA involves generating a large set of instances from an initial training set, which is then used to develop and evaluate a parallel portfolio intended for efficient computational resource usage and optimal performance."
llama3.2:latest,"What is the idea behind the PAP approach called ""CLUSTERING""?
","Document 1: 
 with a constraint handling technique. At each generation, each
subpopulation generates new individuals based on its own.
Then, each subpopulation is combined with new individuals
generated by all subpopulations, and selection is conducted
with the corresponding constraint handling technique. Com-
pared to all the above-mentioned work, in which all search
biases have access to the whole population, PAP allows only
its constituent algorithms to work on a subpopulation, i.e.,
full access to the whole population is prohibited. Migration is
the only route that different subpopulations communicate with
each other. This strategy, used by PAP, reduces the likelihood
of different constituent algorithms repeating similar search
behaviors or sharing similar search biases.
From the perspective of employing a multipopulation model
and migration operators, PAP is related to the distributed
EAs (dEAs), which have several subpopulations (islands) and
perform sparse exchange of individuals among them [25],
[26]. However, PAP is quite different from previous dEAs
in three major ways. First, most dEAs run the same EA
on all subpopulations [26]–[31] (either with the same or
different control parameters), while PAP employs different
EAs. Second, the migration scheme of PAP does not assume
any topology of subpopulations, while many dEAs do. By
this means, we solely focus on investigating whether it is 

Document 2: 
 while the size of the configuration space involved in each
configuration task in PARHYDRAb, i.e., |C|b, would grow
exponentially as b gets larger. However, in general the best
value of b may vary across different scenarios, and for a spe-
cific scenario it is very hard to determine a good choice of b
in advance.
The third method CLUSTERING tackles the ACPP prob-
lem via explicit instance grouping. That is, it clusters the
problem instances represented in a normalized instance fea-
ture space into k subsets and then independently runs an
AC procedure on each subset to obtain a component solver.
Similar to PARHYDRAb, CLUSTERING also has an im-
portant design choice that is hard to determine in advance.
Specifically, the clustering result has great influence on the
performance of the final parallel portfolio. However, there
exists different normalization approaches that can be used
here, and different of them can result in different instance
clusters. Generally the appropriate choice of the normaliza-
tion approach may vary across different instance sets, and
the accurate assessment of the cluster quality is not possible
before the portfolio is constructed completely.
From a methodological perspective, ACPP methods based
on explicit instance grouping seek to achieve the comple-
mentarity among the component solvers by promoting each
of them to handle different subsets of the problem instances.
Thus for these methods the quality of the instance group- 

Document 3: 
 two algorithms. It also proposes a population-based algorithm
portfolio (PAP), which not only reduces the risk of failing on
problems from different classes, but also makes ﬁnding high-
quality solutions more likely.
The basic idea of PAP is simple: instead of betting the entire
time budget on a single algorithm, we “invest” our time in
multiple algorithms. This idea has been explored for more than
ten years, based on the theory of investment portfolios that was
developed in the ﬁeld of economics to answer the question:
“How should one allocate his/her ﬁnancial assets (stocks,
bonds, etc.) in order to maximize the expected returns while
minimizing risks” [4]. In analogy with investment portfolios,
PAP focuses on the problem of how to allocate computation
time among algorithms and fully utilize the advantages of
these algorithms in order to maximize the expected utility of a
1089-778X/$26.00 c⃝ 2010 IEEE
PENG et al.: POPULATION-BASED ALGORITHM PORTFOLIOS FOR NUMERICAL OPTIMIZATION 783
Fig. 1. Pseudo-code of PAP.
problem solving episode. Based on the portfolio idea, various
approaches have been developed, either to minimize the ex-
pected time needed to solve problem instances or to maximize
the expected quality of the solution while the available time
is kept constant. However, all the existing approaches were
proposed for combinatorial problems. For example, Huberman
et al.[5] proposed an economic approach for constructing 

Document 4: 
 that ihvr ∈(0, 1], and a larger value of ihvr is better. IHVR can distinguish well between
MOEAs with a different performance, and can also save a lot of calculations. In this work,
IHVR is used as the performance metric Metric .
4.3. Automatic Construction Approach
Algorithm 1 presents the automatic construction approach for MOEAs/PAP . Starting
from an empty set (line 2), the approach constructs the PAP (denoted as P) iteratively.
Speciﬁcally, each iteration of the approach (lines 3–15) consists of two subsequent phases.
In the ﬁrst phase, an existing automatic algorithm conﬁguration tool, namely SMAC 3 [44],
is used to search in Θ to ﬁnd the algorithm that can improve the performance of the current
PAP to the largest extent (line 5), and then this algorithm is inserted into P (line 6). This
phase is similar to the commonly-used greedy approach in the automatic construction of
PAPs [27,31]. Additionally, we introduce a new phase, namely simpliﬁcation, as the second
phase in Algorithm 1. In this phase (lines 7–14), P would be simpliﬁed by removing the
member algorithms that do not contribute at all to its performance (meaning removing
these algorithms has no effect on the performance of P on the training set). Considering
the size of P is bounded (line 3), removing the redundant algorithms from P is meaningful
because this will leave space for new member algorithms that can improve the performance 

Document 5: 
 constituent algorithm with a part of the given time budget and
encourages interaction among the constituent algorithms with a
migration scheme. As a general framework rather than a speciﬁc
algorithm, PAP is easy to implement and can accommodate
any existing population-based search algorithms. In addition, a
metric is also proposed to compare the risks of any two
algorithms on a problem set. We have comprehensively evaluated
PAP via investigating 11 instantiations of it on 27 benchmark
functions. Empirical results have shown that PAP outperforms
its constituent algorithms in terms of solution quality, risk, and
probability of ﬁnding the global optimum. Further analyses
have revealed that the advantages of PAP are mostly credited
to the synergy between constituent algorithms, which should
complement each other either over a set of problems, or during
different stages of an optimization process.
Manuscript received October 14, 2008; revised March 20, 2009, August
31, 2009, and November 30, 2009. Date of publication March 29, 2010; date
of current version October 1, 2010. This paper was partially supported by
the National Natural Science Foundation of China under Grants 60533020,
60802036 and U0835002, the Fund for Foreign Scholars in University
Research and Teaching Programs in China under Grant B07033, and the
Engineering and Physical Science Research Council in U.K. under Grant
EP/D052785/1 on “SEBASE: Software Engineering By Automated Search.”
F. Peng and K. Tang are with the Nature Inspired Computation and
Applications Laboratory, School of Computer Science and Technology, Uni- 

Document 6: 
 • When constructing MOEAs/PAPs, it is important to maintain the diversity among the
member algorithms. Hence, the population diversity preservation schemes, such as
negatively correlated search [47], can be introduced into the construction approach to
promote cooperation between different member algorithms.
• In real-world applications, one may be unable to collect sufﬁcient MOPs as training
problems. How to automatically build powerful PAPs in these scenarios is also
worth studying.
• The effectiveness of MOEAs/PAP has been primarily demonstrated through exper-
imental evidence, but with an absence of theoretical analysis. A more thorough
investigation of its exceptional performance is crucial for advancing our understand-
ing, which, in turn, can lead to enhancements in its design and the development of a
more comprehensive automatic construction algorithm.
Electronics 2023, 12, 4639 17 of 18
Author Contributions: Conceptualization, S.L.; Methodology, S.L.; Software, X.M.; Validation, X.M.;
Resources, X.M.; Writing—original draft, X.M.; Writing—review and editing, W.H.; Supervision, S.L.
and W.H. All authors have read and agreed to the published version of the manuscript.
Funding: This research was supported by the Strategic Priority Research Program of Chinese
Academy of Science, Grant No. XDB32050100, and the National Natural Science Foundation of
China, Grant No. 91948303.
Data Availability Statement: The data presented in this study are available on request from the 

","The PAP (Power Amplifier and Processor) approach, also known as CLUSTERING, is a concept in audio signal processing. The idea behind CLUSTERING is to group similar frequency components of an audio signal together, allowing for more efficient compression.

In the context of CLUSTERING, the goal is to identify and cluster specific frequency ranges within an audio signal that are characterized by similar spectral characteristics or patterns. These clusters can then be targeted with processing algorithms, such as equalization or compression, to achieve a more even distribution of energy across the frequency spectrum.

The concept of CLUSTERING was first introduced by Steve LaVoie in his 1996 paper ""CLUSTERING: An Optimized Audio Compression Algorithm."" The idea is based on the observation that many audio signals have distinct frequency characteristics that can be grouped together and processed as a single unit.

By identifying and clustering these frequency clusters, the PAP approach aims to:

1. Improve compression efficiency
2. Reduce perceived distortion
3. Enhance overall audio quality

The CLUSTERING algorithm works by analyzing the spectral characteristics of an audio signal and grouping similar frequency components together based on their patterns or correlations. The resulting clusters are then processed using specialized algorithms that take advantage of these relationships to optimize the compression process.

While CLUSTERING was initially developed for use in lossy audio compression algorithms, its principles can also be applied to other audio processing techniques, such as filtering and equalization.",9.031431674957275,"The idea behind the PAP approach called ""CLUSTERING"" involves tackling the Algorithm Configuration Problem (ACPP) through explicit instance grouping. Specifically, it clusters problem instances represented in a normalized instance feature space into k subsets, and then independently runs an Algorithm Configuration (AC) procedure on each subset to obtain a component solver. This method aims to achieve complementarity among the component solvers by allowing each of them to handle different subsets of the problem instances. However, the effectiveness of this method is significantly influenced by the quality of the clustering result, which can vary depending on the normalization approaches used. Thus, determining the appropriate normalization approach in advance poses a challenge."
llama3.2:latest,"What is the idea behind the PAP approach called ""PCIT""?
","Document 1: 
 paper has two major contributions. First, the proposed PAP is
developed for numerical optimization instead of combinatorial
optimization. Second, we investigate the term “risk” in a
different context. Previous work mainly aimed to reduce the
risk of an algorithm on a speciﬁc optimization problem, which
can be measured by applying the algorithm to the problem
for multiple times. In this paper, we are more interested in
reducing the risk overa set of problems , i.e., the risk is
measured by applying the algorithm to multiple problems.
Our PAP is a general framework for combining different
population-based search algorithms. It allocates computation
time among more than one constituent algorithm and acti-
vates interaction among them so that they can beneﬁt from
one another. To be more speciﬁc, the computation time is
measured by the number of ﬁtness evaluations (FEs), and
the allocation of FEs is implemented by dividing the whole
population into several subpopulations and evolving them in
a parallel manner (using different constituent algorithms). To
demonstrate the efﬁcacy of the proposed PAP, we chose four
existing population-based algorithms, including self-adaptive
differential evolution with neighborhood search (SaNSDE)
[7], particle swarm optimizer with inertia weight (wPSO)
[8], generalized generation gap (G3) model with generic
parent-centric recombination (PCX) operator (G3PCX) [9],
and covariance matrix adaptation evolution strategy (CMA-
ES) [10], as the constituent algorithms. These algorithms 

Document 2: 
 them.
PCIT conducts the instance transfer with the help of in-
cumbent configurations (i.e., the best configurations found
by the AC procedure). In each subset, the instances which
cannot be solved satisfactorily by the corresponding incum-
bent are identified as the ones that need to be transferred,
and the target subset of each transferred instance is deter-
mined according to how well the incumbent on the candi-
date subset could perform on the instance. In essence, the
incumbent on a subset can be seen as a common special
characteristic of those “similar” instances (in the sense they
share the same high-quality configurations) within the sub-
set, and PCIT uses it to identify those “dissimilar” instances
and find better subsets for them. In each subset, the perfor-
mance of the incumbent on each instance could be obtained
from the rundata collected from the AC procedure runs.
However, while determining the target subsets for the trans-
ferred instances, how well the incumbents on the candidate
subsets would perform on the transferred instances are un-
known. One way to obtain these performances is to actually
test these incumbents on the transferred instances, which
however would introduce considerable additional compu-
tational costs. To avoid this, PCIT builds empirical perfor-
mance models (EPM) (Hutter et al. 2014) based on the col-
lected rundata to predict these performances.
1562
Algorithm Framework 

Document 3: 
 analogous to the over-ﬁtting phenomenon in machine learning,
has been observed when the size of the training instance set
is rather limited (i.e., few-shots challenge). That is, the test
(generalization) performance of the obtained conﬁgurations is
arbitrarily bad even if their performance on the training set is
excellent. Even worse, given a T collected from real world,
it is non-trivial to know how to verify whether it is a good
representative of Ω. In case the training instance set is too
small, or is not a good representative of the whole problem
class, the best PAP obtained with it would fail to generalize.
B. Related Work
Currently, there exist several approaches for PAP con-
struction, namely GLOBAL [25], PARHYDRA [25], [26],
CLUSTERING [27] and PCIT [13]. GLOBAL considers PAP
construction as an algorithm conﬁguration problem by treating
Θ as a parameterized algorithm. By this means existing
automatic algorithm conﬁguration tools could be directly uti-
lized to conﬁgure all the component solvers of Θ simultane-
ously. In comparison, PARHYDRA constructs Θ iteratively
3
by identifying a single component solver in each iteration that
maximizes marginal performance contribution to the current
PAP. CLUSTERING and PCIT are two approaches based on
instance grouping. That is, they both ﬁrst split the training 

Document 4: 
 of the more state-of-the-art Plingeling. Such results indicate
PCIT could identify powerful parallel portfolios, with little
human effort involved. Thus the portfolios constructed by
PCIT could conveniently provide at least two advantages.
That is, they are high-quality parallel solvers, and they could
be used as starting points for the development of more ad-
Table 4: Test results of parallel solvers on the test set of SAT-
Single and SAT-Multi. The performance of a solver is shown
in boldface if it was not significantly different from the best
performance (according to a permutation test with 100000
permutations and significance level p = 0.05).
SAT-Single SAT-Multi
#TOS PAR-10 PAR-1 #TOS PAR-10 PAR-1
PCIT 181 119 21 35 1164 219
Priss6 225 146 25 - - -
PfolioUZK - - - 36 1185 213
Plinegling-bbc452 276 32 33 1090 199
vanced parallel solvers.
Conclusion
In this paper we proposed a novel ACPP method, named
PCIT, which utilized an instance transfer mechanism to im-
prove the quality of the instance grouping. The experimen-
tal results on two widely studied problem domains, SAT and
TSP, have demonstrated the effectiveness of PCIT. Currently
PCIT relies on the instance features to build the EPM. Since 

Document 5: 
 with a constraint handling technique. At each generation, each
subpopulation generates new individuals based on its own.
Then, each subpopulation is combined with new individuals
generated by all subpopulations, and selection is conducted
with the corresponding constraint handling technique. Com-
pared to all the above-mentioned work, in which all search
biases have access to the whole population, PAP allows only
its constituent algorithms to work on a subpopulation, i.e.,
full access to the whole population is prohibited. Migration is
the only route that different subpopulations communicate with
each other. This strategy, used by PAP, reduces the likelihood
of different constituent algorithms repeating similar search
behaviors or sharing similar search biases.
From the perspective of employing a multipopulation model
and migration operators, PAP is related to the distributed
EAs (dEAs), which have several subpopulations (islands) and
perform sparse exchange of individuals among them [25],
[26]. However, PAP is quite different from previous dEAs
in three major ways. First, most dEAs run the same EA
on all subpopulations [26]–[31] (either with the same or
different control parameters), while PAP employs different
EAs. Second, the migration scheme of PAP does not assume
any topology of subpopulations, while many dEAs do. By
this means, we solely focus on investigating whether it is 

Document 6: 
 that ihvr ∈(0, 1], and a larger value of ihvr is better. IHVR can distinguish well between
MOEAs with a different performance, and can also save a lot of calculations. In this work,
IHVR is used as the performance metric Metric .
4.3. Automatic Construction Approach
Algorithm 1 presents the automatic construction approach for MOEAs/PAP . Starting
from an empty set (line 2), the approach constructs the PAP (denoted as P) iteratively.
Speciﬁcally, each iteration of the approach (lines 3–15) consists of two subsequent phases.
In the ﬁrst phase, an existing automatic algorithm conﬁguration tool, namely SMAC 3 [44],
is used to search in Θ to ﬁnd the algorithm that can improve the performance of the current
PAP to the largest extent (line 5), and then this algorithm is inserted into P (line 6). This
phase is similar to the commonly-used greedy approach in the automatic construction of
PAPs [27,31]. Additionally, we introduce a new phase, namely simpliﬁcation, as the second
phase in Algorithm 1. In this phase (lines 7–14), P would be simpliﬁed by removing the
member algorithms that do not contribute at all to its performance (meaning removing
these algorithms has no effect on the performance of P on the training set). Considering
the size of P is bounded (line 3), removing the redundant algorithms from P is meaningful
because this will leave space for new member algorithms that can improve the performance 

","The PCIT approach is an instance transfer method for improving the quality of instance grouping in Population-Based Optimization Algorithms (PBOAs). It uses an instance transfer mechanism to im-prove the quality of instance grouping, which enables the construction of high-quality parallel solvers. The basic idea behind PCIT is to identify powerful parallel portfolios by transferring instances between different groups and using this information to improve the performance of the individual algorithms within each group.",5.788288116455078,"The PAP approach called ""PCIT"" (Parallel Configuration Instance Transfer) utilizes an instance transfer mechanism to enhance the quality of instance grouping. It identifies ""dissimilar"" instances that cannot be solved satisfactorily by the corresponding incumbents found through an automatic configuration (AC) procedure. PCIT constructs a target subset for each transferred instance based on how well the incumbent configuration performs on similar instances, aiming to provide high-quality parallel solvers with minimal human intervention. It builds empirical performance models to predict how the incumbents would perform on transferred instances, thus avoiding significant computational costs. The effectiveness of PCIT has been demonstrated through experiments in problem domains such as SAT and TSP."
llama3.2:latest,"What is the idea behind the PAP approach called ""CEPS""?
","Document 1: 
 also presented. The performance of the two instantiations on
TSP and VRPSPDTW problems support the effectiveness of
CEPS in the sense that, in comparison with state-of-the-art
PAP construction approaches, the PAPs obtained by CEPS
achieves better generalization performance.
Since CEPS is a generic framework, some discussions
would help elaborate issues that are of signiﬁcance in practice.
First, although this work assumes CEPS takes a set of initial
training instances as the input, such training instances are
not necessarily real-world instances but could be generated
randomly. In other words, CEPS could be used in a fully cold-
start setting (a.k.a. zero-shot), i.e., no real-world instances are
available for the target problem class. Further, CEPS could
either be run ofﬂine or online, i.e., it could accommodate new
real instances whenever available.
Second, the potential of CEPS could be further explored
by taking advantage of the data generated during its run,
except for the ﬁnal obtained PAP. The data contain all the
sampled conﬁgurations and instances, and the performance
of the former on the latter. Considering that when using
a search method to solve a problem instance, its optimal
parameter values are usually problem-instance dependent and
thus need to be tuned. To tune parameters for a new problem
instance, we can learn from the historical data generated by
CEPS to build a mapping from problem instances to their
optimal parameter values, i.e., a low-cost online parameter- 

Document 2: 
 paper has two major contributions. First, the proposed PAP is
developed for numerical optimization instead of combinatorial
optimization. Second, we investigate the term “risk” in a
different context. Previous work mainly aimed to reduce the
risk of an algorithm on a speciﬁc optimization problem, which
can be measured by applying the algorithm to the problem
for multiple times. In this paper, we are more interested in
reducing the risk overa set of problems , i.e., the risk is
measured by applying the algorithm to multiple problems.
Our PAP is a general framework for combining different
population-based search algorithms. It allocates computation
time among more than one constituent algorithm and acti-
vates interaction among them so that they can beneﬁt from
one another. To be more speciﬁc, the computation time is
measured by the number of ﬁtness evaluations (FEs), and
the allocation of FEs is implemented by dividing the whole
population into several subpopulations and evolving them in
a parallel manner (using different constituent algorithms). To
demonstrate the efﬁcacy of the proposed PAP, we chose four
existing population-based algorithms, including self-adaptive
differential evolution with neighborhood search (SaNSDE)
[7], particle swarm optimizer with inertia weight (wPSO)
[8], generalized generation gap (G3) model with generic
parent-centric recombination (PCX) operator (G3PCX) [9],
and covariance matrix adaptation evolution strategy (CMA-
ES) [10], as the constituent algorithms. These algorithms 

Document 3: 
 this approach no longer guarantees the validity of the above
assumption. As a consequence, Θ′may generalize worse than
Θ. A remedy to prevent this as much as possible is to increase
redundancy in the evolution of the PAP. More speciﬁcally, one
could repeat the conﬁguration-removal procedure to Θ for n
times, leading to ntemporary PAPs, ¯Θ1,..., ¯Θn; then for each
temporary PAP ¯Θ, the new conﬁgurations are identiﬁed and
inserted, leading to n new PAPs, Θ′
1,..., Θ′
n, each of which
is of the same size as Θ; ﬁnally, the PAP among them that
performs best against T ∪T′ is retained.
III. C O-EVOLUTION OF PARAMETERIZED SEARCH
By incorporating the above-described procedure into the co-
evolution process, we arrive at the proposed CEPS framework,
as demonstrated in Algorithm 1. In general, CEPS consists
of two major phases, i.e., an initialization phase (lines 2-
7), and a co-evolution phase (lines 8-27) which could be
further subdivided into alternating between the evolution of
the conﬁguration population (representing the PAP) (lines 10-
15) and the evolution of the instance population (representing
the training instances) (lines 17-26) for MaxIte iterations in
total. These modules are detailed as follows. 

Document 4: 
 contributions of this paper include:
1) A novel PAP construction framework, namely Co-
Evolution of Parameterized Search (CEPS), is proposed.
It is also shown that CEPS approximates a process that
minimizes the upper bound, i.e., a tractable surrogate,
of the generalization performance.
2) To demonstrate the implementation details of CEPS as
well as to assess its potential, concrete instantiations are
also presented for two hard optimization problems, i.e.,
TSP and the Vehicle Routing Problem with Simultane-
ous Pickup–Delivery and Time Windows (VRPSPDTW)
[18]. Computational studies conﬁrm that CEPS is able
to obtain PAPs with better generalization performance.
3) The proposal of CEPS extends the realm of Co-
Evolution, for the ﬁrst time, to evolving algorithm
conﬁgurations and problem instances. Since CEPS does
not invoke domain-speciﬁc knowledge, its potential ap-
plications can go beyond optimization problems, even to
planning and learning problems.
The rest of the paper is organized as follows. Section II in-
troduces the challenge of seeking generalizable PAPs, existing
PAP construction methods, as well as the theoretical insight
behind CEPS. Section III presents the CEPS framework. Sec-
tion IV presents its instantiations for TSP and VRPSPDTW.
Computational studies on these two problems are presented in
Section V. Threats to validity of this study are discussed in 

Document 5: 
 that ihvr ∈(0, 1], and a larger value of ihvr is better. IHVR can distinguish well between
MOEAs with a different performance, and can also save a lot of calculations. In this work,
IHVR is used as the performance metric Metric .
4.3. Automatic Construction Approach
Algorithm 1 presents the automatic construction approach for MOEAs/PAP . Starting
from an empty set (line 2), the approach constructs the PAP (denoted as P) iteratively.
Speciﬁcally, each iteration of the approach (lines 3–15) consists of two subsequent phases.
In the ﬁrst phase, an existing automatic algorithm conﬁguration tool, namely SMAC 3 [44],
is used to search in Θ to ﬁnd the algorithm that can improve the performance of the current
PAP to the largest extent (line 5), and then this algorithm is inserted into P (line 6). This
phase is similar to the commonly-used greedy approach in the automatic construction of
PAPs [27,31]. Additionally, we introduce a new phase, namely simpliﬁcation, as the second
phase in Algorithm 1. In this phase (lines 7–14), P would be simpliﬁed by removing the
member algorithms that do not contribute at all to its performance (meaning removing
these algorithms has no effect on the performance of P on the training set). Considering
the size of P is bounded (line 3), removing the redundant algorithms from P is meaningful
because this will leave space for new member algorithms that can improve the performance 

Document 6: 
 cores each (2.20 GHz, 30 MB Cache), running Centos 7.5.
D. Results and Analysis
We report the #TOs, PAR-10 and PANC achieved by the
PAPs on the testing set in Table II and also visualize their
medians and variance across all the testing instances by box-
plots in Figure 1. Note the mean value is also plotted in Figure
1 (indicated by “ ▲”) to show that for a PAP how its PAR-
10/PANC is affected by the outliers (the timeout cases) which
would be hidden by boxplots. In Table II the #TOs, PAR-
10/PANC of a PAP is highlighted in grey if it achieved the best
performance. One could make three important observations
from these results. First, the PAPs obtained by CEPS have
the smallest number of timeouts in all the six experiments,
which means they have the highest success rate for solving the
testing instances among all the tested PAPs. Recall that CEPS
actively searches in the instance space to identify the hard-
to-solve instances for further improving the generalization of
the PAPs. Such a mechanism makes CEPS the method that is
least affected by the hard testing instances which signiﬁcantly
differs from the given training instances. This could be further
veriﬁed by Figure 1, in which CEPS is the method that has
the least gap between the mean value (which takes timeouts
into account) and median value (which naturally ﬁlters out the 

","I couldn't find any information about a specific approach called ""CEPS"" being associated with the PAP (Polarized Alternative Approach) method. The Polarized Alternative Approach (PAP) is a method used in public administration and policy analysis to analyze policy issues from different perspectives or alternatives.

However, I did find that CEPS stands for Community Engagement and Participation Strategy, which is a concept used in community development and participatory planning. It's possible that the PAP approach uses this framework as one of its strategies, but without more context, it's difficult to say for certain.

If you have any further information or clarification about the ""CEPS"" approach within the PAP method, I'll do my best to provide a more specific answer.",6.1481781005859375,"The PAP approach called ""Co-Evolution of Parameterized Search"" (CEPS) is designed to enhance the construction of Parameterized Algorithm Portfolios (PAPs) by effectively combining different population-based search algorithms. The key idea behind CEPS is to co-evolve both algorithm configurations and problem instances, which allows the framework to learn from both the algorithms and the specific characteristics of the problems being solved. The framework consists of two main phases: an initialization phase and a co-evolution phase that alternates between evolving a configuration population (representing the PAP) and an instance population (representing the training instances). CEPS aims to reduce the generalization error of PAPs across a set of problems rather than on individual instances, facilitating adaptation to varying types of problems for better overall performance. This approach also supports both offline and online operations, making it flexible in handling incoming problem instances."
llama3.2:latest,"Please give me the names of some state-of-the-art SAT solvers.
","Document 1: 
 of determining whether a Boolean formula can 
evaluate to true, benefits from very mature and 
advanced algorithms with large practical impact.
Application and research domains like software 
and hardware verification, automated planning,
computational biology, and many others benefit 
from modern SAT solvers. These domains have 
large and difficult instances that provide the SAT 
community with meaningful benchmarks. 
Most of the following challenges are general in 
such a way that the questions they raise should 
positively affect not only research in parallel SAT 
but in parallel search in general. We first present 
the current situation in sequential and parallel SAT 
solving and then give a set of challenges. Each of 
these challenges comes with an overly optimistic 
estimate of its inherent difficulty represented as 
black circles, where we would estimate that every 
black circle represents, roughly, about two years of 
research. 
Context: Sequential SAT Solvers 
State-of-the-art solvers extend the original Davis,
Putnam, Logemann, and Loveland (DPLL) proce -
dure (Davis, Logemann, and Loveland 1962) with 
conflict analysis (Zhang et al. 2001). The general
architecture of such conflict-directed clause-learn -
ing solvers (CDCL) is presented in figure 1. These 
procedures include an optional preprocessing step 
0, which performs variable elimination and clause 
subsumption checks in order to reduce the size of 
the formula and improve the performance of the 

Document 2: 
 Intelligence (AAAI’02), (pp. 674–681). AAAI Press / The MIT Press, Menlo Park, CA, USA.
KhudaBukhsh, A., Xu, L., Hoos, H. H., & Leyton-Brown, K. (2009). SATenstein: Automatically building lo-
cal search sat solvers from components. In Proceedings of the Twenty-ﬁrst International Joint Conference
on Artiﬁcial Intelligence (IJCAI’09), (pp. 517–524).
Le Berre, D. & Simon, L. (2004). Fifty-ﬁve solvers in Vancouver: The SAT 2004 competition. In Hoos, H. H.
& Mitchell, D. G. (Eds.), Theory and Applications of Satisﬁability Testing: Proceedings of the Seventh
International Conference (SAT’04), volume 3542 of Lecture Notes in Computer Science , (pp. 321–344).
Springer Verlag.
Leyton-Brown, K., Nudelman, E., & Shoham, Y . (2002). Learning the empirical hardness of optimization
problems: The case of combinatorial auctions. In Hentenryck, P. V . (Ed.), Principles and Practice of
Constraint Programming – CP 2002: Eighth International Conference , volume 2470 of Lecture Notes in
Computer Science, (pp. 556–572). Springer Verlag, Berlin, Germany. 

Document 3: 
 212
state-of-the-art SLS algorithms. SATenstein-LS has
41 parameters that control the selection and behavior of
its components, leading to a total conﬁguration space of
size 4.82 ×1012. Automatically-identiﬁed conﬁgurations of
SATenstein-LS have been shown to achieve better per-
formance than existing state-of-the-art SLS algorithms on
several well-known instance distributions.
Instances
We investigated the effectiveness of Hydra on four distri-
butions, drawing on well-known families of SAT instances.
Because no state-of-the-art SLS algorithms are able to prove
unsatisﬁability, we considered only satisﬁable instances. We
identiﬁed these by running all complete algorithms that won
a SAT competition category between 2002 and 2007 for
one hour. First, the BM data set is constructed from 500
instances taken from each of the six distributions used by
KhudaBukhsh et al. (2009) (
QCP, SWGCP, FACT, CBMC,
R3FIX, and HGEN), split evenly into training and test sets.
Second, the INDU data set is a mixture of 500 instances
from each of the CBMC and FACT distributions, again split
evenly into training and test sets. Third and fourth, the HAND
and RAND data sets include all satisﬁable instances from the
Random and Handmade categories of the SAT Competitions 

Document 4: 
 form (a conjunction of disjunctions of variables and their negations) and determine a satisﬁable assignment or prove that 
none exists. An incomplete SAT solver can ﬁnd satisfying assignments, but not prove unsatisﬁability.
Most state-of-the-art complete SAT solvers are based on conﬂict-driven clause learning (CDCL; [57]). Their parameters 
control variable selection for branching decisions, clause learning and restart techniques. State-of-the-art incomplete SAT 
solvers use stochastic local search (SLS; [38]), and their parameters control the selection of the variable whose value is 
modiﬁed in each local search step as well as the diversiﬁcation and additional intensiﬁcation strategies. Furthermore, there 
exist several preprocessing techniques (e.g., [21]) to simplify formulas and their parameters control how long and how 
aggressive preprocessing will be used – too much preprocessing can remove important structural information and hence, 
it can increase the hardness of formulas. The eﬃcacy of SAT solvers depends on multiple heuristic components whose 
basic functions and the interplay between them are controlled by parameters. Some parameters are categorical (e.g., choice 
between different search strategies in SLS), while many others are integer- or real-valued (e.g., the damping factor used in 
computing heuristic variable scores in CDCL).
Parallel SAT solvers have received increasing attention in recent years. ManySAT [30,31,29] was one of the ﬁrst parallel 

Document 5: 
 tial solver baselines, indicating the great benefit by combin-
ing complementary configurations obtained from a rich con-
figuration space.
Comparison with Hand-designed Parallel Solvers
To further evaluate the portfolios constructed by PCIT, we
compared them with the state-of-the-art manually designed
parallel solvers. Specifically, we considered the ones con-
structed for SAT. We chose Priss6 (Manthey, Stephan, and
Werner 2016) to compare with the one constructed in SAT-
Single, since Priss6 is the official parallel version of Riss6
(the base solver in SAT-Single). For the same reason, we
chose PfolioUZK (Wotzlaw et al. 2012) (the gold medal
winning solver of the parallel track of the SAT’12 Chal-
lenge) to compare with the one constructed in SAT-Multi.
Finally, we chose Plingeling (version bbc) (Biere 2016),
the gold medal winning solver of the parallel track of the
SAT’16 Competition, to compare with both. Note that all
the manually designed solvers considered here have imple-
mented far more advanced parallel solving strategies (e.g.,
clause sharing) than only independently running component
solvers in parallel. In the experiments the default settings of
these solvers were used and the same statistical tests as be-
fore were conducted. As shown in Table 4, on SAT-Single 

Document 6: 
 ACM 52(10):56–67.
Balyo, T.; Heule, M. J. H.; and J¨arvisalo, M., eds. 2016. Proceed-
ings of SAT Competition 2016: Solver and Benchmark Descrip-
tions, volume B-2016-1 of Department of Computer Science Se-
ries of Publications B. University of Helsinki.
Battiti, R.; Brunato, M.; and Mascia, F., eds. 2008. Reactive
Search and Intelligent Optimization. Springer.
Biere, A. 2016. Splatz, Lingeling, Plingeling, Treengeling, Yal-
SAT Entering the SAT Competition 2016. In Balyo et al. (2016),
44–45.
Burke, E. K.; Gendreau, M.; Hyde, M.; Kendall, G.; Ochoa, G.;
¨Ozcan, E.; and Qu, R. 2013. Hyper-heuristics: A Survey of the
State of the Art. Journal of the Operational Research Society
64(12):1695–1724.
Gomes, C. P., and Selman, B. 2001. Algorithm Portfolios. Arti-
ficial Intelligence 126(1-2):43–62.
Hamadi, Y ., and Wintersteiger, C. M. 2013. Seven Challenges in
Parallel SAT Solving. AI Magazine 34(2):99–106. 

","Here are some mentioned state-of-the-art SAT solvers:

1. Priss6 (Manthey, Stephan, and Werner 2016)
2. PfolioUZK (Wotzlaw et al. 2012)
3. Plingeling (version bbc) (Biere 2016)
4. SATenstein-LS",5.6491663455963135,"Some state-of-the-art SAT solvers include SATenstein, Priss6, PfolioUZK, and Plingeling."
llama3.2:latest,"Please give me the names of some state-of-the-art TSP solvers.
","Document 1: 
 For surveys of the problem and its applications, the reader is referred to the excellent
volumes edited by Lawler et al. [24] and Gutin and Punnen [11].
Local search with k-exchange neighborhoods, k-opt, is the most widely used heu-
ristic method for the TSP. k-opt is a tour improvement algorithm, where in each step
k links of the current tour are replaced by k links in such a way that a shorter tour is
achieved.
It has been shown [7] that k-opt may take an exponential number of iterations and
that the ratio of the length of an optimal tour to the length of a tour constructed byk-opt
can be arbitrarily large when k ≤ n/2 − 5. Such undesirable cases, however, are very
rare when solving practical instances [31]. Usually, high-quality solutions are obtained
in polynomial time. This is, for example, the case for the Lin–Kernighan heuristic,
one of the most effective methods for generating optimal or near-optimal solutions
for the symmetric TSP. High-quality solutions are often obtained, even though only a
small part of the k-exchange neighborhood is searched.
In the original version of the Lin–Kernighan heuristic [ 25], the allowable
k-exchanges (or k-opt moves) are restricted to those that can be decomposed into a
2- or 3-exchange followed by a (possibly empty) sequence of 2-exchanges. This restric- 

Document 2: 
 of determining whether a Boolean formula can 
evaluate to true, benefits from very mature and 
advanced algorithms with large practical impact.
Application and research domains like software 
and hardware verification, automated planning,
computational biology, and many others benefit 
from modern SAT solvers. These domains have 
large and difficult instances that provide the SAT 
community with meaningful benchmarks. 
Most of the following challenges are general in 
such a way that the questions they raise should 
positively affect not only research in parallel SAT 
but in parallel search in general. We first present 
the current situation in sequential and parallel SAT 
solving and then give a set of challenges. Each of 
these challenges comes with an overly optimistic 
estimate of its inherent difficulty represented as 
black circles, where we would estimate that every 
black circle represents, roughly, about two years of 
research. 
Context: Sequential SAT Solvers 
State-of-the-art solvers extend the original Davis,
Putnam, Logemann, and Loveland (DPLL) proce -
dure (Davis, Logemann, and Loveland 1962) with 
conflict analysis (Zhang et al. 2001). The general
architecture of such conflict-directed clause-learn -
ing solvers (CDCL) is presented in figure 1. These 
procedures include an optional preprocessing step 
0, which performs variable elimination and clause 
subsumption checks in order to reduce the size of 
the formula and improve the performance of the 

Document 3: 
 10.0 
12.5 
15.0 
17.5 PAR-10 (c) TSP-3
Fig. 2: Visual comparison in boxplots of the medians and variance of the test performance of each TSP solver across the
testing instances. Note the mean value is also plotted, indicated by “ ▲”.
TABLE III: Comparison of the state-of-the-art TSP solvers
with the PAPs obtained by CEPS, on the testing set. #TOs
refers to number of total timeouts. PAR-10 is the penalized
average runtime-10. Performance of a solver is highlighted in
grey if it achieved the best testing performance.
TSP-1 TSP-2 TSP-3
#TOs PAR-10 #TOs PAR-10 #TOs PAR-10
LKH-default 131 30.84 137 31.98 150 34.73
LKH-tuned 29 8.23 34 9.40 27 7.67
EAX-default 69 17.98 73 18.91 69 17.95
EAX-tuned 33 10.97 30 10.38 29 10.12
VBS 6 3.82 7 4.26 6 4.13
CEPS 6 2.74 4 2.15 2 1.94
signiﬁcant performance improvement, though still obviously
falling behind of the PAPs obtained by CEPS. Second, the only
solver that could match the PAP’s performance level in one
of the three scenarios, is the VBS of the algorithm portfolio
considered by the algorithm selection approaches [29], [30].
However, in TSP-2 and TSP-3, the performance advantage of 

Document 4: 
 troduces the challenge of seeking generalizable PAPs, existing
PAP construction methods, as well as the theoretical insight
behind CEPS. Section III presents the CEPS framework. Sec-
tion IV presents its instantiations for TSP and VRPSPDTW.
Computational studies on these two problems are presented in
Section V. Threats to validity of this study are discussed in
Section VI. Section VII concludes the paper with discussions.
II. P ARAMETERIZED SOLVERS MADE GENERALIZABLE
A. Notations and Problem Description
Assume a PAP is to be built for a problem class (e.g., TSP),
for which an instance of the problem class is denoted as s, and
the set of all possible sis denoted as Ω. Given a parameterized
algorithm, each component solver of the PAP is a conﬁguration
(full instantiation) of the algorithm. Generally speaking, the
parameterized algorithm can be any concrete computational
process, e.g., a traditional heuristic search process such as the
LK Heuristic for TSP or even a neural network [19]–[21] that
outputs a solution for a given instance of the target problem
class. Let θ denote a conﬁguration and let Θ denote a PAP
that contains K different conﬁgurations (component solvers),
i.e., Θ = {θ1,...,θ K}. The quality of a conﬁguration θ on a 

Document 5: 
 H. Trautmann, “Evolving diverse TSP instances by means of novel and
creative mutation operators,” in Proceedings of the 15th ACM/SIGEVO
Conference on Foundations of Genetic Algorithms, FOGA’2019. Pots-
dam, Germany: ACM, Aug 2019, pp. 58–71.
[38] Y . Nagata and S. Kobayashi, “A powerful genetic algorithm using edge
assembly crossover for the traveling salesman problem,” INFORMS
Journal on Computing , vol. 25, no. 2, pp. 346–363, 2013.
[39] X. Xie and J. Liu, “Multiagent optimization system for solving the
traveling salesman problem (tsp),” IEEE Transactions on Systems, Man,
and Cybernetics, Part B , vol. 39, no. 2, pp. 489–502, 2009.
[40] C. Wang, D. Mu, F. Zhao, and J. W. Sutherland, “A parallel simulated
annealing method for the vehicle routing problem with simultaneous
pickup-delivery and time windows,” Computers & Industrial Engineer-
ing, vol. 83, pp. 111–122, 2015.
[41] W. Huang and T. Zhang, “Vehicle routing problem with simultaneous
pick-up and delivery and time-windows based on improved global arti-
ﬁcial ﬁsh swarm algorithm,” Computer Engineering and Applications ,
vol. 52, no. 21, pp. 21–29, 2016. 

Document 6: 
 Portfolio-based algorithm selection for SAT,” Journal of Artiﬁcial In-
telligence Research, vol. 32, pp. 565–606, 2008.
[29] P. Kerschke, L. Kotthoff, J. Bossek, H. H. Hoos, and H. Trautmann,
“Leveraging TSP solver complementarity through machine learning,”
Evolutionary Computation, vol. 26, no. 4, pp. 597–620, 2018.
[30] K. Zhao, S. Liu, Y . Rong, and J. X. Yu, “Leveraging TSP solver
complementarity via deep learning,” arXiv preprint arXiv:2006.00715 ,
2020.
[31] L. Kotthoff, “Algorithm selection for combinatorial search problems: A
survey,” AI Magazine, vol. 35, no. 3, pp. 48–60, 2014.
[32] C. D. Rosin and R. K. Belew, “New methods for competitive coevolu-
tion,” Evolutionary Computation, vol. 5, no. 1, pp. 1–29, 1997.
[33] J. I. van Hemert, “Evolving combinatorial problem instances that are
difﬁcult to solve,” Evolutionary Computation , vol. 14, no. 4, pp. 433–
462, 2006.
[34] K. Helsgaun, “General k-opt submoves for the Lin-Kernighan TSP 

","Here are some state-of-the-art Traveling Salesman Problem (TSP) solvers:

1. **Google OR-Tools**: A free, open-source software framework for optimization problems, including TSP. It uses a combination of exact and approximate methods to solve TSP instances.
2. **OpenTSP**: An open-source software package specifically designed for solving TSP instances. It uses various algorithms, including the Christofides algorithm and genetic algorithms.
3. **Concorde**: A widely used TSP solver that has been shown to be one of the fastest exact solvers for large instances. It is based on a combination of cutting plane methods and branch-and-bound techniques.
4. **Dantzig Solver**: A state-of-the-art solver developed by IBM Research, which uses a combination of exact and approximate methods, including a novel algorithm that leverages graph neural networks.
5. **Sabre**: An open-source TSP solver that uses a combination of genetic algorithms and simulated annealing to solve instances.
6. **TSPLIB**: A software package that contains a collection of well-known TSP instances, along with their solution data. It also includes some simple solvers for smaller instances.
7. **Scipy's LinearProgramming**: While not specifically designed for TSP, the SciPy library in Python can be used to solve linear programs, including those related to TSP.

Please note that the choice of solver depends on the size and complexity of the instance, as well as the desired trade-off between speed and accuracy.",10.182646036148071,"Some state-of-the-art TSP solvers mentioned include the Lin–Kernighan heuristic (LKH), the Effective Ant Colony (EAX), and the Variable Neighborhood Search (VBS). These solvers have been compared in performance metrics such as PAR-10 and number of timeouts (TOs) across different testing instances."
llama3.2:latest,"Please give me the names of some state-of-the-art Automatic Algorithm Configuration approaches.
","Document 1: 
 Journal of Artiﬁcial Intelligence Research 75 (2022) 425-487 Submitted 02/2022; published 10/2022
A Survey of Methods for Automated
Algorithm Conﬁguration
Elias Schede elias.schede@uni-bielefeld.de
Decision and Operation Technologies Group,
Bielefeld University, Bielefeld, Germany
Jasmin Brandt jasmin.brandt@upb.de
Alexander Tornede alexander.tornede@upb.de
Department of Computer Science,
Paderborn University, Paderborn, Germany
Marcel Wever marcel.wever@ifi.lmu.de
Institute of Informatics, LMU Munich &
Munich Center for Machine Learning, Munich, Germany
Viktor Bengs viktor.bengs@ifi.lmu.de
Institute of Informatics,
LMU Munich, Munich, Germany
Eyke H¨ ullermeier eyke@lmu.de
Institute of Informatics, LMU Munich &
Munich Center for Machine Learning, Munich, Germany
Kevin Tierney kevin.tierney@uni-bielefeld.de
Decision and Operation Technologies Group,
Bielefeld University, Bielefeld, Germany
Abstract
Algorithm conﬁguration (AC) is concerned with the automated search of the most
suitable parameter conﬁguration of a parametrized algorithm. There is currently a wide
variety of AC problem variants and methods proposed in the literature. Existing reviews 

Document 2: 
 2 Related Work
2.1 Automatic Algorithm Conﬁguration
Several approaches exist in the literature for the automatic tuning
of algorithms. Some of these were created for a speciﬁc algorithm
or task. For example, [24] devises a modular algorithm for solving
constraint satisfaction problems (CSPs). Using a combination of ex-
haustive enumeration of all possible conﬁgurations and parallel hill-
climbing, the technique automatically conﬁgures the system for a
given set of training instances. Another approach, presented in [30],
focuses on the conﬁguration of adaptive algorithms, employing a se-
quential parameter optimization approach.
Other approaches automatically design and build an entire solver
to best tackle a set of example training instances. For example, [28]
uses genetic programming to create an evolutionary algorithm (EA).
Here the chromosome is an EA operation like the selection of par-
ents, mutation, or crossover, and the task is to ﬁnd a sequence of
the genetic programming operators that is best suited for the speci-
ﬁed problem. For SAT, [8] classiﬁes local search (LS) approaches by
means of context-free grammars. This approach then uses a genetic
programming approach to select a good LS algorithm for a given set
of instances.
There also exist approaches that are applicable to more general al-
gorithms. For example, in order to tune continuous parameters, [5]
suggests an approach that determines good parameters for individual
training instances. This approach ﬁrst evaluates the extreme param- 

Document 3: 
 470
A Survey of Methods for Automated Algorithm Configuration
General AC systems
D-SMAC https://github.com/tqichun/distributed-SMAC3
GPS https://github.com/YashaPushak/GPS
irace https://github.com/MLopez-Ibanez/irace
OAT (GGA) https://docs.optano.com/algorithm.tuner/current/
ParamILS https://www.cs.ubc.ca/labs/algorithms/Projects/ParamILS/
PyDGGA http://ulog.udl.cat/software/
REVAC https://github.com/ChrisTimperley/RubyREVAC
SMAC 3 https://github.com/automl/SMAC3
Benchmarks
AClib https://bitbucket.org/mlindauer/aclib2/src/master/
DAC https://github.com/automl/DAC
Table 7: List of available software in the realm of AC.
References
Belarmino Adenso-Diaz & Manuel Laguna. Fine-tuning of algorithms using fractional ex-
perimental designs and local search. Operations research, 54(1):99–114, 2006.
¨Ozg¨ ur Akg¨ un, Nguyen Dang, Ian Miguel, Andr´ as Z Salamon, & Christopher Stone. In- 

Document 4: 
 cal (e.g., choice of heuristic). Categorical parameters can be used to select and combine discrete
building blocks of an algorithm (e.g., preprocessing and variable ordering heuristics); consequently,
our general view of algorithm conﬁguration includes the automated construction of a heuristic algo-
rithm from such building blocks. To the best of our knowledge, the methods discussed in this article
are yet the only general ones available for the conﬁguration of algorithms with many categorical
parameters.
We now give an overview of what follows and highlight our main contributions. After for-
mally stating the algorithm conﬁguration problem in Section 2, in Section 3 we describe ParamILS
(ﬁrst introduced by Hutter, Hoos & St ¨utzle, 2007), a versatile stochastic local search approach for
automated algorithm conﬁguration, and two of its instantiations, BasicILS and FocusedILS.
We then introduce adaptive capping of algorithm runs, a novel technique that can be used to
enhance search-based algorithm conﬁguration procedures independently of the underlying search
strategy (Section 4). Adaptive capping is based on the idea of avoiding unnecessary runs of the
algorithm to be conﬁgured by developing bounds on the performance measure to be optimized.
We present a trajectory-preserving variant and a heuristic extension of this technique. After dis-
cussing experimental preliminaries in Section 5, in Section 6 we present empirical evidence show-
ing that adaptive capping speeds up both BasicILS and FocusedILS. We also show that BasicILS
268 

Document 5: 
 rithm conﬁguration that minimizes some cost measure over the 
set of instances that will be seen during the production phase. 
In other words, the ﬁnal goal is that the conﬁguration of the al- 
gorithm found during the tuning phase generalizes to similar but 
unseen instances. The tuning phase may also use automatic conﬁg- 
uration methods repeatedly while engineering an algorithm [71] . 
Due to the separation between a tuning and a production phase, 
automatic algorithm conﬁguration is also known as oﬄine param- 
eter tuning to differentiate it from online approaches that adapt or 
control parameter settings while solving an instance [13,50] . Nev- 
ertheless, online approaches also contain parameters that need to 
be deﬁned oﬄine, for example, which and how parameters are 
adapted at run-time; such parameters and design choices can be 
conﬁgured by an oﬄine tuning method [59] . 
In our research on making the algorithm conﬁguration process 
more automatic , we have focused on racing approaches. Birattari 
et al. [19,20] proposed an automatic conﬁguration approach, F- 
Race, based on racing [64] and Friedman’s non-parametric two-way 
analysis of variance by ranks. This proposal was later improved 
by sampling conﬁgurations from the parameter space, and reﬁn- 
ing the sampling distribution by means of repeated applications of 
F-Race. The resulting automatic conﬁguration approach was called 
Iterated F-race (I/F-Race) [10,21] . Although a formal description of 

Document 6: 
 formance of FocusedILS [43], and we are convinced that, at least in cases where
the parameter response of a given target algorithm is reasonably regular and per-
formance evaluations are very costly, such advanced SMBO methods hold great
promise.
3.6 Conclusions and Future Work
Automated algorithm conﬁguration and parameter tuning methods have been de-
veloped and used for more than a decade, and many of the fundamental techniques
date back even further. However, it has only recently become possible to effectively
solve complex conﬁguration problems involving target algorithms with dozens of
parameters, which are often categorical and conditional. This success is based in
3 Automated Algorithm Conﬁguration and Parameter Tuning 65
part on the increased availability of computational resources, but has mostly been
enabled by methodological advances underlying recent conﬁguration procedures.
Still, we see much room (and, indeed, need) for future work on automated algo-
rithm conﬁguration and parameter tuning methods. We believe that in developing
such methods, the fundamental features underlying all three types of methods dis-
cussed in this chapter can play an important role, and that the best methods will
employ combinations of these. We further believe that different conﬁguration pro-
cedures will likely be most effective for solving different types of conﬁguration
problems (depending, in particular, on the number and type of target algorithm pa-
rameters, but also on regularities in the parameter response). Therefore, we see a
need for research aiming to determine which conﬁgurator is most effective under 

","Here are some state-of-the-art Automatic Algorithm Configuration (AAC) approaches:

1. **Parameter-free Bayesian Optimization**:
	* **Uncertainty-aware Bayesian optimization**: This approach uses uncertainty estimation to optimize hyperparameters without explicit bounds.
	* **Randomized Bayesian optimization**: This approach combines Bayesian optimization with random search to improve efficiency and robustness.
2. **Stochastic Model-Based Optimization (SMBO)**:
	* **FocusedILS** (Iterative Learning System): A SMBO approach that uses a learning system to adaptively select the most informative points in the search space.
	* **F-Search**: A SMBO approach that combines model-based optimization with Bayesian optimization.
3. **Meta-Learning and Knowledge Distillation**:
	* **ML-KD (Meta-Learning-based Knowledge Distillation)**: This approach uses meta-learning to learn a compact representation of a target algorithm's hyperparameters, which can be used for configuration.
4. **Deep Learning-based Methods**:
	* **Hyperband**: A deep learning-based approach that uses reinforcement learning to optimize hyperparameters in a search space.
	* **Auto-ILS (Auto-tuning with ILS)**: This approach uses autoencoders to learn a compact representation of an algorithm's behavior, which can be used for configuration.
5. **Evolutionary Computation and Evolutionary Optimization**:
	* **PESO (Personalized Expectation-based Search Optimization)**: An evolutionary optimization approach that uses personalized expectations to guide the search process.
6. **Adaptive Capping Methods**:
	* **Adaptive Capping**: This is a technique used in BasicILS and FocusedILS to adaptively cap the number of algorithm runs based on the performance improvement achieved so far.
7. **Hierarchical Optimization Methods**:
	* **Hierarchical Optimization**: A method that uses hierarchical search strategies to efficiently explore the search space.

Note that this is not an exhaustive list, and new AAC approaches are being developed and published in the research community regularly.",12.331979990005491,"Some state-of-the-art Automatic Algorithm Configuration approaches include D-SMAC, GPS, irace, OAT (GGA), ParamILS, PyDGGA, REVAC, and SMAC 3."
llama3.2:latest,"What is the idea behind the AAC approach called ""irace""?
","Document 1: 
 analysis of variance by ranks. This proposal was later improved 
by sampling conﬁgurations from the parameter space, and reﬁn- 
ing the sampling distribution by means of repeated applications of 
F-Race. The resulting automatic conﬁguration approach was called 
Iterated F-race (I/F-Race) [10,21] . Although a formal description of 
the I/F-Race procedure is given in those publications, an imple- 
mentation was not made publicly available. The irace package im- 
plements a general iterated racing procedure, which includes I/F- 
Race as a special case. It also implements several extensions al- 
ready described by Birattari [19] , such as the use of the paired 
t -test instead of Friedman’s test. Finally, irace incorporates sev- 
eral improvements not published before, such as sampling from a 
truncated normal distribution, a parallel implementation, a restart 
strategy that avoids premature convergence, and an elitist racing 
procedure to ensure that the best parameter conﬁgurations found 
are also evaluated on the highest number of training instances. 
The paper is structured as follows. Section 2 introduces the 
algorithm conﬁguration problem and gives an overview of ap- 
proaches to automatic algorithm conﬁguration. Section 3 describes 
the iterated racing procedure as implemented in the irace pack- 
age as well as several further extensions including the elitist irace . 
Section 4 illustrates the steps followed to apply irace to two con- 

Document 2: 
 5.2. Multi-objective optimization metaheuristics 
Besides the application to the MOACO framework described 
above [58] , irace has been applied to aid in the design of other 
multi-objective optimization algorithms. Dubois-Lacoste et al. 
[31] used irace to tune a hybrid of two-phase local search and 
Pareto local search (TP + PLS) to produce new state-of-the-art al- 
gorithms for various bi-objective permutation ﬂowshop problems. 
Fisset et al. [33] used irace to tune a framework of multi-objective 
optimization algorithms for clustering. When applied to a suﬃ- 
ciently ﬂexible algorithmic framework, irace has been used to de- 
sign new state-of-the-art multi-objective evolutionary algorithms 
[16,17] . 
5.3. Anytime algorithms (improve time-quality trade-offs) 
There is often a trade-off between solution quality and com- 
putation time: Algorithms that converge quickly tend to produce 
better solutions for shorter runtimes, whereas more exploratory al- 
gorithms tend to produce better solutions for longer runtimes. Im- 
proving the anytime behavior of an algorithm amounts to improv- 
ing the trade-off curve between solution quality and computation 
time such that an algorithm is able to produce as high quality so- 
lutions as possible at any moment during their execution. López- 

Document 3: 
 effect on the budget consumed is lower. The same experiment for 
the ACOTSP scenario showed that the best conﬁgurations become 
worse when T new or T ﬁrst are increased. This is due to the fact that 
ACOTSP has a homogeneous training set and, therefore, sampling 
new candidates is more important than executing a large number 
of instances. 
5. Other applications of irace 
Since the ﬁrst version of the irace package became publicly 
available in 2012, there have been many other applications of 
irace . In this section, we provide a list of the applications of the 
irace package of which we are aware at the time of writing. Some 
of these applications go beyond what is traditionally understood as 
algorithm conﬁguration, demonstrating the ﬂexibility of irace . 
54 M. López-Ibáñez et al. / Operations Research Perspectives 3 (2016) 43–58 
5.1. Algorithm conﬁguration 
The traditional application of irace is the automatic conﬁgura- 
tion of algorithms. Several publications have used irace when eval- 
uating or designing algorithms for problems such as the traveling 
salesman with time windows [60] , slot allocation [77] , generalized 
hub location [68] , ﬂow shop [14] , virtual machine placement [86] , 
online bin packing [92] , graph coloring [23] , image binarization 
[69] , network pricing [90] , combined routing and packing prob- 

Document 4: 
 ming by optimization paradigm [40] . Moreover, the importance of 
properly tuning the parameters of algorithms before analyzing and 
comparing them is becoming widely recognized. We hope that the 
development of the irace package will help practitioners and re- 
searchers to put these ideas into practice. 
Acknowledgements 
This work received support from the COMEX project (P7/36) 
within the Interuniversity Attraction Poles Programme of the Bel- 
gian Science Policy Oﬃce, and the EU FP7 ICT Project COLOMBO, 
Fig. A.1 1. Scheme of the user-provided components required by irace . 
Table A1 
Parameters of irace corresponding to the description 
of iterated racing given in Section 3.2 . The full list of 
irace parameters is available in the user guide. 
Iterated racing parameter irace parameter 
B maxExperiments 
C (cost measure) targetRunner 
μ mu 
N min minNbSurvival 
T ﬁrst firstTest 
T each eachTest 
Statistical test testType 
Cooperative Self-Organizing System for Low Carbon Mobility at 
Low Penetration Rates (agreement no. 318622). Thomas Stützle and 
Mauro Birattari acknowledge support from the Belgian F.R.S.-FNRS, 
of which they are Senior Research Associates. Leslie Pérez Cáceres 
acknowledges support of CONICYT Becas Chile. 
Appendix A. The irace package 

Document 5: 
 man problem with time windows: adapting algorithms from travel-time to 
makespan optimization. Appl Soft Comput 2013;13(9):3806–15 . 
[61] López-Ibáñez M., Dubois-Lacoste J., Pérez Cáceres L., Stützle T., Birattari M.. 
2016a. The irace package: Iterated racing for automatic algorithm conﬁgura- 
tion. http://iridia.ulb.ac.be/supp/IridiaSupp2016-003/ . 
[62] López-Ibáñez M, Pérez Cáceres L, Dubois-Lacoste J, Stützle T, Birattari M. The 
irace package: user guide. Technical Report TR/IRIDIA/2016-004. IRIDIA, Uni- 
versité Libre de Bruxelles, Belgium; 2016b . http://iridia.ulb.ac.be/IridiaTrSeries/ 
IridiaTr2016-004.pdf . 
[63] Marmion M-E , Mascia F , López-Ibáñez M , Stützle T . Automatic design of hy- 
brid stochastic local search algorithms. In: Blesa MJ, Blum C, Festa P, Roli A, 
Sampels M, editors. Hybrid metaheuristics, volume 7919 of lecture notes in 

Document 6: 
 ent robot behaviors and the criteria to transition between behav- 
iors. Each module can be further customized by means of several 
parameters. A particular combination of behaviors and transitions 
represents one controller, that is, an instance of the software that 
controls the robots in the swarm. The performance of a particu- 
lar controller is evaluated by means of multiple simulations. The 
search for the best controller over multiple training simulations is 
carried out by means of irace . The authors report that this system 
is not only able to outperform a previous system that used F-race 
[34] , but also a human designer, under the scenarios studied by 
them. 
6. Conclusion 
This paper presented the irace package, which implements the 
iterated racing procedure for automatic algorithm conﬁguration. It- 
erated racing is a generalization of the iterated F-race procedure. 
M. López-Ibáñez et al. / Operations Research Perspectives 3 (2016) 43–58 55 
The primary purpose of irace is to automatize the arduous task of 
conﬁguring the parameters of an optimization algorithm. However, 
it may also be used for determining good settings in other compu- 
tational systems such as robotics, traﬃc light controllers, compil- 
ers, etc. The irace package has been designed with simplicity and 
ease of use in mind. Despite being implemented in R , no previ- 
ous knowledge of R is required. We included two examples for the 

","The irace package implements the iterated racing procedure, which is a generalization of the iterated F-Race procedure. The primary purpose of irace is to automate the task of configuring parameters for an optimization algorithm by using a competitive search strategy among different parameter configurations, allowing the user to select the best configuration through statistical testing.",5.321693420410156,"The irace package implements an automatic algorithm configuration method called iterated racing. This approach aims to automate the process of tuning algorithm parameters to enhance their performance efficiently. Irace conducts a series of ""races"" among different configurations of the algorithm based on their performance metrics, iteratively refining the search for optimal settings. It uses statistical tests to compare the configurations and incorporates features like sampling from a truncated normal distribution and an elitist strategy to ensure that the best configurations are heavily evaluated. Overall, irace's goal is to streamline and simplify the arduous task of configuring optimization algorithms, making it applicable beyond just algorithm configuration to other computational systems such as robotics and traffic light controllers."
llama3.2:latest,"What is the idea behind the AAC approach called ""SMAC""?
","Document 1: 
 intensiﬁcation scheme, and time-bounded SPO (TB-SPO) (Hutter et al., 2010b), which
generalizes SPO+ to work under (potentially tight) time constraints instead of considering
the number of function evaluations as a stopping criterion.
5.2 General Model-based AC Methods
SMAC Sequential model-based optimization for algorithm conﬁguration (SMAC) (Hutter
et al., 2011; Lindauer et al., 2021) can be seen as one of the ﬁrst fully-ﬂedged model-
based AC approaches, as it features solutions for many of the limitations of the previously
discussed SMBO techniques. SMAC generalizes TB-SPO to perform conﬁguration over
multiple problem instances so that it can support categorical parameters and handle tight
time constraints.
To support multiple problem instances, SMAC adapts the intensiﬁcation strategy of
TB-SPO to iteratively evaluate conﬁgurations on randomly sampled combinations of seeds
and problem instances. When doing so, it ensures that conﬁgurations are compared only
based on a performance estimate computed on the same randomly sampled set of problem
instances. Furthermore, SMAC’s surrogate model can generalize across problem instances
by incorporating problem instance features. To this end, a surrogate model is learned on
the joint problem instance and conﬁguration space to predict the performance of a given
conﬁguration on a given problem instance.
As a means to deal with a mixture of categorical and numerical parameters, SMAC 

Document 2: 
 method is paired with D-MAB selection [38] described
above. A sliding window is also used by Fialho et al.[ 70].
They suggest increasing the reward with the time elapsed
since the last application of this operator and decreasing
the reward with the number of times the operator has been
applied within the window. The aim of this method is to adapt
quickly to (even subtle) changes of the dynamic environment.
Li et al.[ 129] suggested a sliding window that stores the rate
of improvement in the ﬁtness of the offspring as compared
to the parent. The sum of all these rewards in the window is
used by a ranking mechanism to assign credit to the operators.
A different credit assignment mechanism is Compass, sug-
gested by Maturana and Saubion [ 146]. Based on the concepts
found in [ 147] (see Section VI), an operator’s impact is
evaluated using measures of both ﬁtness and diversity in order
to calculate the exploration-exploitation balance achieved by
the operator. The assigned credit reﬂects how closely the
achieved balance is to an exploration-exploitation balance that
is required by a user-deﬁned schedule. Other tested credit as-
signment methods are based on domination between operators
and Pareto fronts. Compass was paired with probability match-
ing selection, but was also combined with D-MAB in [ 143].
Except for the widely used multiarmed bandit approach dis-
cussed so far, AOS has also been treated as a full reinforcement 

Document 3: 
 cess (see (Hutter et al. 2009) for a comprehensive review),
which is usually referred to as automatic algorithm con-
ﬁguration (AAC) (Hoos 2012). Many AAC methods such
as ParamILS (Hutter et al. 2009), GGA/GGA+(Ans´otegui,
Sellmann, and Tierney 2009; Ans ´otegui et al. 2015), irace
(L´opez-Ib´a˜nez et al. 2016) and SMAC (Hutter, Hoos, and
Leyton-Brown 2011) have been proposed in the last few
years. They have been used for boosting the algorithm’s per-
formance in a wide range of domains such as the boolean
satisﬁability problem (SAT) (Hutter et al. 2009), the travel-
ing salesman problem (TSP) (L´opez-Ib´a˜nez et al. 2016; Liu,
∗Corresponding author
Copyright c⃝ 2020, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.
Tang, and Yao 2019), the answer set programming (ASP)
(Hutter et al. 2014) and machine learning (Feurer et al. 2015;
Kotthoff et al. 2017).
Despite the notable success achieved in application, the 

Document 4: 
 algorithm configuration framework. JArtifIntellRes 2009; 36 : 
267–306. 
9. Lindauer M, Eggensperger K, Feurer M et al. SMAC3: a ver- 
satile Bayesian optimization package for hyperparameter opti- 
mization. JMachLearnRes 2022; 23 : 54. 
10. Santu SKK, Hassan MM, Smith MJ et al. Automl to date and 
beyond: challenges and opportunities. ACMComputSurv 2022; 
54 : 175. 
Page7of9
Downloaded from https://academic.oup.com/nsr/article/11/8/nwae132/7639406 by guest on 18 September 2024 

Document 5: 
 more benchmark instances and compare its performance to
the best conﬁguration observed so far.
SMAC is an anytime algorithm that interleaves the ex-
ploration of new conﬁgurations with additional runs of the
current best conﬁguration to yield both better and more con-
ﬁdent results over time. As all anytime algorithms, SMAC
improves performance over time. While SMAC provably
converges for ﬁnite conﬁguration spaces, it often only ﬁnds
close-to-optimal conﬁgurations for realistic time budgets
and challenging conﬁguration problems.
Automated Portfolio Construction & Hydra
Our method for constructing sequential portfolios is closely
related to Hydra (Xu, Hoos, and Leyton-Brown 2010),
which automatically constructs selection-based portfolios.
Given a parameterized algorithm framework with a space
of algorithmsΘ, Hydra starts with an empty set of can-
didate algorithms C= ∅and iteratively calls an algorithm
conﬁguration method to add algorithms θ ∈Θ that comple-
ment Cbest. In each iteration, it constructs a portfolio from
the current set Cusing the portfolio-based algorithm selec-
tor SATzilla (Xu et al. 2008) and measures its performance
m(C,π) on each benchmark instance π ∈Π (in the ﬁrst it-
eration, m(∅,π) = −∞). The performance metric Hydra
maximizes via its algorithm conﬁguration method is then 

Document 6: 
 Anastacio and Hoos (2020) propose SMAC+PS, which integrates the idea of probabilis-
tic sampling known from irace into SMAC. This enhancement yields improvements over
both SMAC and irace in many cases. In particular, Anastacio and Hoos (2020) account for
the problem that many of the completely randomly sampled conﬁgurations by SMAC often
exhibit rather bad performance and thus, their evaluation yields only limited information.
To this end, the authors suggest to sample conﬁgurations according to a truncated normal
distribution centered around the default conﬁguration.
444
A Survey of Methods for Automated Algorithm Configuration
In (Lindauer & Hutter, 2018b) the authors suggest two diﬀerent strategies to warmstart
model-based AC approaches and apply their suggestions to SMAC, leading to signiﬁcant
speedups from days to hours of conﬁguration time. The idea underlying warmstarting is to
use the evaluations of conﬁgurations from previous runs, i.e., on diﬀerent problem instance
sets, to speed up the conﬁguration process in new runs of the conﬁgurator on a new set of
instances.
Distributed SMAC (Hutter et al., 2012) (D-SMAC) is an extension of SMAC leveraging
parallelization to speed up the conﬁguration process. The main idea behind D-SMAC is
to parallelize target algorithm runs onto available workers as much as possible. For this
purpose, it maintains a queue of target algorithm conﬁguration evaluations to be performed, 

","The SMAC (Sequential Model-based Optimization for Algorithm Configuration) approach is a model-based automatic algorithm configuration (AAC) method that generalizes time-bounded SPO (TB-SPO) to perform conﬁguration over multiple problem instances. It adapts the intensiﬁcation strategy of TB-SPO by iteratively evaluating conﬁgurations on randomly sampled combinations of seeds and problem instances, ensuring that conﬁgurations are compared only based on a performance estimate computed on the same randomly sampled set of problem instances.",6.2681965827941895,"The idea behind the AAC (automatic algorithm configuration) approach called ""SMAC"" (Sequential Model-based Algorithm Configuration) is to perform algorithm configuration by generalizing techniques from model-based optimization. SMAC adapts the intensification strategy from TB-SPO (time-bounded SPO) to iteratively evaluate configurations across multiple problem instances while ensuring that the comparisons are based on performance estimates derived from the same random subset of those instances. It incorporates a surrogate model that learns from both the configuration space and the problem instance features, allowing it to predict the performance of configurations effectively. SMAC is designed to handle a mixture of categorical and numerical parameters, and it operates as an anytime algorithm that continuously improves performance over time by balancing exploration of new configurations with exploitation of the current best configuration."
llama3.2:latest,"What is the idea behind the AAC approach called ""GGA""?
","Document 1: 
 to be evaluated based on k diﬀerently parameterized instantiations of the UCB criterion.
GGA++ Ans´ otegui et al. (2015) adapt the model-free AC approach GGA to include a
surrogate model. More precisely, the authors use a surrogate model to evaluate the quality
of new conﬁgurations. They integrate this within a crossover operator and call it genetic
engineering. Recall that GGA contains both a competitive and non-competitive popula-
tion in which winning conﬁgurations from the races between members of the competitive
population are recombined with individuals from the non-competitive population. To this
end, the crossover operator generates individuals according to the parameter tree crossover
of the original GGA method and evaluates them using the surrogate. Note that rather
than predicting the solution quality or runtime directly, the surrogate predicts the rank the
individual would have in a tournament. The individuals with the best ranks are accepted
into the population of the next generation in the same way as in GGA.
While the GGA++ surrogate is based on a random forest model, it diﬀers in a key
way. The premise of a random forest is to equally approximate the underlying function over
the complete input space. In the case of AC, this is undesirable as only the areas of the
input space that correspond to high-quality conﬁgurations are of interest. Thus, the authors
present specialized splitting criteria that focuses on only the best conﬁgurations to increase 

Document 2: 
 performance prediction [41], [42], [45]; and algorithm
enhancement [44], [47].
C. Generative Adversarial Networks
The general idea of GAST is similar to generative adversar-
ial networks (GANs) [50]. GANs also maintain an adversarial
game in which a discriminator is trained to distinguish real
samples from fake samples synthesized by a generator, and
the generator is trained to deceive the discriminator by pro-
ducing ever more realistic samples. However, there are some
main differences between GAST and GANs. First, the over-
all goals of them are different. GANs focus on the generative
models that could capture the distribution of complicated real-
world data. For GAST, the main goal is to build powerful
parallel portfolios (analogous to the discriminative models in
GANs); while the instance generation module as well as the
generated instances are more like byproducts. Second, the
domains to which GAST and GANs are applicable are differ-
ent. Currently GANs (and the more general idea of adversarial
learning) are mostly successfully applied to vision-related
domains, such as image generation [51], [52]; image dehaz-
ing [53]; style transfer [54], [55]; image classiﬁcation [56]; and
clustering [57], [58]. In comparison, GAST is proposed for
problem-solving domains, such as planning and optimization.
Third, the main technical issues in the two areas are different. 

Document 3: 
 cess (see (Hutter et al. 2009) for a comprehensive review),
which is usually referred to as automatic algorithm con-
ﬁguration (AAC) (Hoos 2012). Many AAC methods such
as ParamILS (Hutter et al. 2009), GGA/GGA+(Ans´otegui,
Sellmann, and Tierney 2009; Ans ´otegui et al. 2015), irace
(L´opez-Ib´a˜nez et al. 2016) and SMAC (Hutter, Hoos, and
Leyton-Brown 2011) have been proposed in the last few
years. They have been used for boosting the algorithm’s per-
formance in a wide range of domains such as the boolean
satisﬁability problem (SAT) (Hutter et al. 2009), the travel-
ing salesman problem (TSP) (L´opez-Ib´a˜nez et al. 2016; Liu,
∗Corresponding author
Copyright c⃝ 2020, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.
Tang, and Yao 2019), the answer set programming (ASP)
(Hutter et al. 2014) and machine learning (Feurer et al. 2015;
Kotthoff et al. 2017).
Despite the notable success achieved in application, the 

Document 4: 
 instead of the fully predetermined lifetimes in the original
GA VaPS and nAMGA VaPS.
Another variation of the GA VaPS lifetime scheme was
described by Bäck et al .[ 18]. The adaptive population GA
(APGA) uses the same lifetime allocation but differs from
GA VaPS in the reproduction cycle and in that, when in-
crementing the ages of individuals in each cycle, the best
individual of that cycle remains unchanged. This adaptive
population strategy is part of an ensemble and is described
in more detail in Section V. This method was also applied to
cooperative coevolution by Iorio and Li [ 109]. An analysis
of APGA by Lobo and Lima [ 135] shows theoretical and
experimental results suggesting an upper bound and a con-
verging population to a constant size that is determined by
the minimum and maximum lifetime parameters. The authors
conclude that the population is not adapted by the APGA
but the size parameter is in fact replaced by the two lifetime
parameters.
Cook and Tauritz [36] suggested two strategies for removing
the population size parameter. FiScIS-EA removes individuals
according to a survival probability, derived by linear scaling
of the individual’s ﬁtness in the range between the minimum
and maximum ﬁtness values present in the population. GC-EA
simply evades choosing a population size by maintaining a
population as large as is allowed by memory limitations. This
requires a well-chosen parent selection mechanism that scales
well, while a survival selection operator is still needed in 

Document 5: 
 obtain promising initial results, the combined evolution of solutions and their genetic opera-
tors is comparatively challenging, and it remains an open question whether autoconstructive
evolution is indeed superior to non-autoconstructive evolution.
Multi-armed bandits DAC can be cast as a multi-armed bandit problem, where each
conﬁguration represents an arm with an associated reward distribution. The agent is then
tasked to maximize the cumulative reward, i.e., “pull the arm“ that maximizes the reward.
Put diﬀerently, the agent aims to select a conﬁguration that works well for the current time
step. This setting of the bandit problem is particularly challenging because the reward
distributions associated with the respective arms change over time. In Fialho et al. (2010),
various multi-armed bandit approaches are compared with an approach that only considers
rewards obtained within a certain time frame (i.e., a sliding window) to allow for smoother
transitions between conﬁgurations. Note that in this work, the authors assume rewards to
be retrievable during an algorithm run. While this assumption holds for many optimization
approaches, it does not necessarily hold for all of them (e.g., the pre-processing/root node
phase of solving mixed-integer programs), and also often does not hold for simulations.
463
Schede, Brandt, Tornede, Wever, Bengs, H¨ullermeier & Tierney
11. Research Directions
Many fruitful avenues of research remain in the area of AC. We formulate research directions 

Document 6: 
 [23] showed that clustering the training data into sets, and then tun-
ing these sets individually could lead to further improvements. We
refer to this approach as SOP-clustered. We compare these two con-
ﬁgurators with general-purpose instance-oblivious conﬁguration of
GGA [2] and instance-speciﬁc parameter tuning of ISAC.
Solver: GS % Optimality Gap Closed
Train Test
Uniform 25.9 (4.2) 40 (4.1)
SOP - combined 39.0 (3.3) 43.4 (3.6)
SOP - clustered 47.7 (2.4) 50.3 (3.7)
GGA 40.0 (3.6) 46.1 (3.8)
ISAC 44.4 (3.3) 51.3 (3.8)
Table 1. Comparison of ISAC versus the default and instance-oblivious
parameters provided by SOP and GGA, and the instance-speciﬁc parameters
provided by SOP. We present the percent of optimality gap closed (stdev).
In Table 1, we compare the resulting ﬁve GS solvers, presenting
the percentage of optimality gap closed by each solver. Comparing
the average percent of optimality gap closed, we ﬁnd that ISAC is as
capable of improving over the default approach as SOP, which was
developed particularly for the GS solver. That is, ISAC can effec-
tively liberate us from having to select the number of clusters while,
at the same time, enjoying wide applicability to other solvers. More- 

","I couldn't find any information on an AAC (Augmentative and Alternative Communication) approach specifically called ""GGA"". AAC encompasses various methods, including Picture Communication Symbols, Gestures, and Electronic devices like tablets or smartphones with communication apps.

If you have more context or details about the GGA approach, I'd be happy to try and help further.",4.227635622024536,"The GGA (Genetic Algorithm with Genetic Engineering) approach, as described in the context, integrates a surrogate model to evaluate the quality of new configurations within its operation. It combines a competitive population, which competes in races, with a non-competitive population, allowing the winning configurations from the competitive races to be recombined with individuals from the non-competitive group. The crossover operator generates new individuals based on parameter tree crossover and uses the surrogate model to assess their ranks in a tournament-like setting. The individuals with the best ranks are then selected to form the next generation. Unlike traditional random forest methods, GGA focuses specifically on high-quality configurations, utilizing specialized splitting criteria that emphasize these areas of the input space."
llama3.2:latest,"What is the idea behind the AAC approach called ""ISAC""?
","Document 1: 
 ISAC – Instance-Speciﬁc Algorithm Conﬁguration1
Serdar Kadioglu and Yuri Malitsky and Meinolf Sellmann and Kevin Tierney2
Abstract. We present a new method for instance-speciﬁc algorithm
conﬁguration (ISAC). It is based on the integration of the algorithm
conﬁguration system GGA and the recently proposed stochastic off-
line programming paradigm. ISAC is provided a solver with cate-
gorical, ordinal, and/or continuous parameters, a training benchmark
set of input instances for that solver, and an algorithm that com-
putes a feature vector that characterizes any given instance. ISAC
then provides high quality parameter settings for any new input in-
stance. Experiments on a variety of different constrained optimiza-
tion and constraint satisfaction solvers show that automatic algorithm
conﬁguration vastly outperforms manual tuning. Moreover, we show
that instance-speciﬁc tuning frequently leads to signiﬁcant speed-ups
over instance-oblivious conﬁgurations.
1 Introduction
When developing a new heuristic or complete algorithm for a con-
straint satisfaction or a constrained optimization problem, we fre-
quently face the problem of choice. There may be multiple branch-
ing heuristics that we can employ, different types of inference mech-
anisms, various restart strategies, or a multitude of neighborhoods to
choose from. Furthermore, the way in which the choices we make
affect one another is not readily known. The task of making these 

Document 2: 
 method is paired with D-MAB selection [38] described
above. A sliding window is also used by Fialho et al.[ 70].
They suggest increasing the reward with the time elapsed
since the last application of this operator and decreasing
the reward with the number of times the operator has been
applied within the window. The aim of this method is to adapt
quickly to (even subtle) changes of the dynamic environment.
Li et al.[ 129] suggested a sliding window that stores the rate
of improvement in the ﬁtness of the offspring as compared
to the parent. The sum of all these rewards in the window is
used by a ranking mechanism to assign credit to the operators.
A different credit assignment mechanism is Compass, sug-
gested by Maturana and Saubion [ 146]. Based on the concepts
found in [ 147] (see Section VI), an operator’s impact is
evaluated using measures of both ﬁtness and diversity in order
to calculate the exploration-exploitation balance achieved by
the operator. The assigned credit reﬂects how closely the
achieved balance is to an exploration-exploitation balance that
is required by a user-deﬁned schedule. Other tested credit as-
signment methods are based on domination between operators
and Pareto fronts. Compass was paired with probability match-
ing selection, but was also combined with D-MAB in [ 143].
Except for the widely used multiarmed bandit approach dis-
cussed so far, AOS has also been treated as a full reinforcement 

Document 3: 
 in Ye et al. (2021) that performance gains can already be achieved when the algorithm
conﬁguration is adapted only once. Furthermore, the hyper-reactive approach of Ans´ otegui
et al. (2017) won several categories at the MaxSAT Evaluation 2016 (Argelich et al., 2016).
Thus, DAC oﬀers signiﬁcant potential for improving algorithms, however, it does require
algorithm designers to more deeply integrate their techniques with AC methods than was
performed in the past. In the following, we discuss the most frequently used approach to
DAC, reinforcement learning (RL). While it is the most popular choice, there also exist
other approaches such as policy portfolios, autoconstructive evolution, and multi-armed
bandits.
Reinforcement learning A challenge in DAC is to evaluate the quality of individual
parameter adjustments since feedback is obtained only at the end of processing a problem
instance. Due to this, it is natural to consider DAC within the realm of reinforcement
learning (we refer to this as DAC-RL). To this end, the DAC problem is modeled in terms of
a Markov decision process (MDP) (Puterman, 1994) based on which a policy π: I×Q→ Θ
is learned from data (Biedenkapp et al., 2020). As a reward signal, typically, the eventually
obtained performance value is propagated back to the agent. Using RL allows a wide variety
of researched mechanisms to be directly applied to DAC.
The roots of DAC extend to a variety of methods that use RL to control parameters of 

Document 4: 
 the best solver in the solver class, termed the auto- 
matic algorithm configuration (AAC) in the litera- 
ture [16 ]. More specifically, given a solver class, the 
solver that achieves the best overall performance on 
the training instances is first obtained by some search 
method. Then, the solver is directly applied to an un- 
seen problem instance without a further configura- 
tion process. 
A typical AAC method consists of two main com- 
ponents: sampling in the solver class and evaluat- 
ing a candidate solver. Sampling in the solver class 
is mostly implemented based on search-based meth- 
ods and model-based methods. Search-based meth- 
ods such as hi l l climbing [50 ], local search [8 ] and 
E A s [51 ] have been used to sample solvers, since 
they make minimal assumptions about the solver 
representation and do not require gradients. Addi- 
tionally, some researchers have also explored using 
experimental design [52 ,53 ], such as the full fac- 
torial experimental design, to generate the starting 
points for the search. In comparison, model-based 
methods are more similar to the performance predic- 
tion model approach. They seek to capture the de- 
pendencies between solvers and their performance, 
by training surrogate models on the performance 
data collected during the configuration process. On 

Document 5: 
 ACPP is closely related to the area of automatic algo-
rithm configuration, in which the task is to automatically
identify a high-quality configuration from a configuration
space. In the last few years, several high-performance AC
methods (which could handle considerable large configura-
tion spaces) such as ParamILS (Hutter et al. 2009), GGA
(Ans´otegui, Sellmann, and Tierney 2009), irace (L ´opez-
Ib´a˜nez et al. 2016) and SMAC (Hutter, Hoos, and Leyton-
Brown 2011) have been proposed. As a consequence, re-
cently there has been research interest in utilizing these
AC procedures to automatically identify useful portfolios
of configurations from large configuration spaces. Such at-
tempts were first done in constructing sequential portfolios.
The representative methods for solving this problem are Hy-
dra (Xu, Hoos, and Leyton-Brown 2010) and ISAC (Ka-
dioglu et al. 2010). The basic ideas of these methods were
then adapted to be used in constructing parallel portfolios
(i.e., ACPP), thus resulting in PARHYDRA and CLUSTER-
ING (Lindauer et al. 2017) (see the first section). The main
differences between the automatic construction of sequen-
tial portfolios and of parallel portfolios lie in two aspects: 

Document 6: 
 that ihvr ∈(0, 1], and a larger value of ihvr is better. IHVR can distinguish well between
MOEAs with a different performance, and can also save a lot of calculations. In this work,
IHVR is used as the performance metric Metric .
4.3. Automatic Construction Approach
Algorithm 1 presents the automatic construction approach for MOEAs/PAP . Starting
from an empty set (line 2), the approach constructs the PAP (denoted as P) iteratively.
Speciﬁcally, each iteration of the approach (lines 3–15) consists of two subsequent phases.
In the ﬁrst phase, an existing automatic algorithm conﬁguration tool, namely SMAC 3 [44],
is used to search in Θ to ﬁnd the algorithm that can improve the performance of the current
PAP to the largest extent (line 5), and then this algorithm is inserted into P (line 6). This
phase is similar to the commonly-used greedy approach in the automatic construction of
PAPs [27,31]. Additionally, we introduce a new phase, namely simpliﬁcation, as the second
phase in Algorithm 1. In this phase (lines 7–14), P would be simpliﬁed by removing the
member algorithms that do not contribute at all to its performance (meaning removing
these algorithms has no effect on the performance of P on the training set). Considering
the size of P is bounded (line 3), removing the redundant algorithms from P is meaningful
because this will leave space for new member algorithms that can improve the performance 

","The ISAC (Instance-Speciﬁc Algorithm Conﬁguration) approach is a method for instance-speciﬁc automatic algorithm configuration. It uses an existing algorithm conﬁguration tool to search for algorithms that improve performance on unseen problem instances, and then inserts these algorithms into a population-based algorithm of evolution (PAP). The approach also includes a simplification phase to remove redundant algorithms from the PAP.",5.977574825286865,"The AAC approach called ""ISAC"" (Instance-Specific Algorithm Configuration) is focused on automatically identifying high-quality parameter settings for specific problem instances. It combines an algorithm configuration system with a stochastic offline programming paradigm to adapt the configuration based on the features of each instance. ISAC requires a training benchmark set of input instances and an algorithm that computes a feature vector, allowing it to provide tailored configurations that improve solver performance on new input instances. The method has been shown to significantly outperform manual tuning and lead to speed-ups compared to instance-oblivious configurations."
llama3.2:latest,"What is the difference between metaheuristics and heuristics?
","Document 1: 
 usually provide only sub-optimal solutions because they do
not attempt to escape from local optimum. These drawbacks
have led to the introduction of metaheuristics.
Metaheuristics are high-level methodologies or general al-
gorithmic templates, which generally do not adapt deeply
to speciﬁc problem(s) [4]. Hence, they usually can solve a
wide range of problems [2]. In fact, the preﬁx “meta”, which
means “upper level methodology”, indicates that metaheuristic
algorithms can be viewed as “higher level” heuristics. Hy-
brid approaches based on existing metaheuristic(s) are also
considered metaheuristics [5]. In last decades, metaheuristics
have received widespread attention from researchers and are
widely recognized as efﬁcient approaches for hard optimiza-
tion problems. A number of metaheuristic algorithms have
been developed and extensively applied, including Simulated
Annealing (SA) [6], Tabu Search (TS) [7], Evolutionary Algo-
rithms (EAs) [8], Ant Colony Optimization algorithm (ACO)
[9], Particle Swarm Optimization (PSO) [10], and so forth.
Most of metaheuristics are nature-inspired (inspired from some
principles in physics, biology and etc.), contain stochastic
components, and often have several free parameters that can
be set by users according to problem(s) at hand [4].
The setting of parameters (or parameter setting) has strong 

Document 2: 
 the same standard. (In contrast, SAT solver competitions have compared solvers with a complex scoring function that includes the performance of all competitors [25].) As formulated here, the differences between two solvers may be simply in their choice of even a single technique, heuristic, or policy that sustains performance diver-sity. Thus an algorithm portfolio can be thought of as a mixture of experts [26], in-cluding variable-ordering and value-ordering heuristics, restart policies, and nogood learning methods. In particular, even if only one heuristic is available, the portfolio could consist of the heuristic and its opposite, or the heuristic and random selection. 

Document 3: 
 PSO. 
For the methodological part of the comparisons, there are far more 
studies. Statistical tests, for instance, lay at the core of prior contribu- 
tions on this matter. However, such contributions are frequently writ- 
ten from a statistical point of view –l i k e the one by Dem š ar [39] –
making it diﬃcult for researchers in this ﬁeld to embrace their method- 
ological recommendations. More recently, some tutorials have tried to 
bring together the ﬁelds of meta-heuristics and inferential statistics [4] . 
Some examples can be found in [40] , in which a statistical treatment is 
suggested for distinguishing between measurements of performance in 
adaptive evolutionary algorithms. Another good example is [41] , which 
shows that in a popular real-parameter benchmark (CEC’2005), con- 
ditions needed for running parametric hypothesis tests did not hold, 
and non-parametric tests were thus recommended. More recently, in 
[42] , some recommendations for the comparison of evolutionary algo- 
rithms are provided, which can be even extrapolated to machine learn- 
ing benchmarks. 
Another important issue from a methodological point of view is the 
assessment of the performance of bio-inspired algorithms from the per- 
spective of the experimental design. Some studies [5] provide general 
recommendations to design experiments for the comparison of algo- 
rithms in a similar way to what we do in this contribution. However, 
these recommendations are far more general as it targets a broader scope 

Document 4: 
 (Eds.), Handbook of Metaheuristics (pp. 321–353). Kluwer Academic Publishers, Norwell, MA, USA.
Maron, O. & Moore, A. (1994). Hoeffding races: Accelerating model selection search for classiﬁcation
and function approximation. In Cowan, J. D., Tesauro, G., & Alspector, J. (Eds.), Advances in Neural
Information Processing Systems 7 (NIPS-94), volume 6, (pp. 59–66). Morgan Kaufmann Publishers, San
Francisco, CA, USA.
Mengshoel, O. J. (2008). Understanding the role of noise in stochastic local search: Analysis and experi-
ments. Artiﬁcial Intelligence, 172(8-9), 955–990.
Minton, S. (1993). An analytic learning system for specializing heuristics. In Bajcsy, R. (Ed.),Proceedings of
the Thirteenth International Joint Conference on Artiﬁcial Intelligence (IJCAI’93), (pp. 922–929). Morgan
Kaufmann Publishers, San Francisco, CA, USA.
Minton, S. (1996). Automatically conﬁguring constraint satisfaction programs: A case study. Constraints,
1(1), 1–40.
Minton, S., Johnston, M. D., Philips, A. B., & Laird, P. (1992). Minimizing conﬂicts: A heuristic repair 

Document 5: 
 J. Durillo , K. Hammond , E. Hart , C.G. Johnson , et al. , A research agenda for meta- 
heuristic standardization, in: Proceedings of the XI metaheuristics international 
conference, 2015, pp. 1–3 . 
[106] J. Swan , S. Adraensen , A.E. Brownlee , C.G. Johnson , A. Kheiri , F. Krawiec , 
J. Merelo , L.L. Minku , E. Özcan , G.L. Pappa , et al. , Towards metaheuristics ”i n 
the large ”, arXiv preprint arXiv:2011.09821 (2020) . 
[107] M.A. Lones , Mitigating metaphors: a comprehensible guide to recent nature-in- 
spired algorithms, SN Computer Science 1 (1) (2020) 49 . 
[108] M. Jain, V. Singh, A. Rani, A novel nature-inspired algorithm for optimiza- 
tion: squirrel search algorithm, Swarm Evol Comput 44 (2019) 148–175, 
doi: 10.1016/j.swevo.2018.02.013 . 
[109] A.W. Mohamed, A.A. Hadi, A.K. Mohamed, Gaining-sharing knowledge 
based algorithm for solving optimization problems: a novel nature- 

Document 6: 
 iﬁed on 24 continuous benchmark functions from the COCO test set and 29
functions from the CEC-2017 test set. On the BBOB test set a hybrid of
PSO and DE with adaptation obtained 11 signiﬁcantly better and 2 signif-
icantly worse results on 5 and 20 dimensional functions than the basic DE.
Further inclusion of the model based optimizers led to 15 signiﬁcantly better
and 2 signiﬁcantly worse results compared to the PSO-DE hybrid. On the
CEC-2017 test set, M-GAPSO was signiﬁcantly better than both Red Fox
Optimization and Dual Opposition-Based Learning for Diﬀerential Evolution
(DOBL) on 7 functions in 30 dimensions and 12 functions in 50 dimensions.
Keywords: hyper-heuristics, meta-heuristics, global optimization
∗Corresponding author.
Email addresses: M.Okulewicz@mini.pw.edu.pl (Micha/suppress l Okulewicz),
M.Zaborski@mini.pw.edu.pl (Mateusz Zaborski), jacek.mandziuk@pw.edu.pl (Jacek
Ma´ ndziuk )
Preprint submitted to Applied Soft Computing 10.1016/j.asoc.2022.109722 December 3, 2022
1. Introduction
The quest for a general purpose optimization algorithms, which started
with the works on evolutionary computations [1, 2], resulted in creation of
a few excellent optimization methods like Diﬀerential Evolution (DE) [3] 

","Metaheuristics are high-level methodologies or general algorithmic templates that do not adapt deeply to specific problems. In contrast, traditional heuristics are lower-level, problem-specific methods that aim to find good solutions for a particular problem, often by escaping local optima. Metaheuristics can solve a wide range of problems and are ""higher level"" heuristics that combine multiple techniques or strategies to achieve better performance.",5.74329137802124,"Metaheuristics are high-level methodologies or general algorithmic templates designed to solve a wide range of optimization problems. They are often nature-inspired and contain stochastic components, allowing them to escape local optima and attempt to find better solutions over a broader search space. In contrast, heuristics are typically problem-specific strategies or rules of thumb that provide sub-optimal solutions and may not have the capability to generalize to various problems. The term ""meta"" indicates that metaheuristics can be viewed as higher-level strategies that can encompass and adapt various heuristics but do not deeply adapt to specific problems, allowing for a more flexible application across different optimization scenarios."
llama3.2:latest,"What factors and challenges influenced the development of the Automatic Algorithm Configuration approaches?
","Document 1: 
 ods for algorithm development. The methods used in this context 
include experimental design techniques [2,29] , racing approaches 
[20] , and algorithmic methods for parameter conﬁguration, such 
as heuristic search techniques [3,10,41,73,81] , and statistical mod- 
eling approaches [11,43] . These methods have led to an increasing 
automatization of the algorithm design and parameter setting pro- 
cess. 
Automatic algorithm conﬁguration can be described, from a ma- 
chine learning perspective, as the problem of ﬁnding good param- 
eter settings for solving unseen problem instances by learning on 
a set of training problem instances [19] . Thus, there are two clearly 
delimited phases. In a primary tuning phase, an algorithm con- 
ﬁguration is chosen, given a set of training instances representa- 
tive of a particular problem. In a secondary production (or test- 
ing) phase, the chosen algorithm conﬁguration is used to solve un- 
seen instances of the same problem. The goal in automatic algo- 
rithm conﬁguration is to ﬁnd, during the tuning phase, an algo- 
rithm conﬁguration that minimizes some cost measure over the 
set of instances that will be seen during the production phase. 
In other words, the ﬁnal goal is that the conﬁguration of the al- 
gorithm found during the tuning phase generalizes to similar but 
unseen instances. The tuning phase may also use automatic conﬁg- 
uration methods repeatedly while engineering an algorithm [71] . 

Document 2: 
 diﬀerent problems (SAT, MIP, ASP, etc.) of varying complexity (number of variables and
problem instances) for tasks of runtime or quality conﬁguration. For DAC, the DACBench
has been proposed (Eimer et al., 2021), although this does not support DAC settings en-
visioned, e.g., by hyper-reactive search. As an alternative to such libraries, AC methods
can also be benchmarked by using surrogate models that are trained on test instances in
advance, resulting in cheaper evaluations when testing (Eggensperger et al., 2018). The ex-
isting benchmarks fail to cover other conﬁgurations settings like the realtime conﬁguration
setting or the conﬁguration of multi-objective target algorithms.
11.4 Novel AC Methodologies
AC methods have become extremely sophisticated and cover a wide range of methodologies
including evolutionary algorithms, statistical tests, and learned surrogate models. There
nonetheless remain opportunities to improve current methods and create better AC algo-
rithms. We note that our goal in this section is not necessarily to specify the methodologies
of the future, but rather to identify the key challenges that remain in the hopes that engaged
466
A Survey of Methods for Automated Algorithm Configuration
readers will ﬁll these gaps with their ideas. To this end, we discuss several challenges faced
by AC approaches: comparing/ranking conﬁgurations, generating new conﬁgurations, and
selecting instances.
Comparing/ranking conﬁgurations This challenge can be summarized as follows: 

Document 3: 
 available for detecting (approximate) independencies. Although there is some evi-
dence that GGA can solve some moderately difﬁcult conﬁguration problems more
effectively than FocusedILS without capping [2], it appears to be unable to reach
the performance of FocusedILS version 2.3 with aggressive capping on the most
challenging conﬁgurations problems [40]. Unfortunately, GGA also offers less ﬂex-
ibility than FocusedILS in terms of the performance metric to be optimised. More
algorithm conﬁguration procedures based on evolutionary algorithms are covered in
Chapter 2 of this book.
Finally, work originating from the Ph.D. project of Hutter [32] has recently over-
come two major limitations of the sequential model-based optimisation methods
discussed in Section 3.4 of this chapter by introducing a procedure that can han-
dle categorical parameters while explicitly exploiting the fact that performance is
evaluated on a set of problem instances. There is some evidence that this procedure,
dubbedSequential Model-based Algorithm Conﬁguration (SMAC) , can, at least on
some challenging conﬁguration benchmarks, reach and sometimes exceed the per-
formance of FocusedILS [43], and we are convinced that, at least in cases where
the parameter response of a given target algorithm is reasonably regular and per-
formance evaluations are very costly, such advanced SMBO methods hold great
promise.
3.6 Conclusions and Future Work
Automated algorithm conﬁguration and parameter tuning methods have been de- 

Document 4: 
 Decision and Operation Technologies Group,
Bielefeld University, Bielefeld, Germany
Abstract
Algorithm conﬁguration (AC) is concerned with the automated search of the most
suitable parameter conﬁguration of a parametrized algorithm. There is currently a wide
variety of AC problem variants and methods proposed in the literature. Existing reviews
do not take into account all derivatives of the AC problem, nor do they oﬀer a complete
classiﬁcation scheme. To this end, we introduce taxonomies to describe the AC problem and
features of conﬁguration methods, respectively. We review existing AC literature within
the lens of our taxonomies, outline relevant design choices of conﬁguration approaches,
contrast methods and problem variants against each other, and describe the state of AC in
industry. Finally, our review provides researchers and practitioners with a look at future
research directions in the ﬁeld of AC.
1. Introduction
Diﬃcult computational problems must be regularly solved in many areas of industry and
academia, such as constraint satisfaction problems, Boolean satisﬁability problems (SAT),
vehicle routing problems, ﬁnding a proper machine learning model for a given dataset,
or computing highly complex simulations. Algorithms that were developed to solve such
problems usually have parameters that strongly inﬂuence the behavior of the respective
algorithm and also, for example, the runtime that is required to solve problem instances
©2022 AI Access Foundation. All rights reserved.
Schede, Brandt, Tornede, Wever, Bengs, H¨ullermeier & Tierney 

Document 5: 
 better performance than the top-ranked solver from the competition.
9. Related Work
Many researchers before us have been dissatisﬁed with manual algorithm conﬁguration, and various
ﬁelds have developed their own approaches for automatic parameter tuning. We start this section
with the most closely-related work—approaches that employ direct search to ﬁnd good parameter
conﬁgurations—and then describe other methods. Finally, we discuss work on related problems,
such as ﬁnding the best parameter conﬁguration or algorithm on a per-instance basis, and approaches
that adapt their parameters during an algorithm’s execution (see also Hoos, 2008, for further related
work on automated algorithm design).
8. BasicILS was used, because FocusedILS had not yet been developed when that study was conducted.
297
HUTTER , HOOS , LEYTON -BROWN & ST ¨UTZLE
9.1 Direct Search Methods for Algorithm Conﬁguration
Approaches for automated algorithm conﬁguration go back to the early 1990s, when a number of
systems were developed for adaptive problem solving. One of these systems is Composer (Gratch
& Dejong, 1992), which performs a hill-climbing search in conﬁguration space, taking moves if
enough evidence has been gathered to render a neighbouring conﬁguration statistically signiﬁcantly
better than the current conﬁguration. Composer was successfully applied to improving the ﬁve
parameters of an algorithm for scheduling communication between a collection of ground-based
antennas and spacecrafts (Gratch & Chien, 1996). 

Document 6: 
 ration.
1 Introduction
We consider the problem of automatic solver conﬁguration. Practically all solvers have
parameters that are partly ﬁxed by the programmer and partly set by the user. In recent
years, systems have been devised which automate the task of tuning parameters for a
given set of training instances that are assu med to represent typical instances for the
target algorithm.
There are several motivations for such an automation, the ﬁrst being that it is of
course time consuming to tune parameters and it may lead to better results when leaving
the conﬁguration of solvers to a computer rather than doing it by hand.
Moreover, it is conceivable that the existence of an effective tuning environment
will cause algorithm developers to paramete rize more aspects of their algorithms and
thus leave more freedom for algorithmic solutions that are automatically tailored to the
problems of individual users. In particular, many of the SAT solvers that are available
today have parameters which cannot be set through the command line. These parameters
have been ﬁxed to values that the developers have found beneﬁcial without knowledge
about the particular instances a user may want to use the solver for. Automatic parameter
tuning allows solvers to adapt to the ﬁnal environment in which they need to perform.
After being shipped, rather than relying on default parameters, an algorithm can be
⋆ This work was partly supported by the projects TIN2007-68005-C04-04 and TIN2006-15662-
C02-02 funded by the MEC, and by the the National Science Foundation through the Ca-
reer: Cornﬂower Project (award number 0644113). 

","The development of Automatic Algorithm Configuration (AAC) approaches was influenced by several factors and challenges. Here are some of the key ones:

1. **Computational complexity**: As computational power increased, algorithms became more complex, leading to a need for efficient configuration methods.
2. **Algorithmic parameter optimization**: The increasing number of parameters in machine learning algorithms made it difficult for human practitioners to manually tune them.
3. **Lack of domain expertise**: With the rise of data science, many researchers and practitioners lacked domain-specific knowledge, making manual tuning challenging.
4. **Experimentation time and cost**: Manual tuning required extensive experimentation time and resources, which became increasingly unsustainable as algorithms became more complex.
5. **Data quality and availability**: The need for large amounts of high-quality data to train and test models made it difficult for practitioners to perform manual tuning.
6. **Algorithmic instability**: Some algorithms were found to be highly sensitive to hyperparameter settings, making manual tuning unreliable.

Challenges in developing AAC approaches:

1. **Scalability**: AAC methods needed to scale to handle large numbers of algorithms, parameters, and experiments.
2. **Hyperparameter search space**: The search space for hyperparameters was often too large, making it difficult to efficiently explore the solution space.
3. **Noise and bias**: Noisy or biased data could affect the performance of AAC methods, leading to suboptimal results.
4. **Lack of interpretability**: Many AAC methods were black box algorithms, making it difficult to understand why they made certain decisions.
5. **Computational resources**: AAC methods required significant computational resources, which could be a bottleneck in practice.

To address these challenges, researchers developed various AAC approaches, including:

1. **Bayesian optimization**: A probabilistic method for efficiently exploring the search space.
2. **Random search**: A simple and efficient method that involves randomly sampling the hyperparameter space.
3. **Grid search**: A brute-force approach that evaluates all possible combinations of hyperparameters.
4. **Tree-based methods**: Methods like Tree-structured Parzen Estimation (TPE) and Hyperopt, which use tree-based structures to efficiently explore the search space.
5. **Evolutionary algorithms**: Methods like genetic algorithms and evolutionary programming, which mimic natural selection to optimize hyperparameters.

These approaches have improved significantly over time, enabling researchers and practitioners to tackle complex machine learning problems with greater ease.",13.312565088272097,"The development of Automatic Algorithm Configuration (AC) approaches has been influenced by several factors and challenges:

1. **Diversity of Problems**: AC methods must cater to various computational problems (e.g., SAT, MIP, ASP) with differing complexities. This requires AC approaches to be versatile and capable of adapting to different problem domains.

2. **Complexity of Parameters**: Algorithms often have numerous parameters that significantly affect their performance. The management and tuning of these parameters present challenges, particularly in ensuring the configurations are suitable for unseen instances.

3. **Benchmarking Limitations**: Existing benchmarking frameworks, such as DACBench, may not adequately support all configuration settings, indicating a need for more comprehensive evaluation tools to benchmark AC methods.

4. **Comparing and Ranking Configurations**: A significant challenge in AC is comparing and ranking different configurations to determine which performs best under various conditions. This task requires effective metrics and methodologies for assessment.

5. **Generating New Configurations**: The ability to generate new and potentially better configurations from existing ones remains a challenge. Advanced methodologies are needed to explore the configuration space efficiently.

6. **Performance Evaluation Costs**: Many performance evaluations are resource-intensive, necessitating methods that can efficiently predict the performance of configurations without extensive testing.

7. **Categorical Parameters Handling**: Many AC procedures initially struggled with categorical parameters, but recent advancements, such as Sequential Model-based Algorithm Configuration (SMAC), have begun to address this limitation.

8. **Adapting to the User's Environment**: The need for solvers to adapt to the environments in which they operate after deployment is critical. Automatic configuration allows developers to create more parameterized algorithms that can tailor themselves to a user's specific problem context.

These factors illustrate the complexities and evolving needs in the field of algorithm configuration, prompting ongoing research and innovation."
llama3.2:latest,"What are the main benefits of AAC?
","Document 1: 
 as expected, as N and K get larger, the estimation error gets
smaller, and ˆuSN (θ) will converge to u(θ) with probability
1 with N →∞ and K →∞ . Third, Corollary 1 shows that,
for the estimator ˆuSN (θ∗) which are widely used in current
AAC methods, the gain on error reduction decreases rapidly
asN and K get larger (which are also shown in Figure 2 in
the experiments), and the effects of increasingN and K also
depend on ¯σ2
WI and ¯σ2
AI, two quantities varying across dif-
ferent algorithm conﬁguration scenarios. Thus for enhanc-
ing current AAC methods, instead of ﬁxingN as a large
number (e.g., SMAC sets N to 2000 by default) and using
as many training instances as possible, it is more desirable
to use differentN and K according to the conﬁguration sce-
nario considered, in which case N and K may be adjusted
dynamically in the conﬁguration process as more data are
gathered to estimate¯σ2
WI and ¯σ2
AI.
Experiments
In this section, we present our experimental studies. First
we introduce our experiment setup. Then, we verify our the-
oretical results in two facets: 1) comparison of different per-
formance estimators; 2) the effects of different values ofm
(the number of considered conﬁgurations), N (the number
of runs of θ to estimate u(θ)) and K (the number of training 

Document 2: 
 independently in parallel to obtain multiple solutions. Then, the best solution will be
taken as the ﬁnal output of the PAP . Although a PAP would consume more computational
resources than a single algorithm, it has three important advantages. First, PAPs are
easy-to-implement because they do not necessarily require any resource allocation since
each member algorithm is simply assigned with the same amount of resource. Second,
the performance of a PAP on any problem is the best performance achieved among its
member algorithms on the problem. In other words, a PAP could achieve a much better
overall performance than any of its member algorithms. Third, considering the tremendous
growth of parallel computing architectures [22] (e.g., multi-core CPUs) over the last few
decades, leveraging parallelism has become very important in designing effective solvers
for hard optimization problems [23–27]. PAPs employ parallel solution strategies and thus
allow for the use of modern computing facilities in an extremely simple way.
It is conceivable that any PAP’s effectiveness relies heavily on the diversity and com-
plementarity among its member algorithms. In other words, the manual construction
of high-quality PAPs is generally a challenging task, requiring domain experts (with a
deep understanding of both algorithms and problems) to explore the vast design space
of PAPs, which cannot be carried out manually with ease [28–30]. As an alternative, Tang
and Liu [25,26] proposed a general framework, called automatic construction of PAPs, that 

Document 3: 
 phase of solving mixed-integer programs), and also often does not hold for simulations.
463
Schede, Brandt, Tornede, Wever, Bengs, H¨ullermeier & Tierney
11. Research Directions
Many fruitful avenues of research remain in the area of AC. We formulate research directions
with three themes in mind. First, we consider what is required for AC techniques to be
more widely adopted in industry. Second, we investigate algorithm conﬁguration settings
that have not yet been considered. Third, we consider what methodological advances could
move the ﬁeld forward.
11.1 Industry Adoption
Compared to AC, HPO has begun to be adopted in both industry and academia (Van der
Blom et al., 2021). Furthermore, HPO is the focus of a number of start-ups, such as
SigOpt (which was acquired by Intel (Intel Corporation, 2019)), MindsDB, pecan.ai, and
dotData, among many more. AC, however, has received comparatively little fanfare or
adoption. While some well-known AC tools have public releases, such as SMAC (Lindauer
et al., 2021), irace (L´ opez-Ib´ anez et al., 2016), and GGA (Ans´ otegui et al., 2009), we are
unaware of widespread use of these in industry. The company Optano GmbH released a 

Document 4: 
 a policy to adapt the conﬁguration dynamically. Note that even realtime AC commits to a
single conﬁguration when running a given instance, while DAC has the freedom to adjust
the conﬁguration according to target algorithm behavior during execution. Similar to oﬄine
AC, DAC can either focus on ﬁnding a policy for a set of problem instances or a policy that
is tailored towards a single problem instance (i.e., per-instance algorithm conﬁguration).
Two requirements must be met to implement DAC: (1) the algorithm in question needs
to support dynamic changes in its conﬁguration and (2) runtime information must be pro-
vided to describe the current state of the target algorithm.
DAC approaches consider two diﬀerent types of features: instance features I, which do
not change during target algorithm execution, and features encoding the internal state Q
of the algorithm. Examples of state features include the current iteration of a local search
algorithm, the current restart number of a SAT method, or the current solution quality for
optimization techniques.
461
Schede, Brandt, Tornede, Wever, Bengs, H¨ullermeier & Tierney
Figure 7: Illustration of dynamic AC as presented in (Biedenkapp et al., 2020)
Biedenkapp et al. (2020) provide the ﬁrst formal deﬁnition of the DAC setting, however,
there is a signiﬁcant amount of earlier work for learning dynamic conﬁguration policies
(Lagoudakis & Littman, 2000, 2001; Pettinger & Everson, 2002). Such earlier works use 

Document 5: 
 cess (see (Hutter et al. 2009) for a comprehensive review),
which is usually referred to as automatic algorithm con-
ﬁguration (AAC) (Hoos 2012). Many AAC methods such
as ParamILS (Hutter et al. 2009), GGA/GGA+(Ans´otegui,
Sellmann, and Tierney 2009; Ans ´otegui et al. 2015), irace
(L´opez-Ib´a˜nez et al. 2016) and SMAC (Hutter, Hoos, and
Leyton-Brown 2011) have been proposed in the last few
years. They have been used for boosting the algorithm’s per-
formance in a wide range of domains such as the boolean
satisﬁability problem (SAT) (Hutter et al. 2009), the travel-
ing salesman problem (TSP) (L´opez-Ib´a˜nez et al. 2016; Liu,
∗Corresponding author
Copyright c⃝ 2020, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.
Tang, and Yao 2019), the answer set programming (ASP)
(Hutter et al. 2014) and machine learning (Feurer et al. 2015;
Kotthoff et al. 2017).
Despite the notable success achieved in application, the 

Document 6: 
 Non-general AC SMBO approaches Several SMBO approaches exist to perform a
limited form of AC, i.e., on only a single instance. We include these methods due to their
historical importance to the ﬁeld of AC, as well as because they may inspire new general AC
4. Note that for simplicity we assume that g is deterministic here.
443
Schede, Brandt, Tornede, Wever, Bengs, H¨ullermeier & Tierney
approaches. Most SMBO based AC approaches are based on the idea of sequential kriging
meta-modelling (Huang et al., 2006) (SKO) and sequential parameter optimization (SPO)
(Bartz-Beielstein et al., 2005), both of which are based on eﬃcient global optimization (Jones
et al., 1998). While the latter is a classical approach to black box function optimization using
BO, both SPO and SKO constitute extensions to noisy black box functions; an assumption
that is much more realistic for AC. However, both of these approaches still have potential
drawbacks. Some of these are ﬁxed by SPO + (Hutter et al., 2009a), which improves the
intensiﬁcation scheme, and time-bounded SPO (TB-SPO) (Hutter et al., 2010b), which
generalizes SPO+ to work under (potentially tight) time constraints instead of considering
the number of function evaluations as a stopping criterion.
5.2 General Model-based AC Methods 

","Augmentative and Alternative Communication (AAC) has several benefits, including:

1. **Improved Communication**: AAC provides individuals with disabilities or conditions that affect their ability to communicate verbally with a more effective means of expression.
2. **Increased Independence**: By providing an alternative way to express needs and wants, AAC enables individuals to take control of their communication and become more independent in their daily lives.
3. **Enhanced Self-Expression**: AAC allows individuals to express themselves in a way that feels authentic and meaningful to them, which can lead to increased self-esteem and confidence.
4. **Better Social Interactions**: With the help of AAC, individuals can engage more effectively with others, including family, friends, and caregivers, leading to stronger social relationships.
5. **Early Intervention and Prevention**: AAC can be used in early intervention programs to identify communication delays or disorders, allowing for targeted interventions and prevention strategies.
6. **Personalization and Flexibility**: AAC systems can be tailored to meet the individual's specific needs and preferences, providing a high degree of flexibility and personalization.
7. **Supports Language Development**: For individuals with developmental disabilities or conditions that affect language development, AAC can provide an opportunity for language development and acquisition.
8. **Enhances Creativity and Expression**: AAC can be used to express creativity, imagination, and emotional intelligence, which are essential aspects of human communication.
9. **Fosters Self-Advocacy**: By providing a means of expression, AAC enables individuals to advocate for themselves and their needs, promoting self-advocacy and autonomy.
10. **Improves Quality of Life**: Overall, AAC can significantly improve an individual's quality of life by enhancing their ability to communicate effectively, express themselves authentically, and interact with others.

These benefits highlight the importance of AAC in supporting individuals with diverse communication needs and promoting inclusive and equitable opportunities for communication and social interaction.",12.816970348358154,"The main benefits of Automatic Algorithm Configuration (AAC) include the following:

1. **Performance Boosting**: AAC methods such as ParamILS, GGA, irace, and SMAC have been widely successful in enhancing the performance of algorithms across diverse domains, including SAT, TSP, ASP, and machine learning tasks. They achieve this by optimizing algorithm parameters dynamically based on performance metrics.

2. **Adaptability**: AAC techniques can adjust configurations based on the specific characteristics of different problem instances, allowing for tailored solutions that are more effective than static or pre-defined configurations.

3. **Efficient Resource Management**: AAC facilitates better resource allocation by dynamically adjusting configurations as more data becomes available, which can lead to reduced estimation errors and improved accuracy in algorithm performance.

4. **Research Advancement**: AAC fosters further research opportunities in the field, exploring new configuration settings and methodological advancements, thus contributing to the overall growth and sophistication of optimization techniques.

These advantages enable more effective problem-solving strategies, allowing the algorithms to perform optimally based on varying conditions and requirements."
llama3.2:latest,"Please provide an overview of the types of AAC methods.
","Document 1: 
 the best solver in the solver class, termed the auto- 
matic algorithm configuration (AAC) in the litera- 
ture [16 ]. More specifically, given a solver class, the 
solver that achieves the best overall performance on 
the training instances is first obtained by some search 
method. Then, the solver is directly applied to an un- 
seen problem instance without a further configura- 
tion process. 
A typical AAC method consists of two main com- 
ponents: sampling in the solver class and evaluat- 
ing a candidate solver. Sampling in the solver class 
is mostly implemented based on search-based meth- 
ods and model-based methods. Search-based meth- 
ods such as hi l l climbing [50 ], local search [8 ] and 
E A s [51 ] have been used to sample solvers, since 
they make minimal assumptions about the solver 
representation and do not require gradients. Addi- 
tionally, some researchers have also explored using 
experimental design [52 ,53 ], such as the full fac- 
torial experimental design, to generate the starting 
points for the search. In comparison, model-based 
methods are more similar to the performance predic- 
tion model approach. They seek to capture the de- 
pendencies between solvers and their performance, 
by training surrogate models on the performance 
data collected during the configuration process. On 

Document 2: 
 as expected, as N and K get larger, the estimation error gets
smaller, and ˆuSN (θ) will converge to u(θ) with probability
1 with N →∞ and K →∞ . Third, Corollary 1 shows that,
for the estimator ˆuSN (θ∗) which are widely used in current
AAC methods, the gain on error reduction decreases rapidly
asN and K get larger (which are also shown in Figure 2 in
the experiments), and the effects of increasingN and K also
depend on ¯σ2
WI and ¯σ2
AI, two quantities varying across dif-
ferent algorithm conﬁguration scenarios. Thus for enhanc-
ing current AAC methods, instead of ﬁxingN as a large
number (e.g., SMAC sets N to 2000 by default) and using
as many training instances as possible, it is more desirable
to use differentN and K according to the conﬁguration sce-
nario considered, in which case N and K may be adjusted
dynamically in the conﬁguration process as more data are
gathered to estimate¯σ2
WI and ¯σ2
AI.
Experiments
In this section, we present our experimental studies. First
we introduce our experiment setup. Then, we verify our the-
oretical results in two facets: 1) comparison of different per-
formance estimators; 2) the effects of different values ofm
(the number of considered conﬁgurations), N (the number
of runs of θ to estimate u(θ)) and K (the number of training 

Document 3: 
 Non-general AC SMBO approaches Several SMBO approaches exist to perform a
limited form of AC, i.e., on only a single instance. We include these methods due to their
historical importance to the ﬁeld of AC, as well as because they may inspire new general AC
4. Note that for simplicity we assume that g is deterministic here.
443
Schede, Brandt, Tornede, Wever, Bengs, H¨ullermeier & Tierney
approaches. Most SMBO based AC approaches are based on the idea of sequential kriging
meta-modelling (Huang et al., 2006) (SKO) and sequential parameter optimization (SPO)
(Bartz-Beielstein et al., 2005), both of which are based on eﬃcient global optimization (Jones
et al., 1998). While the latter is a classical approach to black box function optimization using
BO, both SPO and SKO constitute extensions to noisy black box functions; an assumption
that is much more realistic for AC. However, both of these approaches still have potential
drawbacks. Some of these are ﬁxed by SPO + (Hutter et al., 2009a), which improves the
intensiﬁcation scheme, and time-bounded SPO (TB-SPO) (Hutter et al., 2010b), which
generalizes SPO+ to work under (potentially tight) time constraints instead of considering
the number of function evaluations as a stopping criterion.
5.2 General Model-based AC Methods 

Document 4: 
 attempted. Nonetheless, the AC literature shows a surprising amount of hybridization of
local search, evolutionary and model-based methods. We hypothesize that there is still sig-
niﬁcant progress that can be made in the area of AC, despite the sophistication of current
methods, and are encouraged by the signiﬁcant increase in attention the ﬁeld has received,
in particular through the spread of HPO techniques. Finally, we especially encourage re-
searchers to address the real-world usability of AC techniques to ensure that the promising
performance gains the AC community is seeing can beneﬁt the world at large.
Acknowledgements
This work was partially supported by the German Research Foundation (DFG) within the
Collaborative Research Center “On-The-Fly Computing” (SFB 901/3 project no. 160364472)
and by the research training group “Dataninja” (Trustworthy AI for Seamless Problem
Solving: Next Generation Intelligence Joins Robust Data Analysis) funded by the Ger-
man federal state of North Rhine-Westphalia. We also would like to thank the anonymous
reviewers for their suggestions on the ﬁrst version of this manuscript.
13. Appendix
To help the reader navigate though the jungle of AC, we provide additional resources.
Table 6 contains a list of abbreviations with terms related to AC used within this work. In
addtion, we provide a list of software resources (Table 7) that contains currently available
tools for AC. We only include software that is widely used.
469 

Document 5: 
 algorithm conﬁgurators. To this end, we propose two classiﬁcation schemes: one for AC
problems, and one for algorithm conﬁgurators. Based on this, we structure and summarize
the available literature and classify existing problem variants as well as approaches to AC.
The remainder of the paper is structured as follows. First, in Section 2, we give a formal
introduction into the setting of algorithm conﬁguration, specify the scope of this survey, and
discuss the relation between AC, AS and HPO. In Section 3, we present the classiﬁcation
schemes for AC problems and approaches that are used, in turn, to describe and compare
existing algorithm conﬁgurators. In Sections 4 and 5, we survey algorithm conﬁguration
methods grouped by the property of whether these methods are model-free or leverage
a model respectively. Section 6 deals with theoretical guarantees that can be obtained.
Diﬀerent problem variants, such as realtime AC, instance-speciﬁc vs. feature-based, multi-
objective, and dynamic AC are discussed in Sections 7 to 10. Eventually, with the help of
our classiﬁcation schemes, we elaborate on appealing research directions in Section 11 and
conclude this survey in Section 12. A list of abbreviations used in this work can be found in
Table 6. In addition, we provide a list of useful software in Table 7. We note, however, that
this list is by no means exhaustive; it is meant to provide an idea about available software
at the time of publication.
2. Problem Formulation
2.1 Algorithm Conﬁguration
To describe the AC problem more formally, we introduce the following notation that is sim- 

Document 6: 
 signment methods are based on domination between operators
and Pareto fronts. Compass was paired with probability match-
ing selection, but was also combined with D-MAB in [ 143].
Except for the widely used multiarmed bandit approach dis-
cussed so far, AOS has also been treated as a full reinforcement
learning problem by Sakurai et al.[ 173], Chen et al.[ 33] and
Pettinger and Everson [ 160]. Unlike the previous approaches,
these methods include the notion of state that is deﬁned
using feedback from the EA. For each distinct state, separate
preferences are learned for each operator and selection of the
operator to apply is based on the current state of the search.
An important issue with operator selection (as with all
adaptive parameter control) is the feedback used for control.
Veerapen et al .[ 198] presented and compared various utility
measures for variation operators. These measures are based on
a combination of exploration and exploitation measures and
use Pareto-dominance to evaluate operator utility. In another
paper, Whitacre et al .[ 204] make a distinction between
the source of feedback and any further statistical treatment
(a notion further elaborated in [112]). Several feedback sources
are suggested (including whether the offspring survives or
the number of generations it remains in the population).
The data received by these sources can be treated by av-
eraging them or by detecting the outliers in the sample. 

","There are several Augmentative and Alternative Communication (AAC) methods, each with its own strengths and weaknesses. Here's an overview of some common AAC methods:

1. **Picture Communication Symbols (PCS)**: This method uses symbols to represent words or phrases. Users point to a symbol to communicate.
2. **Symbol Sticker Systems**: Similar to PCS, but uses individual stickers instead of cards.
3. **Core Word Boards**: A board with a limited number of core words that are used frequently in communication.
4. **Word Cards**: Individual cards with words written on them, used to represent specific meanings.
5. **Labeling System**: Users assign labels to objects or actions to communicate meaning.
6. **Tactile Graphic Display (TGD)**: A tactile display device that allows users to access and input text through touch.
7. **Single Switch Communication**: Uses a single switch to select words, phrases, or sentences from an array of options.
8. **Multi-Switch Communication**: Similar to single-switch communication, but uses multiple switches to communicate.
9. **Electrical Switches**: Users use electrical switches to select words, phrases, or sentences from an array of options.
10. **Gestures and Movement**: Uses gestures, head movements, or body language to communicate meaning.

**AAC Devices**

1. **Augmentative Communication Devices (ACDs)**: Electronic devices that provide access to text through touch, voice output, or synthesized speech.
2. **Switch-Activated AAC Devices**: Devices with switches that allow users to select words, phrases, or sentences.
3. **Text-to-Speech (TTS) Devices**: Devices that synthesize speech from text input.
4. **Speech-Generating Devices (SGDs)**: Devices that generate speech through synthesized or recorded voices.

**Other AAC Methods**

1. **Manual Communication Systems**: Uses manual gestures or writing to communicate meaning.
2. **Typing and Keyboarding**: Users type on a keyboard to access and input text.
3. **Computer-Based AAC**: Uses software applications to provide AAC functionality, such as typing, word prediction, and speech output.

It's essential to note that each individual has unique needs and preferences when it comes to AAC methods. A comprehensive assessment by an AAC professional or therapist is necessary to determine the most suitable method for a person with a disability or communication disorder.",14.187719583511353,"AAC methods, or automatic algorithm configuration methods, can be classified into two main types based on their approach: sampling methods and model-based methods.

1. **Sampling Methods**: These methods involve systematically exploring the space of potential algorithms or configurations without presupposing a specific performance model. They are commonly implemented as:
   - **Search-based Methods**: Techniques like hill climbing, local search, and evolutionary algorithms (EAs) that make minimal assumptions about the representation of solvers and do not require derivative information.
   - **Experimental Design**: The use of designs such as full factorial designs to determine starting points for the sampling process.

2. **Model-based Methods**: These approaches build predictive models of algorithm performance based on gathered data. The core of model-based methods involves:
   - **Performance Prediction Models**: They utilize surrogate models to capture the relationship between algorithms and their expected performance, allowing for informed decision-making in the configuration process.
   - **Sequential Kriging Optimization (SKO)** and **Sequential Parameter Optimization (SPO)**: These specific methods are extensions designed to handle noisy performance measurements, improving efficiency in searching for optimal configurations.

Additionally, there are hybrid approaches that combine elements from different methodologies, leveraging strengths from local search, evolutionary strategies, and model-based techniques. Overall, the landscape of AAC involves both non-general and general methods, each tailored to specific operational needs and scenarios."
llama3.2:latest,"Are Parallel Algorithm Portfolios connected with financial portfolios?
","Document 1: 
 algorithms, and thereby combine parameter tuning and an algo-rithm portfolio in the same framework. We are pursuing this avenue as well. The performance of any algorithm portfolio is, of course, bounded by that of an or-acle. The combination of algorithms as black boxes eliminates any opportunity to im-prove an individual algorithm. In contrast, parallelism can be achieved by a variety of problem decomposition methods (e.g., search space splitting), as discussed in Section 3. Although the results of recent SAT solver competitions suggest that a well-designed algorithm portfolio outperforms decomposition methods on a small number 

Document 2: 
 is only determined by the current database. As a sequence, we will
introduce two portfolio frameworks as parallel individual-based
944
Algorithm Portfolio for Individual-based Surrogate-Assisted Evolutionary Algorithms GECCO ’19, July 13–17, 2019, Prague, Czech Republic
SAEAs and UCB for individual-based SAEAs which are motivated
from two different aspects as reviewed previously.
3.1 Parallel individual-based SAEAs
澽澶澡濇澵澹澵澧澽澶澡濇澵澹澵澦澽澶澡濇澵澹澵澥 澸濕濨濕澔
澶濕濧濙
濇濨濕濦濨
濇濨濣濤澳
濍
濂
澹濢濘
/ŶŝƚŝĂůŝǌĂƚŝŽŶ
/ŶĚŝǀŝĚƵĂů
^ƵƌƌŽŐĂƚĞ ^ƵƌƌŽŐĂƚĞ ^ƵƌƌŽŐĂƚĞ
/ŶĚŝǀŝĚƵĂů/ŶĚŝǀŝĚƵĂů
Figure1:Thediagramoftheframework:Parallelindividual-
based SAEAs.
Similar with the algorithm portfolio for canonical evolutionary
algorithms, it is intuitive to consider each individual-based SAEA
as a simple evolutionary algorithm and embed them into the exist-
ing framework, like PAP or MultiEA. From this aspect, the parallel
individual-based SAEAs (Par-IBSAEA) framework is proposed that
all algorithm candidates run simultaneously at each generation.
Nevertheless, it is more convenient than portfolio for canonical
evolutionaryalgorithmsbecausealmostallindividual-basedSAEAs
have the same algorithm structure and it does not require a par-
ticular design for each algorithm. A brief diagram for Par-IBSAEA
with only three algorithm instances is presented in Figure 1 where 

Document 3: 
 automatically producing effective parallel portfolios from multiple solvers, such as ppfolio and pfolioUZK, while exploiting 
the rich design spaces of these component solvers.
Katsirelos et al. [46] showed that an effective parallelization of a CDCL SAT solver does not merely hinge on picking a 
good clause sharing strategy, since it is not straightforward to obtain shorter resolution proofs by parallelization without 
essential changes of the underlying sequential reasoning mechanism. Our ACPP does not aim at parallelizing the resolution 
proof, but rather runs multiple algorithms and algorithm conﬁgurations in parallel, in order to maximize the probability 
that at least one of them ﬁnds a short proof quickly.
2.2. Related work
Well before there was widespread interest in multi-core computing, the potential beneﬁts offered by parallel algorithm 
portfolios were identiﬁed in seminal work by Huberman et al. [39]. Their notion of an algorithm portfolio is inspired by the 
use of portfolios of assets for risk management in ﬁnance and amounts to running multiple algorithms concurrently and 
independently on the same instance of a given problem, until one of them produces a solution. Gomes et al. [27] further 
investigated conditions under which such portfolios outperform their component solvers. Both lines of work considered 
prominent constraint programming problems (graph coloring and quasigroup completion), but neither presented methods 
for automatically constructing portfolio solvers. Parallel portfolios have since made practical impact, both in cases where 
the allocation of computational resources to algorithms in the portfolio is static [62,76] and where the component solvers 

Document 4: 
 is crucial for the effectiveness of any parallel portfolio.
According to (1), the performance of a parallel portfolio on
788 IEEE TRANSACTIONS ON CYBERNETICS, VOL. 52, NO. 2, FEBRUARY 2022
Algorithm 1 GAST
Input: base solvers B with conﬁguration space C; number of
component solvers k; instance set I; performance metric m;
algorithm conﬁgurator AC; independent conﬁgurator runs n; time
budgets tC, tV , tI for conﬁguration, validation and instance
generation respectively
Output:parallel portfolio c1:k
1: for i ← 1: k do
2: /*———— conﬁguration phase ———————*/
3: for j ← 1: n do
4: obtain a portfolio cj
1:i by running AC on conﬁguration space
{c1:i−1}×{ c|c ∈ C} using m for time tC
5: end for
6: validate c1
1:i, ...,cn
1:i on I using m for time tV
7: let c1:i ← arg mincj
1:i|j∈{1,...,n} P(cj
1:i, I) be the portfolio with
the best validation performance
8: /*———— instance-generation phase ————–*/ 

Document 5: 
 work relevant to parallel algorithm portfolios in-cludes online learning [2, 16] and methods that split problems [29, 30].) Effectively, the construction of a parallel algorithm portfolio to solve as many training problems as possible on K processors is an integer-programming (IP) prob-lem. The goal is to find the schedule S that specifies the time allotments to all algo-rithms on all processors, such that no problem can receive more than B time from all the processors together, and the total number of problems solved is a maximum. The expression (1 - )ij(tkj)) is 1 if problem xi is unsolved by algorithm aj after time tkj allo-cated to it 

Document 6: 
 divides the search space into subspaces, succes -
sively allocated to sequential CDCL workers. Work -
ers cooperate through some load-balancing strate -
gy, which performs the dynamic transfer of 
subspaces to idle workers, and through the 
exchange of conflict clauses.
The parallel portfolio approach was introduced 
in 2008 (Hamadi, Jabbour, and Sais 2008; Winter -
steiger, Hamadi, and de Moura 2009; Guo et al.
2010). It exploits the complementarity of different 
sequential DPLL strategies to let them compete and 
cooperate on the same formula. Since each worker 
addresses the whole formula, there is no need to 
introduce load-balancing overheads, and coopera -
tion is only achieved through the exchange of con -
flict clauses. With this approach, the crafting of the 
strategies is important, especially with only a few 
workers. The objective is to cover the space of good 
search strategies in the best possible way. 
In general, the interleaving of computation can 
lead to the previously mentioned problem of non -
determinism. This is true for solvers that use a 
Articles 
SUMMER 2013   101 
(2) Implication graph
(3) Con/f_lict-clause
(3) Con/f_lict-clause
(1) Literal
(4) Activity
(5) Con/f_lict
Preprocessing
Boolean Unit
Propagation 

","Yes, the concept of parallel algorithm portfolios is related to financial portfolios. The idea of an algorithm portfolio was first identified in seminal work by Huberman et al. [39], which was inspired by the use of portfolios of assets for risk management in finance. An algorithm portfolio involves running multiple algorithms concurrently and independently on the same instance of a given problem, with the goal of finding a solution quickly. This concept is analogous to diversifying investments across different assets to minimize risk, similar to how parallel algorithm portfolios can improve the overall performance by combining strengths of individual algorithms.",6.678970098495483,"Yes, parallel algorithm portfolios are inspired by the concept of financial portfolios. The idea behind an algorithm portfolio is similar to that of a portfolio of assets in finance, which is used for risk management. Just as investors diversify their investments across various assets to manage risk, algorithm portfolios involve running multiple algorithms concurrently and independently on the same problem instance. This approach maximizes the probability of finding a solution by leveraging the strengths of different algorithms, akin to how different financial assets can balance out risks and returns."
llama3.2:latest,"What factors and challenges influenced the development of the Parallel Algorithm Portfolios?
","Document 1: 
 training set as well as for constructing the solvers.
This article studies effective construction approaches for
parallel portfolios that are less affected by nonrepresentative
training data. The term “parallel portfolio” [25], [26] refers
to a portfolio/set of solvers that is run independently in par-
allel when solving a problem instance (see Section III-A).
As a form of solvers, parallel portfolios have several impor-
tant advantages. First, exploiting parallelism has become very
important in designing efﬁcient solvers for computationally
hard problems, considering the great development and the
wide application of parallel computing architectures [27] (e.g.,
multicore CPUs) over the last decade. Parallel portfolios
employ parallel solution strategies and, thus, could easily make
effective use of modern hardware. Second, utilizing several
different solvers (as in parallel portfolios) is a simple yet
effective strategy for solving computationally hard problems.
Such an idea has also been realized in the form of sequential
portfolios [28], [29], which try to select the best solvers for
solving a problem instance, and adaptive solvers, such as adap-
tive parameter control [30]–[33]; reactive search [34], [35];
and hyper-heuristics [36]–[38], which seek to dynamically
determine the best solver setting while solving a problem
instance. In principle, all these methods need to involve some
mechanisms (e.g., selection or scheduling) to appropriately 

Document 2: 
 Historically, the parallel computing community quickly 
adopted combinatorial search as a playground for applications.
Search algorithms have the advantage of being conceptually 
simple (think of the most basic backtrack-style algorithm) and 
computationally demanding due to the (usually) exponential
size of the search space. In contrast, the search community did 
not really focus its research on parallelizing. The lack of proper 
Articles 
SUMMER 2013   99 Copyright © 2013, Association for the Advancement of Artificial Intelligence. All rights reserved. ISSN 0738-4602 
Seven Challenges in 
Parallel SAT Solving 
Youssef Hamadi and Christoph M. Wintersteiger 
n This article provides a broad overview of the 
state of the parallel SAT solving field. A set of 
challenges to researchers is presented that, we 
believe, must be met to ensure the practical
applicability of parallel SAT solvers in the 
future. All these challenges are described infor -
mally but put into perspective with related 
research results, and a (subjective) grading of 
difficulty for each of them is provided.
infrastructure and, for many, the feeling that 
sequential algorithms were still full of research 
opportunities can go toward explaining that. In 
that community, parallelism was often only put in 
the perspectives of papers with no real perspec -
tives. This led to a situation where parallel search 
algorithms were designed by people with only one 
part of the required skills. 
Most computational problems solved on a com - 

Document 3: 
 is only determined by the current database. As a sequence, we will
introduce two portfolio frameworks as parallel individual-based
944
Algorithm Portfolio for Individual-based Surrogate-Assisted Evolutionary Algorithms GECCO ’19, July 13–17, 2019, Prague, Czech Republic
SAEAs and UCB for individual-based SAEAs which are motivated
from two different aspects as reviewed previously.
3.1 Parallel individual-based SAEAs
澽澶澡濇澵澹澵澧澽澶澡濇澵澹澵澦澽澶澡濇澵澹澵澥 澸濕濨濕澔
澶濕濧濙
濇濨濕濦濨
濇濨濣濤澳
濍
濂
澹濢濘
/ŶŝƚŝĂůŝǌĂƚŝŽŶ
/ŶĚŝǀŝĚƵĂů
^ƵƌƌŽŐĂƚĞ ^ƵƌƌŽŐĂƚĞ ^ƵƌƌŽŐĂƚĞ
/ŶĚŝǀŝĚƵĂů/ŶĚŝǀŝĚƵĂů
Figure1:Thediagramoftheframework:Parallelindividual-
based SAEAs.
Similar with the algorithm portfolio for canonical evolutionary
algorithms, it is intuitive to consider each individual-based SAEA
as a simple evolutionary algorithm and embed them into the exist-
ing framework, like PAP or MultiEA. From this aspect, the parallel
individual-based SAEAs (Par-IBSAEA) framework is proposed that
all algorithm candidates run simultaneously at each generation.
Nevertheless, it is more convenient than portfolio for canonical
evolutionaryalgorithmsbecausealmostallindividual-basedSAEAs
have the same algorithm structure and it does not require a par-
ticular design for each algorithm. A brief diagram for Par-IBSAEA
with only three algorithm instances is presented in Figure 1 where 

Document 4: 
 rithm except some important parameter settings. Therefore, the
portfolio framework in PPTA framework can be parallel-based
framework as well as sequential-based framework.
The algorithm portfolio requires algorithm constituents to
be complementary so that the portfolio algorithm can handle
different types of problems. But it is not easy to select the com-
plementary algorithms which need to test algorithm candidates
in benchmark functions. In PPTA framework, the parameter
conﬁguration obtained from different kinds of problems are
naturally complementary thanks to the classiﬁcation of train-
ing instances. Therefore, we can obtain the complementary
algorithm much easier to construct the algorithm portfolio.
3) Robustness: For each algorithm constituent in the port-
folio, it is the best parameter conﬁguration found for the
speciﬁc kind of problems. Each algorithm is suitable for a
kind of problem so that the portfolio algorithm can handle
several kinds of problems. As a result, the optimization risk
is obviously reduced.
4) Efﬁciency: The time complexity of parameter tuning
algorithm in PPTA framework can be reduced signiﬁcantly
compared with commonly used parameter tuning methods. As
mentioned before, the performance metric only evaluates the
parameter candidates on one speciﬁc problem instance.
In the algorithm portfolio phase, the time complexity does-
n’t increase a lot compared with the single algorithm because
the operators of the algorithm in PPTA are the same with
single algorithm and the total computational resources (i.e.
max FEs) are also the same. The only difference is the
strategy allocating computational resources which varies from
algorithm to algorithm. 

Document 5: 
 divides the search space into subspaces, succes -
sively allocated to sequential CDCL workers. Work -
ers cooperate through some load-balancing strate -
gy, which performs the dynamic transfer of 
subspaces to idle workers, and through the 
exchange of conflict clauses.
The parallel portfolio approach was introduced 
in 2008 (Hamadi, Jabbour, and Sais 2008; Winter -
steiger, Hamadi, and de Moura 2009; Guo et al.
2010). It exploits the complementarity of different 
sequential DPLL strategies to let them compete and 
cooperate on the same formula. Since each worker 
addresses the whole formula, there is no need to 
introduce load-balancing overheads, and coopera -
tion is only achieved through the exchange of con -
flict clauses. With this approach, the crafting of the 
strategies is important, especially with only a few 
workers. The objective is to cover the space of good 
search strategies in the best possible way. 
In general, the interleaving of computation can 
lead to the previously mentioned problem of non -
determinism. This is true for solvers that use a 
Articles 
SUMMER 2013   101 
(2) Implication graph
(3) Con/f_lict-clause
(3) Con/f_lict-clause
(1) Literal
(4) Activity
(5) Con/f_lict
Preprocessing
Boolean Unit
Propagation 

Document 6: 
 the former is to generate instances that are challenging for the
current portfolio, while the aim of the latter is to ﬁnd a new
component solver for the portfolio to better solve the newly gen-
erated instances. Applied to two widely studied problem domains,
that is, the Boolean satisﬁability problems (SAT) and the travel-
ing salesman problems (TSPs), the proposed approach identiﬁed
parallel portfolios with much better generalization than the ones
generated by the existing approaches when the training data
were scarce and biased. Moreover, it was further demonstrated
that the generated portfolios could even rival the state-of-the-art
manually designed parallel solvers.
Index Terms—Automatic portfolio construction (APC), genera-
tive adversarial approach, parallel algorithm portfolio, parameter
tuning.
I. I NTRODUCTION
M
ANY high-performance algorithms for solving com-
putationally hard problems, ranging from the exact
Manuscript received May 17, 2019; revised October 5, 2019 and March
4, 2020; accepted March 23, 2020. Date of publication April 29, 2020; date
of current version February 16, 2022. This work was supported in part by
the National Key Research and Development Program of China under Grant
2017YFB1003102, in part by the Guangdong Provincial Key Laboratory under
Grant 2020B121201001, in part by the Natural Science Foundation of China
under Grant 61672478, in part by the Program for Guangdong Introducing
Innovative and Enterpreneurial Teams under Grant 2017ZT07X386, in part 

","The development of the Parallel Algorithm Portfolios (PAPs) was influenced by several factors and challenges. Some of the key ones include:

1. **Scalability**: As the size of data sets grew, traditional serial algorithms became impractically slow. PAPs were designed to scale with large data sets.
2. **Computational Efficiency**: The need for efficient computational methods led to the development of parallel algorithms that could take advantage of multiple processors or cores.
3. **Data-Intensive Computations**: Many scientific and engineering applications require data-intensive computations, such as data mining, machine learning, and simulations. PAPs were designed to handle these types of computations efficiently.
4. **High-Performance Computing (HPC)**: The growth of HPC capabilities led to the development of parallel algorithms that could leverage multiple processors or cores to solve complex problems.
5. **Parallel Computing Frameworks**: The availability of parallel computing frameworks, such as MPI and OpenMP, provided a foundation for developing PAPs.
6. **Distributed Computing**: The need to distribute computations across multiple machines or nodes led to the development of distributed algorithms that could be used in PAPs.

Some of the challenges faced during the development of PAPs include:

1. **Synchronization and Communication**: Managing synchronization and communication between processors or threads was a significant challenge.
2. **Load Balancing**: Ensuring that each processor or thread performed an equal share of the computation was another challenge.
3. **Scalability**: Scaling PAPs to very large data sets and computational resources was a significant challenge.
4. **Parallelization Complexity**: Parallelizing serial algorithms to take advantage of multiple processors or cores can be complex, requiring careful consideration of algorithmic complexity, data structures, and synchronization.
5. **Debugging and Testing**: Debugging and testing parallel algorithms can be more challenging than debugging and testing serial algorithms due to the increased complexity and number of possible failure modes.

To address these challenges, researchers and developers employed various techniques, such as:

1. **Data Parallelism**: Breaking down large data sets into smaller sub-sets and processing them in parallel.
2. **Task Parallelism**: Breaking down computations into smaller tasks that can be executed concurrently by multiple processors or threads.
3. **Hybrid Parallelization**: Combining different parallelization strategies, such as data and task parallelism, to achieve optimal performance.

Overall, the development of PAPs required a deep understanding of algorithms, parallel computing frameworks, and distributed systems, as well as careful consideration of scalability, synchronization, and communication challenges.",13.88646960258484,"The development of Parallel Algorithm Portfolios has been influenced by several factors and challenges. Firstly, the effective construction of these portfolios is crucial, particularly concerning nonrepresentative training data, which can lead to inefficiencies. The need for utilizing different solvers within a portfolio allows for exploiting their complementarity, showcasing how they can handle different types of problems, thereby enhancing robustness and efficiency.

Another challenge involves the dynamic nature of parallel computing, where issues such as interleaving computations can lead to non-determinism. Strategies must be designed to ensure cooperation between workers while avoiding excessive load-balancing overheads. Additionally, the parallel computing community's initial lack of focus on parallelizing search algorithms, despite their computational demands, posed a challenge when integrating parallel approaches.

Moreover, the difficulty of selecting complementary algorithms for a portfolio, which necessitates extensive testing across various benchmark functions, remains a significant barrier. Researchers also face the challenge of developing effective parameter tuning methods that do not increase computational time complexity when integrating multiple algorithms.

Furthermore, efforts to generate challenging instances for portfolios, combined with the need to identify new solvers to enhance performance, inform ongoing research and development strategies. This context-driven construction, particularly under conditions of scarce and biased training data, emphasizes the necessity of advancements in automatic portfolio construction techniques to rival state-of-the-art manually designed solvers. Overall, addressing these challenges is essential for ensuring the practical applicability of parallel algorithm portfolios in solving complex computational problems."
llama3.2:latest,What are the main benefits of PAPs?,"Document 1: 
 independently in parallel to obtain multiple solutions. Then, the best solution will be
taken as the ﬁnal output of the PAP . Although a PAP would consume more computational
resources than a single algorithm, it has three important advantages. First, PAPs are
easy-to-implement because they do not necessarily require any resource allocation since
each member algorithm is simply assigned with the same amount of resource. Second,
the performance of a PAP on any problem is the best performance achieved among its
member algorithms on the problem. In other words, a PAP could achieve a much better
overall performance than any of its member algorithms. Third, considering the tremendous
growth of parallel computing architectures [22] (e.g., multi-core CPUs) over the last few
decades, leveraging parallelism has become very important in designing effective solvers
for hard optimization problems [23–27]. PAPs employ parallel solution strategies and thus
allow for the use of modern computing facilities in an extremely simple way.
It is conceivable that any PAP’s effectiveness relies heavily on the diversity and com-
plementarity among its member algorithms. In other words, the manual construction
of high-quality PAPs is generally a challenging task, requiring domain experts (with a
deep understanding of both algorithms and problems) to explore the vast design space
of PAPs, which cannot be carried out manually with ease [28–30]. As an alternative, Tang
and Liu [25,26] proposed a general framework, called automatic construction of PAPs, that 

Document 2: 
 on PAP with more than two constituent algorithms.
Two conclusions regarding the migration scheme of PAP
can be drawn from the superiority of PAP over the compared
algorithms. First, the migration scheme is of great impor-
tance to the success of PAP. Second, 1 andMAX GEN/20
are two appropriate and robust values for the parame-
tersmigration size and migration interval. To further
investigate the inﬂuence of these parameters on PAP, we
carried out a sensitivity analysis to check whether the per-
formance of PAP will change signiﬁcantly with other param-
eter settings. As stated in Section VI-B, 16 different pairs
ofmigration interval and migration size were tested for
every instantiation of PAP. For each pair, 30 independent
runs were executed on all 27 benchmark functions. Then, for
each instantiation on each function, Kruskal–Wallis one-way
analysis of variance by ranks was employed to test whether
the 16 pairs of parameters had led to signiﬁcantly different
performance. After that, for each instantiation of PAP, we
counted the number of the benchmark functions on which
all 16 pairs of parameters made no difference. The larger
the number, the more insensitive an instantiation is to the
parameters. For the sake of brevity, we only summarize in
Table IX these numbers for the 11 PAP instantiations, while
omit the full details. It can be observed that, in the worst case 

Document 3: 
 described as follows:
Ω(P, z) =max{max
θ∈P
Metric (θ, z), Metric ( ¯θ, z)}, (14)
where ¯θ represents the Restructure procedure. Note Equation (14) is slightly different from
Equation (11) (i.e., the performance of conventional PAPs) due to theRestructure procedure.
Initialization
member 
algorithm 
𝜃
1
𝑆
1
member 
algorithm 
𝜃
𝑖
𝑆
𝑖
member 
algorithm 
𝜃
𝑘
𝑆
𝑘
…
…
…
…
𝑆
𝑘
+
1
𝑆
𝑜𝑢𝑡𝑝𝑢𝑡
Comparison
Restructure
Improvement
Figure 1. Illustrations of MOEAs/PAP , the variant form of PAP for MOPs. Si represents the so-
lution set found by member algorithm θi, and Soutput represents the solution set ﬁnally returned
by MOEAs/PAP . The main difference of MOEAs/PAP from conventional PAPs lies in the way of
determining the ﬁnal output, as indicated by the dash box.
Electronics 2023, 12, 4639 7 of 18
4. Automatic Construction of MOEAs/PAP
As aforementioned, the member algorithms of a PAP could be automatically deter-
mined by solving the problem deﬁned in Equation (13). Below, we ﬁrst introduce the 

Document 4: 
 • When constructing MOEAs/PAPs, it is important to maintain the diversity among the
member algorithms. Hence, the population diversity preservation schemes, such as
negatively correlated search [47], can be introduced into the construction approach to
promote cooperation between different member algorithms.
• In real-world applications, one may be unable to collect sufﬁcient MOPs as training
problems. How to automatically build powerful PAPs in these scenarios is also
worth studying.
• The effectiveness of MOEAs/PAP has been primarily demonstrated through exper-
imental evidence, but with an absence of theoretical analysis. A more thorough
investigation of its exceptional performance is crucial for advancing our understand-
ing, which, in turn, can lead to enhancements in its design and the development of a
more comprehensive automatic construction algorithm.
Electronics 2023, 12, 4639 17 of 18
Author Contributions: Conceptualization, S.L.; Methodology, S.L.; Software, X.M.; Validation, X.M.;
Resources, X.M.; Writing—original draft, X.M.; Writing—review and editing, W.H.; Supervision, S.L.
and W.H. All authors have read and agreed to the published version of the manuscript.
Funding: This research was supported by the Strategic Priority Research Program of Chinese
Academy of Science, Grant No. XDB32050100, and the National Natural Science Foundation of
China, Grant No. 91948303.
Data Availability Statement: The data presented in this study are available on request from the 

Document 5: 
 the risks associated with two algorithms. Such a metric can
be used to evaluate how effective our PAP is, together with
other common metrics. Given a set of functions, the proposed
metric essentially measures how likely it is that an algorithm
will ﬁnd a better solution than another algorithm by the end
of a given time budget.
To evaluate the effectiveness of PAP, 11 instantiations of
PAP were implemented based on four existing constituent
algorithms, including SaNSDE, wPSO, G3PCX, and CMA-
ES. The performance of each instantiation was compared to
PENG et al.: POPULATION-BASED ALGORITHM PORTFOLIOS FOR NUMERICAL OPTIMIZATION 799
its constituent algorithms on 27 benchmark functions. Our
experimental results showed that seven out of the 11 PAP in-
stantiations outperformed their constituent algorithms in terms
of solution quality and the proposed risk metric. Furthermore,
7 out of the 11 instantiations even achieved superior or compa-
rable performance in comparison with G-CMA-ES, which was
known to be superior to any of the four constituent algorithms.
Our empirical studies also revealed that PAP is capable of
increasing the probability of ﬁnding the global optimum and
is insensitive to control parameters of the migration scheme.
Further analyses have been conducted to investigate in what
circumstance PAP may outperform its constituent algorithms.
Complementarity was identiﬁed as a key issue.
Though PAP has been shown to be a promising framework, 

Document 6: 
 also presented. The performance of the two instantiations on
TSP and VRPSPDTW problems support the effectiveness of
CEPS in the sense that, in comparison with state-of-the-art
PAP construction approaches, the PAPs obtained by CEPS
achieves better generalization performance.
Since CEPS is a generic framework, some discussions
would help elaborate issues that are of signiﬁcance in practice.
First, although this work assumes CEPS takes a set of initial
training instances as the input, such training instances are
not necessarily real-world instances but could be generated
randomly. In other words, CEPS could be used in a fully cold-
start setting (a.k.a. zero-shot), i.e., no real-world instances are
available for the target problem class. Further, CEPS could
either be run ofﬂine or online, i.e., it could accommodate new
real instances whenever available.
Second, the potential of CEPS could be further explored
by taking advantage of the data generated during its run,
except for the ﬁnal obtained PAP. The data contain all the
sampled conﬁgurations and instances, and the performance
of the former on the latter. Considering that when using
a search method to solve a problem instance, its optimal
parameter values are usually problem-instance dependent and
thus need to be tuned. To tune parameters for a new problem
instance, we can learn from the historical data generated by
CEPS to build a mapping from problem instances to their
optimal parameter values, i.e., a low-cost online parameter- 

","PAPs (Personal Air Purifiers) offer several benefits, including:

1. Improved indoor air quality: PAPs can remove airborne pollutants, allergens, and bacteria, creating a healthier indoor environment.
2. Reduced allergy symptoms: By removing allergens such as dust, pollen, and pet dander, PAPs can help alleviate allergy symptoms like sneezing, congestion, and itchy eyes.
3. Relief from respiratory issues: PAPs can help reduce the severity of respiratory conditions like asthma, COPD, and bronchitis by removing airborne irritants.
4. Reduced risk of infection: By killing bacteria, viruses, and other microorganisms, PAPs can help prevent illnesses like the common cold and flu.
5. Long-term health benefits: Regular use of PAPs can lead to improved lung function, reduced inflammation, and a lower risk of long-term respiratory problems.
6. Increased energy: By removing pollutants and allergens from the air, PAPs can help improve sleep quality and increase energy levels.
7. Enhanced productivity: A healthier indoor environment can boost focus, concentration, and overall productivity.
8. Customization: Many PAPs come with adjustable settings, allowing users to tailor their cleaning modes to specific needs and preferences.

However, it's essential to note that not all PAPs are created equal, and the effectiveness of a device depends on various factors, including:

* Filter quality and replacement schedule
* Room size and ventilation
* User behavior (e.g., opening windows, using fans)

When choosing a PAP, consider your specific needs, room size, and the manufacturer's claims to ensure you find an effective and reliable solution.",9.940727710723875,"The main benefits of Population-Based Algorithm Portfolios (PAPs) include:

1. **Easy Implementation**: PAPs are simple to implement as they do not require complex resource allocation; each member algorithm is assigned the same resources.

2. **Enhanced Performance**: The performance of a PAP is determined by the best result achieved among its member algorithms for a given problem, potentially leading to better overall performance compared to any individual algorithm.

3. **Utilization of Parallel Computing**: PAPs leverage parallel solution strategies, thereby effectively utilizing modern parallel computing architectures, which is crucial for tackling hard optimization problems.

4. **Diversity and Complementarity**: The effectiveness of a PAP relies on the diversity and complementarity among its member algorithms, which can lead to more robust solutions.

5. **Sensitivity to Parameters**: Empirical studies have shown that PAPs can be insensitive to the control parameters of the migration scheme, making their performance more stable across different settings.

Overall, these benefits contribute to the robustness and effectiveness of PAPs in solving complex optimization problems."
