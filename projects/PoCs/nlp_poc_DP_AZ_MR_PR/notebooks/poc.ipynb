{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "from engine.ner_detector import tokenize_evaluate_and_detect_NERs\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    TextClassificationPipeline,\n",
    ")\n",
    "import numpy as np\n",
    "from typing import Any\n",
    "from engine.data import prepare_data_for_fine_tuning, read_data\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA is available. Using GPU.\")\n",
    "        return \"cuda\"\n",
    "    else:\n",
    "        print(\"CUDA not available. Using CPU.\")\n",
    "        return \"cpu\"\n",
    "    \n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"roberta-base\"\n",
    "MODEL_PATH = \"output/best/model.safetensors\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9899ebe30444a3b510eca60839c043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/795 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = read_data(\"data/split_raw/test.tsv\")\n",
    "test_dataset = prepare_data_for_fine_tuning(test, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_PATH, config=config\n",
    ")\n",
    "model.eval()\n",
    "pipeline = TextClassificationPipeline(\n",
    "    model=model, tokenizer=tokenizer, top_k=2, device=device\n",
    ")\n",
    "\n",
    "if(device == \"cuda\"):\n",
    "    model.cuda()\n",
    "else:\n",
    "    model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16036/16036 [00:00<00:00, 1282043.71it/s]\n"
     ]
    }
   ],
   "source": [
    "res = tokenize_evaluate_and_detect_NERs(pipeline, \n",
    "                                  test['text'], \n",
    "                                  spacy_model=\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = list(map(lambda x: x[0], res))\n",
    "importance = list(map(lambda x: x[1], res))\n",
    "ners = list(map(lambda x: x[2], res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={'token': tokens, 'importance': importance, 'ner': ners})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.1763361692428589"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(df[df['ner'] == 'PERSON']['importance'].values)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_importance = df[df['ner'] == 'PERSON']['importance'].max()\n",
    "least_importance = -1.1763361692428589 # min value is oabamacare which obama's programme\n",
    "# df[df['ner'] == 'PERSON']['importance'].min()\n",
    "\n",
    "most_important_person = df[df['importance'] == most_importance]['token'].values[0][1:]\n",
    "least_important_person = df[df['importance'] == least_importance]['token'].values[0][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Romney', 'Obama')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_important_person, least_important_person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample token replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs1 = test[test['text'].str.contains(most_important_person)]\n",
    "obs2 = test[test['text'].str.contains(least_important_person)]\n",
    "\n",
    "adv_obs1 = obs1.copy()\n",
    "adv_obs2 = obs2.copy()\n",
    "\n",
    "adv_obs1['text'] = adv_obs1['text'].str.replace(most_important_person, least_important_person)\n",
    "adv_obs2['text'] = adv_obs2['text'].str.replace(least_important_person, most_important_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1_org = pipeline(obs1[\"text\"].tolist())\n",
    "predictions2_org = pipeline(obs2[\"text\"].tolist())\n",
    "\n",
    "predictions1_adv = pipeline(adv_obs1[\"text\"].tolist())\n",
    "predictions2_adv = pipeline(adv_obs2[\"text\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_prediction(pred: list[dict[str, Any]]) -> np.ndarray:\n",
    "    if pred[0][\"label\"] == \"LABEL_1\":\n",
    "        return pred[0][\"score\"]\n",
    "    else:\n",
    "        return pred[1][\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    (np.array(list(map(convert_prediction, predictions1_org))) >= 0.5)\n",
    "    == (np.array(list(map(convert_prediction, predictions1_adv))) >= 0.5)\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6438356164383562"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    (np.array(list(map(convert_prediction, predictions2_org))) >= 0.5)\n",
    "    == (np.array(list(map(convert_prediction, predictions2_adv))) >= 0.5)\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples to presentation/report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mitt Romney drove to Canada with the family dog Seamus strapped to the roof of the car.\n",
      "prediction: 0.08\n"
     ]
    }
   ],
   "source": [
    "pred = convert_prediction(pipeline(obs1[\"text\"].tolist()[0])[0])\n",
    "\n",
    "print(obs1.iloc[0, 0])\n",
    "print(f'prediction: {pred:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mitt Obama drove to Canada with the family dog Seamus strapped to the roof of the car.\n",
      "prediction: 0.79\n"
     ]
    }
   ],
   "source": [
    "pred = convert_prediction(pipeline(adv_obs1[\"text\"].tolist()[0])[0])\n",
    "\n",
    "print(adv_obs1.iloc[0, 0])\n",
    "print(f'prediction: {pred:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
