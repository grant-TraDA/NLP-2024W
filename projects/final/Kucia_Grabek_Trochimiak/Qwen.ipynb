{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Directory containing text files\n",
    "data_dir = 'data'\n",
    "all_text = ''\n",
    "\n",
    "# Reading all text files from the directory\n",
    "for file_name in os.listdir(data_dir):\n",
    "    if file_name.endswith('.txt'):\n",
    "        with open(os.path.join(data_dir, file_name), 'r', encoding='utf-8') as file:\n",
    "            all_text += file.read() + '\\n'\n",
    "\n",
    "# Splitting data into training (80%) and evaluation (20%) sets\n",
    "train_text, eval_text = train_test_split(all_text.split('\\n'), test_size=0.2, random_state=42)\n",
    "\n",
    "# Joining lines to form complete text for training and evaluation\n",
    "train_text = '\\n'.join(train_text)\n",
    "eval_text = '\\n'.join(eval_text)\n",
    "\n",
    "# Saving the training and evaluation data to separate files\n",
    "with open('train.txt', 'w', encoding='utf-8') as train_file:\n",
    "    train_file.write(train_text)\n",
    "\n",
    "with open('eval.txt', 'w', encoding='utf-8') as eval_file:\n",
    "    eval_file.write(eval_text)\n",
    "\n",
    "print(\"Data split and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 56/56 [00:00<00:00, 1866.71 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:00<00:00, 833.27 examples/s]\n",
      "C:\\Users\\Filip\\AppData\\Local\\Temp\\ipykernel_17420\\239879204.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "\n",
      "\u001b[A\n",
      "                                      \n",
      "\u001b[A                                            \n",
      "\n",
      "  0%|          | 0/42 [10:15<?, ?it/s]       \n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.82485294342041, 'eval_runtime': 0.3054, 'eval_samples_per_second': 49.118, 'eval_steps_per_second': 13.098, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "                                      \n",
      "\u001b[A                                            \n",
      "\n",
      "  0%|          | 0/42 [10:19<?, ?it/s]       \n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.740758895874023, 'eval_runtime': 0.3216, 'eval_samples_per_second': 46.636, 'eval_steps_per_second': 12.436, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                      \n",
      "\u001b[A                                            \n",
      "\n",
      "  0%|          | 0/42 [10:25<?, ?it/s]       \n",
      "\u001b[A\n",
      "                                      \n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42/42 [00:14<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.708907604217529, 'eval_runtime': 0.402, 'eval_samples_per_second': 37.312, 'eval_steps_per_second': 9.95, 'epoch': 3.0}\n",
      "{'train_runtime': 14.4416, 'train_samples_per_second': 11.633, 'train_steps_per_second': 2.908, 'train_loss': 4.7641652425130205, 'epoch': 3.0}\n",
      "Fine-tuning complete and model saved.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load tokenizer and model (you can replace 'gpt2' with any other LLM)\n",
    "model_name = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Load the text files into datasets\n",
    "train_dataset = load_dataset('text', data_files='train.txt')['train']\n",
    "eval_dataset = load_dataset('text', data_files='eval.txt')['train']\n",
    "\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "# Set pad_token if not already set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Tokenize the datasets and include labels\n",
    "def tokenize_function(examples):\n",
    "    outputs = tokenizer(examples['text'], padding='max_length', truncation=True, max_length=512)\n",
    "    outputs[\"labels\"] = outputs[\"input_ids\"].copy()  # Set labels to be the same as input_ids for causal LM\n",
    "    return outputs\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True, remove_columns=['text'])\n",
    "eval_dataset = eval_dataset.map(tokenize_function, batched=True, remove_columns=['text'])\n",
    "\n",
    "# Define a data collator that will dynamically pad the inputs and labels\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False  # Set to False for causal language modeling\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained('./fine-tuned-model')\n",
    "tokenizer.save_pretrained('./fine-tuned-model')\n",
    "\n",
    "print(\"Fine-tuning complete and model saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Filip\\anaconda3\\envs\\ASP\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Filip\\.cache\\huggingface\\hub\\models--xlm-roberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 56/56 [00:00<00:00, 800.00 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:00<00:00, 500.02 examples/s]\n",
      "c:\\Users\\Filip\\anaconda3\\envs\\ASP\\lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\Filip\\AppData\\Local\\Temp\\ipykernel_17420\\3907470921.py:51: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                      \n",
      "\u001b[A                                           \n",
      "\n",
      "  0%|          | 0/42 [26:09<?, ?it/s]       \n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.205465078353882, 'eval_runtime': 1.0121, 'eval_samples_per_second': 14.82, 'eval_steps_per_second': 7.904, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                      \n",
      "\u001b[A                                            \n",
      "\n",
      "  0%|          | 0/42 [26:37<?, ?it/s]       \n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.551729917526245, 'eval_runtime': 1.1791, 'eval_samples_per_second': 12.722, 'eval_steps_per_second': 6.785, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                      \n",
      "\u001b[A                                            \n",
      "\n",
      "  0%|          | 0/42 [27:06<?, ?it/s]       \n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.179887056350708, 'eval_runtime': 1.046, 'eval_samples_per_second': 14.34, 'eval_steps_per_second': 7.648, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      \n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [01:17<00:00,  3.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 77.2222, 'train_samples_per_second': 2.176, 'train_steps_per_second': 0.272, 'train_loss': 2.478679656982422, 'epoch': 3.0}\n",
      "Fine-tuning complete and model saved.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelForMaskedLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load tokenizer and model (using 'xlm-roberta-base' for multilingual capabilities)\n",
    "model_name = 'xlm-roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "\n",
    "# Load the text files into datasets\n",
    "train_dataset = load_dataset('text', data_files='train.txt')['train']\n",
    "eval_dataset = load_dataset('text', data_files='eval.txt')['train']\n",
    "\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "# Set pad_token if not already set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Tokenize the datasets and include labels\n",
    "def tokenize_function(examples):\n",
    "    outputs = tokenizer(examples['text'], padding='max_length', truncation=True, max_length=512)\n",
    "    outputs[\"labels\"] = outputs[\"input_ids\"].copy()  # Set labels to be the same as input_ids for masked LM\n",
    "    return outputs\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True, remove_columns=['text'])\n",
    "eval_dataset = eval_dataset.map(tokenize_function, batched=True, remove_columns=['text'])\n",
    "\n",
    "# Define a data collator that will dynamically pad the inputs and labels\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=True,  # Enable masked language modeling for training\n",
    "    mlm_probability=0.15  # Set the probability of masking tokens\n",
    ")\n",
    "\n",
    "# Define training arguments with constraints for limited VRAM\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,  # Adjust batch size as needed\n",
    "    per_device_eval_batch_size=2,   # Adjust as needed\n",
    "    gradient_accumulation_steps=4,  # Increase to simulate a larger batch size with less VRAM\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=500,\n",
    "    fp16=True,  # Use mixed precision for better VRAM efficiency\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained('./fine-tuned-model')\n",
    "tokenizer.save_pretrained('./fine-tuned-model')\n",
    "\n",
    "print(\"Fine-tuning complete and model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: The capital of <mask> is Paris.\n",
      "Predicted answer: France\n",
      "Input: New media as software = Recens√£o <mask>.\n",
      "Predicted answer: Software\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Step 1: Load the fine-tuned model and tokenizer\n",
    "model_path = './fine-tuned-model'\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Step 2: Function to run inference and predict masked tokens\n",
    "def predict_masked_token(text):\n",
    "    # Tokenize input with <mask>\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = outputs.logits\n",
    "    \n",
    "    # Find the index of the masked token and get the predicted token\n",
    "    masked_index = torch.where(inputs['input_ids'] == tokenizer.mask_token_id)[1]\n",
    "    predicted_token_id = torch.argmax(predictions[0, masked_index, :])\n",
    "    predicted_token = tokenizer.decode(predicted_token_id)\n",
    "    \n",
    "    return predicted_token\n",
    "\n",
    "# Step 3: Use the function to answer a question or complete a sentence\n",
    "example_text = \"The capital of <mask> is Paris.\"\n",
    "answer = predict_masked_token(example_text)\n",
    "print(f\"Input: {example_text}\")\n",
    "print(f\"Predicted answer: {answer}\")\n",
    "\n",
    "# Example for asking a question\n",
    "question = \"New media as software = Recens√£o <mask>.\"\n",
    "answer = predict_masked_token(question)\n",
    "print(f\"Input: {question}\")\n",
    "print(f\"Predicted answer: {answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 485/485 [00:00<00:00, 768.56 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17708/17708 [00:23<00:00, 755.21 examples/s]\n",
      "c:\\Users\\Filip\\anaconda3\\envs\\ASP\\lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "  1%|          | 100/12100 [00:30<1:00:00,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.6963, 'grad_norm': 8.378801345825195, 'learning_rate': 4.958677685950414e-05, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 200/12100 [01:00<56:47,  3.49it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.8958, 'grad_norm': 12.086433410644531, 'learning_rate': 4.917355371900827e-05, 'epoch': 1.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 300/12100 [01:30<57:43,  3.41it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.5834, 'grad_norm': 9.473154067993164, 'learning_rate': 4.87603305785124e-05, 'epoch': 2.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|‚ñé         | 400/12100 [01:59<57:20,  3.40it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.4235, 'grad_norm': 8.992918968200684, 'learning_rate': 4.834710743801653e-05, 'epoch': 3.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 500/12100 [02:29<1:02:44,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.2344, 'grad_norm': 9.476482391357422, 'learning_rate': 4.793388429752066e-05, 'epoch': 4.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|‚ñç         | 500/12100 [06:39<1:02:44,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7.236117839813232, 'eval_runtime': 250.3105, 'eval_samples_per_second': 70.744, 'eval_steps_per_second': 8.845, 'epoch': 4.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|‚ñç         | 600/12100 [07:12<1:00:24,  3.17it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.1583, 'grad_norm': 8.530677795410156, 'learning_rate': 4.75206611570248e-05, 'epoch': 4.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñå         | 700/12100 [07:44<1:05:59,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.0105, 'grad_norm': 8.562764167785645, 'learning_rate': 4.7107438016528926e-05, 'epoch': 5.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|‚ñã         | 800/12100 [08:14<58:46,  3.20it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.9265, 'grad_norm': 9.934786796569824, 'learning_rate': 4.669421487603306e-05, 'epoch': 6.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|‚ñã         | 900/12100 [08:43<1:00:27,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.7926, 'grad_norm': 8.429489135742188, 'learning_rate': 4.6280991735537196e-05, 'epoch': 7.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 1000/12100 [09:13<53:25,  3.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.7525, 'grad_norm': 8.050535202026367, 'learning_rate': 4.586776859504133e-05, 'epoch': 8.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|‚ñä         | 1000/12100 [13:24<53:25,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7.091294765472412, 'eval_runtime': 251.4555, 'eval_samples_per_second': 70.422, 'eval_steps_per_second': 8.805, 'epoch': 8.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|‚ñâ         | 1100/12100 [14:00<1:01:47,  2.97it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.6527, 'grad_norm': 8.725563049316406, 'learning_rate': 4.545454545454546e-05, 'epoch': 9.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñâ         | 1200/12100 [14:34<58:11,  3.12it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.5476, 'grad_norm': 7.808073043823242, 'learning_rate': 4.504132231404959e-05, 'epoch': 9.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|‚ñà         | 1300/12100 [15:09<1:02:44,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.4995, 'grad_norm': 7.877635478973389, 'learning_rate': 4.462809917355372e-05, 'epoch': 10.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñè        | 1400/12100 [15:54<1:22:49,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.4029, 'grad_norm': 8.554482460021973, 'learning_rate': 4.4214876033057856e-05, 'epoch': 11.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñè        | 1500/12100 [16:37<2:02:35,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.3504, 'grad_norm': 8.313836097717285, 'learning_rate': 4.3801652892561984e-05, 'epoch': 12.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      " 12%|‚ñà‚ñè        | 1500/12100 [21:10<2:02:35,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.9733734130859375, 'eval_runtime': 272.9511, 'eval_samples_per_second': 64.876, 'eval_steps_per_second': 8.111, 'epoch': 12.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|‚ñà‚ñé        | 1600/12100 [21:45<53:04,  3.30it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.2681, 'grad_norm': 8.52759075164795, 'learning_rate': 4.338842975206612e-05, 'epoch': 13.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|‚ñà‚ñç        | 1700/12100 [22:18<52:54,  3.28it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.2176, 'grad_norm': 8.901269912719727, 'learning_rate': 4.2975206611570254e-05, 'epoch': 14.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|‚ñà‚ñç        | 1800/12100 [22:52<56:18,  3.05it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.1398, 'grad_norm': 8.279951095581055, 'learning_rate': 4.256198347107438e-05, 'epoch': 14.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñå        | 1900/12100 [23:25<54:05,  3.14it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0836, 'grad_norm': 8.595198631286621, 'learning_rate': 4.214876033057851e-05, 'epoch': 15.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|‚ñà‚ñã        | 2000/12100 [24:00<53:18,  3.16it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0194, 'grad_norm': 10.841180801391602, 'learning_rate': 4.1735537190082645e-05, 'epoch': 16.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 17%|‚ñà‚ñã        | 2000/12100 [28:26<53:18,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.88667631149292, 'eval_runtime': 266.4374, 'eval_samples_per_second': 66.462, 'eval_steps_per_second': 8.31, 'epoch': 16.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|‚ñà‚ñã        | 2100/12100 [29:01<53:45,  3.10it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9962, 'grad_norm': 9.193202018737793, 'learning_rate': 4.132231404958678e-05, 'epoch': 17.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñä        | 2200/12100 [29:30<46:58,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.917, 'grad_norm': 9.272565841674805, 'learning_rate': 4.0909090909090915e-05, 'epoch': 18.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|‚ñà‚ñâ        | 2300/12100 [29:59<47:01,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8658, 'grad_norm': 9.78098201751709, 'learning_rate': 4.049586776859504e-05, 'epoch': 18.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñâ        | 2400/12100 [30:28<45:38,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8488, 'grad_norm': 9.63419246673584, 'learning_rate': 4.008264462809918e-05, 'epoch': 19.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|‚ñà‚ñà        | 2500/12100 [30:59<52:18,  3.06it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.7537, 'grad_norm': 10.415353775024414, 'learning_rate': 3.9669421487603306e-05, 'epoch': 20.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 21%|‚ñà‚ñà        | 2500/12100 [35:19<52:18,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.8289666175842285, 'eval_runtime': 259.6469, 'eval_samples_per_second': 68.2, 'eval_steps_per_second': 8.527, 'epoch': 20.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|‚ñà‚ñà‚ñè       | 2600/12100 [35:55<51:15,  3.09it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.7082, 'grad_norm': 9.23658275604248, 'learning_rate': 3.925619834710744e-05, 'epoch': 21.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|‚ñà‚ñà‚ñè       | 2700/12100 [36:30<52:26,  2.99it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6993, 'grad_norm': 10.451447486877441, 'learning_rate': 3.884297520661157e-05, 'epoch': 22.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|‚ñà‚ñà‚ñé       | 2800/12100 [37:02<51:32,  3.01it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6424, 'grad_norm': 12.360048294067383, 'learning_rate': 3.8429752066115703e-05, 'epoch': 23.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|‚ñà‚ñà‚ñç       | 2900/12100 [37:32<52:03,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6004, 'grad_norm': 9.5986328125, 'learning_rate': 3.801652892561984e-05, 'epoch': 23.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|‚ñà‚ñà‚ñç       | 3000/12100 [38:06<46:26,  3.27it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5543, 'grad_norm': 10.398751258850098, 'learning_rate': 3.760330578512397e-05, 'epoch': 24.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 25%|‚ñà‚ñà‚ñç       | 3000/12100 [42:37<46:26,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.756008148193359, 'eval_runtime': 271.2696, 'eval_samples_per_second': 65.278, 'eval_steps_per_second': 8.162, 'epoch': 24.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|‚ñà‚ñà‚ñå       | 3100/12100 [43:12<1:04:59,  2.31it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5119, 'grad_norm': 10.71173095703125, 'learning_rate': 3.71900826446281e-05, 'epoch': 25.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|‚ñà‚ñà‚ñã       | 3200/12100 [43:43<47:10,  3.14it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5191, 'grad_norm': 11.558547019958496, 'learning_rate': 3.6776859504132236e-05, 'epoch': 26.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 3300/12100 [44:14<41:50,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.4484, 'grad_norm': 10.745762825012207, 'learning_rate': 3.6363636363636364e-05, 'epoch': 27.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 3400/12100 [44:45<41:33,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.4251, 'grad_norm': 10.158214569091797, 'learning_rate': 3.59504132231405e-05, 'epoch': 28.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|‚ñà‚ñà‚ñâ       | 3500/12100 [45:18<46:16,  3.10it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.38, 'grad_norm': 11.752439498901367, 'learning_rate': 3.553719008264463e-05, 'epoch': 28.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 29%|‚ñà‚ñà‚ñâ       | 3500/12100 [49:37<46:16,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.795668125152588, 'eval_runtime': 259.1897, 'eval_samples_per_second': 68.321, 'eval_steps_per_second': 8.542, 'epoch': 28.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñâ       | 3600/12100 [50:09<39:10,  3.62it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.3667, 'grad_norm': 11.629626274108887, 'learning_rate': 3.512396694214876e-05, 'epoch': 29.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|‚ñà‚ñà‚ñà       | 3700/12100 [50:38<43:34,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.2962, 'grad_norm': 10.828832626342773, 'learning_rate': 3.47107438016529e-05, 'epoch': 30.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|‚ñà‚ñà‚ñà‚ñè      | 3800/12100 [51:09<38:04,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.3004, 'grad_norm': 12.258402824401855, 'learning_rate': 3.429752066115703e-05, 'epoch': 31.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 3900/12100 [51:38<41:30,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.2631, 'grad_norm': 13.483973503112793, 'learning_rate': 3.388429752066116e-05, 'epoch': 32.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 4000/12100 [52:08<41:21,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.2327, 'grad_norm': 10.779280662536621, 'learning_rate': 3.347107438016529e-05, 'epoch': 32.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 4000/12100 [56:20<41:21,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.743625640869141, 'eval_runtime': 251.6857, 'eval_samples_per_second': 70.358, 'eval_steps_per_second': 8.797, 'epoch': 32.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 4100/12100 [56:57<44:24,  3.00it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1938, 'grad_norm': 12.065994262695312, 'learning_rate': 3.305785123966942e-05, 'epoch': 33.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|‚ñà‚ñà‚ñà‚ñç      | 4200/12100 [57:26<35:42,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1864, 'grad_norm': 12.930488586425781, 'learning_rate': 3.264462809917356e-05, 'epoch': 34.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 4300/12100 [57:56<37:18,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1479, 'grad_norm': 12.388154029846191, 'learning_rate': 3.2231404958677685e-05, 'epoch': 35.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñã      | 4400/12100 [58:25<37:40,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1338, 'grad_norm': 12.389945983886719, 'learning_rate': 3.181818181818182e-05, 'epoch': 36.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 4500/12100 [58:58<40:19,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.101, 'grad_norm': 13.095452308654785, 'learning_rate': 3.1404958677685955e-05, 'epoch': 37.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 4500/12100 [1:03:17<40:19,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.744268894195557, 'eval_runtime': 259.1294, 'eval_samples_per_second': 68.337, 'eval_steps_per_second': 8.544, 'epoch': 37.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 4600/12100 [1:03:48<44:33,  2.80it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0666, 'grad_norm': 12.968731880187988, 'learning_rate': 3.099173553719008e-05, 'epoch': 37.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|‚ñà‚ñà‚ñà‚ñâ      | 4700/12100 [1:04:19<34:25,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0527, 'grad_norm': 11.472243309020996, 'learning_rate': 3.057851239669421e-05, 'epoch': 38.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñâ      | 4800/12100 [1:04:49<49:28,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0039, 'grad_norm': 11.85537052154541, 'learning_rate': 3.016528925619835e-05, 'epoch': 39.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 4900/12100 [1:05:19<34:35,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0411, 'grad_norm': 12.782691955566406, 'learning_rate': 2.975206611570248e-05, 'epoch': 40.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 5000/12100 [1:05:50<34:28,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9893, 'grad_norm': 12.806731224060059, 'learning_rate': 2.9338842975206616e-05, 'epoch': 41.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      " 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 5000/12100 [1:10:06<34:28,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.726179122924805, 'eval_runtime': 255.3026, 'eval_samples_per_second': 69.361, 'eval_steps_per_second': 8.672, 'epoch': 41.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 5100/12100 [1:10:38<45:22,  2.57it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9475, 'grad_norm': 13.565256118774414, 'learning_rate': 2.8925619834710744e-05, 'epoch': 42.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 5200/12100 [1:11:12<33:39,  3.42it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9462, 'grad_norm': 12.958394050598145, 'learning_rate': 2.8512396694214875e-05, 'epoch': 42.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 5300/12100 [1:11:41<30:52,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9153, 'grad_norm': 13.223419189453125, 'learning_rate': 2.809917355371901e-05, 'epoch': 43.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 5400/12100 [1:12:12<36:26,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.903, 'grad_norm': 13.815834045410156, 'learning_rate': 2.7685950413223145e-05, 'epoch': 44.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 5500/12100 [1:12:46<41:47,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8906, 'grad_norm': 13.465398788452148, 'learning_rate': 2.7272727272727273e-05, 'epoch': 45.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 5500/12100 [1:16:56<41:47,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.762022495269775, 'eval_runtime': 249.7169, 'eval_samples_per_second': 70.912, 'eval_steps_per_second': 8.866, 'epoch': 45.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 5600/12100 [1:17:26<29:25,  3.68it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.857, 'grad_norm': 14.012314796447754, 'learning_rate': 2.6859504132231405e-05, 'epoch': 46.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 5700/12100 [1:17:55<31:26,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8471, 'grad_norm': 13.57468032836914, 'learning_rate': 2.644628099173554e-05, 'epoch': 47.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 5800/12100 [1:18:23<30:40,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8203, 'grad_norm': 14.73724365234375, 'learning_rate': 2.6033057851239674e-05, 'epoch': 47.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 5900/12100 [1:18:51<28:54,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8063, 'grad_norm': 14.033075332641602, 'learning_rate': 2.5619834710743802e-05, 'epoch': 48.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 6000/12100 [1:19:19<27:09,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7909, 'grad_norm': 12.858050346374512, 'learning_rate': 2.5206611570247934e-05, 'epoch': 49.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 6000/12100 [1:23:24<27:09,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.764978408813477, 'eval_runtime': 245.4937, 'eval_samples_per_second': 72.132, 'eval_steps_per_second': 9.019, 'epoch': 49.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 6100/12100 [1:23:56<29:15,  3.42it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.766, 'grad_norm': 13.190642356872559, 'learning_rate': 2.4797520661157024e-05, 'epoch': 50.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 6200/12100 [1:24:26<29:13,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7615, 'grad_norm': 13.797409057617188, 'learning_rate': 2.438429752066116e-05, 'epoch': 51.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 6300/12100 [1:24:56<27:15,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7482, 'grad_norm': 14.228917121887207, 'learning_rate': 2.397107438016529e-05, 'epoch': 51.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 6400/12100 [1:25:26<28:08,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7192, 'grad_norm': 14.130762100219727, 'learning_rate': 2.3557851239669422e-05, 'epoch': 52.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 6500/12100 [1:25:55<25:08,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7023, 'grad_norm': 14.36883544921875, 'learning_rate': 2.3144628099173554e-05, 'epoch': 53.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 6500/12100 [1:30:00<25:08,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.756079196929932, 'eval_runtime': 244.8559, 'eval_samples_per_second': 72.32, 'eval_steps_per_second': 9.042, 'epoch': 53.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 6600/12100 [1:30:29<25:05,  3.65it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7045, 'grad_norm': 14.90459156036377, 'learning_rate': 2.273140495867769e-05, 'epoch': 54.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 6700/12100 [1:31:04<30:15,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6768, 'grad_norm': 13.32442855834961, 'learning_rate': 2.231818181818182e-05, 'epoch': 55.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 6800/12100 [1:31:34<28:51,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.659, 'grad_norm': 15.18667221069336, 'learning_rate': 2.190495867768595e-05, 'epoch': 56.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 6900/12100 [1:32:06<27:23,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.639, 'grad_norm': 14.812850952148438, 'learning_rate': 2.1491735537190083e-05, 'epoch': 56.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 7000/12100 [1:32:41<25:36,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6332, 'grad_norm': 15.713417053222656, 'learning_rate': 2.1078512396694218e-05, 'epoch': 57.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 7000/12100 [1:36:55<25:36,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.772141456604004, 'eval_runtime': 254.0101, 'eval_samples_per_second': 69.714, 'eval_steps_per_second': 8.716, 'epoch': 57.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 7100/12100 [1:37:29<28:36,  2.91it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6229, 'grad_norm': 15.490211486816406, 'learning_rate': 2.066528925619835e-05, 'epoch': 58.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 7200/12100 [1:38:02<24:57,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.5912, 'grad_norm': 14.377694129943848, 'learning_rate': 2.025206611570248e-05, 'epoch': 59.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 7300/12100 [1:38:34<29:55,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6226, 'grad_norm': 15.346203804016113, 'learning_rate': 1.984297520661157e-05, 'epoch': 60.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 7400/12100 [1:39:08<22:43,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.5829, 'grad_norm': 15.62594223022461, 'learning_rate': 1.9429752066115702e-05, 'epoch': 61.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 7500/12100 [1:39:41<25:43,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.5681, 'grad_norm': 15.886835098266602, 'learning_rate': 1.9016528925619837e-05, 'epoch': 61.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 7500/12100 [1:44:05<25:43,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.789973258972168, 'eval_runtime': 263.6608, 'eval_samples_per_second': 67.162, 'eval_steps_per_second': 8.397, 'epoch': 61.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 7600/12100 [1:44:36<21:25,  3.50it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.555, 'grad_norm': 15.317134857177734, 'learning_rate': 1.860330578512397e-05, 'epoch': 62.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 7700/12100 [1:45:09<24:14,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.5558, 'grad_norm': 14.709211349487305, 'learning_rate': 1.81900826446281e-05, 'epoch': 63.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 7800/12100 [1:45:40<23:06,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.5143, 'grad_norm': 14.96395492553711, 'learning_rate': 1.777685950413223e-05, 'epoch': 64.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 7900/12100 [1:46:12<20:46,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.51, 'grad_norm': 15.254074096679688, 'learning_rate': 1.7363636363636366e-05, 'epoch': 65.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 8000/12100 [1:46:44<23:09,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.5304, 'grad_norm': 14.901637077331543, 'learning_rate': 1.6950413223140495e-05, 'epoch': 65.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 8000/12100 [1:51:02<23:09,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.7808837890625, 'eval_runtime': 258.8076, 'eval_samples_per_second': 68.421, 'eval_steps_per_second': 8.555, 'epoch': 65.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 8100/12100 [1:51:36<20:00,  3.33it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4925, 'grad_norm': 15.152372360229492, 'learning_rate': 1.653719008264463e-05, 'epoch': 66.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 8200/12100 [1:52:05<20:03,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.5067, 'grad_norm': 16.16629409790039, 'learning_rate': 1.612396694214876e-05, 'epoch': 67.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 8300/12100 [1:52:36<17:59,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4814, 'grad_norm': 14.660419464111328, 'learning_rate': 1.5710743801652896e-05, 'epoch': 68.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 8400/12100 [1:53:06<18:42,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4508, 'grad_norm': 15.333077430725098, 'learning_rate': 1.5297520661157024e-05, 'epoch': 69.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 8500/12100 [1:53:35<16:40,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4726, 'grad_norm': 14.836492538452148, 'learning_rate': 1.4884297520661159e-05, 'epoch': 70.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 8500/12100 [1:57:55<16:40,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.8048529624938965, 'eval_runtime': 260.3177, 'eval_samples_per_second': 68.025, 'eval_steps_per_second': 8.505, 'epoch': 70.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 8600/12100 [1:58:25<20:12,  2.89it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4523, 'grad_norm': 15.271116256713867, 'learning_rate': 1.447107438016529e-05, 'epoch': 70.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 8700/12100 [1:58:55<16:18,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4367, 'grad_norm': 15.634391784667969, 'learning_rate': 1.4057851239669423e-05, 'epoch': 71.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 8800/12100 [1:59:24<16:18,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4278, 'grad_norm': 15.47030258178711, 'learning_rate': 1.3644628099173553e-05, 'epoch': 72.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 8900/12100 [1:59:54<15:27,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4372, 'grad_norm': 15.563417434692383, 'learning_rate': 1.3231404958677688e-05, 'epoch': 73.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 9000/12100 [2:00:22<14:39,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4062, 'grad_norm': 16.24469757080078, 'learning_rate': 1.2818181818181818e-05, 'epoch': 74.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 9000/12100 [2:04:43<14:39,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.8253936767578125, 'eval_runtime': 260.0948, 'eval_samples_per_second': 68.083, 'eval_steps_per_second': 8.512, 'epoch': 74.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 9100/12100 [2:05:13<14:07,  3.54it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4083, 'grad_norm': 13.833292961120605, 'learning_rate': 1.2404958677685952e-05, 'epoch': 75.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 9200/12100 [2:05:42<13:40,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3966, 'grad_norm': 14.789444923400879, 'learning_rate': 1.1991735537190084e-05, 'epoch': 75.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 9300/12100 [2:06:12<13:45,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3922, 'grad_norm': 15.984077453613281, 'learning_rate': 1.1578512396694215e-05, 'epoch': 76.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 9400/12100 [2:06:41<13:06,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3848, 'grad_norm': 15.620939254760742, 'learning_rate': 1.1165289256198348e-05, 'epoch': 77.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 9500/12100 [2:07:10<12:19,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3858, 'grad_norm': 15.602383613586426, 'learning_rate': 1.075206611570248e-05, 'epoch': 78.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 9500/12100 [2:11:30<12:19,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.81731653213501, 'eval_runtime': 260.1879, 'eval_samples_per_second': 68.059, 'eval_steps_per_second': 8.509, 'epoch': 78.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 9600/12100 [2:12:00<11:54,  3.50it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3808, 'grad_norm': 15.339333534240723, 'learning_rate': 1.0338842975206613e-05, 'epoch': 79.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 9700/12100 [2:12:29<11:25,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3416, 'grad_norm': 16.559043884277344, 'learning_rate': 9.925619834710745e-06, 'epoch': 80.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 9800/12100 [2:12:59<11:20,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.357, 'grad_norm': 15.714468002319336, 'learning_rate': 9.512396694214878e-06, 'epoch': 80.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 9900/12100 [2:13:28<11:42,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3362, 'grad_norm': 16.044240951538086, 'learning_rate': 9.09917355371901e-06, 'epoch': 81.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10000/12100 [2:13:58<10:02,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3498, 'grad_norm': 16.537641525268555, 'learning_rate': 8.685950413223142e-06, 'epoch': 82.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10000/12100 [2:18:18<10:02,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.829772472381592, 'eval_runtime': 260.2676, 'eval_samples_per_second': 68.038, 'eval_steps_per_second': 8.507, 'epoch': 82.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10100/12100 [2:18:48<09:40,  3.44it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.345, 'grad_norm': 15.380019187927246, 'learning_rate': 8.272727272727274e-06, 'epoch': 83.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 10200/12100 [2:19:17<09:17,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3241, 'grad_norm': 16.44738006591797, 'learning_rate': 7.859504132231405e-06, 'epoch': 84.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 10300/12100 [2:19:47<08:58,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3278, 'grad_norm': 15.550043106079102, 'learning_rate': 7.446280991735538e-06, 'epoch': 84.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 10400/12100 [2:20:16<08:05,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3163, 'grad_norm': 16.36534309387207, 'learning_rate': 7.033057851239671e-06, 'epoch': 85.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 10500/12100 [2:20:45<07:47,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.313, 'grad_norm': 16.257549285888672, 'learning_rate': 6.619834710743802e-06, 'epoch': 86.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 10500/12100 [2:25:05<07:47,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.851263999938965, 'eval_runtime': 260.3414, 'eval_samples_per_second': 68.018, 'eval_steps_per_second': 8.504, 'epoch': 86.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 10600/12100 [2:25:36<06:59,  3.58it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.307, 'grad_norm': 17.11347007751465, 'learning_rate': 6.206611570247934e-06, 'epoch': 87.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 10700/12100 [2:26:05<06:46,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3075, 'grad_norm': 15.412469863891602, 'learning_rate': 5.793388429752066e-06, 'epoch': 88.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 10800/12100 [2:26:35<06:10,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3038, 'grad_norm': 15.852795600891113, 'learning_rate': 5.380165289256198e-06, 'epoch': 89.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 10900/12100 [2:27:09<07:09,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3048, 'grad_norm': 15.737333297729492, 'learning_rate': 4.9669421487603305e-06, 'epoch': 89.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 11000/12100 [2:27:42<05:27,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2888, 'grad_norm': 16.05455780029297, 'learning_rate': 4.553719008264463e-06, 'epoch': 90.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 11000/12100 [2:32:14<05:27,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.84592866897583, 'eval_runtime': 271.8607, 'eval_samples_per_second': 65.136, 'eval_steps_per_second': 8.144, 'epoch': 90.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 11100/12100 [2:32:46<04:47,  3.48it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2843, 'grad_norm': 16.33783531188965, 'learning_rate': 4.140495867768595e-06, 'epoch': 91.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 11200/12100 [2:33:15<04:20,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2904, 'grad_norm': 16.69676399230957, 'learning_rate': 3.727272727272727e-06, 'epoch': 92.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 11300/12100 [2:33:45<04:26,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2689, 'grad_norm': 16.69298553466797, 'learning_rate': 3.3181818181818183e-06, 'epoch': 93.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 11400/12100 [2:34:14<03:11,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2924, 'grad_norm': 16.267929077148438, 'learning_rate': 2.90495867768595e-06, 'epoch': 94.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 11500/12100 [2:34:43<02:43,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2822, 'grad_norm': 16.490894317626953, 'learning_rate': 2.4917355371900825e-06, 'epoch': 94.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 11500/12100 [2:39:00<02:43,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.851628303527832, 'eval_runtime': 257.0795, 'eval_samples_per_second': 68.881, 'eval_steps_per_second': 8.612, 'epoch': 94.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 11600/12100 [2:39:32<02:29,  3.35it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2666, 'grad_norm': 16.766637802124023, 'learning_rate': 2.0785123966942152e-06, 'epoch': 95.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 11700/12100 [2:40:03<01:54,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2754, 'grad_norm': 15.42139720916748, 'learning_rate': 1.6652892561983473e-06, 'epoch': 96.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 11800/12100 [2:40:32<01:23,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2563, 'grad_norm': 16.441789627075195, 'learning_rate': 1.2520661157024794e-06, 'epoch': 97.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 11900/12100 [2:41:00<00:57,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2836, 'grad_norm': 16.650550842285156, 'learning_rate': 8.388429752066116e-07, 'epoch': 98.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 12000/12100 [2:41:29<00:29,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2776, 'grad_norm': 15.606143951416016, 'learning_rate': 4.2561983471074387e-07, 'epoch': 98.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 12000/12100 [2:45:46<00:29,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.856013298034668, 'eval_runtime': 257.7867, 'eval_samples_per_second': 68.692, 'eval_steps_per_second': 8.588, 'epoch': 98.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12100/12100 [2:46:15<00:00,  3.61it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2557, 'grad_norm': 14.04565715789795, 'learning_rate': 1.2396694214876035e-08, 'epoch': 99.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12100/12100 [2:46:16<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 9976.7676, 'train_samples_per_second': 4.861, 'train_steps_per_second': 1.213, 'train_loss': 3.1137027835057784, 'epoch': 99.79}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_t5\\\\tokenizer_config.json',\n",
       " './fine_tuned_t5\\\\special_tokens_map.json',\n",
       " './fine_tuned_t5\\\\spiece.model',\n",
       " './fine_tuned_t5\\\\added_tokens.json')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from transformers import (\n",
    "    T5Config, T5Tokenizer, T5ForConditionalGeneration, TrainingArguments, Trainer\n",
    ")\n",
    "from datasets import Dataset\n",
    "\n",
    "# 1. Create a custom T5 configuration\n",
    "config = T5Config(\n",
    "    vocab_size=32128,\n",
    "    n_positions=512,\n",
    "    d_model=512,\n",
    "    d_kv=64,\n",
    "    d_ff=2048,\n",
    "    num_layers=6,\n",
    "    num_decoder_layers=6,\n",
    "    num_heads=8,\n",
    "    relative_attention_num_buckets=32,\n",
    "    dropout_rate=0.1,\n",
    "    layer_norm_epsilon=1e-6,\n",
    "    initializer_factor=1.0,\n",
    "    is_encoder_decoder=True,\n",
    "    pad_token_id=0,\n",
    "    eos_token_id=1,\n",
    "    decoder_start_token_id=0  # Set to the pad_token_id\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Load the tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "\n",
    "# 3. Initialize the T5 model with the custom configuration\n",
    "model = T5ForConditionalGeneration(config)\n",
    "\n",
    "# 4. Load and preprocess data with chunks and in-book train-test splits\n",
    "train_chunks = []\n",
    "test_chunks = []\n",
    "\n",
    "for filename in os.listdir('data'):\n",
    "    if filename.endswith('.txt'):\n",
    "        with open(os.path.join('data', filename), 'r', encoding='utf-8') as file:\n",
    "            content = file.read().strip()\n",
    "            \n",
    "            # Tokenize the content into tokens of length 512\n",
    "            tokenized_content = tokenizer.encode(content, truncation=False, return_tensors=\"pt\")[0]\n",
    "            \n",
    "            # Split the tokenized content into chunks of 512 tokens\n",
    "            for i in range(0, len(tokenized_content), 512):\n",
    "                chunk = tokenized_content[i:i+512]\n",
    "                \n",
    "                # Decode the chunk back to text and store it as a chunk\n",
    "                chunk_text = tokenizer.decode(chunk, skip_special_tokens=True).strip()\n",
    "                if chunk_text:  # Ensure the chunk is not empty\n",
    "                    train_chunks.append(chunk_text)\n",
    "            \n",
    "            # Split into training and testing chunks (80/20 split)\n",
    "            split_index = int(len(train_chunks) * 0.8)\n",
    "            test_chunks.extend(train_chunks[split_index:])\n",
    "            train_chunks = train_chunks[:split_index]\n",
    "\n",
    "# Convert the train and test chunks into Dataset objects\n",
    "train_dataset = Dataset.from_dict({\"text\": train_chunks})\n",
    "test_dataset = Dataset.from_dict({\"text\": test_chunks})\n",
    "\n",
    "\n",
    "# Tokenize the datasets\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"longest\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    # Set the input as the label for unsupervised learning\n",
    "    model_inputs[\"labels\"] = model_inputs[\"input_ids\"].clone()\n",
    "    return model_inputs\n",
    "\n",
    "# Apply preprocessing to the training and test data\n",
    "tokenized_train_data = train_dataset.map(preprocess_function, batched=True, remove_columns=[\"text\"])\n",
    "tokenized_test_data = test_dataset.map(preprocess_function, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "# 5. Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=100,\n",
    "    per_device_train_batch_size=1,  # Adjust to fit VRAM\n",
    "    gradient_accumulation_steps=4,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,  # Evaluate every 500 steps\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    fp16=True,  # Enable mixed precision\n",
    "    remove_unused_columns=False  # Ensure all columns are retained\n",
    ")\n",
    "\n",
    "# 6. Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_data,\n",
    "    eval_dataset=tokenized_test_data\n",
    ")\n",
    "\n",
    "# 7. Train the model\n",
    "trainer.train()\n",
    "\n",
    "# 8. Save the trained model and tokenizer\n",
    "trainer.save_model(\"./fine_tuned_t5\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_t5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['180 Manuel Portela Software Takes Command accurately revisi ts and summarizes the history of human -computer interaction, while analyzing these interactions as they are embodied in our current software. The work develops its own critical language and provides a model for analyzing computer applications, theorizing t hem as formal components that are determinant in the creation of media and in the transcoding of cultural practices that incorporate media software. The intelligence and breadth of Manovich‚Äôs approach makes this book relevant for all those who, in the fiel ds of computer science, art, design, history and theory of new media, and related disciplines, wish to understand the multiple forms and structures of interaction and manipulation encoded in the software we use in many of our creative and communicative pra ctices. Manovich beautifully synthesizes a significant part of his work as programmer, designer and digital animator, media artist, researcher and professor, helping to strengthen and expand the field of cultural studies of software, one of the corollaries of his previous systematic analysis of the language of new media. This is an essential book in the canon, still in formation, of software studies, and it should be added to books and essays by Matthew Fuller, Michael Mateas, Mark C. Marino, Noah Wardrip -Fruin, Nick Montfort and Wendy Hui Kyong Chun .  2013 Manuel Portela . View publication statsSee discussions, st ats, and author pr ofiles f or this public ation at : https: .researchgate.ne t ation New media as software = Recenso a: Lev Manovich - Software takes command: extending the language of new media Article in Matlit R evista do Pr ograma de Dout orament o em Mat erialidades da Lit eratura  Januar y 2013 DOI: 10.14195 CITATIONS 0READS 321 1 author: Manuel P ortela Univ ersity of Coimbr a 51 PUBLICA TIONS 127 CITATIONS SEE PROFILE All c ontent f ollo wing this p age was uplo aded b',\n",
       " 'y Manuel P ortela on 17 Sept ember 2017. The user has r equest ed enhanc ement of the do wnlo aded file. A navega√ßo consulta e descarregamento dos ttulos inseridos nas Bibliotecas Digitais UC Digitalis, UC Pombalina e UC Impactum, pressupem a aceita√ßo plena e sem reservas dos Termos e Condi√ßes de Uso destas Bibliotecas Digitais, disponveis em https: Conforme exposto nos referidos Termos e Condi√ßes de Uso, o descarregamento de ttulos de acesso restrito requer uma licen√ßa v√°lida de autoriza√ßo devendo o utilizador aceder ao(s) documento(s) a partir de um endere√ßo de IP da institui√ßo detentora da supramencionada licen√ßa. Ao utilizador √© apenas permitido o descarregamento para uso pessoal, pelo que o emprego do(s) ttulo(s) descarregado(s) para outro fim, designadamente comercial, carece de autoriza√ßo do respetivo autor ou editor da obra. Na medida em que todas as obras da UC Digitalis se encontram protegidas pelo C√≥digo do Direito de Autor e Direitos Conexos e demais legisla√ßo aplic√°vel, toda a c√≥pia, parcial ou total, deste documento, nos casos em que √© legalmente admitida, dever√° conter ou fazerse',\n",
       " 'acompanhar por este aviso. New media as software = Recenso a: Lev Manovich - Software takes command: extending the language of new media Autor(es): Portela, Manuel Publicado por: Centro de Literatura Portuguesa URL persistente:URI:http: DOI: DOI:http: Accessed : 17Sep2017 15:46:38 digitalis.uc.ptimpactum.uc.ptMATLIT 1.2 (2013 ): 176180. ISSN 21828830 New Media as Software MANUEL PORTELA CLP | University of Coimbra Lev Manovich, Software Takes Command: Extending the Language of New Media . London: Bloomsbury, 2013, 358 pp. ISBN 9781623568177. uly 2013 saw the publication of the fifth volume in the series ‚ÄòInternational Texts in Critical Media Aesthetics‚Äô, directed by Francisco J. Ricardo. Following the volumes by C.T. Funkhouser ( New Directions in Digital Poetry , 2012), Markku Eskelinen ( Cybertext Poetics: The Critical Landscape of New Media Literary Theory , 2012; see review in MATLIT, Volume 1.1 , pp. 208212), Martha Buskirk ( Creative Enterprise: Contemporary Art between Museum and Marketplace , 2012), and Franci sco J. Ricardo ( The Aesthetic Engagement: Experiencing New Media Art through Critique , 2013), Software Takes Command confirms the importance of this series in the renewal of critical thinking about digital mediation by its interdisciplinary method for addr essing the technical, aesthetic, and social dimensions of ongoing processes. The development of a critical theory of media which attempts to be, at the same time, a critical aesthetics of media is a sign of the revaluation of the aesthetic and, in particul ar, of the appreciation of media arts in their multiple forms (digital art, digital music, digital literature) as practices and devices for interrogating the medial condition of human culture in the computer age. In Lev Manovich‚Äôs most recent book, this programmatic interrogation of our medial condition leads to the following question: do media still exist',\n",
       " \"after software? This is the question that triggers Manovich‚Äôs dialogue both with computing history and with theories of digital media of recent decades, including the extension of his own previous formulations in The Language of New Media , published in 2001, and which became a major reference work in the field. The subtitle of the new book points precisely to this critical J New Media as Software 177 revisit ing of his earlier work in the context of ubiquitous computing and accelerated transcoding of social, cultural and artistic practices by software. Its title, in turn, contains a reference to Mechanization Takes Command (1947), by Sigfried Giedion, a book t hat described the process of mechanization of society in many sectors of industry, commerce, and services. The book‚Äôs title thus suggests a similar chain of multiple and wide -ranging effects based on the observation of the action of the digital computer as a tool for social reproduction. This analysis of retroactivity between culture and software is described in three stages. The first part (‚ÄòInventing Media Software', pp. 53 -157) describes the invention of media software based on a historical analysis of t he conceptual models contained in the interfaces and programs designed by some of the engineers who theorized the features of interaction and visualization of the digital computer. Noteworthy inventors and thinkers discussed include J. C. R. Licklider, Iva n Sutherland, Ted Nelson, Douglas Engelbart and, in particular, Alan Kay, in whose ideas Manovich sees the foreshadowing of the 'universal media machine' that would come to define the shape of the digital computer as a set of applications for authoring and editing media objects in the same unified interface, currently embodied in the integrated operations of hardware, software, and network. The remediating nature of digital media, highlighted by Bolter and Grusin as one of their predominant formal principle s, seems to have originated in a particular conceptual model for programming and interfacing. The second part (‚ÄòHybridization and Evolution‚Äô, p p. 159 -239) describes the strategies for hybridization of genres and forms that a ccompanied the transformation of the computer into a multimedia machine, which can be theorized either as a metamedium that remediates\",\n",
       " \"all other media, or as a monomedium that dissolves the boundaries of those media it absorbs. Finally, in the third part ('Software in Action', pp. 241 -327), Manovich examines in detail various media software applications showing how the properties of software have become properties of media. Throughout the book, several applications are closely analyzed, namely, the image editing program Photoshop (pp. 124 -147) and the video editing program After Effects (pp. 243 -327), demonstrating how their layered compos itional properties result in an aesthetics of hybridity, remixing, and variability. One of the premises of Manovich is that software has become 'the engine of contemporary societies' to such a degree that the terms 'software society' and 'software culture' constitute by now appropriate metonymies to symbolize a wide range of processes of social reproduction, which extend to the economic, artistic and commu nication processes. Media software, the main object of Software Takes Command , would be one of those technocultural categories, through which it becomes possible to understand the overdetermination of media content by software form. The two basic hypothes es posed by Manovich are that the specificity of new media culture can be 178 Manuel Portela described from this software layer, and the materiality of digital processing, that is, the unification of multiple data streams via the same universal binary encoding process, calls into question the very separation of media as distinct technologies. The preponderance of the software as a common layer would imply the eventual dissolution of their technical, generic and formal identity. An analysis of media archaeology shows that elec tronic media of late nineteenth century led to the replacement of direct inscription in a surface that was accessible to human senses (as was the case of engraving, letterpress, lithography and photography) by a set of electrical signals which had to be represented and controlled via an interface ‚Äì for example, the frequency display and buttons of a radio device. The introduction of this interface for representation and control changed the operation of media, since their properties also came to depend on th is interface. Digitization of media in the late twentieth century continued this separation of data display from their technical representation in the coding layer. With the representation of\",\n",
       " \"data in the form of numerical codes, these can only be accessed through software applications, thus instituting the separation between hardware and software. Properties of digital media are now determined by the specific properties of the software that makes them accessible and processable. The history of computing sho ws that the development of programming and interfaces consisted essentially of exploring the simulating capabilities theorized by Alan Turing and John von Neumann when they conceptualized the computer as a multifunctional simulatory machine. Unlike the his torical evolution of analog media towards their own particular languages, the digital computer seems realize itself ontologically through the simulation of previous media, constantly expanding their possibilities. This flexibility results from the separati on of hardware from software, which makes possible a process of continuous experimentation that leads to the creation of the ‚Äònew‚Äô in new media, and which is described through an analogy with the avantgarde experimentation with processes and media: What differentiates a modern digital computer from any other machine ‚Äì including industrial media machines for capturing and playing media ‚Äì is separation of hardware and software. It is because an endless number of different programs performing different tasks can be written to run on the same type of machine, that that machine ‚Äì i.e. a digital computer ‚Äì is used so widely today. Consequently, the constant invention of new (and modification of existing) media software, is simply one example of this general prin ciple. In its very structure computational media is ‚Äúavantgarde‚Äù since it is constantly being extended and thus redefined. (92 -93) Extensibility and constant redefinition would result, ultimately, in the overdetermination of the content of media by the software with which they are processed, i.e., produced, distributed, received, and appropriated. In the New Media as Software 179 context of a complete digitization of media, the postulate 'the medium is the message' can be rephrased as 'the software is the message'. In turn, the prominence of software as a common substrate for all media seems to imply the loss of operational value for the very notion of media inherited from previous technologies. Other recent works, such as Inventing the Medium (2012) by Janet H. Murray, have propo sed the replacement of the concept 'digital media' by 'digital medium', suggesting\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Output: a w roku z gldaszt ia. W k o naakiej si cym zasy, kt√≥rzym dody czytelazu Muzeumaem. Krzto tywyka wana dobdzie najwaanianie ej rozbrze ‚Äì uzowa byaowanizuca sazkadzia latwartuki. Jegosza ju kiednystaw√≥rzuje si\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# 1. Load the trained model and tokenizer\n",
    "model_path = \"./fine_tuned_t5\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "\n",
    "# 2. Move the model to the appropriate device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 3. Prepare the input text for inference\n",
    "input_text = \"Jaka strategia ta kierowa≈Ça Warholem ju≈º w wywiadzie z 1963 roku?\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "# 4. Generate predictions with appropriate generation parameters\n",
    "try:\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_length=512,       # Maximum length of the generated text\n",
    "        num_return_sequences=1,\n",
    "        temperature=0.9,      # Adjusts randomness (increase for more diverse output)\n",
    "        top_k=50,             # Top-k sampling to limit possible tokens\n",
    "        top_p=0.95,           # Nucleus sampling for balanced generation\n",
    "        num_beams=5,          # Use beam search for coherent results\n",
    "        early_stopping=True,\n",
    "        no_repeat_ngram_size=2  # Prevents repeating n-grams for more coherent output\n",
    "    )\n",
    "\n",
    "    # 5. Decode and print the generated output\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(\"Generated Output:\", generated_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error during generation:\", str(e))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
