{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Tomcio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "nltk.download('wordnet')\n",
    "from rouge_score import rouge_scorer\n",
    "from copy import deepcopy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bert_score import score\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_questions = '../data_processing_scripts/q_a/questions'\n",
    "path_to_answers = '../data_processing_scripts/q_a/answers_auto'\n",
    "path_to_model_answers = '../data_processing_scripts/q_a/model_answers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['Balladyna']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['Balladyna', 'Dziady_(Mickiewicz)', 'Konrad_Wallenrod',\n",
    "               'Kordian', 'Lalka_(Prus)', 'Ogniem_i_mieczem', 'Pan_Tadeusz_(wyd._1834)',\n",
    "                 'Pan_Wołodyjowski', 'Potop_(Sienkiewicz)', 'Quo_vadis', 'Sonety_Adama_Mickiewicza']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bert_score_results(df_questions, df_answers, df_model_answers):\n",
    "    BERT_scores = []\n",
    "    \n",
    "    for i in range(len(df_questions)):\n",
    "        hypothesis = df_answers.iloc[:,0][i]\n",
    "        reference = df_model_answers.iloc[:,0][i]\n",
    "\n",
    "\n",
    "        P, R, F1 = score([hypothesis], [reference], lang=\"pl\", verbose=False)\n",
    "\n",
    "        BERT_scores.append(float(F1))\n",
    "\n",
    "    return BERT_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_BLEU_results(df_questions, df_answers, df_model_answers):\n",
    "    BLEU_scores = []\n",
    "    \n",
    "    for i in range(len(df_questions)):\n",
    "        hypothesis = df_answers.iloc[:,0][i].split(\" \")\n",
    "        reference = df_model_answers.iloc[:,0][i]\n",
    "        reference = [i.split(\" \") for i in reference]\n",
    "\n",
    "        #print(hypothesis)\n",
    "        #print(reference)\n",
    "        #print('--------------')\n",
    "\n",
    "\n",
    "        BLEUscore = nltk.translate.bleu_score.sentence_bleu(reference, hypothesis, weights=([1]))\n",
    "        BLEU_scores.append(BLEUscore)\n",
    "\n",
    "    return BLEU_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_METEOR_results(df_questions, df_answers, df_model_answers):\n",
    "    METEOR_scores = []\n",
    "    \n",
    "    for i in range(len(df_questions)):\n",
    "        hypothesis = df_answers.iloc[:,0][i].split(\" \")\n",
    "        reference = df_model_answers.iloc[:,0][i]\n",
    "\n",
    "        METEORscore = nltk.translate.meteor_score.meteor_score([reference], hypothesis)\n",
    "        METEOR_scores.append(METEORscore)\n",
    "\n",
    "    return METEOR_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ROUGE_results(df_questions, df_answers, df_model_answers):\n",
    "    ROGUE_scores = []\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    for i in range(len(df_questions)):\n",
    "        hypothesis = df_answers.iloc[:,0][i]\n",
    "        reference = df_model_answers.iloc[:,0][i]\n",
    "\n",
    "        cur_rouge_score = []\n",
    "\n",
    "        for ref in reference:\n",
    "            ROGUEscore = scorer.score(ref, hypothesis)\n",
    "            cur_rouge_score.append(ROGUEscore)\n",
    "\n",
    "        # Initialize variables to store highest scores\n",
    "        max_rouge1 = {'score': 0, 'rouge': None}\n",
    "        max_rouge2 = {'score': 0, 'rouge': None} \n",
    "        max_rougeL = {'score': 0, 'rouge': None}\n",
    "\n",
    "        # Iterate through scores\n",
    "        for i, score in enumerate(cur_rouge_score):\n",
    "            rouge1_fmeasure = score['rouge1'].fmeasure\n",
    "            rouge2_fmeasure = score['rouge2'].fmeasure\n",
    "            rougeL_fmeasure = score['rougeL'].fmeasure\n",
    "            \n",
    "            if rouge1_fmeasure >= max_rouge1['score']:\n",
    "                max_rouge1['score'] = rouge1_fmeasure\n",
    "                max_rouge1['rouge'] = score['rouge1']\n",
    "                \n",
    "            if rouge2_fmeasure >= max_rouge2['score']:\n",
    "                max_rouge2['score'] = rouge2_fmeasure\n",
    "                max_rouge2['rouge'] = score['rouge2']\n",
    "                \n",
    "            if rougeL_fmeasure >= max_rougeL['score']:\n",
    "                max_rougeL['score'] = rougeL_fmeasure\n",
    "                max_rougeL['rouge'] = score['rougeL']\n",
    "    \n",
    "\n",
    "        ROGUE_scores.append({'rouge1':max_rouge1['rouge'], 'rouge2':max_rouge2['rouge'], 'rougeL':max_rougeL['rouge']})\n",
    "\n",
    "    return ROGUE_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(model=None):\n",
    "    if model is None:\n",
    "        return 'pass the model name variable, named like the result files'\n",
    "    \n",
    "    BLEU = {}\n",
    "    METEOR = {}\n",
    "    ROUGE = {}\n",
    "    BERT = {}\n",
    "\n",
    "    for file in file_names:\n",
    "        print(file)\n",
    "        df_questions = pd.read_table(path_to_questions + '/' + file + '_questions.txt', sep='\\t', header=None)\n",
    "        with open(path_to_answers + '/' + file + '/anserws_' + model + '.txt', 'r', encoding='utf-8') as f:\n",
    "            content = f.read().split('===')\n",
    "        df_answers = pd.DataFrame(content, columns=['Answer'])\n",
    "        df_answers['Answer'] = df_answers['Answer'].str.strip(\"\\n\")\n",
    "        #df_answers = pd.read_table(path_to_answers + '/' + file + '/answers_' + model + '.txt', lineterminator='===', header=None)\n",
    "        df_model_answers = pd.read_table(path_to_model_answers + '/' + file + '_paraphrased.txt', sep=\"\\t\", header=None)\n",
    "        df_model_answers.iloc[:,0] = df_model_answers.iloc[:,0].str.split('\\n')\n",
    "\n",
    "        BLEU_result = calculate_BLEU_results(df_questions, df_answers, df_model_answers)\n",
    "        #print(BLEU_result)\n",
    "\n",
    "        METEOR_result = calculate_METEOR_results(df_questions, df_answers, df_model_answers)\n",
    "        #print(METEOR_result)\n",
    "\n",
    "        # TO ZWRACA DICTA XDDDDD\n",
    "        ROUGE_result = calculate_ROUGE_results(df_questions, df_answers, df_model_answers)\n",
    "        #print(ROUGE_result)\n",
    "\n",
    "        BERT_result = calculate_bert_score_results(df_questions, df_answers, df_model_answers)\n",
    "\n",
    "        BLEU[file] = BLEU_result\n",
    "        METEOR[file] = METEOR_result\n",
    "        ROUGE[file] = ROUGE_result\n",
    "        BERT[file] = BERT_result\n",
    "\n",
    "    ROUGE_1 = deepcopy(ROUGE)\n",
    "    ROUGE_2 = deepcopy(ROUGE)\n",
    "    ROUGE_L = deepcopy(ROUGE)\n",
    "\n",
    "    for key, val in ROUGE.items():\n",
    "        ROUGE_1[key] = [val[i]['rouge1'].fmeasure for i in range(len(val))]\n",
    "        ROUGE_2[key] = [val[i]['rouge2'].fmeasure for i in range(len(val))]\n",
    "        ROUGE_L[key] = [val[i]['rougeL'].fmeasure for i in range(len(val))]\n",
    "\n",
    "    for file in file_names:\n",
    "        print(f\"{file} & {sum(BLEU[file]) / 100:.3f} & {sum(METEOR[file]) / 100:.3f} & {sum(ROUGE_1[file]) / 100:.3f} & {sum(BERT[file]) / 100:.3f} \\\\\\\\\")\n",
    "        print(\"\\hline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balladyna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dziady_(Mickiewicz)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konrad_Wallenrod\n",
      "Kordian\n",
      "Lalka_(Prus)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ogniem_i_mieczem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pan_Tadeusz_(wyd._1834)\n",
      "Pan_Wołodyjowski\n",
      "Potop_(Sienkiewicz)\n",
      "Quo_vadis\n",
      "Sonety_Adama_Mickiewicza\n",
      "Balladyna & 0.252 & 0.000 & 0.310 & 0.751 \\\\\n",
      "\\hline\n",
      "Dziady_(Mickiewicz) & 0.155 & 0.000 & 0.221 & 0.705 \\\\\n",
      "\\hline\n",
      "Konrad_Wallenrod & 0.158 & 0.000 & 0.234 & 0.724 \\\\\n",
      "\\hline\n",
      "Kordian & 0.180 & 0.000 & 0.251 & 0.732 \\\\\n",
      "\\hline\n",
      "Lalka_(Prus) & 0.305 & 0.000 & 0.368 & 0.772 \\\\\n",
      "\\hline\n",
      "Ogniem_i_mieczem & 0.038 & 0.000 & 0.097 & 0.660 \\\\\n",
      "\\hline\n",
      "Pan_Tadeusz_(wyd._1834) & 0.093 & 0.000 & 0.138 & 0.676 \\\\\n",
      "\\hline\n",
      "Pan_Wołodyjowski & 0.149 & 0.000 & 0.235 & 0.726 \\\\\n",
      "\\hline\n",
      "Potop_(Sienkiewicz) & 0.124 & 0.000 & 0.191 & 0.699 \\\\\n",
      "\\hline\n",
      "Quo_vadis & 0.135 & 0.000 & 0.215 & 0.721 \\\\\n",
      "\\hline\n",
      "Sonety_Adama_Mickiewicza & 0.085 & 0.000 & 0.135 & 0.674 \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(model='qwen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balladyna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dziady_(Mickiewicz)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konrad_Wallenrod\n",
      "Kordian\n",
      "Lalka_(Prus)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ogniem_i_mieczem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pan_Tadeusz_(wyd._1834)\n",
      "Pan_Wołodyjowski\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potop_(Sienkiewicz)\n",
      "Quo_vadis\n",
      "Sonety_Adama_Mickiewicza\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balladyna & 0.068 & 0.000 & 0.111 & 0.613 \\\\\n",
      "\\hline\n",
      "Dziady_(Mickiewicz) & 0.074 & 0.000 & 0.109 & 0.625 \\\\\n",
      "\\hline\n",
      "Konrad_Wallenrod & 0.067 & 0.000 & 0.107 & 0.620 \\\\\n",
      "\\hline\n",
      "Kordian & 0.065 & 0.000 & 0.105 & 0.625 \\\\\n",
      "\\hline\n",
      "Lalka_(Prus) & 0.071 & 0.000 & 0.113 & 0.611 \\\\\n",
      "\\hline\n",
      "Ogniem_i_mieczem & 0.015 & 0.000 & 0.035 & 0.567 \\\\\n",
      "\\hline\n",
      "Pan_Tadeusz_(wyd._1834) & 0.049 & 0.000 & 0.073 & 0.598 \\\\\n",
      "\\hline\n",
      "Pan_Wołodyjowski & 0.042 & 0.000 & 0.080 & 0.598 \\\\\n",
      "\\hline\n",
      "Potop_(Sienkiewicz) & 0.044 & 0.000 & 0.078 & 0.596 \\\\\n",
      "\\hline\n",
      "Quo_vadis & 0.044 & 0.000 & 0.080 & 0.599 \\\\\n",
      "\\hline\n",
      "Sonety_Adama_Mickiewicza & 0.068 & 0.000 & 0.093 & 0.610 \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(model='llama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balladyna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dziady_(Mickiewicz)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konrad_Wallenrod\n",
      "Kordian\n",
      "Lalka_(Prus)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ogniem_i_mieczem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pan_Tadeusz_(wyd._1834)\n",
      "Pan_Wołodyjowski\n",
      "Potop_(Sienkiewicz)\n",
      "Quo_vadis\n",
      "Sonety_Adama_Mickiewicza\n",
      "Balladyna & 0.107 & 0.000 & 0.155 & 0.678 \\\\\n",
      "\\hline\n",
      "Dziady_(Mickiewicz) & 0.085 & 0.000 & 0.134 & 0.667 \\\\\n",
      "\\hline\n",
      "Konrad_Wallenrod & 0.084 & 0.000 & 0.130 & 0.668 \\\\\n",
      "\\hline\n",
      "Kordian & 0.082 & 0.000 & 0.124 & 0.666 \\\\\n",
      "\\hline\n",
      "Lalka_(Prus) & 0.111 & 0.000 & 0.145 & 0.676 \\\\\n",
      "\\hline\n",
      "Ogniem_i_mieczem & 0.033 & 0.000 & 0.064 & 0.636 \\\\\n",
      "\\hline\n",
      "Pan_Tadeusz_(wyd._1834) & 0.059 & 0.000 & 0.086 & 0.644 \\\\\n",
      "\\hline\n",
      "Pan_Wołodyjowski & 0.071 & 0.000 & 0.112 & 0.672 \\\\\n",
      "\\hline\n",
      "Potop_(Sienkiewicz) & 0.075 & 0.000 & 0.122 & 0.666 \\\\\n",
      "\\hline\n",
      "Quo_vadis & 0.110 & 0.000 & 0.170 & 0.693 \\\\\n",
      "\\hline\n",
      "Sonety_Adama_Mickiewicza & 0.073 & 0.000 & 0.120 & 0.662 \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(model='bielik')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balladyna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dziady_(Mickiewicz)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konrad_Wallenrod\n",
      "Kordian\n",
      "Lalka_(Prus)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ogniem_i_mieczem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pan_Tadeusz_(wyd._1834)\n",
      "Pan_Wołodyjowski\n",
      "Potop_(Sienkiewicz)\n",
      "Quo_vadis\n",
      "Sonety_Adama_Mickiewicza\n",
      "Balladyna & 0.246 & 0.000 & 0.310 & 0.732 \\\\\n",
      "\\hline\n",
      "Dziady_(Mickiewicz) & 0.142 & 0.000 & 0.196 & 0.703 \\\\\n",
      "\\hline\n",
      "Konrad_Wallenrod & 0.145 & 0.000 & 0.218 & 0.710 \\\\\n",
      "\\hline\n",
      "Kordian & 0.136 & 0.000 & 0.207 & 0.706 \\\\\n",
      "\\hline\n",
      "Lalka_(Prus) & 0.248 & 0.000 & 0.315 & 0.739 \\\\\n",
      "\\hline\n",
      "Ogniem_i_mieczem & 0.026 & 0.000 & 0.070 & 0.641 \\\\\n",
      "\\hline\n",
      "Pan_Tadeusz_(wyd._1834) & 0.097 & 0.000 & 0.155 & 0.679 \\\\\n",
      "\\hline\n",
      "Pan_Wołodyjowski & 0.139 & 0.000 & 0.220 & 0.711 \\\\\n",
      "\\hline\n",
      "Potop_(Sienkiewicz) & 0.117 & 0.000 & 0.183 & 0.689 \\\\\n",
      "\\hline\n",
      "Quo_vadis & 0.125 & 0.000 & 0.200 & 0.704 \\\\\n",
      "\\hline\n",
      "Sonety_Adama_Mickiewicza & 0.110 & 0.000 & 0.188 & 0.698 \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(model='mistral')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
