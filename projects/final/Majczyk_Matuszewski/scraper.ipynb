{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import warnings\n",
    "from PyPDF2 import PdfReader\n",
    "from io import BytesIO\n",
    "import re\n",
    "\n",
    "def get_list():\n",
    "    url = \"http://api.sejm.gov.pl/eli/acts\"\n",
    "    response = requests.get(url)\n",
    "    return response.json()\n",
    "\n",
    "def get_acts_list(publisher: str, year: int):\n",
    "    url = f\"http://api.sejm.gov.pl/eli/acts/{publisher}/{year}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        return response.json()\n",
    "    except:\n",
    "        warnings.warn(f\"Couldn't get data from {url}\")\n",
    "        return None\n",
    "    \n",
    "def get_act(publisher: str, year: int, position: int):\n",
    "    url = f\"http://api.sejm.gov.pl/eli/acts/{publisher}/{year}/{position}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        return response.json()\n",
    "    except:\n",
    "        warnings.warn(f\"Couldn't get data from {url}\")\n",
    "        return None\n",
    "    \n",
    "def get_act_text(publisher: str, year: int, position: int):\n",
    "    url = f\"http://api.sejm.gov.pl/eli/acts/{publisher}/{year}/{position}/text.pdf\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        pdf_content = response.content\n",
    "        pdf_reader = PdfReader(BytesIO(pdf_content))\n",
    "        text = \"\"\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text += \" \" + page.extract_text()\n",
    "        # Replace \\n with space\n",
    "        text = re.sub(r\"\\n\", \" \", text)\n",
    "        # Remove multiple spaces\n",
    "        text = re.sub(r\"\\s+\", \" \", text)\n",
    "        return text[1:]\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        warnings.warn(f\"Couldn't get data from {url}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"Error processing PDF: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts_list_DU_2024 = get_acts_list(\"DU\", 2024)\n",
    "acts_list_MP_2024 = get_acts_list(\"MP\", 2024)\n",
    "DU_2024_counts = acts_list_DU_2024['count']\n",
    "MP_2024_counts = acts_list_MP_2024['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "texts = []\n",
    "metadatas = []\n",
    "\n",
    "print(\"Downloading polish acts from 2024...\")\n",
    "for i in tqdm(range(1, DU_2024_counts + 1)):\n",
    "    text = get_act_text(\"DU\", 2024, i)\n",
    "    if text is None:\n",
    "        text = ''\n",
    "    metadata = get_act(\"DU\", 2024, i)\n",
    "    texts.append(text)\n",
    "    metadatas.append(metadata) \n",
    "\n",
    "print(\"Downloading polish acts from 2024...\")\n",
    "for i in tqdm(range(1, MP_2024_counts + 1)):\n",
    "    text = get_act_text(\"MP\", 2024, i)\n",
    "    if text is None:\n",
    "        text = ''\n",
    "    metadata = get_act(\"MP\", 2024, i)\n",
    "    texts.append(text)\n",
    "    metadatas.append(metadata) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./data/texts.pkl', 'rb') as f:\n",
    "    texts = pickle.load(f)\n",
    "\n",
    "with open('./data/metadatas.pkl', 'rb') as f:\n",
    "    metadatas = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1112567"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print max len from texts\n",
    "max_len = 0\n",
    "for text in texts:\n",
    "    max_len = max(max_len, len(text))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# print histogram of lengths\n",
    "plt.hist([len(text) for text in texts], bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da26f479cc894aa68a895e35ae5f7371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\szymo\\.cache\\huggingface\\hub\\models--speakleash--Bielik-7B-v0.1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d0930c26884bd7997abb832daa3e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8dfcfa7bfad4b55a5eb983d7d454e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d570e853f87425e9c91062ff4a75a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80deae76e6754ac28500e25ac469bfb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/593 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d98ad53ef84f29b0b9a6a9f27e6509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81ec6b76cd04859bedbc2626e1765a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006f0e5642bb49ed96420d1849c81623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4650ce1220a408aa1ebae77a62a0e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d28f139d4e4298a07d7f72c23544af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb72d5c36da4793a8504f8f392ca4b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b96725217f843b9bd055d4dd30223b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model_name = \"speakleash/Bielik-7B-v0.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m generated_texts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m---> 13\u001b[0m     generated_texts\u001b[38;5;241m.\u001b[39mappend(\u001b[43mgenerate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m generated_texts:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(text)\n",
      "Cell \u001b[1;32mIn[14], line 9\u001b[0m, in \u001b[0;36mgenerate_text\u001b[1;34m(text, max_length)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_text\u001b[39m(text, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m      8\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(text)\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\text_generation.py:263\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[1;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(chats, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(text_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\base.py:1243\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m   1236\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[0;32m   1237\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1240\u001b[0m         )\n\u001b[0;32m   1241\u001b[0m     )\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\base.py:1250\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1249\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1250\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\base.py:1150\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1149\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1150\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1151\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\text_generation.py:350\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[1;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[0;32m    347\u001b[0m         generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prefix_length\n\u001b[0;32m    349\u001b[0m \u001b[38;5;66;03m# BS x SL\u001b[39;00m\n\u001b[1;32m--> 350\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(input_ids\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgenerate_kwargs)\n\u001b[0;32m    351\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.py:1758\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1750\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1751\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1752\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   1753\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1754\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1755\u001b[0m     )\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 1758\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[0;32m   1759\u001b[0m         input_ids,\n\u001b[0;32m   1760\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   1761\u001b[0m         logits_warper\u001b[38;5;241m=\u001b[39mprepared_logits_warper,\n\u001b[0;32m   1762\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   1763\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   1764\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   1765\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   1766\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1767\u001b[0m     )\n\u001b[0;32m   1769\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   1770\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[0;32m   1771\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1772\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config) \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1773\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.py:2397\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[0;32m   2394\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   2396\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 2397\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\n\u001b[0;32m   2398\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs,\n\u001b[0;32m   2399\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   2400\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   2401\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   2402\u001b[0m )\n\u001b[0;32m   2404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   2405\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:1139\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1136\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m-> 1139\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1151\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1152\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[1;32mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:1024\u001b[0m, in \u001b[0;36mMistralModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1014\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m   1015\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m   1016\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1021\u001b[0m         use_cache,\n\u001b[0;32m   1022\u001b[0m     )\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1024\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1033\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:751\u001b[0m, in \u001b[0;36mMistralDecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[0;32m    749\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m    750\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[1;32m--> 751\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    752\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[0;32m    754\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[1;32mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:178\u001b[0m, in \u001b[0;36mMistralMLP.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdown_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "pipeline = transformers.pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
    "\n",
    "import random\n",
    "\n",
    "def generate_text(text, max_length=1000):\n",
    "    prompt = random.choice(text)\n",
    "    return pipeline(prompt, max_length=max_length)[0]['generated_text']\n",
    "\n",
    "generated_texts = []\n",
    "for i in range(10):\n",
    "    generated_texts.append(generate_text(texts, max_length=1000))\n",
    "\n",
    "for text in generated_texts:\n",
    "    print(text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def parse_pdf(file_path):\n",
    "    # Read and merge all text from the PDF\n",
    "    reader = PdfReader(file_path)\n",
    "    full_text = \"\"\n",
    "    for page in reader.pages:\n",
    "        full_text += page.extract_text() + \"\\n\"\n",
    "\n",
    "    # Remove footers like \"Kancelaria Sejmu s. 1/56, 2015-01-07\"\n",
    "    full_text = re.sub(r\"Kancelaria Sejmu\\.?\", \"\", full_text, flags=re.DOTALL)\n",
    "    full_text = re.sub(r\"\\d\\s*\\d\\s*\\d\\s*\\d\\s*-\\s*\\d\\s*\\d\\s*-\\s*\\d\\s*\\d\", \"\", full_text, flags=re.DOTALL)\n",
    "    full_text = re.sub(r\"s\\.\\s*\\d+\\s*/\\s*\\d+\", \"\", full_text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Split into lines for easier parsing\n",
    "    lines = full_text.split(\"\\n\")\n",
    "    \n",
    "    data = []\n",
    "    current_section = None\n",
    "    current_section_title = None\n",
    "    # current_subsection_title = None\n",
    "    current_article = None\n",
    "    text_buffer = []\n",
    "\n",
    "    def save_current_article():\n",
    "        if current_article and text_buffer:\n",
    "            data.append({\n",
    "                \"section\": current_section,\n",
    "                \"section_title\": current_section_title,\n",
    "                # \"subsection_title\": current_subsection_title,\n",
    "                \"article\": current_article,\n",
    "                \"text\": \" \".join(text_buffer).strip()\n",
    "            })\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        # Detect section titles (Rozdzia)\n",
    "        section_match = re.search(r\"ROZDZIA\\s+([IVXLCDM]+)\", line, re.IGNORECASE)\n",
    "        if section_match:\n",
    "            save_current_article()\n",
    "            current_section = section_match.group(1)\n",
    "            current_section_title = None\n",
    "            # current_subsection_title = None\n",
    "            current_article = None\n",
    "            text_buffer = []\n",
    "            continue\n",
    "\n",
    "        # Detect section title (uppercase, just under the section)\n",
    "        if current_section and not current_section_title and line.isupper():\n",
    "            current_section_title = line\n",
    "            continue\n",
    "\n",
    "        # # Detect subsection title (sentence case, as close as possible to articles)\n",
    "        # if current_section and current_section_title and not current_subsection_title and line[0].isupper() and not line.isupper():\n",
    "        #     current_subsection_title = line\n",
    "        #     continue\n",
    "\n",
    "        # Detect articles\n",
    "        article_match = re.match(r\"^Art\\.\\s*(\\d+)\\.\", line)\n",
    "        if article_match:\n",
    "            save_current_article()\n",
    "            current_article = article_match.group(1)\n",
    "            text_buffer = []\n",
    "            line = line[article_match.end():].strip()\n",
    "\n",
    "        # Collect the text for the current article\n",
    "        if line:\n",
    "            text_buffer.append(line)\n",
    "\n",
    "    # Save the last article\n",
    "    save_current_article()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 243 articles.\n"
     ]
    }
   ],
   "source": [
    "# Parse the PDF and save the results\n",
    "pdf_path = \"konstytucja.pdf\"  # Replace with your file path\n",
    "output = parse_pdf(pdf_path)\n",
    "\n",
    "# Save as JSON or process further\n",
    "import json\n",
    "with open(\"parsed_constitution.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(output, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Extracted {len(output)} articles.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['XII',\n",
       " 'VI',\n",
       " 'VIII',\n",
       " 'XI',\n",
       " 'V',\n",
       " 'IV',\n",
       " 'X',\n",
       " 'XIII',\n",
       " 'I',\n",
       " 'III',\n",
       " 'IX',\n",
       " 'VII',\n",
       " 'II']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all sections\n",
    "sections = []\n",
    "for article in output:\n",
    "    sections.append(article['section'])\n",
    "sections = list(set(sections))\n",
    "sections"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
