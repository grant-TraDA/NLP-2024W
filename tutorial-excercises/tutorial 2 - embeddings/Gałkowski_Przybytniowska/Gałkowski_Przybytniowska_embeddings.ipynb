{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b610ebde-be4d-4f05-9cc6-6698c757eff0",
   "metadata": {},
   "source": [
    "# Tutorial task - Embeddings\n",
    "\n",
    "Authors: \n",
    "- Mikołaj Gałkowski\n",
    "- Julia Przybytniowska"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c692dc4-53c4-4854-86ef-a59be4203305",
   "metadata": {},
   "source": [
    "### Preprocessing steps\n",
    "\n",
    "1. Removing non-alphanumeric characters.\n",
    "2. Removing stopwords.\n",
    "3. Lemmatization\n",
    "4. Stemming.\n",
    "\n",
    "We will try out their different combinations when training our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7d58fa7-f901-4afd-b4e1-1c0ab223f1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^A-Za-z\\s]\", \"\", text.lower())\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "\n",
    "def stem_text(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "\n",
    "def preprocess_text(text, preprocessing_steps):\n",
    "    text = clean_text(text)\n",
    "    if \"stopwords\" in preprocessing_steps:\n",
    "        text = remove_stopwords(text)\n",
    "    if \"lemmatization\" in preprocessing_steps:\n",
    "        text = lemmatize_text(text)\n",
    "    if \"stemming\" in preprocessing_steps:\n",
    "        text = stem_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36857b6c-3871-4d87-832e-afd15f12b5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "imdb = load_dataset(\"stanfordnlp/imdb\")\n",
    "del imdb[\"unsupervised\"]  # stay only with train / test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2722362-72e2-4342-96dc-23ea9b4c0cd1",
   "metadata": {},
   "source": [
    "## Word2Vec, FastText and Glove\n",
    "\n",
    "All three embedding method are pretrained ones. Word2Vec and FastText return embeddings of 300 length and GloVe of 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "919f8c9b-b603-4d95-9182-fa0daa15649a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word2vec\n",
      "Loading fasttext\n",
      "Loading glove\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "print(\"Loading word2vec\")\n",
    "word2vec_embeddings = gensim.downloader.load(\"word2vec-google-news-300\")\n",
    "\n",
    "print(\"Loading fasttext\")\n",
    "fasttext_embeddings = gensim.downloader.load(\"fasttext-wiki-news-subwords-300\")\n",
    "\n",
    "print(\"Loading glove\")\n",
    "glove_embeddings = gensim.downloader.load(\"glove-twitter-200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4c20cfa-0615-4926-af39-278857d83346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# function to get the average word vector for a sentence\n",
    "def get_average_word_vector(sentence, model, vector_size=300):\n",
    "    words = sentence.split()\n",
    "    word_vectors = [model[word] for word in words if word in model]\n",
    "    if len(word_vectors) > 0:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(vector_size)\n",
    "\n",
    "\n",
    "train = imdb[\"train\"].to_pandas()\n",
    "test = imdb[\"test\"].to_pandas()\n",
    "\n",
    "X_train = train[\"text\"]\n",
    "y_train = train[\"label\"]\n",
    "X_test = test[\"text\"]\n",
    "y_test = test[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8538a9a2-2884-4489-8da2-1ce514c66790",
   "metadata": {},
   "source": [
    "Below preprocessing combinations are proposed and different classification models such as:\n",
    "- Logisitic Regression,\n",
    "- Naive Bayes,\n",
    "- Random Forest Classifier,\n",
    "- XGBoost Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f1bdf68-27f0-491f-804a-584570469089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4e35981617401ab82b7b29aa91cfad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing Type:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Model Type:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Model Type:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Model Type:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Model Type:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Model Type:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Model Type:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>0.82768</td>\n",
       "      <td>0.833008</td>\n",
       "      <td>0.81968</td>\n",
       "      <td>0.826290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>None</td>\n",
       "      <td>0.77892</td>\n",
       "      <td>0.786413</td>\n",
       "      <td>0.76584</td>\n",
       "      <td>0.775990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>glove</td>\n",
       "      <td>None</td>\n",
       "      <td>0.81252</td>\n",
       "      <td>0.817421</td>\n",
       "      <td>0.80480</td>\n",
       "      <td>0.811061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>0.69820</td>\n",
       "      <td>0.729038</td>\n",
       "      <td>0.63088</td>\n",
       "      <td>0.676416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>None</td>\n",
       "      <td>0.68188</td>\n",
       "      <td>0.712695</td>\n",
       "      <td>0.60944</td>\n",
       "      <td>0.657036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>[stopwords, stemming]</td>\n",
       "      <td>0.75668</td>\n",
       "      <td>0.760494</td>\n",
       "      <td>0.74936</td>\n",
       "      <td>0.754886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>glove</td>\n",
       "      <td>[stopwords, stemming]</td>\n",
       "      <td>0.74148</td>\n",
       "      <td>0.739165</td>\n",
       "      <td>0.74632</td>\n",
       "      <td>0.742725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>[stopwords, stemming]</td>\n",
       "      <td>0.78088</td>\n",
       "      <td>0.779850</td>\n",
       "      <td>0.78272</td>\n",
       "      <td>0.781282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>[stopwords, stemming]</td>\n",
       "      <td>0.78616</td>\n",
       "      <td>0.789870</td>\n",
       "      <td>0.77976</td>\n",
       "      <td>0.784783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>glove</td>\n",
       "      <td>[stopwords, stemming]</td>\n",
       "      <td>0.76688</td>\n",
       "      <td>0.771220</td>\n",
       "      <td>0.75888</td>\n",
       "      <td>0.765000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model Embedding          Preprocessing  Accuracy  \\\n",
       "0       LogisticRegression  word2vec                   None   0.82768   \n",
       "1       LogisticRegression  fasttext                   None   0.77892   \n",
       "2       LogisticRegression     glove                   None   0.81252   \n",
       "3               GaussianNB  word2vec                   None   0.69820   \n",
       "4               GaussianNB  fasttext                   None   0.68188   \n",
       "..                     ...       ...                    ...       ...   \n",
       "67  RandomForestClassifier  fasttext  [stopwords, stemming]   0.75668   \n",
       "68  RandomForestClassifier     glove  [stopwords, stemming]   0.74148   \n",
       "69           XGBClassifier  word2vec  [stopwords, stemming]   0.78088   \n",
       "70           XGBClassifier  fasttext  [stopwords, stemming]   0.78616   \n",
       "71           XGBClassifier     glove  [stopwords, stemming]   0.76688   \n",
       "\n",
       "    Precision   Recall        F1  \n",
       "0    0.833008  0.81968  0.826290  \n",
       "1    0.786413  0.76584  0.775990  \n",
       "2    0.817421  0.80480  0.811061  \n",
       "3    0.729038  0.63088  0.676416  \n",
       "4    0.712695  0.60944  0.657036  \n",
       "..        ...      ...       ...  \n",
       "67   0.760494  0.74936  0.754886  \n",
       "68   0.739165  0.74632  0.742725  \n",
       "69   0.779850  0.78272  0.781282  \n",
       "70   0.789870  0.77976  0.784783  \n",
       "71   0.771220  0.75888  0.765000  \n",
       "\n",
       "[72 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "preprocessing_options = [\n",
    "    None,  # No preprocessing\n",
    "    [\"stopwords\"],  # Remove stopwords\n",
    "    [\"lemmatization\"],  # Lemmatization\n",
    "    [\"stemming\"],  # Stemming\n",
    "    [\"stopwords\", \"lemmatization\"],  # Stopwords + Lemmatization\n",
    "    [\"stopwords\", \"stemming\"],  # Stopwords + Stemming\n",
    "]\n",
    "\n",
    "model_classes = [\n",
    "    LogisticRegression,\n",
    "    GaussianNB,\n",
    "    RandomForestClassifier,\n",
    "    xgb.XGBClassifier,\n",
    "]\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for preprocessing in tqdm(preprocessing_options, desc=\"Preprocessing Type\"):\n",
    "    X_train_processed = X_train.apply(\n",
    "        lambda x: preprocess_text(x, preprocessing) if preprocessing else x\n",
    "    )\n",
    "    X_test_processed = X_test.apply(\n",
    "        lambda x: preprocess_text(x, preprocessing) if preprocessing else x\n",
    "    )\n",
    "\n",
    "    X_train_word2vec = np.array(\n",
    "        [\n",
    "            get_average_word_vector(text, word2vec_embeddings, vector_size=300)\n",
    "            for text in X_train_processed\n",
    "        ]\n",
    "    )\n",
    "    X_test_word2vec = np.array(\n",
    "        [\n",
    "            get_average_word_vector(text, word2vec_embeddings, vector_size=300)\n",
    "            for text in X_test_processed\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    X_train_fasttext = np.array(\n",
    "        [\n",
    "            get_average_word_vector(text, fasttext_embeddings, vector_size=300)\n",
    "            for text in X_train_processed\n",
    "        ]\n",
    "    )\n",
    "    X_test_fasttext = np.array(\n",
    "        [\n",
    "            get_average_word_vector(text, fasttext_embeddings, vector_size=300)\n",
    "            for text in X_test_processed\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    X_train_glove = np.array(\n",
    "        [\n",
    "            get_average_word_vector(text, glove_embeddings, vector_size=200)\n",
    "            for text in X_train_processed\n",
    "        ]\n",
    "    )\n",
    "    X_test_glove = np.array(\n",
    "        [\n",
    "            get_average_word_vector(text, glove_embeddings, vector_size=200)\n",
    "            for text in X_test_processed\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    embedding_data = [\n",
    "        (\"word2vec\", X_train_word2vec, X_test_word2vec),\n",
    "        (\"fasttext\", X_train_fasttext, X_test_fasttext),\n",
    "        (\"glove\", X_train_glove, X_test_glove),\n",
    "    ]\n",
    "\n",
    "    for model_class in tqdm(model_classes, desc=\"Model Type\", leave=False):\n",
    "        for name, X__train, X__test in embedding_data:\n",
    "            params = {\"max_iter\": 1000} if model_class == LogisticRegression else {}\n",
    "            model = model_class(**params) if params else model_class()\n",
    "\n",
    "            model.fit(X__train, y_train)\n",
    "\n",
    "            y_pred = model.predict(X__test)\n",
    "\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "            results_list.append(\n",
    "                {\n",
    "                    \"Model\": model_class.__name__,\n",
    "                    \"Embedding\": name,\n",
    "                    \"Preprocessing\": preprocessing if preprocessing else \"None\",\n",
    "                    \"Accuracy\": accuracy,\n",
    "                    \"Precision\": precision,\n",
    "                    \"Recall\": recall,\n",
    "                    \"F1\": f1,\n",
    "                }\n",
    "            )\n",
    "\n",
    "results = pd.concat([pd.DataFrame([res]) for res in results_list], ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e748db27-b737-4b9e-8977-259370f596bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results.to_csv('results_not_transformers.csv', index=False)\n",
    "# results = pd.read_csv('results_not_transformers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6eb7f1-b9d6-4320-a6c8-0cc15693b23c",
   "metadata": {},
   "source": [
    "# Fine-tuning Distil Bert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9603ed5d-6c1d-4c8a-a494-4702e16191ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"distilbert/distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2).to(\n",
    "    device\n",
    ")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "014a0109-073e-4bfe-9fe8-1f144d764522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efced617efe443588717e8eb6797d190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8fa8290f7d540069c8ff077aa537e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_imdb = imdb.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "286bda45-853b-4a00-bce5-f4708496bf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "precision_metric = evaluate.load(\"precision\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    precision = precision_metric.compute(\n",
    "        predictions=predictions, references=labels, average=\"binary\"\n",
    "    )\n",
    "    recall = recall_metric.compute(\n",
    "        predictions=predictions, references=labels, average=\"binary\"\n",
    "    )\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"binary\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy[\"accuracy\"],\n",
    "        \"precision\": precision[\"precision\"],\n",
    "        \"recall\": recall[\"recall\"],\n",
    "        \"f1\": f1[\"f1\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e97898b-4290-4a4b-90ea-298376cf960f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1173' max='1173' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1173/1173 18:17, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.207738</td>\n",
       "      <td>0.924640</td>\n",
       "      <td>0.926825</td>\n",
       "      <td>0.922080</td>\n",
       "      <td>0.924447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.136400</td>\n",
       "      <td>0.219272</td>\n",
       "      <td>0.929160</td>\n",
       "      <td>0.933145</td>\n",
       "      <td>0.924560</td>\n",
       "      <td>0.928833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.090700</td>\n",
       "      <td>0.244043</td>\n",
       "      <td>0.929840</td>\n",
       "      <td>0.925146</td>\n",
       "      <td>0.935360</td>\n",
       "      <td>0.930225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1173, training_loss=0.10757970931889761, metrics={'train_runtime': 1098.4496, 'train_samples_per_second': 68.278, 'train_steps_per_second': 1.068, 'total_flos': 9935003154122400.0, 'train_loss': 0.10757970931889761, 'epoch': 3.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_imdb[\"train\"],\n",
    "    eval_dataset=tokenized_imdb[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8b6e73c-c5e1-49fe-95fc-04633320199a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results: {'eval_loss': 0.20773789286613464, 'eval_accuracy': 0.92464, 'eval_precision': 0.9268253457703441, 'eval_recall': 0.92208, 'eval_f1': 0.924446583253128, 'eval_runtime': 92.962, 'eval_samples_per_second': 268.927, 'eval_steps_per_second': 4.206, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print(f\"Test results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f2067eb-8752-4c13-8f91-30f54d0f195c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_imdb[\"test\"])\n",
    "\n",
    "preds = torch.argmax(torch.tensor(predictions.predictions), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "673d03de-509e-4970-ae0e-545457e6fad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate additional metrics manually and add to a DataFrame\n",
    "accuracy = accuracy_metric.compute(\n",
    "    predictions=preds.numpy(), references=tokenized_imdb[\"test\"][\"label\"]\n",
    ")\n",
    "precision = precision_metric.compute(\n",
    "    predictions=preds.numpy(),\n",
    "    references=tokenized_imdb[\"test\"][\"label\"],\n",
    "    average=\"binary\",\n",
    ")\n",
    "recall = recall_metric.compute(\n",
    "    predictions=preds.numpy(),\n",
    "    references=tokenized_imdb[\"test\"][\"label\"],\n",
    "    average=\"binary\",\n",
    ")\n",
    "f1 = f1_metric.compute(\n",
    "    predictions=preds.numpy(),\n",
    "    references=tokenized_imdb[\"test\"][\"label\"],\n",
    "    average=\"binary\",\n",
    ")\n",
    "\n",
    "df_results = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"Model\": \"distilbert-base-uncased\",\n",
    "            \"Embedding\": \"-\",\n",
    "            \"Preprocessing\": \"-\",\n",
    "            \"Accuracy\": accuracy[\"accuracy\"],\n",
    "            \"Precision\": precision[\"precision\"],\n",
    "            \"Recall\": recall[\"recall\"],\n",
    "            \"F1\": f1[\"f1\"],\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "df_results.to_csv(\"distilbert.csv\", index=False)\n",
    "# df_results = pd.read_csv(\"distilbert.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9263abc7-51c1-453e-97f5-abfcbeee08bb",
   "metadata": {},
   "source": [
    "## Using finetuned model from HuggingFace \n",
    "\n",
    "Not fine-tuning, just inference on out-of-the-box model imported from HF hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ebefa65-9d27-4f86-819b-749bd77ede1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7092b4-aff0-42f7-a00b-16660336b523",
   "metadata": {},
   "source": [
    "### We checked distribution of the length of inputs in the test set to find out the optimal `max_length` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "32213c82-8f35-4809-a93a-522770c5abe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>297.807480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>220.395691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>161.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>223.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>361.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3090.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             length\n",
       "count  25000.000000\n",
       "mean     297.807480\n",
       "std      220.395691\n",
       "min       10.000000\n",
       "25%      161.000000\n",
       "50%      223.000000\n",
       "75%      361.250000\n",
       "max     3090.000000"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_lengths = [\n",
    "    len(tokenizer(x)[\"input_ids\"]) for x in tokenized_imdb[\"test\"][\"text\"]\n",
    "]\n",
    "\n",
    "lengths_df = pd.DataFrame(tokenized_lengths, columns=[\"length\"])\n",
    "\n",
    "lengths_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "29362eec-5b30-4617-9d85-4740c2902e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(lengths_df[\"length\"], bins=50, color=\"c\", edgecolor=\"black\")\n",
    "plt.title(\"Distribution of Sentence Lengths in IMDB Test Set\")\n",
    "plt.xlabel(\"Number of Tokens\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584f9934-56c6-477d-b9f1-58acb1cd8735",
   "metadata": {},
   "source": [
    "### We decided to stick with the `1024 max_length` as there wasn't any specified for this model in the config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "576529af-5d7f-412f-967e-d7e4fcf63876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d5f06bc17f452abb7ada06938baa58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ffb9877230c4df9859975df41088945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dfurman/deberta-v3-base-imdb\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"dfurman/deberta-v3-base-imdb\"\n",
    ")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], max_length=1024, truncation=True, padding=True)\n",
    "\n",
    "\n",
    "tokenized_imdb = imdb.map(tokenize_function, batched=True)\n",
    "\n",
    "test_loader = DataLoader(tokenized_imdb[\"test\"].with_format(\"torch\"), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1fda8fb6-c2a8-496a-a8bf-89afbbc84ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e16b644b5bf4c74a05661a54ad824e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "75df168c-fced-4ceb-8571-b40072787f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deberta-v3-base-imdb</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.95404</td>\n",
       "      <td>0.943087</td>\n",
       "      <td>0.9664</td>\n",
       "      <td>0.954601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Embedding Preprocessing  Accuracy  Precision  Recall  \\\n",
       "0  deberta-v3-base-imdb         -             -   0.95404   0.943087  0.9664   \n",
       "\n",
       "         F1  \n",
       "0  0.954601  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "accuracy = accuracy_metric.compute(predictions=all_preds, references=all_labels)\n",
    "precision = precision_metric.compute(\n",
    "    predictions=all_preds, references=all_labels, average=\"binary\"\n",
    ")\n",
    "recall = recall_metric.compute(\n",
    "    predictions=all_preds, references=all_labels, average=\"binary\"\n",
    ")\n",
    "f1 = f1_metric.compute(predictions=all_preds, references=all_labels, average=\"binary\")\n",
    "\n",
    "df_results = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"Model\": \"deberta-v3-base-imdb\",\n",
    "            \"Embedding\": \"-\",\n",
    "            \"Preprocessing\": \"-\",\n",
    "            \"Accuracy\": accuracy[\"accuracy\"],\n",
    "            \"Precision\": precision[\"precision\"],\n",
    "            \"Recall\": recall[\"recall\"],\n",
    "            \"F1\": f1[\"f1\"],\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "df_results.to_csv(\"deberta_results.csv\", index=False)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bf0d01f-f150-431e-8984-6bac72212b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_515775/3323215690.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  res = pd.concat([res, pd.read_csv('./wyniki/' + file)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.82768</td>\n",
       "      <td>0.833008</td>\n",
       "      <td>0.81968</td>\n",
       "      <td>0.826290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77892</td>\n",
       "      <td>0.786413</td>\n",
       "      <td>0.76584</td>\n",
       "      <td>0.775990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>glove</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.81252</td>\n",
       "      <td>0.817421</td>\n",
       "      <td>0.80480</td>\n",
       "      <td>0.811061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.69820</td>\n",
       "      <td>0.729038</td>\n",
       "      <td>0.63088</td>\n",
       "      <td>0.676416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.68188</td>\n",
       "      <td>0.712695</td>\n",
       "      <td>0.60944</td>\n",
       "      <td>0.657036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>['stopwords', 'stemming']</td>\n",
       "      <td>0.78088</td>\n",
       "      <td>0.779850</td>\n",
       "      <td>0.78272</td>\n",
       "      <td>0.781282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>['stopwords', 'stemming']</td>\n",
       "      <td>0.78616</td>\n",
       "      <td>0.789870</td>\n",
       "      <td>0.77976</td>\n",
       "      <td>0.784783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>glove</td>\n",
       "      <td>['stopwords', 'stemming']</td>\n",
       "      <td>0.76688</td>\n",
       "      <td>0.771220</td>\n",
       "      <td>0.75888</td>\n",
       "      <td>0.765000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deberta-v3-base-imdb</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.95404</td>\n",
       "      <td>0.943087</td>\n",
       "      <td>0.96640</td>\n",
       "      <td>0.954601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.92464</td>\n",
       "      <td>0.926825</td>\n",
       "      <td>0.92208</td>\n",
       "      <td>0.924447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model Embedding              Preprocessing  Accuracy  \\\n",
       "0        LogisticRegression  word2vec                        NaN   0.82768   \n",
       "1        LogisticRegression  fasttext                        NaN   0.77892   \n",
       "2        LogisticRegression     glove                        NaN   0.81252   \n",
       "3                GaussianNB  word2vec                        NaN   0.69820   \n",
       "4                GaussianNB  fasttext                        NaN   0.68188   \n",
       "..                      ...       ...                        ...       ...   \n",
       "69            XGBClassifier  word2vec  ['stopwords', 'stemming']   0.78088   \n",
       "70            XGBClassifier  fasttext  ['stopwords', 'stemming']   0.78616   \n",
       "71            XGBClassifier     glove  ['stopwords', 'stemming']   0.76688   \n",
       "0      deberta-v3-base-imdb         -                          -   0.95404   \n",
       "0   distilbert-base-uncased         -                          -   0.92464   \n",
       "\n",
       "    Precision   Recall        F1  \n",
       "0    0.833008  0.81968  0.826290  \n",
       "1    0.786413  0.76584  0.775990  \n",
       "2    0.817421  0.80480  0.811061  \n",
       "3    0.729038  0.63088  0.676416  \n",
       "4    0.712695  0.60944  0.657036  \n",
       "..        ...      ...       ...  \n",
       "69   0.779850  0.78272  0.781282  \n",
       "70   0.789870  0.77976  0.784783  \n",
       "71   0.771220  0.75888  0.765000  \n",
       "0    0.943087  0.96640  0.954601  \n",
       "0    0.926825  0.92208  0.924447  \n",
       "\n",
       "[74 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "res = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"Model\",\n",
    "        \"Embedding\",\n",
    "        \"Preprocessing\",\n",
    "        \"Accuracy\",\n",
    "        \"Precision\",\n",
    "        \"Recall\",\n",
    "        \"F1\",\n",
    "    ]\n",
    ")\n",
    "for file in os.listdir(\"./\"):\n",
    "    if file.endswith(\".csv\"):\n",
    "        res = pd.concat([res, pd.read_csv(file)])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc59080-c216-4865-8f20-deec2db8dd0b",
   "metadata": {},
   "source": [
    "# Top 5 Results based on each metric "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bdf345-f245-4fb6-8ce3-2df5b57991dc",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9843aea9-28e3-413f-9799-1714cad85457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deberta-v3-base-imdb</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.95404</td>\n",
       "      <td>0.943087</td>\n",
       "      <td>0.96640</td>\n",
       "      <td>0.954601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.92464</td>\n",
       "      <td>0.926825</td>\n",
       "      <td>0.92208</td>\n",
       "      <td>0.924447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>['stopwords']</td>\n",
       "      <td>0.85124</td>\n",
       "      <td>0.853360</td>\n",
       "      <td>0.84824</td>\n",
       "      <td>0.850792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>['stopwords', 'lemmatization']</td>\n",
       "      <td>0.84840</td>\n",
       "      <td>0.851153</td>\n",
       "      <td>0.84448</td>\n",
       "      <td>0.847803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>['lemmatization']</td>\n",
       "      <td>0.84464</td>\n",
       "      <td>0.850814</td>\n",
       "      <td>0.83584</td>\n",
       "      <td>0.843261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model Embedding                   Preprocessing  \\\n",
       "0      deberta-v3-base-imdb         -                               -   \n",
       "0   distilbert-base-uncased         -                               -   \n",
       "12       LogisticRegression  word2vec                   ['stopwords']   \n",
       "48       LogisticRegression  word2vec  ['stopwords', 'lemmatization']   \n",
       "24       LogisticRegression  word2vec               ['lemmatization']   \n",
       "\n",
       "    Accuracy  Precision   Recall        F1  \n",
       "0    0.95404   0.943087  0.96640  0.954601  \n",
       "0    0.92464   0.926825  0.92208  0.924447  \n",
       "12   0.85124   0.853360  0.84824  0.850792  \n",
       "48   0.84840   0.851153  0.84448  0.847803  \n",
       "24   0.84464   0.850814  0.83584  0.843261  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sort_values(\"Accuracy\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7945146-3391-4df8-bb39-d78ec3afed0a",
   "metadata": {},
   "source": [
    "## Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3cdfe96-0fd2-401e-aa12-0511285ae3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deberta-v3-base-imdb</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.95404</td>\n",
       "      <td>0.943087</td>\n",
       "      <td>0.96640</td>\n",
       "      <td>0.954601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.92464</td>\n",
       "      <td>0.926825</td>\n",
       "      <td>0.92208</td>\n",
       "      <td>0.924447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>['stopwords']</td>\n",
       "      <td>0.85124</td>\n",
       "      <td>0.853360</td>\n",
       "      <td>0.84824</td>\n",
       "      <td>0.850792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>['stopwords', 'lemmatization']</td>\n",
       "      <td>0.84840</td>\n",
       "      <td>0.851153</td>\n",
       "      <td>0.84448</td>\n",
       "      <td>0.847803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>['lemmatization']</td>\n",
       "      <td>0.84464</td>\n",
       "      <td>0.850814</td>\n",
       "      <td>0.83584</td>\n",
       "      <td>0.843261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model Embedding                   Preprocessing  \\\n",
       "0      deberta-v3-base-imdb         -                               -   \n",
       "0   distilbert-base-uncased         -                               -   \n",
       "12       LogisticRegression  word2vec                   ['stopwords']   \n",
       "48       LogisticRegression  word2vec  ['stopwords', 'lemmatization']   \n",
       "24       LogisticRegression  word2vec               ['lemmatization']   \n",
       "\n",
       "    Accuracy  Precision   Recall        F1  \n",
       "0    0.95404   0.943087  0.96640  0.954601  \n",
       "0    0.92464   0.926825  0.92208  0.924447  \n",
       "12   0.85124   0.853360  0.84824  0.850792  \n",
       "48   0.84840   0.851153  0.84448  0.847803  \n",
       "24   0.84464   0.850814  0.83584  0.843261  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sort_values(\"Precision\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b48f7c-a1c1-4e68-9de8-d25663542580",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c18db0d-129e-4ae6-bd52-7b0b41b626d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deberta-v3-base-imdb</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.95404</td>\n",
       "      <td>0.943087</td>\n",
       "      <td>0.96640</td>\n",
       "      <td>0.954601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.92464</td>\n",
       "      <td>0.926825</td>\n",
       "      <td>0.92208</td>\n",
       "      <td>0.924447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>['stopwords']</td>\n",
       "      <td>0.85124</td>\n",
       "      <td>0.853360</td>\n",
       "      <td>0.84824</td>\n",
       "      <td>0.850792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>['stopwords', 'lemmatization']</td>\n",
       "      <td>0.84840</td>\n",
       "      <td>0.851153</td>\n",
       "      <td>0.84448</td>\n",
       "      <td>0.847803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>['lemmatization']</td>\n",
       "      <td>0.84464</td>\n",
       "      <td>0.850814</td>\n",
       "      <td>0.83584</td>\n",
       "      <td>0.843261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model Embedding                   Preprocessing  \\\n",
       "0      deberta-v3-base-imdb         -                               -   \n",
       "0   distilbert-base-uncased         -                               -   \n",
       "12       LogisticRegression  word2vec                   ['stopwords']   \n",
       "48       LogisticRegression  word2vec  ['stopwords', 'lemmatization']   \n",
       "24       LogisticRegression  word2vec               ['lemmatization']   \n",
       "\n",
       "    Accuracy  Precision   Recall        F1  \n",
       "0    0.95404   0.943087  0.96640  0.954601  \n",
       "0    0.92464   0.926825  0.92208  0.924447  \n",
       "12   0.85124   0.853360  0.84824  0.850792  \n",
       "48   0.84840   0.851153  0.84448  0.847803  \n",
       "24   0.84464   0.850814  0.83584  0.843261  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sort_values(\"Recall\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9d51fe-15d9-419a-9645-c1a31ed84c6d",
   "metadata": {},
   "source": [
    "## F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18c2c05e-afb0-4660-a7ba-f45307a0b10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deberta-v3-base-imdb</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.95404</td>\n",
       "      <td>0.943087</td>\n",
       "      <td>0.96640</td>\n",
       "      <td>0.954601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.92464</td>\n",
       "      <td>0.926825</td>\n",
       "      <td>0.92208</td>\n",
       "      <td>0.924447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>['stopwords']</td>\n",
       "      <td>0.85124</td>\n",
       "      <td>0.853360</td>\n",
       "      <td>0.84824</td>\n",
       "      <td>0.850792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>['stopwords', 'lemmatization']</td>\n",
       "      <td>0.84840</td>\n",
       "      <td>0.851153</td>\n",
       "      <td>0.84448</td>\n",
       "      <td>0.847803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>['lemmatization']</td>\n",
       "      <td>0.84464</td>\n",
       "      <td>0.850814</td>\n",
       "      <td>0.83584</td>\n",
       "      <td>0.843261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model Embedding                   Preprocessing  \\\n",
       "0      deberta-v3-base-imdb         -                               -   \n",
       "0   distilbert-base-uncased         -                               -   \n",
       "12       LogisticRegression  word2vec                   ['stopwords']   \n",
       "48       LogisticRegression  word2vec  ['stopwords', 'lemmatization']   \n",
       "24       LogisticRegression  word2vec               ['lemmatization']   \n",
       "\n",
       "    Accuracy  Precision   Recall        F1  \n",
       "0    0.95404   0.943087  0.96640  0.954601  \n",
       "0    0.92464   0.926825  0.92208  0.924447  \n",
       "12   0.85124   0.853360  0.84824  0.850792  \n",
       "48   0.84840   0.851153  0.84448  0.847803  \n",
       "24   0.84464   0.850814  0.83584  0.843261  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sort_values(\"F1\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27811ed-d359-43b7-83cd-aadfc0bd00d7",
   "metadata": {},
   "source": [
    "### Saving final table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcb9c9cd-0a81-4b65-9ace-ff5d34ddec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(\"Galkowski_Przybytniowska_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b1d0b8-064b-4981-96a9-f72054762fdd",
   "metadata": {},
   "source": [
    "**Disclaimer**: Some parts of the code have been generated using Copilot AI Assistant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
