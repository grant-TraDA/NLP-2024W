{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial task - embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors:\n",
    "- Hubert Bujakowski\n",
    "- Jan Kruszewski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load imdb dataset with custom train and test data splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "splits = {'train': 'plain_text/train-00000-of-00001.parquet', 'test': 'plain_text/test-00000-of-00001.parquet'}\n",
    "train = pd.read_parquet(\"hf://datasets/stanfordnlp/imdb/\" + splits[\"train\"])\n",
    "test = pd.read_parquet(\"hf://datasets/stanfordnlp/imdb/\" + splits[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is **simple text preprocessing**. It includes deleting *HTML* tags, removing punctuation, as well as converting uppercase letters to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['processed'] = train['text'].apply(preprocess_text)\n",
    "test['processed'] = test['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import gensim.downloader as api\n",
    "\n",
    "glove_wiki = api.load(\"glove-wiki-gigaword-50\")\n",
    "\n",
    "X_train = train['processed']\n",
    "X_test = test['processed']\n",
    "y_train = train['label']\n",
    "y_test = test['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings and classifier models comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the methods, we chose 3 metrics, including f1_score, precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "def metrics(y_test, y_pred):\n",
    "    return {'f1': f1_score(y_test, y_pred), 'precision': precision_score(y_test, y_pred), 'recall': recall_score(y_test, y_pred)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract features from text we used 3 embedding models:\n",
    "- Word2Vec\n",
    "- FastText\n",
    "- GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word2vec_embeddings(sentences):\n",
    "    tokenized_sentences = [sentence.split() for sentence in sentences]\n",
    "    model = Word2Vec(tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "    embeddings = [np.mean([model.wv[word] for word in sentence.split() if word in model.wv], axis=0) for sentence in sentences]\n",
    "    return np.array(embeddings)\n",
    "\n",
    "def get_fasttext_embeddings(sentences):\n",
    "    model = FastText(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "    embeddings = [np.mean([model.wv[word] for word in sentence.split() if word in model.wv], axis=0) for sentence in sentences]\n",
    "    return np.array(embeddings)\n",
    "\n",
    "def get_glove_embeddings(series):\n",
    "    def get_glove_embedding(text, vectors=glove_wiki):\n",
    "        embeddings = []\n",
    "        for word in text.split():\n",
    "            try:\n",
    "                embeddings.append(vectors[word])\n",
    "            except KeyError:\n",
    "                continue\n",
    "        if len(embeddings) == 0:\n",
    "            return np.zeros(vectors.vector_size)\n",
    "        return np.mean(embeddings, axis=0)\n",
    "\n",
    "    return np.vstack(series.apply(lambda x: get_glove_embedding(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification we tested 3 models:\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "lr_classifier = LogisticRegression(max_iter=1000)\n",
    "rf_classifier = RandomForestClassifier()\n",
    "svm_classifier = SVC()\n",
    "\n",
    "X_train_w2v = get_word2vec_embeddings(X_train)\n",
    "X_test_w2v = get_word2vec_embeddings(X_test)\n",
    "\n",
    "X_train_ft = get_fasttext_embeddings(X_train)\n",
    "X_test_ft = get_fasttext_embeddings(X_test)\n",
    "\n",
    "X_train_glove = get_glove_embeddings(X_train)\n",
    "X_test_glove = get_glove_embeddings(X_test)\n",
    "\n",
    "classifiers = [lr_classifier, rf_classifier, svm_classifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LogisticRegression with w2v embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LogisticRegression with ft embeddings\n",
      "Training LogisticRegression with glove embeddings\n",
      "Training RandomForestClassifier with w2v embeddings\n",
      "Training RandomForestClassifier with ft embeddings\n",
      "Training RandomForestClassifier with glove embeddings\n",
      "Training SVC with w2v embeddings\n",
      "Training SVC with ft embeddings\n",
      "Training SVC with glove embeddings\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for classifier in classifiers:\n",
    "    for X_train, X_test, name in zip([X_train_w2v, X_train_ft, X_train_glove], [X_test_w2v, X_test_ft, X_test_glove], ['w2v', 'ft', 'glove']):\n",
    "        print(f\"Training {classifier.__class__.__name__} with {name} embeddings\")\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        results.append({'classifier': classifier.__class__.__name__, 'embedding': name, 'f1': metrics(y_test, y_pred)['f1'], 'precision': metrics(y_test, y_pred)['precision'], 'recall': metrics(y_test, y_pred)['recall']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we used the `transformers` library to potentially achieve better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SentimentDataset(X_train, y_train, tokenizer)\n",
    "test_dataset = SentimentDataset(X_test, y_test, tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the model performs on the test data without finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5001801513271148\n",
      "Recall: 0.99952\n",
      "F1 Score: 0.6667200298834014\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "precision = precision_score(all_labels, all_predictions)\n",
    "recall = recall_score(all_labels, all_predictions)\n",
    "f1 = f1_score(all_labels, all_predictions)\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are not promising, so we decided to fine-tune the model for 1 epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1563/1563 [13:01<00:00,  2.00it/s, loss=0.328] \n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1):\n",
    "    loop = tqdm(train_dataloader, leave=True)\n",
    "    for batch in loop:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9224198730507014\n",
      "Recall: 0.94168\n",
      "F1 Score: 0.9319504374331974\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "precision = precision_score(all_labels, all_predictions)\n",
    "recall = recall_score(all_labels, all_predictions)\n",
    "f1 = f1_score(all_labels, all_predictions)\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we tested several models, the `BERT` model achieved the best results, especially when fine-tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>embedding</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BERT</td>\n",
       "      <td>BERT</td>\n",
       "      <td>0.931950</td>\n",
       "      <td>0.922420</td>\n",
       "      <td>0.94168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>glove</td>\n",
       "      <td>0.752823</td>\n",
       "      <td>0.761858</td>\n",
       "      <td>0.74400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVC</td>\n",
       "      <td>glove</td>\n",
       "      <td>0.751232</td>\n",
       "      <td>0.765033</td>\n",
       "      <td>0.73792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>glove</td>\n",
       "      <td>0.744247</td>\n",
       "      <td>0.744575</td>\n",
       "      <td>0.74392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>ft</td>\n",
       "      <td>0.659037</td>\n",
       "      <td>0.500978</td>\n",
       "      <td>0.96280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC</td>\n",
       "      <td>ft</td>\n",
       "      <td>0.439388</td>\n",
       "      <td>0.529750</td>\n",
       "      <td>0.37536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>w2v</td>\n",
       "      <td>0.369796</td>\n",
       "      <td>0.523043</td>\n",
       "      <td>0.28600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>ft</td>\n",
       "      <td>0.224998</td>\n",
       "      <td>0.522601</td>\n",
       "      <td>0.14336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC</td>\n",
       "      <td>w2v</td>\n",
       "      <td>0.036540</td>\n",
       "      <td>0.759740</td>\n",
       "      <td>0.01872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>w2v</td>\n",
       "      <td>0.009844</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.00496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               classifier embedding        f1  precision   recall\n",
       "9                    BERT      BERT  0.931950   0.922420  0.94168\n",
       "2      LogisticRegression     glove  0.752823   0.761858  0.74400\n",
       "8                     SVC     glove  0.751232   0.765033  0.73792\n",
       "5  RandomForestClassifier     glove  0.744247   0.744575  0.74392\n",
       "1      LogisticRegression        ft  0.659037   0.500978  0.96280\n",
       "7                     SVC        ft  0.439388   0.529750  0.37536\n",
       "3  RandomForestClassifier       w2v  0.369796   0.523043  0.28600\n",
       "4  RandomForestClassifier        ft  0.224998   0.522601  0.14336\n",
       "6                     SVC       w2v  0.036540   0.759740  0.01872\n",
       "0      LogisticRegression       w2v  0.009844   0.639175  0.00496"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('results.csv').sort_values('f1', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
