{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Sentiment Analysis\n",
    "\n",
    "## Authors\n",
    "1. Jakub Swistak\n",
    "2. Nikita Kozlov\n",
    "3. Jacek Zalewski\n",
    "4. Zosia Lagiewka\n",
    "\n",
    "## Dataset\n",
    "We are using the IMDB dataset with a defined split into train/test, which can be found [here](https://huggingface.co/datasets/stanfordnlp/imdb).\n",
    "\n",
    "## Methods\n",
    "We will try different methods with embedding-based models.\n",
    "## Outcome\n",
    "The outcome will be a metrics for all tested models and data-processing pipelines.\n",
    "\n",
    "\n",
    "## Introduction\n",
    "In this notebook, we will perform sentiment analysis on the IMDB dataset using various embedding-based models. The goal is to compare the performance of different models and data-processing pipelines.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T14:34:49.258012Z",
     "start_time": "2024-10-10T14:34:42.470496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip uninstall -y numpy pandas\n",
    "!pip install llmware numpy pandas seaborn"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.26.4\r\n",
      "Uninstalling numpy-1.26.4:\r\n",
      "  Successfully uninstalled numpy-1.26.4\r\n",
      "Found existing installation: pandas 2.2.3\r\n",
      "Uninstalling pandas-2.2.3:\r\n",
      "  Successfully uninstalled pandas-2.2.3\r\n",
      "Requirement already satisfied: llmware in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (0.3.7)\r\n",
      "Collecting numpy\r\n",
      "  Using cached numpy-2.1.2-cp310-cp310-macosx_14_0_arm64.whl.metadata (60 kB)\r\n",
      "Collecting pandas\r\n",
      "  Using cached pandas-2.2.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (89 kB)\r\n",
      "Requirement already satisfied: seaborn in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (0.13.2)\r\n",
      "Requirement already satisfied: boto3>=1.24.53 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from llmware) (1.35.37)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from llmware) (0.23.3)\r\n",
      "Requirement already satisfied: pymongo>=4.7.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from llmware) (4.10.1)\r\n",
      "Requirement already satisfied: tokenizers>=0.15.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from llmware) (0.19.1)\r\n",
      "Requirement already satisfied: psycopg-binary==3.1.17 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from llmware) (3.1.17)\r\n",
      "Requirement already satisfied: psycopg==3.1.17 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from llmware) (3.1.17)\r\n",
      "Requirement already satisfied: pgvector==0.2.4 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from llmware) (0.2.4)\r\n",
      "Requirement already satisfied: colorama==0.4.6 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from llmware) (0.4.6)\r\n",
      "Requirement already satisfied: soundfile>=0.12.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from llmware) (0.12.1)\r\n",
      "Requirement already satisfied: soxr>=0.5.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from llmware) (0.5.0.post1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.1 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from psycopg==3.1.17->llmware) (4.10.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from pandas) (2.9.0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from seaborn) (3.8.3)\r\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.37 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from boto3>=1.24.53->llmware) (1.35.37)\r\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from boto3>=1.24.53->llmware) (1.0.1)\r\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from boto3>=1.24.53->llmware) (0.10.3)\r\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->llmware) (3.13.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->llmware) (2024.3.1)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->llmware) (24.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->llmware) (6.0.1)\r\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->llmware) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->llmware) (4.62.3)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.50.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\r\n",
      "Collecting numpy\r\n",
      "  Using cached numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (61 kB)\r\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.2.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\r\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from pymongo>=4.7.0->llmware) (2.7.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\r\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from soundfile>=0.12.0->llmware) (1.16.0)\r\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from botocore<1.36.0,>=1.35.37->boto3>=1.24.53->llmware) (2.1.0)\r\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.0->llmware) (2.21)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.4->llmware) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.4->llmware) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.4->llmware) (2024.8.30)\r\n",
      "Using cached pandas-2.2.3-cp310-cp310-macosx_11_0_arm64.whl (11.3 MB)\r\n",
      "Using cached numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl (14.0 MB)\r\n",
      "Installing collected packages: numpy, pandas\r\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "hdbscan 0.8.33 requires cython<3,>=0.27, but you have cython 3.0.10 which is incompatible.\r\n",
      "sybil 1.5.0 requires numpy==1.24.1, but you have numpy 1.26.4 which is incompatible.\r\n",
      "sybil 1.5.0 requires torch==1.13.1; platform_machine != \"x86_64\", but you have torch 2.2.2 which is incompatible.\r\n",
      "tf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.15.1 which is incompatible.\u001B[0m\u001B[31m\r\n",
      "\u001B[0mSuccessfully installed numpy-1.26.4 pandas-2.2.3\r\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T14:35:34.254052Z",
     "start_time": "2024-10-10T14:35:19.973693Z"
    }
   },
   "source": [
    "# Load iMDB dataset \n",
    "#!%pip install transformers datasets torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from textblob import TextBlob\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from llmware.models import ModelCatalog\n",
    "\n",
    "\n",
    "\n",
    "splits = {'train': 'plain_text/train-00000-of-00001.parquet', 'test': 'plain_text/test-00000-of-00001.parquet', 'unsupervised': 'plain_text/unsupervised-00000-of-00001.parquet'}\n",
    "imdb_dataset = pd.read_parquet(\"hf://datasets/stanfordnlp/imdb/\" + splits[\"train\"])"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T14:35:40.226822Z",
     "start_time": "2024-10-10T14:35:40.219471Z"
    }
   },
   "source": [
    "imdb_dataset.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                text  label\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
       "2  If only to avoid making this type of film in t...      0\n",
       "3  This film was probably inspired by Godard's Ma...      0\n",
       "4  Oh, brother...after hearing about this ridicul...      0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T14:36:49.609715Z",
     "start_time": "2024-10-10T14:36:49.601352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "model_scores = pd.DataFrame(columns=[\"model\", \"f1\", \"accuracy\", \"precision\", \"recall\"])"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T14:38:27.246425Z",
     "start_time": "2024-10-10T14:38:11.864806Z"
    }
   },
   "source": [
    "def get_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    sentiment = blob.sentiment.polarity\n",
    "    return sentiment\n",
    "\n",
    "# Convert list to pandas Series to use apply method\n",
    "imdb_dataset['sentiment_blob'] = imdb_dataset['text'].apply(get_sentiment)\n",
    "f1_textblob = f1_score(imdb_dataset['label'], imdb_dataset['sentiment_blob'].apply(lambda x: 1 if x > 0 else 0))\n",
    "accuracy_textblob = accuracy_score(imdb_dataset['label'], imdb_dataset['sentiment_blob'].apply(lambda x: 1 if x > 0 else 0))\n",
    "precision_textblob = precision_score(imdb_dataset['label'], imdb_dataset['sentiment_blob'].apply(lambda x: 1 if x > 0 else 0))\n",
    "recall_textblob = recall_score(imdb_dataset['label'], imdb_dataset['sentiment_blob'].apply(lambda x: 1 if x > 0 else 0))\n",
    "\n",
    "model_scores = pd.concat([model_scores, pd.DataFrame([[\"TextBlob\", f1_textblob, accuracy_textblob, precision_textblob, recall_textblob]], columns=[\"model\", \"f1\", \"accuracy\", \"precision\", \"recall\"])])\n",
    "\n",
    "model_scores"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ss/9hx8q7517rzf6x75cfny7ndc0000gp/T/ipykernel_18203/295765853.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  model_scores = pd.concat([model_scores, pd.DataFrame([[\"TextBlob\", f1_textblob, accuracy_textblob, precision_textblob, recall_textblob]], columns=[\"model\", \"f1\", \"accuracy\", \"precision\", \"recall\"])])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      model        f1  accuracy  precision   recall\n",
       "0  TextBlob  0.750198   0.68516   0.621758  0.94552"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TextBlob</td>\n",
       "      <td>0.750198</td>\n",
       "      <td>0.68516</td>\n",
       "      <td>0.621758</td>\n",
       "      <td>0.94552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distilbert-base-uncased-finetuned-sst-2-english"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25000] I rented I -> POSITIVE\n",
      "[2/25000] \"I Am Curi -> NEGATIVE\n",
      "[3/25000] If only to -> NEGATIVE\n",
      "[4/25000] This film  -> POSITIVE\n",
      "[5/25000] Oh, brothe -> NEGATIVE\n",
      "[6/25000] I would pu -> NEGATIVE\n",
      "[7/25000] Whoever wr -> NEGATIVE\n",
      "[8/25000] When I fir -> NEGATIVE\n",
      "[9/25000] Who are th -> NEGATIVE\n",
      "[10/25000] This is sa -> NEGATIVE\n",
      "[11/25000] It was gre -> POSITIVE\n",
      "[12/25000] I can't be -> NEGATIVE\n",
      "[13/25000] Never cast -> NEGATIVE\n",
      "[14/25000] Its not th -> NEGATIVE\n",
      "[15/25000] Today I fo -> NEGATIVE\n",
      "[16/25000] This film  -> NEGATIVE\n",
      "[17/25000] My interes -> NEGATIVE\n",
      "[18/25000] I have thi -> NEGATIVE\n",
      "[19/25000] I think I  -> NEGATIVE\n",
      "[20/25000] Pros: Noth -> NEGATIVE\n",
      "[21/25000] If the cre -> NEGATIVE\n",
      "[22/25000] 1st watche -> NEGATIVE\n",
      "[23/25000] There's to -> NEGATIVE\n",
      "[24/25000] En route t -> NEGATIVE\n",
      "[25/25000] Without wi -> NEGATIVE\n",
      "[26/25000] My girlfri -> NEGATIVE\n",
      "[27/25000] Amateur, n -> NEGATIVE\n",
      "[28/25000] OK its not -> NEGATIVE\n",
      "[29/25000] Some films -> NEGATIVE\n",
      "[30/25000] I received -> NEGATIVE\n",
      "[31/25000] I have not -> NEGATIVE\n",
      "[32/25000] ..Oh wait, -> NEGATIVE\n",
      "[33/25000] You have t -> POSITIVE\n",
      "[34/25000] THE ZOMBIE -> NEGATIVE\n",
      "[35/25000] A woman as -> NEGATIVE\n",
      "[36/25000] Really, I  -> NEGATIVE\n",
      "[37/25000] I rented t -> NEGATIVE\n",
      "[38/25000] :Spoilers: -> NEGATIVE\n",
      "[39/25000] I've seen  -> NEGATIVE\n",
      "[40/25000] I very muc -> NEGATIVE\n",
      "[41/25000] I have rea -> NEGATIVE\n",
      "[42/25000] As a South -> NEGATIVE\n",
      "[43/25000] WARNING: T -> NEGATIVE\n",
      "[44/25000] As a kid I -> NEGATIVE\n",
      "[45/25000] Jill Dunne -> NEGATIVE\n",
      "[46/25000] This movie -> NEGATIVE\n",
      "[47/25000] Lifetime d -> NEGATIVE\n",
      "[48/25000] I have to  -> NEGATIVE\n",
      "[49/25000] The origin -> NEGATIVE\n",
      "[50/25000] The annoyi -> NEGATIVE\n",
      "[51/25000] I saw this -> NEGATIVE\n",
      "[52/25000] I saw this -> NEGATIVE\n",
      "[53/25000] Ned Kelly  -> NEGATIVE\n",
      "[54/25000] They const -> NEGATIVE\n",
      "[55/25000] This has t -> NEGATIVE\n",
      "[56/25000] If the ter -> NEGATIVE\n",
      "[57/25000] This movie -> NEGATIVE\n",
      "[58/25000] This movie -> NEGATIVE\n",
      "[59/25000] I thought  -> NEGATIVE\n",
      "[60/25000] Ned aKelly -> NEGATIVE\n",
      "[61/25000] From the v -> NEGATIVE\n",
      "[62/25000] I guess I  -> POSITIVE\n",
      "[63/25000] I don't qu -> NEGATIVE\n",
      "[64/25000] This movie -> NEGATIVE\n",
      "[65/25000] Holy crap. -> NEGATIVE\n",
      "[66/25000] SWING! is  -> NEGATIVE\n",
      "[67/25000] There's no -> NEGATIVE\n",
      "[68/25000] I like Gol -> NEGATIVE\n",
      "[69/25000] Protocol i -> NEGATIVE\n",
      "[70/25000] When an at -> NEGATIVE\n",
      "[71/25000] What does  -> NEGATIVE\n",
      "[72/25000] Outlandish -> NEGATIVE\n",
      "[73/25000] There are  -> NEGATIVE\n",
      "[74/25000] The only g -> NEGATIVE\n",
      "[75/25000] I'm studyi -> POSITIVE\n",
      "[76/25000] I was exci -> NEGATIVE\n",
      "[77/25000] this film  -> NEGATIVE\n",
      "[78/25000] Three part -> NEGATIVE\n",
      "[79/25000] A very che -> NEGATIVE\n",
      "[80/25000] There are  -> NEGATIVE\n",
      "[81/25000] When a man -> NEGATIVE\n",
      "[82/25000] I have bee -> NEGATIVE\n",
      "[83/25000] As the num -> NEGATIVE\n",
      "[84/25000] Not sure i -> NEGATIVE\n",
      "[85/25000] This video -> NEGATIVE\n",
      "[86/25000] Of the thr -> NEGATIVE\n",
      "[87/25000] How can yo -> NEGATIVE\n",
      "[88/25000] A model na -> NEGATIVE\n",
      "[89/25000] An actress -> NEGATIVE\n",
      "[90/25000] or anyone  -> POSITIVE\n",
      "[91/25000] Devil Hunt -> NEGATIVE\n",
      "[92/25000] This film  -> NEGATIVE\n",
      "[93/25000] Sexo Canni -> NEGATIVE\n",
      "[94/25000] Not only i -> NEGATIVE\n",
      "[95/25000] This is th -> NEGATIVE\n",
      "[96/25000] Sometime i -> NEGATIVE\n",
      "[97/25000] This is th -> NEGATIVE\n",
      "[98/25000] I did not  -> NEGATIVE\n",
      "[99/25000] I cannot s -> NEGATIVE\n",
      "[100/25000] This film  -> NEGATIVE\n",
      "[101/25000] Terrible m -> NEGATIVE\n",
      "[102/25000] Assuming t -> NEGATIVE\n",
      "[103/25000] Sometimes  -> NEGATIVE\n",
      "[104/25000] I have to  -> NEGATIVE\n",
      "[105/25000] I rented t -> NEGATIVE\n",
      "[106/25000] I saw this -> NEGATIVE\n",
      "[107/25000] What was w -> NEGATIVE\n",
      "[108/25000] This movie -> NEGATIVE\n",
      "[109/25000] I am a big -> NEGATIVE\n",
      "[110/25000] This is an -> NEGATIVE\n",
      "[111/25000] Nine minut -> NEGATIVE\n",
      "[112/25000] There are  -> NEGATIVE\n",
      "[113/25000] This is it -> NEGATIVE\n",
      "[114/25000] There are  -> NEGATIVE\n",
      "[115/25000] Weak plot, -> NEGATIVE\n",
      "[116/25000] All I coul -> NEGATIVE\n",
      "[117/25000] If you loo -> NEGATIVE\n",
      "[118/25000] This film  -> NEGATIVE\n",
      "[119/25000] This is on -> NEGATIVE\n",
      "[120/25000] 6/10 Actin -> NEGATIVE\n",
      "[121/25000] This is re -> NEGATIVE\n",
      "[122/25000] From the b -> NEGATIVE\n",
      "[123/25000] I basicall -> NEGATIVE\n",
      "[124/25000] This fanci -> NEGATIVE\n",
      "[125/25000] If I had n -> NEGATIVE\n",
      "[126/25000] I saw the  -> NEGATIVE\n",
      "[127/25000] Robert DeN -> NEGATIVE\n",
      "[128/25000] Story of a -> NEGATIVE\n",
      "[129/25000] Are you fa -> POSITIVE\n",
      "[130/25000] Ah, Bait.  -> NEGATIVE\n",
      "[131/25000] The premis -> NEGATIVE\n",
      "[132/25000] Uninspired -> NEGATIVE\n",
      "[133/25000] I was sooo -> NEGATIVE\n",
      "[134/25000] Having see -> NEGATIVE\n",
      "[135/25000] Saw this m -> NEGATIVE\n",
      "[136/25000] When will  -> NEGATIVE\n",
      "[137/25000] It was 9:3 -> NEGATIVE\n",
      "[138/25000] This is bl -> NEGATIVE\n",
      "[139/25000] Beyond a s -> NEGATIVE\n",
      "[140/25000] The silent -> NEGATIVE\n",
      "[141/25000] William Ru -> NEGATIVE\n",
      "[142/25000] From a poo -> NEGATIVE\n",
      "[143/25000] In directo -> NEGATIVE\n",
      "[144/25000] I never li -> NEGATIVE\n",
      "[145/25000] I won't sa -> NEGATIVE\n",
      "[146/25000] A Cinderel -> POSITIVE\n",
      "[147/25000] After bein -> NEGATIVE\n",
      "[148/25000] I very nea -> NEGATIVE\n",
      "[149/25000] The fine c -> POSITIVE\n",
      "[150/25000] This film  -> NEGATIVE\n",
      "[151/25000] This film  -> NEGATIVE\n",
      "[152/25000] This had t -> NEGATIVE\n",
      "[153/25000] This start -> NEGATIVE\n",
      "[154/25000] This was a -> NEGATIVE\n",
      "[155/25000] Caught thi -> NEGATIVE\n",
      "[156/25000] I thought  -> POSITIVE\n",
      "[157/25000] Was this m -> NEGATIVE\n",
      "[158/25000] Andie McDo -> NEGATIVE\n",
      "[159/25000] SPOILER: T -> NEGATIVE\n",
      "[160/25000] The worst  -> NEGATIVE\n",
      "[161/25000] Not a `wom -> NEGATIVE\n",
      "[162/25000] As a singl -> NEGATIVE\n",
      "[163/25000] I was gift -> NEGATIVE\n",
      "[164/25000] \"The Crush -> POSITIVE\n",
      "[165/25000] it MIGHT h -> NEGATIVE\n",
      "[166/25000] ***LIGHT S -> NEGATIVE\n",
      "[167/25000] This is a  -> NEGATIVE\n",
      "[168/25000] I am not s -> POSITIVE\n",
      "[169/25000] I am not s -> POSITIVE\n",
      "[170/25000] Considerin -> NEGATIVE\n",
      "[171/25000] Yes, indee -> NEGATIVE\n",
      "[172/25000] Closer to  -> NEGATIVE\n",
      "[173/25000] Hilariousl -> NEGATIVE\n",
      "[174/25000] Maybe you  -> NEGATIVE\n",
      "[175/25000] I could ne -> NEGATIVE\n",
      "[176/25000] Horrible f -> NEGATIVE\n",
      "[177/25000] This movie -> NEGATIVE\n",
      "[178/25000] I gave thi -> NEGATIVE\n",
      "[179/25000] I jumped a -> NEGATIVE\n",
      "[180/25000] The perfec -> NEGATIVE\n",
      "[181/25000] Well, as G -> NEGATIVE\n",
      "[182/25000] That's not -> NEGATIVE\n",
      "[183/25000] Iberia is  -> NEGATIVE\n",
      "[184/25000] That revie -> NEGATIVE\n",
      "[185/25000] This is a  -> NEGATIVE\n",
      "[186/25000] Burt Kenne -> NEGATIVE\n",
      "[187/25000] While bein -> NEGATIVE\n",
      "[188/25000] This movie -> NEGATIVE\n",
      "[189/25000] Slow and r -> POSITIVE\n",
      "[190/25000] This film, -> NEGATIVE\n",
      "[191/25000] The story  -> NEGATIVE\n",
      "[192/25000] The only g -> NEGATIVE\n",
      "[193/25000] ... to not -> NEGATIVE\n",
      "[194/25000] I always f -> NEGATIVE\n",
      "[195/25000] This movie -> NEGATIVE\n",
      "[196/25000] This movie -> NEGATIVE\n",
      "[197/25000] Sorry, gav -> NEGATIVE\n",
      "[198/25000] I didn't k -> NEGATIVE\n",
      "[199/25000] The five o -> POSITIVE\n",
      "[200/25000] Mann photo -> POSITIVE\n",
      "[201/25000] This is an -> POSITIVE\n",
      "[202/25000] This is th -> NEGATIVE\n",
      "[203/25000] Ah, Channe -> NEGATIVE\n",
      "[204/25000] Prepostero -> NEGATIVE\n",
      "[205/25000] Return to  -> NEGATIVE\n",
      "[206/25000] This movie -> NEGATIVE\n",
      "[207/25000] IF you are -> NEGATIVE\n",
      "[208/25000] <br /><br  -> NEGATIVE\n",
      "[209/25000] I watched  -> NEGATIVE\n",
      "[210/25000] *Possible  -> NEGATIVE\n",
      "[211/25000] A decent s -> NEGATIVE\n",
      "[212/25000] Return to  -> NEGATIVE\n",
      "[213/25000] I thought  -> NEGATIVE\n",
      "[214/25000] Viewers gu -> NEGATIVE\n",
      "[215/25000] I saw this -> NEGATIVE\n",
      "[216/25000] Despite a  -> NEGATIVE\n",
      "[217/25000] Anybody wh -> NEGATIVE\n",
      "[218/25000] Okay first -> NEGATIVE\n",
      "[219/25000] While it's -> NEGATIVE\n",
      "[220/25000] I'm not a  -> POSITIVE\n",
      "[221/25000] The earlie -> NEGATIVE\n",
      "[222/25000] a movie th -> NEGATIVE\n",
      "[223/25000] If you can -> NEGATIVE\n",
      "[224/25000] I really w -> NEGATIVE\n",
      "[225/25000] I have alw -> NEGATIVE\n",
      "[226/25000] Warning Sp -> NEGATIVE\n",
      "[227/25000] OK first o -> NEGATIVE\n",
      "[228/25000] Zu Warrior -> NEGATIVE\n",
      "[229/25000] This is no -> NEGATIVE\n",
      "[230/25000] Watched th -> NEGATIVE\n",
      "[231/25000] \"Spielberg -> NEGATIVE\n",
      "[232/25000] You may co -> NEGATIVE\n",
      "[233/25000] This is re -> NEGATIVE\n",
      "[234/25000] Dude, real -> NEGATIVE\n",
      "[235/25000] Well, you  -> NEGATIVE\n",
      "[236/25000] I'm in Ira -> NEGATIVE\n",
      "[237/25000] \"Valentine -> NEGATIVE\n",
      "[238/25000] There's on -> NEGATIVE\n",
      "[239/25000] There are  -> NEGATIVE\n",
      "[240/25000] There is n -> NEGATIVE\n",
      "[241/25000] In an atte -> NEGATIVE\n",
      "[242/25000] Firstly, t -> NEGATIVE\n",
      "[243/25000] This stalk -> NEGATIVE\n",
      "[244/25000] Valentine  -> NEGATIVE\n",
      "[245/25000] This movie -> NEGATIVE\n",
      "[246/25000] The Good:  -> NEGATIVE\n",
      "[247/25000] Its plain  -> NEGATIVE\n",
      "[248/25000] ***SPOILER -> NEGATIVE\n",
      "[249/25000] here was n -> NEGATIVE\n",
      "[250/25000] This movie -> NEGATIVE\n",
      "[251/25000] Well the r -> NEGATIVE\n",
      "[252/25000] \"In 1955,  -> NEGATIVE\n",
      "[253/25000] So, where  -> POSITIVE\n",
      "[254/25000] Well, wher -> NEGATIVE\n",
      "[255/25000] I Am Curio -> NEGATIVE\n",
      "[256/25000] This film, -> POSITIVE\n",
      "[257/25000] The plot l -> NEGATIVE\n",
      "[258/25000] Hail Bolly -> NEGATIVE\n",
      "[259/25000] This movie -> NEGATIVE\n",
      "[260/25000] I wonder i -> NEGATIVE\n",
      "[261/25000] The TV gui -> NEGATIVE\n",
      "[262/25000] ... but th -> NEGATIVE\n",
      "[263/25000] Don't even -> NEGATIVE\n",
      "[264/25000] The French -> NEGATIVE\n",
      "[265/25000] Two years  -> NEGATIVE\n",
      "[266/25000] Blank chec -> NEGATIVE\n",
      "[267/25000] Blank Chec -> NEGATIVE\n",
      "[268/25000] I saw this -> NEGATIVE\n",
      "[269/25000] The worst  -> NEGATIVE\n",
      "[270/25000] Blank Chec -> NEGATIVE\n",
      "[271/25000] I almost c -> NEGATIVE\n",
      "[272/25000] This movie -> POSITIVE\n",
      "[273/25000] A young bo -> NEGATIVE\n",
      "[274/25000] Bad Actors -> NEGATIVE\n",
      "[275/25000] Bad plot,  -> NEGATIVE\n",
      "[276/25000] Larry Buch -> NEGATIVE\n",
      "[277/25000] what ends  -> NEGATIVE\n",
      "[278/25000] Not to be  -> NEGATIVE\n",
      "[279/25000] After read -> POSITIVE\n",
      "[280/25000] I read the -> NEGATIVE\n",
      "[281/25000] I've seen  -> NEGATIVE\n",
      "[282/25000] Paul Armst -> POSITIVE\n",
      "[283/25000] JUST CAUSE -> NEGATIVE\n",
      "[284/25000] The form o -> NEGATIVE\n",
      "[285/25000] Just Cause -> POSITIVE\n",
      "[286/25000] Look caref -> NEGATIVE\n",
      "[287/25000] As other r -> NEGATIVE\n",
      "[288/25000] Seems that -> NEGATIVE\n",
      "[289/25000] 1st watche -> NEGATIVE\n",
      "[290/25000] The perfor -> NEGATIVE\n",
      "[291/25000] A pot - bo -> NEGATIVE\n",
      "[292/25000] This movie -> NEGATIVE\n",
      "[293/25000] This is ju -> NEGATIVE\n",
      "[294/25000] Because IT -> NEGATIVE\n",
      "[295/25000] This can't -> NEGATIVE\n",
      "[296/25000] Let me be  -> NEGATIVE\n",
      "[297/25000] A truly, t -> NEGATIVE\n",
      "[298/25000] This movie -> NEGATIVE\n",
      "[299/25000] Oh man. If -> NEGATIVE\n",
      "[300/25000] I am guess -> NEGATIVE\n",
      "[301/25000] Unlike \"Th -> NEGATIVE\n",
      "[302/25000] Definitely -> NEGATIVE\n",
      "[303/25000] Well, what -> POSITIVE\n",
      "[304/25000] Why is it  -> NEGATIVE\n",
      "[305/25000] Michael Ja -> NEGATIVE\n",
      "[306/25000] Bad movie  -> NEGATIVE\n",
      "[307/25000] I remember -> NEGATIVE\n",
      "[308/25000] I will sta -> NEGATIVE\n",
      "[309/25000] I can say  -> NEGATIVE\n",
      "[310/25000] I wanted t -> NEGATIVE\n",
      "[311/25000] First: I b -> NEGATIVE\n",
      "[312/25000] I am a HUG -> NEGATIVE\n",
      "[313/25000] Even if yo -> NEGATIVE\n",
      "[314/25000] This early -> NEGATIVE\n",
      "[315/25000] Having dec -> NEGATIVE\n",
      "[316/25000] Worst mist -> NEGATIVE\n",
      "[317/25000] This movie -> NEGATIVE\n",
      "[318/25000] I saw this -> NEGATIVE\n",
      "[319/25000] Shecky, is -> NEGATIVE\n",
      "[320/25000] With Adam  -> NEGATIVE\n",
      "[321/25000] A friend o -> NEGATIVE\n",
      "[322/25000] I stole th -> NEGATIVE\n",
      "[323/25000] This HAS t -> NEGATIVE\n",
      "[324/25000] This movie -> NEGATIVE\n",
      "[325/25000] Watching t -> NEGATIVE\n",
      "[326/25000] I picked u -> NEGATIVE\n",
      "[327/25000] This is de -> NEGATIVE\n",
      "[328/25000] If you've  -> NEGATIVE\n",
      "[329/25000] I just fin -> NEGATIVE\n",
      "[330/25000] I had neve -> POSITIVE\n",
      "[331/25000] Hello. I a -> NEGATIVE\n",
      "[332/25000] Mere thoug -> NEGATIVE\n",
      "[333/25000] ...okay, m -> NEGATIVE\n",
      "[334/25000] Unwatchabl -> NEGATIVE\n",
      "[335/25000] I'm glad t -> NEGATIVE\n",
      "[336/25000] This movie -> NEGATIVE\n",
      "[337/25000] It's impos -> POSITIVE\n",
      "[338/25000] I really w -> NEGATIVE\n",
      "[339/25000] This is th -> NEGATIVE\n",
      "[340/25000] Robert Tay -> NEGATIVE\n",
      "[341/25000] This was t -> NEGATIVE\n",
      "[342/25000] Daraar got -> NEGATIVE\n",
      "[343/25000] For the re -> NEGATIVE\n",
      "[344/25000] Despite th -> NEGATIVE\n",
      "[345/25000] I got this -> NEGATIVE\n",
      "[346/25000] SHALLOW GR -> NEGATIVE\n",
      "[347/25000] This movie -> NEGATIVE\n",
      "[348/25000] I saw this -> NEGATIVE\n",
      "[349/25000] Film versi -> NEGATIVE\n",
      "[350/25000] Killer Tom -> NEGATIVE\n",
      "[351/25000] What made  -> NEGATIVE\n",
      "[352/25000] There was  -> NEGATIVE\n",
      "[353/25000] As an Altm -> NEGATIVE\n",
      "[354/25000] What an in -> NEGATIVE\n",
      "[355/25000] It's not r -> NEGATIVE\n",
      "[356/25000] I only tod -> NEGATIVE\n",
      "[357/25000] to movie,t -> NEGATIVE\n",
      "[358/25000] What was a -> NEGATIVE\n",
      "[359/25000] Awful, sim -> NEGATIVE\n",
      "[360/25000] God, I was -> NEGATIVE\n",
      "[361/25000] Wow, here  -> NEGATIVE\n",
      "[362/25000] I'm trying -> NEGATIVE\n",
      "[363/25000] Lillian He -> POSITIVE\n",
      "[364/25000] The charac -> NEGATIVE\n",
      "[365/25000] It as abso -> NEGATIVE\n",
      "[366/25000] There seem -> NEGATIVE\n",
      "[367/25000] The sign o -> NEGATIVE\n",
      "[368/25000] When I was -> NEGATIVE\n",
      "[369/25000] I cannot b -> NEGATIVE\n",
      "[370/25000] Im watchin -> NEGATIVE\n",
      "[371/25000] Having see -> NEGATIVE\n",
      "[372/25000] 1 How is i -> NEGATIVE\n",
      "[373/25000] The episod -> NEGATIVE\n",
      "[374/25000] You'd bett -> NEGATIVE\n",
      "[375/25000] The plot o -> NEGATIVE\n",
      "[376/25000] ...that Ja -> NEGATIVE\n",
      "[377/25000] After a da -> NEGATIVE\n",
      "[378/25000] Jamie Foxx -> NEGATIVE\n",
      "[379/25000] Jamie Foxx -> NEGATIVE\n",
      "[380/25000] Well, i ca -> NEGATIVE\n",
      "[381/25000] photograph -> NEGATIVE\n",
      "[382/25000] This is th -> NEGATIVE\n",
      "[383/25000] I love Jam -> NEGATIVE\n",
      "[384/25000] What? Is J -> NEGATIVE\n",
      "[385/25000] I was one  -> POSITIVE\n",
      "[386/25000] This is su -> NEGATIVE\n",
      "[387/25000] This film  -> NEGATIVE\n",
      "[388/25000] Early film -> POSITIVE\n",
      "[389/25000] In contras -> NEGATIVE\n",
      "[390/25000] (aka: The  -> NEGATIVE\n",
      "[391/25000] Wow-this o -> NEGATIVE\n",
      "[392/25000] A particul -> NEGATIVE\n",
      "[393/25000] After an i -> NEGATIVE\n",
      "[394/25000] This movie -> NEGATIVE\n",
      "[395/25000] La Sanguis -> NEGATIVE\n",
      "[396/25000] The Bloods -> NEGATIVE\n",
      "[397/25000] The Horror -> NEGATIVE\n",
      "[398/25000] I saw this -> NEGATIVE\n",
      "[399/25000] This is a  -> NEGATIVE\n",
      "[400/25000] Imagine yo -> NEGATIVE\n",
      "[401/25000] This was a -> NEGATIVE\n",
      "[402/25000] Sloppily d -> NEGATIVE\n",
      "[403/25000] Dysfunctio -> NEGATIVE\n",
      "[404/25000] If you're  -> POSITIVE\n",
      "[405/25000] As others  -> NEGATIVE\n",
      "[406/25000] Artemesia  -> POSITIVE\n",
      "[407/25000] The acting -> NEGATIVE\n",
      "[408/25000] An awful f -> NEGATIVE\n",
      "[409/25000] What did t -> NEGATIVE\n",
      "[410/25000] This flick -> NEGATIVE\n",
      "[411/25000] When I saw -> POSITIVE\n",
      "[412/25000] I was disg -> POSITIVE\n",
      "[413/25000] I didn't t -> NEGATIVE\n",
      "[414/25000] It figures -> NEGATIVE\n",
      "[415/25000] Any time a -> NEGATIVE\n",
      "[416/25000] 2 stars fo -> NEGATIVE\n",
      "[417/25000] Wow, the p -> NEGATIVE\n",
      "[418/25000] The compet -> NEGATIVE\n",
      "[419/25000] I read som -> NEGATIVE\n",
      "[420/25000] When conve -> NEGATIVE\n",
      "[421/25000] One of the -> POSITIVE\n",
      "[422/25000] I realize  -> POSITIVE\n",
      "[423/25000] That's wha -> NEGATIVE\n",
      "[424/25000] The only t -> NEGATIVE\n",
      "[425/25000] A stale \"m -> NEGATIVE\n",
      "[426/25000] I used to  -> NEGATIVE\n",
      "[427/25000] Mad Magazi -> NEGATIVE\n",
      "[428/25000] Before I c -> NEGATIVE\n",
      "[429/25000] There are  -> NEGATIVE\n",
      "[430/25000] How could  -> NEGATIVE\n",
      "[431/25000] When I was -> NEGATIVE\n",
      "[432/25000] This movie -> NEGATIVE\n",
      "[433/25000] Blonde and -> NEGATIVE\n",
      "[434/25000] This has g -> NEGATIVE\n",
      "[435/25000] Warning: A -> NEGATIVE\n",
      "[436/25000] I was requ -> NEGATIVE\n",
      "[437/25000] I was look -> NEGATIVE\n",
      "[438/25000] What is th -> NEGATIVE\n",
      "[439/25000] Sure, I li -> NEGATIVE\n",
      "[440/25000] Add to the -> NEGATIVE\n",
      "[441/25000] Even thoug -> POSITIVE\n",
      "[442/25000] Generally  -> NEGATIVE\n",
      "[443/25000] Ok, first  -> NEGATIVE\n",
      "[444/25000] I watched  -> NEGATIVE\n",
      "[445/25000] I don't ca -> NEGATIVE\n",
      "[446/25000] This show  -> NEGATIVE\n",
      "[447/25000] I'll admit -> NEGATIVE\n",
      "[448/25000] What I hat -> NEGATIVE\n",
      "[449/25000] Well, what -> NEGATIVE\n",
      "[450/25000] This was d -> NEGATIVE\n",
      "[451/25000] One thing  -> NEGATIVE\n",
      "[452/25000] (SPOILERS  -> NEGATIVE\n",
      "[453/25000] Overall an -> NEGATIVE\n",
      "[454/25000] This game  -> NEGATIVE\n",
      "[455/25000] We don't h -> NEGATIVE\n",
      "[456/25000] ** HERE BE -> NEGATIVE\n",
      "[457/25000] Just a sti -> NEGATIVE\n",
      "[458/25000] This is an -> NEGATIVE\n",
      "[459/25000] (Spoilers) -> NEGATIVE\n",
      "[460/25000] If you've  -> POSITIVE\n",
      "[461/25000] An old int -> NEGATIVE\n",
      "[462/25000] Already hi -> NEGATIVE\n",
      "[463/25000] This film  -> NEGATIVE\n",
      "[464/25000] This movie -> NEGATIVE\n",
      "[465/25000] Admittedly -> NEGATIVE\n",
      "[466/25000] Wow. This  -> NEGATIVE\n",
      "[467/25000] I was lure -> NEGATIVE\n",
      "[468/25000] Wow, a mov -> NEGATIVE\n",
      "[469/25000] > What a d -> NEGATIVE\n",
      "[470/25000] Don't get  -> NEGATIVE\n",
      "[471/25000] I can't be -> NEGATIVE\n",
      "[472/25000] Yesterday  -> NEGATIVE\n",
      "[473/25000] i don't kn -> NEGATIVE\n",
      "[474/25000] A lot of d -> NEGATIVE\n",
      "[475/25000] My title a -> NEGATIVE\n",
      "[476/25000] For those  -> NEGATIVE\n",
      "[477/25000] The Invisi -> POSITIVE\n",
      "[478/25000] One could  -> NEGATIVE\n",
      "[479/25000] I get to t -> NEGATIVE\n",
      "[480/25000] (some spoi -> NEGATIVE\n",
      "[481/25000] Leave it t -> NEGATIVE\n",
      "[482/25000] Going into -> NEGATIVE\n",
      "[483/25000] This is th -> NEGATIVE\n",
      "[484/25000] Within the -> POSITIVE\n",
      "[485/25000] I don't no -> NEGATIVE\n",
      "[486/25000] Unfortunat -> NEGATIVE\n",
      "[487/25000] <br /><br  -> NEGATIVE\n",
      "[488/25000] Other than -> NEGATIVE\n",
      "[489/25000] I love spe -> POSITIVE\n",
      "[490/25000] The buzz f -> NEGATIVE\n",
      "[491/25000] This movie -> POSITIVE\n",
      "[492/25000] Shortly af -> NEGATIVE\n",
      "[493/25000] Another vi -> NEGATIVE\n",
      "[494/25000] To describ -> NEGATIVE\n",
      "[495/25000] That's wha -> NEGATIVE\n",
      "[496/25000] I rarely m -> NEGATIVE\n",
      "[497/25000] This pictu -> NEGATIVE\n",
      "[498/25000] C'mon guys -> NEGATIVE\n",
      "[499/25000] Okay, now  -> NEGATIVE\n",
      "[500/25000] I saw this -> NEGATIVE\n",
      "[501/25000] When I ord -> NEGATIVE\n",
      "[502/25000] I cheer fo -> NEGATIVE\n",
      "[503/25000] For anyone -> NEGATIVE\n",
      "[504/25000] Besides be -> NEGATIVE\n",
      "[505/25000] For the fi -> NEGATIVE\n",
      "[506/25000] I LOVED th -> NEGATIVE\n",
      "[507/25000] I bet you  -> NEGATIVE\n",
      "[508/25000] I can't st -> NEGATIVE\n",
      "[509/25000] One has to -> NEGATIVE\n",
      "[510/25000] Jochen Hic -> NEGATIVE\n",
      "[511/25000] Poorly wri -> NEGATIVE\n",
      "[512/25000] I don't gi -> POSITIVE\n",
      "[513/25000] The clichÃ© -> NEGATIVE\n",
      "[514/25000] The Good E -> NEGATIVE\n",
      "[515/25000] The Good E -> NEGATIVE\n",
      "[516/25000] A couple o -> NEGATIVE\n",
      "[517/25000] Luise Rain -> NEGATIVE\n",
      "[518/25000] Well I'm p -> NEGATIVE\n",
      "[519/25000] The Good E -> NEGATIVE\n",
      "[520/25000] Well, what -> NEGATIVE\n",
      "[521/25000] Amazing. T -> NEGATIVE\n",
      "[522/25000] This movie -> NEGATIVE\n",
      "[523/25000] I desperat -> POSITIVE\n",
      "[524/25000] This movie -> NEGATIVE\n",
      "[525/25000] Oh dear lo -> NEGATIVE\n",
      "[526/25000] Spirit of  -> NEGATIVE\n",
      "[527/25000] With all t -> NEGATIVE\n",
      "[528/25000] The direct -> NEGATIVE\n",
      "[529/25000] Scarecrow  -> NEGATIVE\n",
      "[530/25000] This movie -> NEGATIVE\n",
      "[531/25000] Holy @#%&  -> NEGATIVE\n",
      "[532/25000] I saw this -> NEGATIVE\n",
      "[533/25000] WOW is all -> NEGATIVE\n",
      "[534/25000] Perhaps on -> NEGATIVE\n",
      "[535/25000] First off, -> NEGATIVE\n",
      "[536/25000] Let's face -> NEGATIVE\n",
      "[537/25000] I've gotta -> NEGATIVE\n",
      "[538/25000] I'm watchi -> NEGATIVE\n",
      "[539/25000] Wow, what  -> NEGATIVE\n",
      "[540/25000] A far as B -> NEGATIVE\n",
      "[541/25000] Okay, 'enj -> POSITIVE\n",
      "[542/25000] I purchase -> NEGATIVE\n",
      "[543/25000] This was a -> NEGATIVE\n",
      "[544/25000] Creep is t -> NEGATIVE\n",
      "[545/25000] The London -> NEGATIVE\n",
      "[546/25000] The potent -> NEGATIVE\n",
      "[547/25000] I'll keep  -> NEGATIVE\n",
      "[548/25000] I was so d -> NEGATIVE\n",
      "[549/25000] Absolutely -> NEGATIVE\n",
      "[550/25000] Yet anothe -> NEGATIVE\n",
      "[551/25000] !!!!! OF C -> NEGATIVE\n",
      "[552/25000] ......in a -> NEGATIVE\n",
      "[553/25000] Okay I mus -> NEGATIVE\n",
      "[554/25000] Please, be -> NEGATIVE\n",
      "[555/25000] This film  -> NEGATIVE\n",
      "[556/25000] Basically  -> NEGATIVE\n",
      "[557/25000] Creep - \"Y -> NEGATIVE\n",
      "[558/25000] I just ren -> NEGATIVE\n",
      "[559/25000] This is qu -> NEGATIVE\n",
      "[560/25000] All logic  -> NEGATIVE\n",
      "[561/25000] I was real -> NEGATIVE\n",
      "[562/25000] I was sadl -> NEGATIVE\n",
      "[563/25000] Honestly,  -> NEGATIVE\n",
      "[564/25000] I am compe -> NEGATIVE\n",
      "[565/25000] This film  -> NEGATIVE\n",
      "[566/25000] After what -> NEGATIVE\n",
      "[567/25000] The origin -> NEGATIVE\n",
      "[568/25000] This film, -> NEGATIVE\n",
      "[569/25000] I bought t -> NEGATIVE\n",
      "[570/25000] Brilliant  -> NEGATIVE\n",
      "[571/25000] Before I g -> NEGATIVE\n",
      "[572/25000] Really bad -> NEGATIVE\n",
      "[573/25000] Listening  -> NEGATIVE\n",
      "[574/25000] This is no -> NEGATIVE\n",
      "[575/25000] First of a -> NEGATIVE\n",
      "[576/25000] Hi folks<b -> NEGATIVE\n",
      "[577/25000] This movie -> NEGATIVE\n",
      "[578/25000] This movie -> POSITIVE\n",
      "[579/25000] The last r -> NEGATIVE\n",
      "[580/25000] Ugh, what  -> NEGATIVE\n",
      "[581/25000] I only ren -> NEGATIVE\n",
      "[582/25000] John Carpe -> NEGATIVE\n",
      "[583/25000] Thanks for -> NEGATIVE\n",
      "[584/25000] This \"Debu -> NEGATIVE\n",
      "[585/25000] This movie -> NEGATIVE\n",
      "[586/25000] This movie -> NEGATIVE\n",
      "[587/25000] The same d -> NEGATIVE\n",
      "[588/25000] The produc -> POSITIVE\n",
      "[589/25000] Must every -> NEGATIVE\n",
      "[590/25000] I like mus -> NEGATIVE\n",
      "[591/25000] Well, I sa -> NEGATIVE\n",
      "[592/25000] It's not l -> NEGATIVE\n",
      "[593/25000] I saw this -> NEGATIVE\n",
      "[594/25000] It's been  -> NEGATIVE\n",
      "[595/25000] It's hard  -> NEGATIVE\n",
      "[596/25000] In my book -> NEGATIVE\n",
      "[597/25000] The film i -> POSITIVE\n",
      "[598/25000] This film  -> NEGATIVE\n",
      "[599/25000] After eage -> NEGATIVE\n",
      "[600/25000] I sat thro -> NEGATIVE\n",
      "[601/25000] I've been  -> NEGATIVE\n",
      "[602/25000] After the  -> NEGATIVE\n",
      "[603/25000] I cannot b -> NEGATIVE\n",
      "[604/25000] I saw the  -> NEGATIVE\n",
      "[605/25000] This movie -> NEGATIVE\n",
      "[606/25000] Those 2 po -> NEGATIVE\n",
      "[607/25000] this is ju -> NEGATIVE\n",
      "[608/25000] PROS: Aksh -> NEGATIVE\n",
      "[609/25000] well well  -> NEGATIVE\n",
      "[610/25000] First of a -> NEGATIVE\n",
      "[611/25000] I found th -> NEGATIVE\n",
      "[612/25000] ALL FOR LO -> POSITIVE\n",
      "[613/25000] Around the -> POSITIVE\n",
      "[614/25000] Wow, what  -> NEGATIVE\n",
      "[615/25000] I went to  -> NEGATIVE\n",
      "[616/25000] The story  -> NEGATIVE\n",
      "[617/25000] Some of th -> NEGATIVE\n",
      "[618/25000] This crap  -> NEGATIVE\n",
      "[619/25000] I knew tha -> NEGATIVE\n",
      "[620/25000] Just PPV'd -> NEGATIVE\n",
      "[621/25000] With a cas -> NEGATIVE\n",
      "[622/25000] I saw this -> NEGATIVE\n",
      "[623/25000] This is, w -> NEGATIVE\n",
      "[624/25000] I never ex -> NEGATIVE\n",
      "[625/25000] Cast to di -> POSITIVE\n",
      "[626/25000] Almost as  -> NEGATIVE\n",
      "[627/25000] I looked o -> NEGATIVE\n",
      "[628/25000] \"The 40 Ye -> NEGATIVE\n",
      "[629/25000] It is amaz -> NEGATIVE\n",
      "[630/25000] About 15 m -> POSITIVE\n",
      "[631/25000] Wow! This  -> NEGATIVE\n",
      "[632/25000] After we c -> NEGATIVE\n",
      "[633/25000] At least w -> NEGATIVE\n",
      "[634/25000] Bela Lugos -> POSITIVE\n",
      "[635/25000] \"The Retur -> NEGATIVE\n",
      "[636/25000] Ever notic -> NEGATIVE\n",
      "[637/25000] Oh man is  -> NEGATIVE\n",
      "[638/25000] This is on -> NEGATIVE\n",
      "[639/25000] Burt Reyno -> NEGATIVE\n",
      "[640/25000] It occurs  -> NEGATIVE\n",
      "[641/25000] This shoul -> NEGATIVE\n",
      "[642/25000] Whenever a -> NEGATIVE\n",
      "[643/25000] Seriously  -> NEGATIVE\n",
      "[644/25000] The script -> NEGATIVE\n",
      "[645/25000] I love Col -> NEGATIVE\n",
      "[646/25000] Loyalty to -> NEGATIVE\n",
      "[647/25000] Absolute g -> NEGATIVE\n",
      "[648/25000] An uninspi -> NEGATIVE\n",
      "[649/25000] Most defin -> NEGATIVE\n",
      "[650/25000] This show  -> POSITIVE\n",
      "[651/25000] My childre -> NEGATIVE\n",
      "[652/25000] Normally w -> NEGATIVE\n",
      "[653/25000] I am curre -> NEGATIVE\n",
      "[654/25000] I must adm -> NEGATIVE\n",
      "[655/25000] Wow...<br  -> NEGATIVE\n",
      "[656/25000] Is it poss -> NEGATIVE\n",
      "[657/25000] I honestly -> NEGATIVE\n",
      "[658/25000] After hear -> NEGATIVE\n",
      "[659/25000] Nu Image,  -> NEGATIVE\n",
      "[660/25000] I love mov -> NEGATIVE\n",
      "[661/25000] Finally i  -> NEGATIVE\n",
      "[662/25000] Save the $ -> NEGATIVE\n",
      "[663/25000] I'm not re -> NEGATIVE\n",
      "[664/25000] Holy freak -> NEGATIVE\n",
      "[665/25000] Holy freak -> NEGATIVE\n",
      "[666/25000] If this fi -> NEGATIVE\n",
      "[667/25000] I have jus -> NEGATIVE\n",
      "[668/25000] Well, on i -> NEGATIVE\n",
      "[669/25000] Hines and  -> NEGATIVE\n",
      "[670/25000] Let this s -> NEGATIVE\n",
      "[671/25000] WOW!<br /> -> NEGATIVE\n",
      "[672/25000] Twenty yea -> NEGATIVE\n",
      "[673/25000] Five-year- -> NEGATIVE\n",
      "[674/25000] This movie -> NEGATIVE\n",
      "[675/25000] Those of y -> NEGATIVE\n",
      "[676/25000] A young bo -> NEGATIVE\n",
      "[677/25000] Mike Hawth -> NEGATIVE\n",
      "[678/25000] I have not -> NEGATIVE\n",
      "[679/25000] Before sta -> NEGATIVE\n",
      "[680/25000] i am very  -> NEGATIVE\n",
      "[681/25000] I am reall -> NEGATIVE\n",
      "[682/25000] I am amaze -> NEGATIVE\n",
      "[683/25000] This was a -> NEGATIVE\n",
      "[684/25000] The concep -> NEGATIVE\n",
      "[685/25000] I just did -> NEGATIVE\n",
      "[686/25000] One scene  -> NEGATIVE\n",
      "[687/25000] This film  -> NEGATIVE\n",
      "[688/25000] You may wa -> NEGATIVE\n",
      "[689/25000] This film, -> NEGATIVE\n",
      "[690/25000] The main r -> NEGATIVE\n",
      "[691/25000] It was mea -> NEGATIVE\n",
      "[692/25000] This movie -> NEGATIVE\n",
      "[693/25000] This sound -> NEGATIVE\n",
      "[694/25000] This is a  -> NEGATIVE\n",
      "[695/25000] Can I plea -> NEGATIVE\n",
      "[696/25000] When I sta -> NEGATIVE\n",
      "[697/25000] I'm not su -> NEGATIVE\n",
      "[698/25000] I read Ric -> NEGATIVE\n",
      "[699/25000] This movie -> NEGATIVE\n",
      "[700/25000] The story  -> NEGATIVE\n",
      "[701/25000] \"Feast of  -> NEGATIVE\n",
      "[702/25000] The story  -> NEGATIVE\n",
      "[703/25000] There's so -> NEGATIVE\n",
      "[704/25000] A slick ro -> NEGATIVE\n",
      "[705/25000] College st -> POSITIVE\n",
      "[706/25000] Daphne Zun -> NEGATIVE\n",
      "[707/25000] Over Chris -> NEGATIVE\n",
      "[708/25000] I'm not lo -> NEGATIVE\n",
      "[709/25000] Probably o -> NEGATIVE\n",
      "[710/25000] An uninter -> NEGATIVE\n",
      "[711/25000] The two th -> NEGATIVE\n",
      "[712/25000] Eh, not a  -> NEGATIVE\n",
      "[713/25000] I heard so -> NEGATIVE\n",
      "[714/25000] It's the e -> NEGATIVE\n",
      "[715/25000] ((NB: Spoi -> NEGATIVE\n",
      "[716/25000] One of a m -> NEGATIVE\n",
      "[717/25000] This one p -> NEGATIVE\n",
      "[718/25000] If you've  -> NEGATIVE\n",
      "[719/25000] What the . -> NEGATIVE\n",
      "[720/25000] I've alway -> NEGATIVE\n",
      "[721/25000] I am a big -> NEGATIVE\n",
      "[722/25000] In what wo -> NEGATIVE\n",
      "[723/25000] My wife an -> NEGATIVE\n",
      "[724/25000] Couldn't b -> NEGATIVE\n",
      "[725/25000] Lulu (Loui -> NEGATIVE\n",
      "[726/25000] Please Not -> NEGATIVE\n",
      "[727/25000] This revie -> NEGATIVE\n",
      "[728/25000] I finally  -> POSITIVE\n",
      "[729/25000] This has a -> NEGATIVE\n",
      "[730/25000] All I can  -> POSITIVE\n",
      "[731/25000] I shudder  -> NEGATIVE\n",
      "[732/25000] I wanted t -> NEGATIVE\n",
      "[733/25000] City girl  -> NEGATIVE\n",
      "[734/25000] I have bee -> NEGATIVE\n",
      "[735/25000] ...let me  -> NEGATIVE\n",
      "[736/25000] Prom Night -> NEGATIVE\n",
      "[737/25000] Poor actin -> NEGATIVE\n",
      "[738/25000] Prom Night -> NEGATIVE\n",
      "[739/25000] I am the g -> NEGATIVE\n",
      "[740/25000] So, Prom N -> NEGATIVE\n",
      "[741/25000] When I fir -> NEGATIVE\n",
      "[742/25000] I saw this -> NEGATIVE\n",
      "[743/25000] In Bridgep -> NEGATIVE\n",
      "[744/25000] I'm not pa -> NEGATIVE\n",
      "[745/25000] Imagine th -> NEGATIVE\n",
      "[746/25000] and rent a -> NEGATIVE\n",
      "[747/25000] Okay. So I -> NEGATIVE\n",
      "[748/25000] Good grief -> NEGATIVE\n",
      "[749/25000] This movie -> NEGATIVE\n",
      "[750/25000] I wish I c -> NEGATIVE\n",
      "[751/25000] PROM NIGHT -> NEGATIVE\n",
      "[752/25000] Note: I co -> NEGATIVE\n",
      "[753/25000] I went int -> NEGATIVE\n",
      "[754/25000] \"Prom Nigh -> NEGATIVE\n",
      "[755/25000] If I could -> NEGATIVE\n",
      "[756/25000] I think it -> NEGATIVE\n",
      "[757/25000] I saw this -> NEGATIVE\n",
      "[758/25000] Why Hollyw -> NEGATIVE\n",
      "[759/25000] OK this mo -> NEGATIVE\n",
      "[760/25000] The night  -> NEGATIVE\n",
      "[761/25000] The acting -> NEGATIVE\n",
      "[762/25000] i saw this -> NEGATIVE\n",
      "[763/25000] When I fir -> NEGATIVE\n",
      "[764/25000] We have al -> NEGATIVE\n",
      "[765/25000] I'm a big  -> NEGATIVE\n",
      "[766/25000] First of a -> NEGATIVE\n",
      "[767/25000] In my know -> POSITIVE\n",
      "[768/25000] Chilly, al -> NEGATIVE\n",
      "[769/25000] but \"Cinde -> NEGATIVE\n",
      "[770/25000] Just saw i -> NEGATIVE\n",
      "[771/25000] When I bou -> NEGATIVE\n",
      "[772/25000] (I'll indi -> NEGATIVE\n",
      "[773/25000] Having lov -> NEGATIVE\n",
      "[774/25000] I saw this -> NEGATIVE\n",
      "[775/25000] I've never -> NEGATIVE\n",
      "[776/25000] This was a -> NEGATIVE\n",
      "[777/25000] Following  -> NEGATIVE\n",
      "[778/25000] A few year -> NEGATIVE\n",
      "[779/25000] An antholo -> NEGATIVE\n",
      "[780/25000] New York,  -> NEGATIVE\n",
      "[781/25000] The proble -> NEGATIVE\n",
      "[782/25000] There is a -> POSITIVE\n",
      "[783/25000] Thanks to  -> NEGATIVE\n",
      "[784/25000] Garson Kan -> NEGATIVE\n",
      "[785/25000] Casting bo -> NEGATIVE\n",
      "[786/25000] I can only -> NEGATIVE\n",
      "[787/25000] I was thri -> NEGATIVE\n",
      "[788/25000] Up until t -> NEGATIVE\n",
      "[789/25000] When I sat -> NEGATIVE\n",
      "[790/25000] Long, bori -> NEGATIVE\n",
      "[791/25000] An executi -> NEGATIVE\n",
      "[792/25000] First of a -> NEGATIVE\n",
      "[793/25000] Nicholas W -> NEGATIVE\n",
      "[794/25000] Towards th -> NEGATIVE\n",
      "[795/25000] Where to s -> NEGATIVE\n",
      "[796/25000] Instead, g -> NEGATIVE\n",
      "[797/25000] I had quit -> NEGATIVE\n",
      "[798/25000] \"Plan B\" i -> NEGATIVE\n",
      "[799/25000] I had the  -> NEGATIVE\n",
      "[800/25000] Even thoug -> NEGATIVE\n",
      "[801/25000] I've come  -> NEGATIVE\n",
      "[802/25000] 'Succubus' -> NEGATIVE\n",
      "[803/25000] A disappoi -> NEGATIVE\n",
      "[804/25000] Kubrick me -> NEGATIVE\n",
      "[805/25000] I caught t -> NEGATIVE\n",
      "[806/25000] I hate thi -> NEGATIVE\n",
      "[807/25000] Many King  -> NEGATIVE\n",
      "[808/25000] These writ -> NEGATIVE\n",
      "[809/25000] Not the be -> NEGATIVE\n",
      "[810/25000] Ladies and -> NEGATIVE\n",
      "[811/25000] Ok, honest -> NEGATIVE\n",
      "[812/25000] I am going -> NEGATIVE\n",
      "[813/25000] After just -> NEGATIVE\n",
      "[814/25000] This has g -> NEGATIVE\n",
      "[815/25000] One Star.  -> NEGATIVE\n",
      "[816/25000] OK, If you -> NEGATIVE\n",
      "[817/25000] The movie  -> NEGATIVE\n",
      "[818/25000] This has t -> NEGATIVE\n",
      "[819/25000] It is a pi -> NEGATIVE\n",
      "[820/25000] This has t -> NEGATIVE\n",
      "[821/25000] A BDSM \"su -> NEGATIVE\n",
      "[822/25000] This is no -> NEGATIVE\n",
      "[823/25000] I just wat -> NEGATIVE\n",
      "[824/25000] I agree to -> NEGATIVE\n",
      "[825/25000] The only r -> NEGATIVE\n",
      "[826/25000] [CONTAINS  -> NEGATIVE\n",
      "[827/25000] I saw and  -> NEGATIVE\n",
      "[828/25000] A dedicate -> POSITIVE\n",
      "[829/25000] Having wat -> NEGATIVE\n",
      "[830/25000] I found th -> NEGATIVE\n",
      "[831/25000] There real -> NEGATIVE\n",
      "[832/25000] I give thi -> NEGATIVE\n",
      "[833/25000] Live! Yes, -> NEGATIVE\n",
      "[834/25000] I really d -> NEGATIVE\n",
      "[835/25000] I heard ab -> NEGATIVE\n",
      "[836/25000] Let's see. -> POSITIVE\n",
      "[837/25000] Blazing sa -> NEGATIVE\n",
      "[838/25000] I love the -> NEGATIVE\n",
      "[839/25000] I can't be -> POSITIVE\n",
      "[840/25000] Gene Hackm -> NEGATIVE\n",
      "[841/25000] First, it  -> NEGATIVE\n",
      "[842/25000] There are  -> NEGATIVE\n",
      "[843/25000] Stanley Kr -> POSITIVE\n",
      "[844/25000] What did p -> NEGATIVE\n",
      "[845/25000] \"The Domin -> NEGATIVE\n",
      "[846/25000] This film  -> NEGATIVE\n",
      "[847/25000] \"You're no -> NEGATIVE\n",
      "[848/25000] Back in th -> NEGATIVE\n",
      "[849/25000] I just got -> NEGATIVE\n",
      "[850/25000] This movie -> NEGATIVE\n",
      "[851/25000] The Bigges -> NEGATIVE\n",
      "[852/25000] I am very  -> NEGATIVE\n",
      "[853/25000] The origin -> POSITIVE\n",
      "[854/25000] If you are -> POSITIVE\n",
      "[855/25000] I was expe -> NEGATIVE\n",
      "[856/25000] Extremely  -> NEGATIVE\n",
      "[857/25000] I didn't e -> NEGATIVE\n",
      "[858/25000] This has t -> NEGATIVE\n",
      "[859/25000] Robert Wag -> NEGATIVE\n",
      "[860/25000] I rated th -> NEGATIVE\n",
      "[861/25000] I have rea -> NEGATIVE\n",
      "[862/25000] Like so ma -> NEGATIVE\n",
      "[863/25000] Despite it -> POSITIVE\n",
      "[864/25000] Actually,  -> NEGATIVE\n",
      "[865/25000] In some wa -> NEGATIVE\n",
      "[866/25000] OK, the mo -> POSITIVE\n",
      "[867/25000] I've just  -> NEGATIVE\n",
      "[868/25000] A somewhat -> NEGATIVE\n",
      "[869/25000] When you s -> NEGATIVE\n",
      "[870/25000] Unless you -> NEGATIVE\n",
      "[871/25000] I wasn't s -> NEGATIVE\n",
      "[872/25000] Thanks to  -> NEGATIVE\n",
      "[873/25000] Picture th -> NEGATIVE\n",
      "[874/25000] Here is wh -> NEGATIVE\n",
      "[875/25000] five minut -> NEGATIVE\n",
      "[876/25000] A film wit -> NEGATIVE\n",
      "[877/25000] as an insp -> POSITIVE\n",
      "[878/25000] I saw this -> POSITIVE\n",
      "[879/25000] This ludic -> NEGATIVE\n",
      "[880/25000] Despite po -> NEGATIVE\n",
      "[881/25000] I watched  -> NEGATIVE\n",
      "[882/25000] Outside of -> NEGATIVE\n",
      "[883/25000] This show  -> NEGATIVE\n",
      "[884/25000] This show  -> NEGATIVE\n",
      "[885/25000] Seriously, -> NEGATIVE\n",
      "[886/25000] What has I -> NEGATIVE\n",
      "[887/25000] I can not  -> NEGATIVE\n",
      "[888/25000] I remember -> NEGATIVE\n",
      "[889/25000] John Candy -> POSITIVE\n",
      "[890/25000] This movie -> NEGATIVE\n",
      "[891/25000] No, not th -> NEGATIVE\n",
      "[892/25000] This movie -> NEGATIVE\n",
      "[893/25000] Although t -> NEGATIVE\n",
      "[894/25000] The strang -> NEGATIVE\n",
      "[895/25000] The major  -> NEGATIVE\n",
      "[896/25000] I agree wi -> NEGATIVE\n",
      "[897/25000] LL Cool J  -> NEGATIVE\n",
      "[898/25000] Beginning  -> NEGATIVE\n",
      "[899/25000] The movie  -> NEGATIVE\n",
      "[900/25000] Lets enter -> NEGATIVE\n",
      "[901/25000] Honestly b -> NEGATIVE\n",
      "[902/25000] There is a -> NEGATIVE\n",
      "[903/25000] Oh dear go -> NEGATIVE\n",
      "[904/25000] The movie  -> NEGATIVE\n",
      "[905/25000] Pathetic.. -> NEGATIVE\n",
      "[906/25000] Timberlake -> NEGATIVE\n",
      "[907/25000] If you wat -> NEGATIVE\n",
      "[908/25000] How can th -> NEGATIVE\n",
      "[909/25000] LL Cool J. -> NEGATIVE\n",
      "[910/25000] I rented t -> NEGATIVE\n",
      "[911/25000] *** REVIEW -> NEGATIVE\n",
      "[912/25000] The plot o -> NEGATIVE\n",
      "[913/25000] I found it -> NEGATIVE\n",
      "[914/25000] OK so I he -> NEGATIVE\n",
      "[915/25000] When you g -> POSITIVE\n",
      "[916/25000] Jewish new -> NEGATIVE\n",
      "[917/25000] OK, I am n -> NEGATIVE\n",
      "[918/25000] I don't wa -> NEGATIVE\n",
      "[919/25000] I rented t -> NEGATIVE\n",
      "[920/25000] The plot f -> NEGATIVE\n",
      "[921/25000] I saw 'Des -> NEGATIVE\n",
      "[922/25000] It's prett -> NEGATIVE\n",
      "[923/25000] Having jus -> NEGATIVE\n",
      "[924/25000] Revenge is -> NEGATIVE\n",
      "[925/25000] Rosario Da -> NEGATIVE\n",
      "[926/25000] This movie -> NEGATIVE\n",
      "[927/25000] I'm going  -> NEGATIVE\n",
      "[928/25000] This movie -> NEGATIVE\n",
      "[929/25000] If you wan -> NEGATIVE\n",
      "[930/25000] Do not was -> NEGATIVE\n",
      "[931/25000] Okay so i  -> NEGATIVE\n",
      "[932/25000] This movie -> NEGATIVE\n",
      "[933/25000] You know a -> NEGATIVE\n",
      "[934/25000] This movie -> NEGATIVE\n",
      "[935/25000] 'Dead Lett -> NEGATIVE\n",
      "[936/25000] This pictu -> NEGATIVE\n",
      "[937/25000] When Marle -> NEGATIVE\n",
      "[938/25000] The real s -> NEGATIVE\n",
      "[939/25000] As a great -> NEGATIVE\n",
      "[940/25000] My first f -> NEGATIVE\n",
      "[941/25000] Anyone who -> NEGATIVE\n",
      "[942/25000] I watched  -> NEGATIVE\n",
      "[943/25000] \"Fever Pit -> NEGATIVE\n",
      "[944/25000] I am gener -> NEGATIVE\n",
      "[945/25000] I saw this -> POSITIVE\n",
      "[946/25000] This movie -> NEGATIVE\n",
      "[947/25000] This typic -> NEGATIVE\n",
      "[948/25000] This was a -> NEGATIVE\n",
      "[949/25000] After read -> NEGATIVE\n",
      "[950/25000] normally i -> POSITIVE\n",
      "[951/25000] I was root -> NEGATIVE\n",
      "[952/25000] An intrigu -> NEGATIVE\n",
      "[953/25000] In 1988, P -> NEGATIVE\n",
      "[954/25000] Films star -> NEGATIVE\n",
      "[955/25000] First I li -> NEGATIVE\n",
      "[956/25000] Predictabl -> POSITIVE\n",
      "[957/25000] 'Chances A -> NEGATIVE\n",
      "[958/25000] Chances ar -> NEGATIVE\n",
      "[959/25000] Silly, sim -> NEGATIVE\n",
      "[960/25000] Oh dear. I -> POSITIVE\n",
      "[961/25000] i would ha -> NEGATIVE\n",
      "[962/25000] How did th -> NEGATIVE\n",
      "[963/25000] So, I got  -> NEGATIVE\n",
      "[964/25000] It's amazi -> NEGATIVE\n",
      "[965/25000] I don't th -> POSITIVE\n",
      "[966/25000] The oddly- -> NEGATIVE\n",
      "[967/25000] \"Happy Go  -> NEGATIVE\n",
      "[968/25000] Happy Go L -> NEGATIVE\n",
      "[969/25000] *** May co -> NEGATIVE\n",
      "[970/25000] I caught t -> NEGATIVE\n",
      "[971/25000] I have nev -> NEGATIVE\n",
      "[972/25000] I've tried -> NEGATIVE\n",
      "[973/25000] As someone -> NEGATIVE\n",
      "[974/25000] Why is thi -> NEGATIVE\n",
      "[975/25000] The Invisi -> NEGATIVE\n",
      "[976/25000] Take one l -> POSITIVE\n",
      "[977/25000] Here's an  -> NEGATIVE\n",
      "[978/25000] Saw this l -> NEGATIVE\n",
      "[979/25000] This movie -> NEGATIVE\n",
      "[980/25000] Okay guys, -> NEGATIVE\n",
      "[981/25000] I loved th -> NEGATIVE\n",
      "[982/25000] I may not  -> NEGATIVE\n",
      "[983/25000] How sheep- -> NEGATIVE\n",
      "[984/25000] I don't un -> POSITIVE\n",
      "[985/25000] Users who  -> NEGATIVE\n",
      "[986/25000] Macy, Ullm -> NEGATIVE\n",
      "[987/25000] Undevelope -> NEGATIVE\n",
      "[988/25000] I watched  -> NEGATIVE\n",
      "[989/25000] I cannot b -> NEGATIVE\n",
      "[990/25000] Some kids  -> NEGATIVE\n",
      "[991/25000] My wife an -> POSITIVE\n",
      "[992/25000] This movie -> NEGATIVE\n",
      "[993/25000] I mean rea -> NEGATIVE\n",
      "[994/25000] This movie -> NEGATIVE\n",
      "[995/25000] okay, this -> POSITIVE\n",
      "[996/25000] WARNING SP -> NEGATIVE\n",
      "[997/25000] For some r -> NEGATIVE\n",
      "[998/25000] This film  -> NEGATIVE\n",
      "[999/25000] I rented t -> NEGATIVE\n",
      "[1000/25000] Seriously. -> NEGATIVE\n",
      "[1001/25000] Although I -> NEGATIVE\n",
      "[1002/25000] When Georg -> NEGATIVE\n",
      "[1003/25000] This Film  -> NEGATIVE\n",
      "[1004/25000] Lauren Bac -> NEGATIVE\n",
      "[1005/25000] Yet anothe -> NEGATIVE\n",
      "[1006/25000] (Review in -> NEGATIVE\n",
      "[1007/25000] OK now, le -> NEGATIVE\n",
      "[1008/25000] ...for one -> NEGATIVE\n",
      "[1009/25000] This must  -> NEGATIVE\n",
      "[1010/25000] The story  -> POSITIVE\n",
      "[1011/25000] dont ever  -> NEGATIVE\n",
      "[1012/25000] After buyi -> NEGATIVE\n",
      "[1013/25000] I wrote a  -> NEGATIVE\n",
      "[1014/25000] Yes, this  -> NEGATIVE\n",
      "[1015/25000] An unmarri -> NEGATIVE\n",
      "[1016/25000] \"Stella\",  -> POSITIVE\n",
      "[1017/25000] 1937's \"St -> NEGATIVE\n",
      "[1018/25000] I suppose  -> NEGATIVE\n",
      "[1019/25000] Sophia Lor -> NEGATIVE\n",
      "[1020/25000] ...and not -> NEGATIVE\n",
      "[1021/25000] On the 199 -> NEGATIVE\n",
      "[1022/25000] Eddie Murp -> NEGATIVE\n",
      "[1023/25000] Two years  -> NEGATIVE\n",
      "[1024/25000] This film  -> POSITIVE\n",
      "[1025/25000] This movie -> NEGATIVE\n",
      "[1026/25000] Although t -> NEGATIVE\n",
      "[1027/25000] THE FBI ST -> NEGATIVE\n",
      "[1028/25000] Pedantic,  -> NEGATIVE\n",
      "[1029/25000] This film  -> NEGATIVE\n",
      "[1030/25000] This movie -> POSITIVE\n",
      "[1031/25000] Not much t -> NEGATIVE\n",
      "[1032/25000] Recap: Doc -> NEGATIVE\n",
      "[1033/25000] Even 20+ y -> NEGATIVE\n",
      "[1034/25000] You've bee -> NEGATIVE\n",
      "[1035/25000] Having low -> NEGATIVE\n",
      "[1036/25000] Scary, but -> NEGATIVE\n",
      "[1037/25000] Please not -> NEGATIVE\n",
      "[1038/25000] This was a -> NEGATIVE\n",
      "[1039/25000] I tried tw -> NEGATIVE\n",
      "[1040/25000] Every movi -> NEGATIVE\n",
      "[1041/25000] I haven't  -> NEGATIVE\n",
      "[1042/25000] As a Dane  -> NEGATIVE\n",
      "[1043/25000] I have see -> NEGATIVE\n",
      "[1044/25000] The point  -> NEGATIVE\n",
      "[1045/25000] A shame th -> NEGATIVE\n",
      "[1046/25000] Overlong d -> NEGATIVE\n",
      "[1047/25000] I've seen  -> NEGATIVE\n",
      "[1048/25000] This movie -> NEGATIVE\n",
      "[1049/25000] Boring and -> NEGATIVE\n",
      "[1050/25000] I rented t -> NEGATIVE\n",
      "[1051/25000] I went to  -> NEGATIVE\n",
      "[1052/25000] The openin -> NEGATIVE\n",
      "[1053/25000] I didn't k -> POSITIVE\n",
      "[1054/25000] The acting -> NEGATIVE\n",
      "[1055/25000] Within the -> NEGATIVE\n",
      "[1056/25000] I saw this -> NEGATIVE\n",
      "[1057/25000] Even if th -> NEGATIVE\n",
      "[1058/25000] I was real -> NEGATIVE\n",
      "[1059/25000] I don't kn -> NEGATIVE\n",
      "[1060/25000] This movie -> NEGATIVE\n",
      "[1061/25000] We saw thi -> NEGATIVE\n",
      "[1062/25000] In this da -> NEGATIVE\n",
      "[1063/25000] Hopalong C -> NEGATIVE\n",
      "[1064/25000] I enjoy wa -> NEGATIVE\n",
      "[1065/25000] The closin -> NEGATIVE\n",
      "[1066/25000] One hour,  -> NEGATIVE\n",
      "[1067/25000] This is al -> NEGATIVE\n",
      "[1068/25000] A dreary a -> NEGATIVE\n",
      "[1069/25000] I read the -> NEGATIVE\n",
      "[1070/25000] Don't wast -> NEGATIVE\n",
      "[1071/25000] Oh my. How -> NEGATIVE\n",
      "[1072/25000] This is on -> NEGATIVE\n",
      "[1073/25000] As a young -> NEGATIVE\n",
      "[1074/25000] First off, -> NEGATIVE\n",
      "[1075/25000] This bogus -> NEGATIVE\n",
      "[1076/25000] Since most -> NEGATIVE\n",
      "[1077/25000] I was shoc -> NEGATIVE\n",
      "[1078/25000] I got this -> NEGATIVE\n",
      "[1079/25000] I realise  -> NEGATIVE\n",
      "[1080/25000] While some -> NEGATIVE\n",
      "[1081/25000] I watched  -> NEGATIVE\n",
      "[1082/25000] Hard to de -> POSITIVE\n",
      "[1083/25000] Kitten Nat -> NEGATIVE\n",
      "[1084/25000] Well, I su -> NEGATIVE\n",
      "[1085/25000] Dreary. Sc -> NEGATIVE\n",
      "[1086/25000] this was t -> NEGATIVE\n",
      "[1087/25000] What's up  -> NEGATIVE\n",
      "[1088/25000] Rarely hav -> NEGATIVE\n",
      "[1089/25000] This is on -> NEGATIVE\n",
      "[1090/25000] In spite o -> NEGATIVE\n",
      "[1091/25000] Did anyone -> NEGATIVE\n",
      "[1092/25000] I rented t -> NEGATIVE\n",
      "[1093/25000] This movie -> NEGATIVE\n",
      "[1094/25000] I think I' -> NEGATIVE\n",
      "[1095/25000] There is n -> NEGATIVE\n",
      "[1096/25000] How a dire -> NEGATIVE\n",
      "[1097/25000] I feel lik -> NEGATIVE\n",
      "[1098/25000] Divorced l -> NEGATIVE\n",
      "[1099/25000] Have you e -> NEGATIVE\n",
      "[1100/25000] This was o -> NEGATIVE\n",
      "[1101/25000] The only t -> NEGATIVE\n",
      "[1102/25000] I should n -> NEGATIVE\n",
      "[1103/25000] I can't be -> NEGATIVE\n",
      "[1104/25000] The first  -> NEGATIVE\n",
      "[1105/25000] A very wea -> NEGATIVE\n",
      "[1106/25000] I have see -> NEGATIVE\n",
      "[1107/25000] I saw this -> POSITIVE\n",
      "[1108/25000] My wife an -> NEGATIVE\n",
      "[1109/25000] Only a han -> NEGATIVE\n",
      "[1110/25000] I saw \"Par -> NEGATIVE\n",
      "[1111/25000] Based upon -> NEGATIVE\n",
      "[1112/25000] be warned: -> NEGATIVE\n",
      "[1113/25000] The idea i -> NEGATIVE\n",
      "[1114/25000] Ouch! This -> POSITIVE\n",
      "[1115/25000] In its dep -> NEGATIVE\n",
      "[1116/25000] OK, so it  -> NEGATIVE\n",
      "[1117/25000] I watched  -> NEGATIVE\n",
      "[1118/25000] No Firewor -> NEGATIVE\n",
      "[1119/25000] I'm sorry, -> NEGATIVE\n",
      "[1120/25000] Diana Guzm -> POSITIVE\n",
      "[1121/25000] *Spoiler w -> NEGATIVE\n",
      "[1122/25000] Rural fami -> NEGATIVE\n",
      "[1123/25000] Bizarre ta -> POSITIVE\n",
      "[1124/25000] *****THIS  -> NEGATIVE\n",
      "[1125/25000] Though Fra -> NEGATIVE\n",
      "[1126/25000] Nathan Det -> NEGATIVE\n",
      "[1127/25000] This movie -> NEGATIVE\n",
      "[1128/25000] Raising Vi -> POSITIVE\n",
      "[1129/25000] Someone wi -> NEGATIVE\n",
      "[1130/25000] .... this  -> NEGATIVE\n",
      "[1131/25000] Raising Vi -> NEGATIVE\n",
      "[1132/25000] \"Raising V -> NEGATIVE\n",
      "[1133/25000] What a bad -> NEGATIVE\n",
      "[1134/25000] First of a -> NEGATIVE\n",
      "[1135/25000] How many m -> NEGATIVE\n",
      "[1136/25000] I can't be -> NEGATIVE\n",
      "[1137/25000] This \"film -> NEGATIVE\n",
      "[1138/25000] Raising vi -> NEGATIVE\n",
      "[1139/25000] That this  -> NEGATIVE\n",
      "[1140/25000] Ho-hum. An -> NEGATIVE\n",
      "[1141/25000] Horrible a -> NEGATIVE\n",
      "[1142/25000] After the  -> NEGATIVE\n",
      "[1143/25000] I grew up  -> NEGATIVE\n",
      "[1144/25000] While I ha -> NEGATIVE\n",
      "[1145/25000] This movie -> NEGATIVE\n",
      "[1146/25000] I don't un -> NEGATIVE\n",
      "[1147/25000] My dad is  -> NEGATIVE\n",
      "[1148/25000] I don't re -> NEGATIVE\n",
      "[1149/25000] Normally,  -> NEGATIVE\n",
      "[1150/25000] Wow. I do  -> NEGATIVE\n",
      "[1151/25000] That is th -> NEGATIVE\n",
      "[1152/25000] i saw this -> NEGATIVE\n",
      "[1153/25000] Three tale -> NEGATIVE\n",
      "[1154/25000] Imagine a  -> NEGATIVE\n",
      "[1155/25000] This movie -> NEGATIVE\n",
      "[1156/25000] This is th -> NEGATIVE\n",
      "[1157/25000] This is a  -> NEGATIVE\n",
      "[1158/25000] This shoul -> NEGATIVE\n",
      "[1159/25000] I have two -> NEGATIVE\n",
      "[1160/25000] Did anyone -> NEGATIVE\n",
      "[1161/25000] This movie -> NEGATIVE\n",
      "[1162/25000] Herculis P -> NEGATIVE\n",
      "[1163/25000] This serie -> NEGATIVE\n",
      "[1164/25000] Oh what a  -> NEGATIVE\n",
      "[1165/25000] Why me? Wh -> POSITIVE\n",
      "[1166/25000] If there i -> NEGATIVE\n",
      "[1167/25000] I first di -> NEGATIVE\n",
      "[1168/25000] This movie -> NEGATIVE\n",
      "[1169/25000] There's no -> POSITIVE\n",
      "[1170/25000] This film  -> NEGATIVE\n",
      "[1171/25000] I'm a Jean -> POSITIVE\n",
      "[1172/25000] Yes, CHUNK -> NEGATIVE\n",
      "[1173/25000] Thank you  -> NEGATIVE\n",
      "[1174/25000] Warning: S -> NEGATIVE\n",
      "[1175/25000] If there's -> NEGATIVE\n",
      "[1176/25000] This film  -> NEGATIVE\n",
      "[1177/25000] The acting -> NEGATIVE\n",
      "[1178/25000] I have see -> NEGATIVE\n",
      "[1179/25000] I read som -> NEGATIVE\n",
      "[1180/25000] After look -> POSITIVE\n",
      "[1181/25000] Apart from -> NEGATIVE\n",
      "[1182/25000] I have to  -> NEGATIVE\n",
      "[1183/25000] What a dis -> NEGATIVE\n",
      "[1184/25000] This film  -> NEGATIVE\n",
      "[1185/25000] Not good!  -> NEGATIVE\n",
      "[1186/25000] Spoilers I -> NEGATIVE\n",
      "[1187/25000] Absolutely -> NEGATIVE\n",
      "[1188/25000] This is a  -> NEGATIVE\n",
      "[1189/25000] This movie -> NEGATIVE\n",
      "[1190/25000] while watc -> NEGATIVE\n",
      "[1191/25000] This is th -> NEGATIVE\n",
      "[1192/25000] I think ev -> NEGATIVE\n",
      "[1193/25000] Being a bi -> NEGATIVE\n",
      "[1194/25000] This Tim B -> NEGATIVE\n",
      "[1195/25000] I had VERY -> NEGATIVE\n",
      "[1196/25000] What ever  -> NEGATIVE\n",
      "[1197/25000] I really l -> NEGATIVE\n",
      "[1198/25000] Well, it t -> POSITIVE\n",
      "[1199/25000] Oh my god. -> NEGATIVE\n",
      "[1200/25000] It says th -> NEGATIVE\n",
      "[1201/25000] Della Myer -> NEGATIVE\n",
      "[1202/25000] Words can' -> NEGATIVE\n",
      "[1203/25000] Sorry, but -> NEGATIVE\n",
      "[1204/25000] Wow. Rarel -> NEGATIVE\n",
      "[1205/25000] Even thoug -> NEGATIVE\n",
      "[1206/25000] My, how th -> NEGATIVE\n",
      "[1207/25000] Well, let  -> POSITIVE\n",
      "[1208/25000] Who in the -> NEGATIVE\n",
      "[1209/25000] What a wee -> NEGATIVE\n",
      "[1210/25000] This is on -> NEGATIVE\n",
      "[1211/25000] I remember -> NEGATIVE\n",
      "[1212/25000] She may ha -> NEGATIVE\n",
      "[1213/25000] First of a -> NEGATIVE\n",
      "[1214/25000] So this is -> NEGATIVE\n",
      "[1215/25000] Its Christ -> NEGATIVE\n",
      "[1216/25000] The genre  -> NEGATIVE\n",
      "[1217/25000] I don't of -> NEGATIVE\n",
      "[1218/25000] A friend o -> NEGATIVE\n",
      "[1219/25000] I can't be -> NEGATIVE\n",
      "[1220/25000] Overall th -> NEGATIVE\n",
      "[1221/25000] The only r -> NEGATIVE\n",
      "[1222/25000] Where to s -> NEGATIVE\n",
      "[1223/25000] FAIL. I'd  -> NEGATIVE\n",
      "[1224/25000] OK, if you -> NEGATIVE\n",
      "[1225/25000] Kim Basing -> POSITIVE\n",
      "[1226/25000] This thoug -> NEGATIVE\n",
      "[1227/25000] What's thi -> NEGATIVE\n",
      "[1228/25000] I remember -> POSITIVE\n",
      "[1229/25000] The concep -> NEGATIVE\n",
      "[1230/25000] A dog foun -> NEGATIVE\n",
      "[1231/25000] Devil Dog  -> POSITIVE\n",
      "[1232/25000] VERY dull, -> NEGATIVE\n",
      "[1233/25000] This horro -> NEGATIVE\n",
      "[1234/25000] Amy Poehle -> NEGATIVE\n",
      "[1235/25000] They reall -> NEGATIVE\n",
      "[1236/25000] How can a  -> NEGATIVE\n",
      "[1237/25000] This is th -> NEGATIVE\n",
      "[1238/25000] I have see -> NEGATIVE\n",
      "[1239/25000] You know h -> NEGATIVE\n",
      "[1240/25000] i complete -> NEGATIVE\n",
      "[1241/25000] I'm a big  -> NEGATIVE\n",
      "[1242/25000] Weak Bobby -> NEGATIVE\n",
      "[1243/25000] The show's -> NEGATIVE\n",
      "[1244/25000] Kurosawa r -> NEGATIVE\n",
      "[1245/25000] Nope, I am -> NEGATIVE\n",
      "[1246/25000] Walerian B -> NEGATIVE\n",
      "[1247/25000] Another va -> POSITIVE\n",
      "[1248/25000] this movie -> NEGATIVE\n",
      "[1249/25000] This, and  -> NEGATIVE\n",
      "[1250/25000] This movie -> NEGATIVE\n",
      "[1251/25000] this film  -> NEGATIVE\n",
      "[1252/25000] Notorious  -> NEGATIVE\n",
      "[1253/25000] Unreal \"mo -> NEGATIVE\n",
      "[1254/25000] Completely -> NEGATIVE\n",
      "[1255/25000] This Movie -> NEGATIVE\n",
      "[1256/25000] Revolution -> NEGATIVE\n",
      "[1257/25000] Much has b -> NEGATIVE\n",
      "[1258/25000] Eric Rohme -> NEGATIVE\n",
      "[1259/25000] If I only  -> NEGATIVE\n",
      "[1260/25000] Every so o -> NEGATIVE\n",
      "[1261/25000] I can hard -> NEGATIVE\n",
      "[1262/25000] As a fan o -> NEGATIVE\n",
      "[1263/25000] As interes -> NEGATIVE\n",
      "[1264/25000] I've seen  -> NEGATIVE\n",
      "[1265/25000] I really t -> NEGATIVE\n",
      "[1266/25000] Having see -> NEGATIVE\n",
      "[1267/25000] I'll keep  -> NEGATIVE\n",
      "[1268/25000] I don't kn -> NEGATIVE\n",
      "[1269/25000] Fashionabl -> NEGATIVE\n",
      "[1270/25000] I went to  -> NEGATIVE\n",
      "[1271/25000] As a membe -> NEGATIVE\n",
      "[1272/25000] This has g -> NEGATIVE\n",
      "[1273/25000] Some movie -> NEGATIVE\n",
      "[1274/25000] Tenants Tw -> NEGATIVE\n",
      "[1275/25000] I ended up -> POSITIVE\n",
      "[1276/25000] Watching T -> NEGATIVE\n",
      "[1277/25000] never befo -> NEGATIVE\n",
      "[1278/25000] May (Anne  -> POSITIVE\n",
      "[1279/25000] Disappoint -> NEGATIVE\n",
      "[1280/25000] I understa -> NEGATIVE\n",
      "[1281/25000] After Life -> NEGATIVE\n",
      "[1282/25000] This \"movi -> NEGATIVE\n",
      "[1283/25000] \"A Damsel  -> NEGATIVE\n",
      "[1284/25000] Arthur Ask -> NEGATIVE\n",
      "[1285/25000] An absolut -> NEGATIVE\n",
      "[1286/25000] Dynasty Re -> NEGATIVE\n",
      "[1287/25000] Someone me -> NEGATIVE\n",
      "[1288/25000] Oh, my gos -> NEGATIVE\n",
      "[1289/25000] Ouch, what -> NEGATIVE\n",
      "[1290/25000] I bought t -> NEGATIVE\n",
      "[1291/25000] Let's see, -> NEGATIVE\n",
      "[1292/25000] This film  -> NEGATIVE\n",
      "[1293/25000] You know y -> NEGATIVE\n",
      "[1294/25000] \"The Brain -> NEGATIVE\n",
      "[1295/25000] I thought  -> NEGATIVE\n",
      "[1296/25000] \"Grey Matt -> NEGATIVE\n",
      "[1297/25000] Before thi -> NEGATIVE\n",
      "[1298/25000] I'm a big  -> NEGATIVE\n",
      "[1299/25000] I was very -> NEGATIVE\n",
      "[1300/25000] Went to se -> NEGATIVE\n",
      "[1301/25000] It's hard  -> NEGATIVE\n",
      "[1302/25000] I rated th -> NEGATIVE\n",
      "[1303/25000] \"Hak Hap\", -> NEGATIVE\n",
      "[1304/25000] Jet Li, is -> NEGATIVE\n",
      "[1305/25000] Lame, clic -> NEGATIVE\n",
      "[1306/25000] The movie  -> NEGATIVE\n",
      "[1307/25000] Mild SPOIL -> NEGATIVE\n",
      "[1308/25000] This was t -> NEGATIVE\n",
      "[1309/25000] Monika Mit -> NEGATIVE\n",
      "[1310/25000] It's like  -> NEGATIVE\n",
      "[1311/25000] The volley -> POSITIVE\n",
      "[1312/25000] Of all mov -> NEGATIVE\n",
      "[1313/25000] This movie -> NEGATIVE\n",
      "[1314/25000] Man, this  -> NEGATIVE\n",
      "[1315/25000] This was o -> NEGATIVE\n",
      "[1316/25000] Saw this o -> NEGATIVE\n",
      "[1317/25000] I can't fi -> NEGATIVE\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 22\u001B[0m\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcurrent\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtotal\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtext[:\u001B[38;5;241m10\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m -> \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mid2label[predicted_class_id]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mid2label[predicted_class_id]\n\u001B[0;32m---> 22\u001B[0m imdb_dataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msentiment_bert\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mimdb_dataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtext\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mget_bert_sentiment\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mmap({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNEGATIVE\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPOSITIVE\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m1\u001B[39m})\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/pandas/core/series.py:4924\u001B[0m, in \u001B[0;36mSeries.apply\u001B[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001B[0m\n\u001B[1;32m   4789\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[1;32m   4790\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   4791\u001B[0m     func: AggFuncType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4796\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   4797\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[1;32m   4798\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4799\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[1;32m   4800\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4915\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[1;32m   4916\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m   4917\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   4918\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4919\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4920\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4921\u001B[0m \u001B[43m        \u001B[49m\u001B[43mby_row\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mby_row\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4922\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4923\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m-> 4924\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1424\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_compat()\n\u001B[1;32m   1426\u001B[0m \u001B[38;5;66;03m# self.func is Callable\u001B[39;00m\n\u001B[0;32m-> 1427\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1501\u001B[0m \u001B[38;5;66;03m# row-wise access\u001B[39;00m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m \u001B[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001B[39;00m\n\u001B[1;32m   1504\u001B[0m \u001B[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001B[39;00m\n\u001B[1;32m   1505\u001B[0m \u001B[38;5;66;03m#  Categorical (GH51645).\u001B[39;00m\n\u001B[1;32m   1506\u001B[0m action \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj\u001B[38;5;241m.\u001B[39mdtype, CategoricalDtype) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1507\u001B[0m mapped \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1508\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmapper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcurried\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\n\u001B[1;32m   1509\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[1;32m   1512\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[1;32m   1513\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[1;32m   1514\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/pandas/core/base.py:921\u001B[0m, in \u001B[0;36mIndexOpsMixin._map_values\u001B[0;34m(self, mapper, na_action, convert)\u001B[0m\n\u001B[1;32m    918\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[1;32m    919\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mmap(mapper, na_action\u001B[38;5;241m=\u001B[39mna_action)\n\u001B[0;32m--> 921\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malgorithms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001B[0m, in \u001B[0;36mmap_array\u001B[0;34m(arr, mapper, na_action, convert)\u001B[0m\n\u001B[1;32m   1741\u001B[0m values \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1743\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1745\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mmap_infer_mask(\n\u001B[1;32m   1746\u001B[0m         values, mapper, mask\u001B[38;5;241m=\u001B[39misna(values)\u001B[38;5;241m.\u001B[39mview(np\u001B[38;5;241m.\u001B[39muint8), convert\u001B[38;5;241m=\u001B[39mconvert\n\u001B[1;32m   1747\u001B[0m     )\n",
      "File \u001B[0;32mlib.pyx:2972\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[0;34m()\u001B[0m\n",
      "Cell \u001B[0;32mIn[14], line 16\u001B[0m, in \u001B[0;36mget_bert_sentiment\u001B[0;34m(text)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m     15\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m {name: tensor\u001B[38;5;241m.\u001B[39mto(device) \u001B[38;5;28;01mfor\u001B[39;00m name, tensor \u001B[38;5;129;01min\u001B[39;00m inputs\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[0;32m---> 16\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mlogits\n\u001B[1;32m     17\u001B[0m predicted_class_id \u001B[38;5;241m=\u001B[39m logits\u001B[38;5;241m.\u001B[39margmax()\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcurrent\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtotal\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtext[:\u001B[38;5;241m10\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m -> \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mid2label[predicted_class_id]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:990\u001B[0m, in \u001B[0;36mDistilBertForSequenceClassification.forward\u001B[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    982\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    983\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001B[39;00m\n\u001B[1;32m    984\u001B[0m \u001B[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001B[39;00m\n\u001B[1;32m    985\u001B[0m \u001B[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001B[39;00m\n\u001B[1;32m    986\u001B[0m \u001B[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001B[39;00m\n\u001B[1;32m    987\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    988\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[0;32m--> 990\u001B[0m distilbert_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistilbert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    991\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    992\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    993\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    994\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    995\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    996\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    997\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    998\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    999\u001B[0m hidden_state \u001B[38;5;241m=\u001B[39m distilbert_output[\u001B[38;5;241m0\u001B[39m]  \u001B[38;5;66;03m# (bs, seq_len, dim)\u001B[39;00m\n\u001B[1;32m   1000\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m hidden_state[:, \u001B[38;5;241m0\u001B[39m]  \u001B[38;5;66;03m# (bs, dim)\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:810\u001B[0m, in \u001B[0;36mDistilBertModel.forward\u001B[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    807\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    808\u001B[0m         attention_mask \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mones(input_shape, device\u001B[38;5;241m=\u001B[39mdevice)  \u001B[38;5;66;03m# (bs, seq_length)\u001B[39;00m\n\u001B[0;32m--> 810\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    811\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    812\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattn_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    813\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    814\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    815\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    816\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    817\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:571\u001B[0m, in \u001B[0;36mTransformer.forward\u001B[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    563\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[1;32m    564\u001B[0m         layer_module\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[1;32m    565\u001B[0m         hidden_state,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    568\u001B[0m         output_attentions,\n\u001B[1;32m    569\u001B[0m     )\n\u001B[1;32m    570\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 571\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    572\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    573\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattn_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    574\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    575\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    576\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    578\u001B[0m hidden_state \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    580\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m output_attentions:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:516\u001B[0m, in \u001B[0;36mTransformerBlock.forward\u001B[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001B[0m\n\u001B[1;32m    514\u001B[0m \u001B[38;5;66;03m# Feed Forward Network\u001B[39;00m\n\u001B[1;32m    515\u001B[0m ffn_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mffn(sa_output)  \u001B[38;5;66;03m# (bs, seq_length, dim)\u001B[39;00m\n\u001B[0;32m--> 516\u001B[0m ffn_output: torch\u001B[38;5;241m.\u001B[39mTensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput_layer_norm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mffn_output\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43msa_output\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# (bs, seq_length, dim)\u001B[39;00m\n\u001B[1;32m    518\u001B[0m output \u001B[38;5;241m=\u001B[39m (ffn_output,)\n\u001B[1;32m    519\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m output_attentions:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/torch/nn/modules/normalization.py:202\u001B[0m, in \u001B[0;36mLayerNorm.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    201\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 202\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    203\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnormalized_shape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/torch/nn/functional.py:2576\u001B[0m, in \u001B[0;36mlayer_norm\u001B[0;34m(input, normalized_shape, weight, bias, eps)\u001B[0m\n\u001B[1;32m   2572\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_variadic(\u001B[38;5;28minput\u001B[39m, weight, bias):\n\u001B[1;32m   2573\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m   2574\u001B[0m         layer_norm, (\u001B[38;5;28minput\u001B[39m, weight, bias), \u001B[38;5;28minput\u001B[39m, normalized_shape, weight\u001B[38;5;241m=\u001B[39mweight, bias\u001B[38;5;241m=\u001B[39mbias, eps\u001B[38;5;241m=\u001B[39meps\n\u001B[1;32m   2575\u001B[0m     )\n\u001B[0;32m-> 2576\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer_norm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormalized_shape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackends\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcudnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menabled\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 14,
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "total = len(imdb_dataset)\n",
    "\n",
    "def get_bert_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        inputs = {name: tensor.to(device) for name, tensor in inputs.items()}\n",
    "        logits = model(**inputs).logits\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    \n",
    "    print(f\"[{current}/{total}] {text[:10]} -> {model.config.id2label[predicted_class_id]}\")\n",
    "    return model.config.id2label[predicted_class_id]\n",
    "\n",
    "imdb_dataset['sentiment_bert'] = imdb_dataset['text'].apply(get_bert_sentiment).map({'NEGATIVE': 0, 'POSITIVE': 1})"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 51,
   "source": [
    "#drop df to csv\n",
    "imdb_dataset.to_csv('imdb_dataset.csv')"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T14:46:28.701327Z",
     "start_time": "2024-10-10T14:46:28.434381Z"
    }
   },
   "cell_type": "code",
   "source": "imdb_dataset = pd.read_csv('imdb_dataset.csv')",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T14:46:29.976539Z",
     "start_time": "2024-10-10T14:46:29.944196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "f1_bert = f1_score(imdb_dataset['label'], imdb_dataset['sentiment_bert'])\n",
    "accuracy_bert = accuracy_score(imdb_dataset['label'], imdb_dataset['sentiment_bert'])\n",
    "precision_bert = precision_score(imdb_dataset['label'], imdb_dataset['sentiment_bert'])\n",
    "recall_bert = recall_score(imdb_dataset['label'], imdb_dataset['sentiment_bert'])\n",
    "\n",
    "model_scores = pd.concat([model_scores, pd.DataFrame([[\"distilbert-base-uncased-finetuned-sst-2-english\", f1_bert, accuracy_bert, precision_bert, recall_bert]], columns=[\"model\", \"f1\", \"accuracy\", \"precision\", \"recall\"])])\n",
    "\n",
    "model_scores"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                             model        f1  accuracy  \\\n",
       "0                                         TextBlob  0.750198   0.68516   \n",
       "0  distilbert-base-uncased-finetuned-sst-2-english  0.884697   0.88852   \n",
       "\n",
       "   precision   recall  \n",
       "0   0.621758  0.94552  \n",
       "0   0.916117  0.85536  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TextBlob</td>\n",
       "      <td>0.750198</td>\n",
       "      <td>0.68516</td>\n",
       "      <td>0.621758</td>\n",
       "      <td>0.94552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distilbert-base-uncased-finetuned-sst-2-english</td>\n",
       "      <td>0.884697</td>\n",
       "      <td>0.88852</td>\n",
       "      <td>0.916117</td>\n",
       "      <td>0.85536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide the dataset since all of the samles are quite long to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(imdb_dataset, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slim sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[37mWARNING: remediation - could not find key-value to correct - output may be missing certain content in structured output.\u001B[39m\n",
      "\u001B[37mINFO: update: function call output could not be automatically converted, but remediation was successful to type - dict \u001B[39m\n",
      "\u001B[37mWARNING: remediation - could not find key-value to correct - output may be missing certain content in structured output.\u001B[39m\n",
      "\u001B[37mWARNING: remediation - could not find key-value to correct - output may be missing certain content in structured output.\u001B[39m\n",
      "\u001B[37mINFO: update: function call output could not be automatically converted, but remediation was successful to type - dict \u001B[39m\n"
     ]
    }
   ],
   "source": [
    "from llmware.models import ModelCatalog\n",
    "slim_model = ModelCatalog().load_model(\"llmware/slim-sentiment\")\n",
    "\n",
    "def get_sentiment_llm(text):\n",
    "    response = slim_model.function_call(text, params=[\"sentiment\"], function=\"classify\")\n",
    "    return response\n",
    "\n",
    "test['sentiment_slim_unprocessed'] = test['text'].apply(get_sentiment_llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_dataset.to_csv('imdb_dataset2.csv')"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T14:46:52.548225Z",
     "start_time": "2024-10-10T14:46:52.286059Z"
    }
   },
   "cell_type": "code",
   "source": "imdb_dataset = pd.read_csv('imdb_dataset2.csv')",
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_bert</th>\n",
       "      <th>sentiment_slim_unprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6868</th>\n",
       "      <td>Dumb is as dumb does, in this thoroughly unint...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.040799</td>\n",
       "      <td>0</td>\n",
       "      <td>{'llm_response': {}, 'usage': {'input': 189, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24016</th>\n",
       "      <td>I dug out from my garage some old musicals and...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.351402</td>\n",
       "      <td>1</td>\n",
       "      <td>{'llm_response': {'sentiment': ['positive']}, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9668</th>\n",
       "      <td>After watching this movie I was honestly disap...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.105758</td>\n",
       "      <td>0</td>\n",
       "      <td>{'llm_response': {'sentiment': ['negative']}, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13640</th>\n",
       "      <td>This movie was nominated for best picture but ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.412727</td>\n",
       "      <td>0</td>\n",
       "      <td>{'llm_response': {'sentiment': ['negative']}, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14018</th>\n",
       "      <td>Just like Al Gore shook us up with his painful...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.231805</td>\n",
       "      <td>1</td>\n",
       "      <td>{'llm_response': {'sentiment': ['positive']}, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  sentiment  \\\n",
       "6868   Dumb is as dumb does, in this thoroughly unint...      0  -0.040799   \n",
       "24016  I dug out from my garage some old musicals and...      1   0.351402   \n",
       "9668   After watching this movie I was honestly disap...      0  -0.105758   \n",
       "13640  This movie was nominated for best picture but ...      1   0.412727   \n",
       "14018  Just like Al Gore shook us up with his painful...      1   0.231805   \n",
       "\n",
       "       sentiment_bert                         sentiment_slim_unprocessed  \n",
       "6868                0  {'llm_response': {}, 'usage': {'input': 189, '...  \n",
       "24016               1  {'llm_response': {'sentiment': ['positive']}, ...  \n",
       "9668                0  {'llm_response': {'sentiment': ['negative']}, ...  \n",
       "13640               0  {'llm_response': {'sentiment': ['negative']}, ...  \n",
       "14018               1  {'llm_response': {'sentiment': ['positive']}, ...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.to_csv('test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T14:47:26.392874Z",
     "start_time": "2024-10-10T14:47:26.308851Z"
    }
   },
   "source": [
    "test[\"sentiment_slim_processed\"] = test[\"sentiment_slim_unprocessed\"].apply(lambda x: x['llm_response'])"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m test[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msentiment_slim_processed\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mtest\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msentiment_slim_unprocessed\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mllm_response\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/pandas/core/series.py:4924\u001B[0m, in \u001B[0;36mSeries.apply\u001B[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001B[0m\n\u001B[1;32m   4789\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[1;32m   4790\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   4791\u001B[0m     func: AggFuncType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4796\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   4797\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[1;32m   4798\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4799\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[1;32m   4800\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4915\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[1;32m   4916\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m   4917\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   4918\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4919\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4920\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4921\u001B[0m \u001B[43m        \u001B[49m\u001B[43mby_row\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mby_row\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4922\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4923\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m-> 4924\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1424\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_compat()\n\u001B[1;32m   1426\u001B[0m \u001B[38;5;66;03m# self.func is Callable\u001B[39;00m\n\u001B[0;32m-> 1427\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1501\u001B[0m \u001B[38;5;66;03m# row-wise access\u001B[39;00m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m \u001B[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001B[39;00m\n\u001B[1;32m   1504\u001B[0m \u001B[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001B[39;00m\n\u001B[1;32m   1505\u001B[0m \u001B[38;5;66;03m#  Categorical (GH51645).\u001B[39;00m\n\u001B[1;32m   1506\u001B[0m action \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj\u001B[38;5;241m.\u001B[39mdtype, CategoricalDtype) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1507\u001B[0m mapped \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1508\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmapper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcurried\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\n\u001B[1;32m   1509\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[1;32m   1512\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[1;32m   1513\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[1;32m   1514\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/pandas/core/base.py:921\u001B[0m, in \u001B[0;36mIndexOpsMixin._map_values\u001B[0;34m(self, mapper, na_action, convert)\u001B[0m\n\u001B[1;32m    918\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[1;32m    919\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mmap(mapper, na_action\u001B[38;5;241m=\u001B[39mna_action)\n\u001B[0;32m--> 921\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malgorithms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001B[0m, in \u001B[0;36mmap_array\u001B[0;34m(arr, mapper, na_action, convert)\u001B[0m\n\u001B[1;32m   1741\u001B[0m values \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1743\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1745\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mmap_infer_mask(\n\u001B[1;32m   1746\u001B[0m         values, mapper, mask\u001B[38;5;241m=\u001B[39misna(values)\u001B[38;5;241m.\u001B[39mview(np\u001B[38;5;241m.\u001B[39muint8), convert\u001B[38;5;241m=\u001B[39mconvert\n\u001B[1;32m   1747\u001B[0m     )\n",
      "File \u001B[0;32mlib.pyx:2972\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[0;34m()\u001B[0m\n",
      "Cell \u001B[0;32mIn[19], line 1\u001B[0m, in \u001B[0;36m<lambda>\u001B[0;34m(x)\u001B[0m\n\u001B[0;32m----> 1\u001B[0m test[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msentiment_slim_processed\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m test[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msentiment_slim_unprocessed\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mllm_response\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m)\n",
      "\u001B[0;31mTypeError\u001B[0m: string indices must be integers"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T14:47:35.924557Z",
     "start_time": "2024-10-10T14:47:35.290039Z"
    }
   },
   "source": [
    "test[\"sentiment_slim\"] = test[\"sentiment_slim_processed\"].apply(lambda x: 1 if x.get('sentiment', ['negative'])[0] == \"positive\" else 0)"
   ],
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sentiment_slim_processed'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32mindex.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mindex.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'sentiment_slim_processed'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m test[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msentiment_slim\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mtest\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msentiment_slim_processed\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msentiment\u001B[39m\u001B[38;5;124m'\u001B[39m, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnegative\u001B[39m\u001B[38;5;124m'\u001B[39m])[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpositive\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   4100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   4101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 4102\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   4104\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m   3808\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[1;32m   3809\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[1;32m   3810\u001B[0m     ):\n\u001B[1;32m   3811\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[0;32m-> 3812\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3814\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3815\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3816\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3817\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'sentiment_slim_processed'"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('test2.csv')"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T14:48:06.154479Z",
     "start_time": "2024-10-10T14:48:06.035376Z"
    }
   },
   "cell_type": "code",
   "source": "test = pd.read_csv('test2.csv')",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T14:48:45.714541Z",
     "start_time": "2024-10-10T14:48:45.701707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "f1_slim = f1_score(test['label'], test['sentiment_slim'])\n",
    "accuracy_slim = accuracy_score(test['label'], test['sentiment_slim'])\n",
    "precision_slim = precision_score(test['label'], test['sentiment_slim'])\n",
    "recall_slim = recall_score(test['label'], test['sentiment_slim'])\n",
    "\n",
    "model_scores = pd.concat([model_scores, pd.DataFrame([[\"slim-sentiment\", f1_slim, accuracy_slim, precision_slim, recall_slim]], columns=[\"model\", \"f1\", \"accuracy\", \"precision\", \"recall\"])])\n",
    "\n",
    "model_scores"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                             model        f1  accuracy  \\\n",
       "0                                         TextBlob  0.750198   0.68516   \n",
       "0  distilbert-base-uncased-finetuned-sst-2-english  0.884697   0.88852   \n",
       "0                                   slim-sentiment  0.901526   0.90060   \n",
       "\n",
       "   precision    recall  \n",
       "0   0.621758  0.945520  \n",
       "0   0.916117  0.855360  \n",
       "0   0.887978  0.915493  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TextBlob</td>\n",
       "      <td>0.750198</td>\n",
       "      <td>0.68516</td>\n",
       "      <td>0.621758</td>\n",
       "      <td>0.945520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distilbert-base-uncased-finetuned-sst-2-english</td>\n",
       "      <td>0.884697</td>\n",
       "      <td>0.88852</td>\n",
       "      <td>0.916117</td>\n",
       "      <td>0.855360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>slim-sentiment</td>\n",
       "      <td>0.901526</td>\n",
       "      <td>0.90060</td>\n",
       "      <td>0.887978</td>\n",
       "      <td>0.915493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### "
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
