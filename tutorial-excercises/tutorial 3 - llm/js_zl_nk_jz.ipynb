{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kin281nzYS0t",
    "outputId": "f343eff2-028f-4e03-86cc-bf5d0986b9f4",
    "ExecuteTime": {
     "end_time": "2024-10-27T17:50:59.040636Z",
     "start_time": "2024-10-27T17:50:56.187934Z"
    }
   },
   "source": "!pip install mistralai evaluate python-dotenv openai together pydantic anthropic tqdm sentence_transformers bert_score rouge Levenshtein",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mistralai in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (1.1.0)\r\n",
      "Requirement already satisfied: evaluate in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (0.4.3)\r\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (1.0.1)\r\n",
      "Requirement already satisfied: openai in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (1.52.2)\r\n",
      "Requirement already satisfied: together in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (1.3.3)\r\n",
      "Requirement already satisfied: pydantic in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (2.9.2)\r\n",
      "Requirement already satisfied: anthropic in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (0.37.1)\r\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (4.66.5)\r\n",
      "Requirement already satisfied: sentence_transformers in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (3.2.1)\r\n",
      "Requirement already satisfied: bert_score in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (0.3.13)\r\n",
      "Collecting rouge\r\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\r\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from mistralai) (0.2.0)\r\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from mistralai) (0.27.0)\r\n",
      "Requirement already satisfied: jsonpath-python<2.0.0,>=1.0.6 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from mistralai) (1.0.6)\r\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from mistralai) (2.8.2)\r\n",
      "Requirement already satisfied: typing-inspect<0.10.0,>=0.9.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from mistralai) (0.9.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from python-dateutil==2.8.2->mistralai) (1.16.0)\r\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from evaluate) (2.19.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from evaluate) (1.26.4)\r\n",
      "Requirement already satisfied: dill in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from evaluate) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from evaluate) (2.0.3)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from evaluate) (2.32.3)\r\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from evaluate) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from evaluate) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.3.1)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from evaluate) (0.23.3)\r\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from evaluate) (24.0)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from openai) (4.3.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from openai) (1.9.0)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from openai) (0.6.1)\r\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from openai) (1.3.1)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from openai) (4.12.2)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from together) (3.9.5)\r\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from together) (8.1.7)\r\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from together) (3.13.1)\r\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from together) (10.4.0)\r\n",
      "Requirement already satisfied: pyarrow>=10.0.1 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from together) (16.0.0)\r\n",
      "Requirement already satisfied: rich<14.0.0,>=13.8.1 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from together) (13.9.3)\r\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from together) (0.9.0)\r\n",
      "Requirement already satisfied: typer<0.13,>=0.9 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from together) (0.12.5)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from pydantic) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from pydantic) (2.23.4)\r\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from anthropic) (0.19.1)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from sentence_transformers) (4.42.0.dev0)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from sentence_transformers) (2.2.2)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from sentence_transformers) (1.0.2)\r\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from sentence_transformers) (1.13.1)\r\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from bert_score) (3.8.3)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.9.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (4.0.3)\r\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\r\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\r\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->mistralai) (2024.8.30)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->mistralai) (1.0.4)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->mistralai) (0.14.0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.1.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from rich<14.0.0,>=13.8.1->together) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from rich<14.0.0,>=13.8.1->together) (2.17.2)\r\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (2.8)\r\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.5.15)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.3)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from typer<0.13,>=0.9->together) (1.5.4)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from typing-inspect<0.10.0,>=0.9.0->mistralai) (1.0.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from matplotlib->bert_score) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from matplotlib->bert_score) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from matplotlib->bert_score) (4.50.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from matplotlib->bert_score) (1.4.5)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from matplotlib->bert_score) (3.1.2)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.4.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.8.1->together) (0.1.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/envs/workspace/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\r\n",
      "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\r\n",
      "Installing collected packages: rouge\r\n",
      "Successfully installed rouge-1.0.1\r\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T16:35:35.418160Z",
     "start_time": "2024-10-27T16:35:35.406865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reviews = [\n",
    "    # Thermal Mugs\n",
    "    \"Keeps my coffee hot for hours—just what I need for long workdays. Thanks, Contigo.\",\n",
    "    \"The lid isn’t leak-proof, but it keeps drinks warm for a decent amount of time.\",\n",
    "    \"Love the sleek design of my Zojirushi mug, and it fits perfectly in my car cup holder!\",\n",
    "    \"It’s lightweight but keeps my drinks at the right temperature for hours with Hydro Flask.\",\n",
    "    \"No more cold coffee! This Yeti thermal mug does the job.\",\n",
    "    \"It’s easy to clean, and the thermal insulation works like a charm.\",\n",
    "    \"The handle makes it easy to carry, and it doesn’t spill.\",\n",
    "    \"Not great for keeping drinks cold, but excellent for hot beverages.\",\n",
    "    \"I wish it were bigger, but it’s perfect for my morning tea.\",\n",
    "    \"I accidentally dropped it, and it didn’t dent! Very sturdy.\",\n",
    "    \"The rubber seal around the lid came loose after a few weeks. Disappointing.\",\n",
    "    \"Great for both coffee and soup—keeps them warm for hours.\",\n",
    "    \"The exterior stays cool, even when my drink is piping hot inside.\",\n",
    "    \"I love the color options, and it’s great for on-the-go.\",\n",
    "    \"Keeps ice water cold for hours, even in hot weather!\",\n",
    "    \"It’s a little tricky to open one-handed, but overall, a great mug.\",\n",
    "    \"The size is perfect for travel, and it keeps drinks hot all day.\",\n",
    "    \"It doesn’t leak, even when I toss it in my bag. Highly recommend Contigo.\",\n",
    "    \"The lid is a little tight, but the mug works well for keeping drinks warm.\",\n",
    "    \"Very stylish and functional! I get compliments all the time.\",\n",
    "    \"Keeps my coffee scalding hot for longer than any mug I’ve owned with Zojirushi.\",\n",
    "    \"Great value for the price. Works just as well as more expensive brands.\",\n",
    "    \"The mug is lightweight and easy to carry around.\",\n",
    "    \"It fits perfectly under my single-serve coffee machine!\",\n",
    "    \"Durable, sleek, and it does exactly what it’s supposed to.\",\n",
    "\n",
    "    # Dishwasher Detergents\n",
    "    \"My dishes come out sparkling clean every time with Cascade. Love this detergent!\",\n",
    "    \"It works well on glass, but I’ve noticed spots on my silverware.\",\n",
    "    \"Great for tough, greasy messes. Leaves no residue! Thanks, Finish.\",\n",
    "    \"This detergent smells amazing and leaves my dishwasher fresh.\",\n",
    "    \"It’s a little pricey, but my dishes have never looked better with Cascade Platinum.\",\n",
    "    \"Gets rid of even the most stubborn baked-on food. Highly recommend Finish Quantum.\",\n",
    "    \"Not the best on hard water stains, but otherwise it works great.\",\n",
    "    \"My dishes have never been so spotless after a wash!\",\n",
    "    \"It’s very effective, but I wish it came in a fragrance-free version.\",\n",
    "    \"Cuts through grease like a dream. No more pre-rinsing with Cascade Complete.\",\n",
    "    \"This detergent doesn’t leave any residue on plastic, which I love.\",\n",
    "    \"My glasses come out clear and sparkling every single time.\",\n",
    "    \"It doesn’t work well with my eco dishwasher. Dishes aren’t as clean.\",\n",
    "    \"Very efficient—gets rid of food stains and smells with no problem.\",\n",
    "    \"I noticed some streaks on my glassware, but overall it works well.\",\n",
    "    \"Leaves my dishes spotless and my machine smelling fresh.\",\n",
    "    \"A great, eco-friendly option that actually works!\",\n",
    "    \"It’s a little hard on some of my delicate dishware.\",\n",
    "    \"This is the only detergent that works on my hard water stains.\",\n",
    "    \"No need to rewash dishes after using this—so efficient!\",\n",
    "    \"Perfect for everyday use. My dishes are clean and shiny.\",\n",
    "    \"Leaves a chemical smell, but it’s effective at cleaning.\",\n",
    "    \"A bit expensive, but worth it for the spotless results.\",\n",
    "    \"No more streaks or water spots! Best dishwasher detergent ever.\",\n",
    "    \"My silverware and dishes look brand new after every wash.\",\n",
    "\n",
    "    # Sunscreens\n",
    "    \"Absorbs quickly and doesn’t leave a greasy residue. Great for daily use with Neutrogena.\",\n",
    "    \"The scent is a little strong, but it protects well with Coppertone.\",\n",
    "    \"Perfect for sensitive skin! No breakouts or irritation with La Roche-Posay.\",\n",
    "    \"A bit thick to apply, but once it’s on, it stays all day.\",\n",
    "    \"I love the lightweight formula of CeraVe, perfect for wearing under makeup.\",\n",
    "    \"Doesn’t leave a white cast, even on darker skin tones.\",\n",
    "    \"The spray bottle makes it super easy to apply on the go.\",\n",
    "    \"This sunscreen saved me from burning on a beach vacation with Banana Boat!\",\n",
    "    \"It’s waterproof, which is a must for pool days. Highly recommend Hawaiian Tropic.\",\n",
    "    \"A bit pricey, but the protection it provides is worth every penny with Supergoop.\",\n",
    "    \"This is my go-to sunscreen for both my face and body with Neutrogena.\",\n",
    "    \"It’s a little greasy, but it gets the job done in strong sun.\",\n",
    "    \"No weird scent, and it goes on smooth. Love this product!\",\n",
    "    \"Perfect for outdoor activities—no sunburn, even after hours outside.\",\n",
    "    \"It’s great for kids! No irritation, and it’s easy to apply with Blue Lizard.\",\n",
    "    \"A little too heavy for my face, but works perfectly for the body.\",\n",
    "    \"The texture is nice and light, not sticky at all.\",\n",
    "    \"This sunscreen doesn’t clog my pores, which is a huge plus with EltaMD.\",\n",
    "    \"I’ve tried a lot of sunscreens, and this one offers the best protection with La Roche-Posay.\",\n",
    "    \"It leaves a slight sheen, but I love how protected my skin feels.\",\n",
    "    \"This formula doesn’t dry out my skin like others do.\",\n",
    "    \"It’s great under makeup—no pilling or greasiness.\",\n",
    "    \"I wish it were more affordable, but it’s worth it for the protection.\",\n",
    "    \"Very effective, even after swimming for hours.\",\n",
    "    \"My skin stays soft and protected all day with Neutrogena sunscreen.\"\n",
    "\n",
    "     # Powder Detergents for Laundry\n",
    "    \"Gets my clothes fresh and clean every time. No lingering odor with Tide.\",\n",
    "    \"It dissolves well, even in cold water. My whites have never been brighter thanks to Ariel.\",\n",
    "    \"A little pricey, but worth it for the excellent stain removal power of Persil.\",\n",
    "    \"This powder leaves a residue on darker clothes. Not a fan of OMO.\",\n",
    "    \"Great for sensitive skin! No itching or redness after using Seventh Generation.\",\n",
    "    \"I love how eco-friendly this detergent is. It’s a big plus for me with Ecover.\",\n",
    "    \"I don’t need fabric softener anymore—this leaves my clothes so soft!\",\n",
    "    \"My laundry has never smelled so fresh, and it lasts for days with Gain.\",\n",
    "    \"It’s not the best for heavy stains but works great for daily washes.\",\n",
    "    \"Great value for the price. This box lasts forever! Thanks, Arm & Hammer.\",\n",
    "    \"Perfect for my workout gear—gets rid of all the sweat smells.\",\n",
    "    \"Leaves a bit of powder behind in the machine, but it cleans well.\",\n",
    "    \"I’ve been using it for years, and Tide never disappoints.\",\n",
    "    \"Not as effective in hard water areas, but still decent.\",\n",
    "    \"My go-to detergent for all of my family’s laundry needs.\",\n",
    "    \"I noticed some fading in my darker clothes after a few washes.\",\n",
    "    \"It’s gentle on my baby’s clothes and skin with Dreft.\",\n",
    "    \"Very effective at removing mud and grass stains from the kids’ clothes.\",\n",
    "    \"I like the scent, but it might be too strong for some.\",\n",
    "    \"No complaints so far! My clothes feel clean and fresh.\",\n",
    "    \"Works just as well as liquid detergents but at a lower cost.\",\n",
    "    \"A bit too perfumed for my taste, but it gets the job done.\",\n",
    "    \"My clothes are noticeably softer and smell better than before.\",\n",
    "    \"The box is hard to pour from, but the detergent works well.\",\n",
    "    \"This is my new favorite detergent. So much better than the leading brand!\",\n",
    "]\n",
    "\n",
    "product_offers = [\n",
    "    # Thermal Mugs\n",
    "    \"Contigo Workday Travel Mug – Keeps Coffee Hot for Hours!\",\n",
    "    \"Zojirushi Sleek Travel Mug – Perfect Fit for Car Holders\",\n",
    "    \"Hydro Flask Lightweight Insulation Mug – Stay Warm for Hours\",\n",
    "    \"Yeti Thermal Mug – No More Cold Coffee!\",\n",
    "    \"Contigo All-Day Heat Retention Mug – Ideal for Travel\",\n",
    "    \"Contigo Leak-Proof Mug – Toss in Your Bag with Confidence\",\n",
    "    \"Zojirushi Scalding Hot Coffee Mug – Best Insulation Yet\",\n",
    "\n",
    "    # Dishwasher Detergents\n",
    "    \"Cascade Sparkling Clean Detergent – Your Dishes Will Shine\",\n",
    "    \"Finish Detergent – Tough on Grease, No Residue Left\",\n",
    "    \"Cascade Platinum Detergent – Pricey, But Worth It for Results\",\n",
    "    \"Finish Quantum Detergent – Stubborn Food Stains Gone\",\n",
    "    \"Cascade Complete Detergent – No Pre-Rinsing Needed for Grease\",\n",
    "\n",
    "    # Sunscreens\n",
    "    \"Neutrogena Daily Sunscreen – Quick Absorption, No Grease\",\n",
    "    \"Coppertone Suncream – Strong Scent, Strong Protection\",\n",
    "    \"La Roche-Posay Sensitive Skin Sunscreen – No Breakouts\",\n",
    "    \"CeraVe Lightweight Sunscreen – Perfect Under Makeup\",\n",
    "    \"Banana Boat Beach-Saver Sunscreen – No Burns, Just Fun\",\n",
    "    \"Hawaiian Tropic Waterproof Sunscreen – Pool Day Essential\",\n",
    "    \"Supergoop Premium Sunscreen – Worth Every Penny\",\n",
    "    \"Neutrogena Face & Body Sunscreen – All-Purpose Protection\",\n",
    "    \"EltaMD Pore-Friendly Sunscreen – Protection Without Clogging\",\n",
    "    \"La Roche-Posay Suncream – The Best in Sun Protection\",\n",
    "    \"Neutrogena Sunscreen – Soft, Protected Skin All Day\",\n",
    "\n",
    "    # Powder Detergents for Laundry\n",
    "    \"Tide Powder Detergent – Fresh, Clean Clothes Every Time\",\n",
    "    \"Ariel Powder Detergent – Whites Brighter, Even in Cold Water\",\n",
    "    \"Persil Powder Detergent – Powerful Stain Removal\",\n",
    "    \"OMO Powder Detergent – Leaves Residue on Dark Clothes\",\n",
    "    \"Seventh Generation Powder Detergent – Great for Sensitive Skin\",\n",
    "    \"Ecover Eco-Friendly Detergent – Perfect for the Eco-Conscious\",\n",
    "    \"Gain Powder Detergent – Fresh-Smelling Laundry for Days\",\n",
    "    \"Arm & Hammer Powder Detergent – Great Value, Lasts Forever\",\n",
    "    \"Dreft Baby Powder Detergent – Gentle on Baby Clothes\"\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Creating product definition and model running functions"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T16:35:37.817610Z",
     "start_time": "2024-10-27T16:35:37.807683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Literal\n",
    "\n",
    "\n",
    "class Product(BaseModel):\n",
    "    product_category: Literal[\n",
    "        \"Powder Detergents for Laundry\",\n",
    "        \"Thermal Mugs\",\n",
    "        \"Dishwasher Detergents\",\n",
    "        \"Sunscreens\",\n",
    "        \"Nappies\",\n",
    "        \"Others\"\n",
    "    ] = Field(\n",
    "        description=\"The category of the product.\",\n",
    "        alias=\"product category\"\n",
    "    )\n",
    "    # product_category: str = Field(\n",
    "    #     description=\"The category of the product.\",\n",
    "    #     alias=\"product category\"\n",
    "    # )\n",
    "    brand: str = Field(\n",
    "        description=\"The brand of the product, or 'N/A' if not applicable.\",\n",
    "        alias=\"brand\"\n",
    "    )\n",
    "    \n",
    "    other_keywords: List[str] = Field(\n",
    "        description=\"A list of other keywords associated with the product.\",\n",
    "        alias=\"other keywords\"\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T16:48:54.446072Z",
     "start_time": "2024-10-27T16:48:54.411078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from mistralai import Mistral\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from together import Together\n",
    "from anthropic import Anthropic\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "together_client = Together(api_key=os.getenv(\"TOGETHER_API_KEY\"))\n",
    "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "client_mistral = Mistral(api_key=os.getenv(\"MISTRAL_API_KEY\"))\n",
    "client_anthropic = Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "conversation_template = [\n",
    "    {\n",
    "        \"role\": \"system\", \n",
    "        \"content\": \"Given the user review of the product, extract the following information: product category, brand, and other keywords, which are associated with the product.\"\n",
    "    }, \n",
    "    {\n",
    "        \"role\": \"system\", \n",
    "        \"content\": f\"\"\"\n",
    "            Answer using only JSON format with the following JSON schema:\n",
    "\n",
    "            {Product.model_json_schema()}\n",
    "        \"\"\".lstrip()\n",
    "    },\n",
    "]\n",
    "\n",
    "def run_mistral(user_message, model=\"mistral-large-latest\"):\n",
    "    messages = conversation_template[:1] + [{\"role\": \"user\", \"content\": user_message}] + conversation_template[1:] \n",
    "    #messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "    chat_response = client_mistral.chat.complete(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        response_format={\n",
    "            \"type\": \"json_object\",\n",
    "            \"json_schema\": {\"name\": \"product\", \"schema\": Product.model_json_schema(),}\n",
    "        },\n",
    "    )\n",
    "    return chat_response.choices[0].message.content\n",
    "\n",
    "\n",
    "def run_openai(user_message, model=\"gpt-4o\"):\n",
    "    messages = conversation_template[:1] + [{\"role\": \"user\", \"content\": user_message}] + conversation_template[1:]\n",
    "    chat_response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        response_format={\n",
    "            \"type\": \"json_object\",\n",
    "            # \"json_schema\": {\"name\": \"product\", \"schema\": Product.model_json_schema(),}\n",
    "        }\n",
    "    )\n",
    "    return chat_response.choices[0].message.content\n",
    "\n",
    "def run_together(user_message, model=\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\"):\n",
    "    messages = conversation_template[:1] + [{\"role\": \"user\", \"content\": user_message}] + conversation_template[1:]\n",
    "    chat_response = together_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        response_format={\n",
    "            \"type\": \"json_object\",\n",
    "            \"json_schema\": {\"name\": \"product\", \"schema\": Product.model_json_schema(),}\n",
    "        },\n",
    "    )\n",
    "    return chat_response.choices[0].message.content\n",
    "\n",
    "def run_anthropic(user_message, model=\"claude-3-5-sonnet-20241022\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "    chat_response = client_anthropic.messages.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        system=\"\\n\".join([m[\"content\"] for m in conversation_template]),\n",
    "        max_tokens=1024\n",
    "        # response_format={\n",
    "        #     \"type\": \"json_object\",\n",
    "        #     \"schema\": Product.model_json_schema(),\n",
    "        # },\n",
    "    )\n",
    "    \n",
    "    return chat_response.content[0].text"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Extracting product information from reviews"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwnE02DNY0wr",
    "outputId": "027725d1-0106-4995-dce0-0ceee607c462",
    "ExecuteTime": {
     "end_time": "2024-10-27T17:09:12.761386Z",
     "start_time": "2024-10-27T16:49:33.947681Z"
    }
   },
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "responses = []\n",
    "def write_response_for_review(\n",
    "    review: str\n",
    "):\n",
    "    print(f\"Review: {review}\")\n",
    "    try:\n",
    "        response_mistral = json.loads(run_mistral(review))\n",
    "    except Exception as e:\n",
    "        print(f\"Mistral error: {e}\")\n",
    "        response_mistral = None\n",
    "    \n",
    "    try:\n",
    "        response_openai = json.loads(run_openai(review))\n",
    "    except Exception as e:\n",
    "        print(f\"OpenAI error: {e}\")\n",
    "        response_openai = None\n",
    "        \n",
    "    try:\n",
    "        response_together = json.loads(run_together(review))\n",
    "    except Exception as e:\n",
    "        print(f\"Together error: {e}\")\n",
    "        response_together = None\n",
    "        \n",
    "    try:\n",
    "        response_anthropic = json.loads(run_anthropic(review))\n",
    "    except Exception as e:\n",
    "        print(f\"Anthropic error: {e}\")\n",
    "        response_anthropic = None\n",
    "    \n",
    "    responses.append({\n",
    "        \"review\": review,\n",
    "        \"mistral\": response_mistral,\n",
    "        \"openai\": response_openai,\n",
    "        \"together\": response_together,\n",
    "        \"anthropic\": response_anthropic,\n",
    "    })\n",
    "\n",
    "def write_response_for_product(\n",
    "    product: str\n",
    "):\n",
    "    print(f\"Product: {product}\")\n",
    "    try:\n",
    "        response_mistral = json.loads(run_mistral(product))\n",
    "    except Exception as e:\n",
    "        print(f\"Mistral error: {e}\")\n",
    "        response_mistral = None\n",
    "    \n",
    "    try:\n",
    "        response_openai = json.loads(run_openai(product))\n",
    "    except Exception as e:\n",
    "        print(f\"OpenAI error: {e}\")\n",
    "        response_openai = None\n",
    "        \n",
    "    try:\n",
    "        response_together = json.loads(run_together(product))\n",
    "    except Exception as e:\n",
    "        print(f\"Together error: {e}\")\n",
    "        response_together = None\n",
    "        \n",
    "    try:\n",
    "        response_anthropic = json.loads(run_anthropic(product))\n",
    "    except Exception as e:\n",
    "        print(f\"Anthropic error: {e}\")\n",
    "        response_anthropic = None\n",
    "    \n",
    "    responses.append({\n",
    "        \"product\": product,\n",
    "        \"mistral\": response_mistral,\n",
    "        \"openai\": response_openai,\n",
    "        \"together\": response_together,\n",
    "        \"anthropic\": response_anthropic,\n",
    "    })\n",
    "\n",
    "# for each test case\n",
    "tqdm._instances.clear()\n",
    "for review in tqdm(reviews):\n",
    "    write_response_for_review(review)\n",
    "    \n",
    "for product in tqdm(product_offers):\n",
    "    write_response_for_product(product)\n",
    "\n",
    "with open('js_zl_nk_js_responses.json', 'w') as f:\n",
    "    json.dump(responses, f, indent=4)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Keeps my coffee hot for hours—just what I need for long workdays. Thanks, Contigo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/99 [00:06<11:14,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: The lid isn’t leak-proof, but it keeps drinks warm for a decent amount of time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/99 [00:14<11:47,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Love the sleek design of my Zojirushi mug, and it fits perfectly in my car cup holder!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/99 [00:27<16:01, 10.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: It’s lightweight but keeps my drinks at the right temperature for hours with Hydro Flask.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/99 [00:35<14:43,  9.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: No more cold coffee! This Yeti thermal mug does the job.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/99 [00:45<14:34,  9.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: It’s easy to clean, and the thermal insulation works like a charm.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/99 [00:51<12:49,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: The handle makes it easy to carry, and it doesn’t spill.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/99 [00:58<12:14,  7.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Not great for keeping drinks cold, but excellent for hot beverages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/99 [01:06<11:58,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: I wish it were bigger, but it’s perfect for my morning tea.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/99 [01:14<11:38,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: I accidentally dropped it, and it didn’t dent! Very sturdy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/99 [01:20<10:50,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: The rubber seal around the lid came loose after a few weeks. Disappointing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/99 [01:31<12:36,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Great for both coffee and soup—keeps them warm for hours.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/99 [01:40<12:32,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: The exterior stays cool, even when my drink is piping hot inside.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/99 [01:47<11:32,  8.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: I love the color options, and it’s great for on-the-go.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/99 [01:56<11:45,  8.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Keeps ice water cold for hours, even in hot weather!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/99 [02:03<11:03,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: It’s a little tricky to open one-handed, but overall, a great mug.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/99 [02:11<10:55,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: The size is perfect for travel, and it keeps drinks hot all day.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/99 [02:17<10:16,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: It doesn’t leak, even when I toss it in my bag. Highly recommend Contigo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/99 [02:24<09:57,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: The lid is a little tight, but the mug works well for keeping drinks warm.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/99 [02:32<09:51,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Very stylish and functional! I get compliments all the time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/99 [02:40<09:56,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Keeps my coffee scalding hot for longer than any mug I’ve owned with Zojirushi.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/99 [02:51<11:09,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Great value for the price. Works just as well as more expensive brands.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/99 [02:57<10:21,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: The mug is lightweight and easy to carry around.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/99 [03:05<10:02,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: It fits perfectly under my single-serve coffee machine!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/99 [03:14<10:27,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Durable, sleek, and it does exactly what it’s supposed to.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/99 [03:22<10:03,  8.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: My dishes come out sparkling clean every time with Cascade. Love this detergent!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 26/99 [03:31<10:18,  8.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: It works well on glass, but I’ve noticed spots on my silverware.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/99 [03:39<09:42,  8.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Great for tough, greasy messes. Leaves no residue! Thanks, Finish.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/99 [03:52<11:28,  9.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This detergent smells amazing and leaves my dishwasher fresh.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/99 [04:05<12:18, 10.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: It’s a little pricey, but my dishes have never looked better with Cascade Platinum.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/99 [04:22<14:30, 12.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Gets rid of even the most stubborn baked-on food. Highly recommend Finish Quantum.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 31/99 [04:29<12:30, 11.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Not the best on hard water stains, but otherwise it works great.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/99 [04:35<10:39,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: My dishes have never been so spotless after a wash!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/99 [04:43<09:52,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: It’s very effective, but I wish it came in a fragrance-free version.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/99 [04:52<09:44,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Cuts through grease like a dream. No more pre-rinsing with Cascade Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/99 [05:01<09:36,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This detergent doesn’t leave any residue on plastic, which I love.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 36/99 [05:11<09:49,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: My glasses come out clear and sparkling every single time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/99 [05:19<09:03,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: It doesn’t work well with my eco dishwasher. Dishes aren’t as clean.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/99 [05:28<08:57,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Very efficient—gets rid of food stains and smells with no problem.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/99 [05:36<08:50,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: I noticed some streaks on my glassware, but overall it works well.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/99 [05:45<08:35,  8.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Leaves my dishes spotless and my machine smelling fresh.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 41/99 [05:54<08:38,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: A great, eco-friendly option that actually works!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/99 [06:01<07:53,  8.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: It’s a little hard on some of my delicate dishware.\n",
      "Together error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/99 [06:08<07:28,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This is the only detergent that works on my hard water stains.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/99 [06:16<07:04,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: No need to rewash dishes after using this—so efficient!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/99 [06:22<06:41,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Perfect for everyday use. My dishes are clean and shiny.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 46/99 [06:36<08:05,  9.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Leaves a chemical smell, but it’s effective at cleaning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/99 [06:45<08:00,  9.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: A bit expensive, but worth it for the spotless results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/99 [06:53<07:28,  8.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: No more streaks or water spots! Best dishwasher detergent ever.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/99 [07:00<06:56,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: My silverware and dishes look brand new after every wash.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 50/99 [07:08<06:40,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Absorbs quickly and doesn’t leave a greasy residue. Great for daily use with Neutrogena.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 51/99 [07:18<07:03,  8.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: The scent is a little strong, but it protects well with Coppertone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 52/99 [07:27<06:51,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Perfect for sensitive skin! No breakouts or irritation with La Roche-Posay.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 53/99 [07:36<06:51,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: A bit thick to apply, but once it’s on, it stays all day.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 54/99 [07:43<06:17,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: I love the lightweight formula of CeraVe, perfect for wearing under makeup.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 55/99 [07:50<05:42,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Doesn’t leave a white cast, even on darker skin tones.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 56/99 [07:58<05:39,  7.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: The spray bottle makes it super easy to apply on the go.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 57/99 [08:06<05:33,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This sunscreen saved me from burning on a beach vacation with Banana Boat!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 58/99 [08:15<05:35,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: It’s waterproof, which is a must for pool days. Highly recommend Hawaiian Tropic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 59/99 [08:21<05:01,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: A bit pricey, but the protection it provides is worth every penny with Supergoop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 60/99 [08:34<06:04,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This is my go-to sunscreen for both my face and body with Neutrogena.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 61/99 [08:41<05:28,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: It’s a little greasy, but it gets the job done in strong sun.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 62/99 [09:08<08:39, 14.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: No weird scent, and it goes on smooth. Love this product!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 63/99 [09:15<07:15, 12.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Perfect for outdoor activities—no sunburn, even after hours outside.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 64/99 [09:24<06:29, 11.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: It’s great for kids! No irritation, and it’s easy to apply with Blue Lizard.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 65/99 [09:32<05:39, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: A little too heavy for my face, but works perfectly for the body.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 66/99 [09:38<04:58,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: The texture is nice and light, not sticky at all.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 67/99 [09:47<04:46,  8.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This sunscreen doesn’t clog my pores, which is a huge plus with EltaMD.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 68/99 [09:56<04:35,  8.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: I’ve tried a lot of sunscreens, and this one offers the best protection with La Roche-Posay.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 69/99 [10:02<04:06,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: It leaves a slight sheen, but I love how protected my skin feels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 70/99 [10:12<04:08,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This formula doesn’t dry out my skin like others do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 71/99 [10:18<03:40,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: It’s great under makeup—no pilling or greasiness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 72/99 [10:25<03:25,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: I wish it were more affordable, but it’s worth it for the protection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 73/99 [10:32<03:13,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Very effective, even after swimming for hours.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 74/99 [10:40<03:09,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: My skin stays soft and protected all day with Neutrogena sunscreen.Gets my clothes fresh and clean every time. No lingering odor with Tide.\n",
      "Together error: Extra data: line 3 column 1 (char 163)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 75/99 [10:52<03:34,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: It dissolves well, even in cold water. My whites have never been brighter thanks to Ariel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 76/99 [11:15<05:02, 13.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: A little pricey, but worth it for the excellent stain removal power of Persil.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 77/99 [11:26<04:36, 12.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This powder leaves a residue on darker clothes. Not a fan of OMO.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 78/99 [11:34<03:52, 11.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Great for sensitive skin! No itching or redness after using Seventh Generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 79/99 [11:43<03:29, 10.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: I love how eco-friendly this detergent is. It’s a big plus for me with Ecover.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 80/99 [11:53<03:16, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: I don’t need fabric softener anymore—this leaves my clothes so soft!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 81/99 [12:05<03:12, 10.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: My laundry has never smelled so fresh, and it lasts for days with Gain.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 82/99 [12:12<02:44,  9.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: It’s not the best for heavy stains but works great for daily washes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 83/99 [12:29<03:09, 11.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Great value for the price. This box lasts forever! Thanks, Arm & Hammer.\n",
      "Together error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 84/99 [12:36<02:35, 10.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Perfect for my workout gear—gets rid of all the sweat smells.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 85/99 [12:44<02:14,  9.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Leaves a bit of powder behind in the machine, but it cleans well.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 86/99 [12:52<01:59,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: I’ve been using it for years, and Tide never disappoints.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 87/99 [13:05<02:03, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Not as effective in hard water areas, but still decent.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 88/99 [13:11<01:41,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: My go-to detergent for all of my family’s laundry needs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 89/99 [13:19<01:28,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: I noticed some fading in my darker clothes after a few washes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 90/99 [13:28<01:20,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: It’s gentle on my baby’s clothes and skin with Dreft.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 91/99 [13:36<01:07,  8.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Very effective at removing mud and grass stains from the kids’ clothes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 92/99 [13:44<00:59,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: I like the scent, but it might be too strong for some.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 93/99 [13:51<00:47,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: No complaints so far! My clothes feel clean and fresh.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 94/99 [13:59<00:39,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Works just as well as liquid detergents but at a lower cost.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 95/99 [14:16<00:42, 10.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: A bit too perfumed for my taste, but it gets the job done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 96/99 [14:22<00:28,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: My clothes are noticeably softer and smell better than before.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 97/99 [14:32<00:18,  9.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: The box is hard to pour from, but the detergent works well.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 98/99 [14:40<00:09,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This is my new favorite detergent. So much better than the leading brand!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [14:48<00:00,  8.97s/it]\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Contigo Workday Travel Mug – Keeps Coffee Hot for Hours!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/32 [00:07<03:37,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Zojirushi Sleek Travel Mug – Perfect Fit for Car Holders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 2/32 [00:14<03:37,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Hydro Flask Lightweight Insulation Mug – Stay Warm for Hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 3/32 [00:22<03:37,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Yeti Thermal Mug – No More Cold Coffee!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 4/32 [00:29<03:28,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Contigo All-Day Heat Retention Mug – Ideal for Travel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 5/32 [00:37<03:23,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Contigo Leak-Proof Mug – Toss in Your Bag with Confidence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 6/32 [00:44<03:12,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Zojirushi Scalding Hot Coffee Mug – Best Insulation Yet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 7/32 [00:55<03:35,  8.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Cascade Sparkling Clean Detergent – Your Dishes Will Shine\n",
      "Together error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 8/32 [01:03<03:22,  8.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Finish Detergent – Tough on Grease, No Residue Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 9/32 [01:14<03:29,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Cascade Platinum Detergent – Pricey, But Worth It for Results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 10/32 [01:22<03:16,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Finish Quantum Detergent – Stubborn Food Stains Gone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 11/32 [01:31<03:05,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Cascade Complete Detergent – No Pre-Rinsing Needed for Grease\n",
      "Together error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 12/32 [01:42<03:09,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Neutrogena Daily Sunscreen – Quick Absorption, No Grease\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 13/32 [01:56<03:27, 10.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Coppertone Suncream – Strong Scent, Strong Protection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 14/32 [02:03<02:57,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: La Roche-Posay Sensitive Skin Sunscreen – No Breakouts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 15/32 [02:10<02:32,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: CeraVe Lightweight Sunscreen – Perfect Under Makeup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 16/32 [02:17<02:12,  8.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Banana Boat Beach-Saver Sunscreen – No Burns, Just Fun\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 17/32 [02:25<02:04,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Hawaiian Tropic Waterproof Sunscreen – Pool Day Essential\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 18/32 [02:36<02:04,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Supergoop Premium Sunscreen – Worth Every Penny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 19/32 [02:44<01:53,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Neutrogena Face & Body Sunscreen – All-Purpose Protection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 20/32 [02:54<01:48,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: EltaMD Pore-Friendly Sunscreen – Protection Without Clogging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 21/32 [03:05<01:46,  9.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: La Roche-Posay Suncream – The Best in Sun Protection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 22/32 [03:12<01:29,  8.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Neutrogena Sunscreen – Soft, Protected Skin All Day\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 23/32 [03:23<01:27,  9.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Tide Powder Detergent – Fresh, Clean Clothes Every Time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 24/32 [03:32<01:13,  9.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Ariel Powder Detergent – Whites Brighter, Even in Cold Water\n",
      "Together error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 25/32 [03:41<01:04,  9.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Persil Powder Detergent – Powerful Stain Removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 26/32 [03:57<01:07, 11.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: OMO Powder Detergent – Leaves Residue on Dark Clothes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 27/32 [04:05<00:51, 10.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Seventh Generation Powder Detergent – Great for Sensitive Skin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 28/32 [04:13<00:37,  9.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Ecover Eco-Friendly Detergent – Perfect for the Eco-Conscious\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 29/32 [04:20<00:26,  8.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Gain Powder Detergent – Fresh-Smelling Laundry for Days\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 30/32 [04:28<00:17,  8.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Arm & Hammer Powder Detergent – Great Value, Lasts Forever\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 31/32 [04:42<00:10, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Dreft Baby Powder Detergent – Gentle on Baby Clothes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [04:50<00:00,  9.08s/it]\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load responses from JSON file\n",
    "with open('js_zl_nk_js_responses.json', 'r') as f:\n",
    "    responses = json.load(f)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Comparing similarity of responses from different models"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dm9yYI5_Y3iz",
    "outputId": "7ed92644-16dc-4d11-c0ee-61c8bb58ebb5",
    "ExecuteTime": {
     "end_time": "2024-10-27T18:35:35.073969Z",
     "start_time": "2024-10-27T18:35:35.013620Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# prompt: write code for comparing one review from results with one product from products and add in these comparison extracted keywords with lower weight additionally to categories and brand comparison\n",
    "\n",
    "def compare_json_objects_with_keywords(obj1, obj2, keys_to_compare={'other keywords', 'brand', 'product category'}):\n",
    "    if obj1 is None or obj2 is None:\n",
    "        return 0\n",
    "    \n",
    "    identical_fields = 0\n",
    "    common_keys = set(obj1.keys()) & set(obj2.keys() & keys_to_compare)\n",
    "    for key in common_keys:\n",
    "        if key == 'other keywords':\n",
    "            if isinstance(obj1.get(key), list) and isinstance(obj2.get(key), list):\n",
    "                common_keywords = set(obj1.get(key)) & set(obj2.get(key))\n",
    "                identical_fields += len(common_keywords) * 0.3  # Keywords have lower weight\n",
    "            else:\n",
    "              identical_fields += 0\n",
    "        else:\n",
    "          identical_fields += obj1[key] == obj2[key]\n",
    "    #percentage_identical = (identical_fields / max(len(obj1.keys()), 1)) * 100\n",
    "    percentage_identical = (identical_fields / max(len(keys_to_compare), 1)) * 100\n",
    "\n",
    "    return percentage_identical\n",
    "\n",
    "# for each review and product find similarity between different model responses\n",
    "similarity = pd.DataFrame(columns=['type', 'mistral-openai', 'mistral-together', 'mistral-anthropic', 'openai-together', 'openai-anthropic', 'together-anthropic'])\n",
    "for response in responses:\n",
    "    type = 'review' if 'review' in response else 'product'\n",
    "    mistral_openai = compare_json_objects_with_keywords(response['mistral'], response['openai'])\n",
    "    mistral_together = compare_json_objects_with_keywords(response['mistral'], response['together'])\n",
    "    mistral_anthropic = compare_json_objects_with_keywords(response['mistral'], response['anthropic'])\n",
    "    openai_together = compare_json_objects_with_keywords(response['openai'], response['together'])\n",
    "    openai_anthropic = compare_json_objects_with_keywords(response['openai'], response['anthropic'])\n",
    "    together_anthropic = compare_json_objects_with_keywords(response['together'], response['anthropic'])\n",
    "    \n",
    "    similarity = pd.concat(\n",
    "        [\n",
    "            similarity, \n",
    "            pd.DataFrame(\n",
    "                [[type, mistral_openai, mistral_together, mistral_anthropic, openai_together, openai_anthropic, together_anthropic]],\n",
    "                columns=['type', 'mistral-openai', 'mistral-together', 'mistral-anthropic', 'openai-together', 'openai-anthropic', 'together-anthropic']\n",
    "            )\n",
    "        ],\n",
    "        ignore_index=True\n",
    "    )\n",
    "    \n",
    "similarity.to_csv('js_zl_nk_js_similarity_1.csv', index=False)\n",
    "\n",
    "print(\"Mean similarity between Mistral and OpenAI:\", similarity['mistral-openai'].mean())\n",
    "print(\"Mean similarity between Mistral and Together:\", similarity['mistral-together'].mean())\n",
    "print(\"Mean similarity between Mistral and Anthropic:\", similarity['mistral-anthropic'].mean())\n",
    "print(\"Mean similarity between OpenAI and Together:\", similarity['openai-together'].mean())\n",
    "print(\"Mean similarity between OpenAI and Anthropic:\", similarity['openai-anthropic'].mean())\n",
    "print(\"Mean similarity between Together and Anthropic:\", similarity['together-anthropic'].mean())\n",
    "similarity"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean similarity between Mistral and OpenAI: 80.07633587786259\n",
      "Mean similarity between Mistral and Together: 68.04071246819339\n",
      "Mean similarity between Mistral and Anthropic: 72.44274809160305\n",
      "Mean similarity between OpenAI and Together: 70.20356234096693\n",
      "Mean similarity between OpenAI and Anthropic: 71.80661577608141\n",
      "Mean similarity between Together and Anthropic: 63.94402035623409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        type  mistral-openai  mistral-together  mistral-anthropic  \\\n",
       "0     review       96.666667         86.666667          86.666667   \n",
       "1     review       76.666667         96.666667          66.666667   \n",
       "2     review       86.666667         86.666667          86.666667   \n",
       "3     review       86.666667         76.666667          76.666667   \n",
       "4     review       76.666667         66.666667          76.666667   \n",
       "..       ...             ...               ...                ...   \n",
       "126  product       76.666667         66.666667          66.666667   \n",
       "127  product       86.666667         63.333333          66.666667   \n",
       "128  product       66.666667         86.666667          66.666667   \n",
       "129  product       86.666667         86.666667          66.666667   \n",
       "130  product       96.666667         96.666667          66.666667   \n",
       "\n",
       "     openai-together  openai-anthropic  together-anthropic  \n",
       "0          86.666667         86.666667           76.666667  \n",
       "1          76.666667         66.666667           76.666667  \n",
       "2          86.666667         86.666667           86.666667  \n",
       "3          76.666667         76.666667           76.666667  \n",
       "4          76.666667         86.666667           76.666667  \n",
       "..               ...               ...                 ...  \n",
       "126        66.666667         66.666667           66.666667  \n",
       "127        53.333333         66.666667           33.333333  \n",
       "128        66.666667         76.666667           66.666667  \n",
       "129        86.666667         66.666667           66.666667  \n",
       "130        96.666667         66.666667           66.666667  \n",
       "\n",
       "[131 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>mistral-openai</th>\n",
       "      <th>mistral-together</th>\n",
       "      <th>mistral-anthropic</th>\n",
       "      <th>openai-together</th>\n",
       "      <th>openai-anthropic</th>\n",
       "      <th>together-anthropic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>review</td>\n",
       "      <td>96.666667</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>76.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>review</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>96.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>76.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>review</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>86.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>review</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>76.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>review</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>76.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>product</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>product</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>63.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>product</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>product</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>product</td>\n",
       "      <td>96.666667</td>\n",
       "      <td>96.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>96.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows × 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pVgWzng4j9oy",
    "ExecuteTime": {
     "end_time": "2024-10-27T18:36:10.639055Z",
     "start_time": "2024-10-27T18:36:10.590806Z"
    }
   },
   "source": [
    "# prompt: add comparison when if product has different cateogry there is no similarity, but if it is the same it is about 30%, if has the same category and brand, similarity is about 75%\n",
    "\n",
    "def compare_json_objects_with_keywords(obj1, obj2, keys_to_compare={'other keywords', 'brand', 'product category'}):\n",
    "    if obj1 is None or obj2 is None:\n",
    "        return 0\n",
    "    \n",
    "    if obj1.get('product category') != obj2.get('product category'):\n",
    "        return 0  # No similarity if categories don't match\n",
    "\n",
    "    similarity_score = 0\n",
    "    common_keys = set(obj1.keys()) & set(obj2.keys() & keys_to_compare)\n",
    "\n",
    "    if obj1.get('product category') == obj2.get('product category'):\n",
    "        similarity_score += 0.3  # Base similarity for matching categories\n",
    "\n",
    "    if obj1.get('brand') == obj2.get('brand'):\n",
    "        similarity_score += 0.4  # Additional similarity for matching brands\n",
    "\n",
    "    for key in common_keys:\n",
    "        if key == 'other keywords':\n",
    "            if isinstance(obj1.get(key), list) and isinstance(obj2.get(key), list):\n",
    "                common_keywords = set(obj1.get(key)) & set(obj2.get(key))\n",
    "                similarity_score += len(common_keywords) * 0.05  # Keywords have lower weight\n",
    "            else:\n",
    "                similarity_score += 0\n",
    "\n",
    "\n",
    "    return min(100, round(similarity_score * 100))\n",
    "\n",
    "\n",
    "# for each review and product find similarity between different model responses\n",
    "similarity = pd.DataFrame(columns=['type', 'mistral-openai', 'mistral-together', 'mistral-anthropic', 'openai-together', 'openai-anthropic', 'together-anthropic'])\n",
    "for response in responses:\n",
    "    type = 'review' if 'review' in response else 'product'\n",
    "    mistral_openai = compare_json_objects_with_keywords(response['mistral'], response['openai'])\n",
    "    mistral_together = compare_json_objects_with_keywords(response['mistral'], response['together'])\n",
    "    mistral_anthropic = compare_json_objects_with_keywords(response['mistral'], response['anthropic'])\n",
    "    openai_together = compare_json_objects_with_keywords(response['openai'], response['together'])\n",
    "    openai_anthropic = compare_json_objects_with_keywords(response['openai'], response['anthropic'])\n",
    "    together_anthropic = compare_json_objects_with_keywords(response['together'], response['anthropic'])\n",
    "\n",
    "    similarity = pd.concat(\n",
    "        [\n",
    "            similarity,\n",
    "            pd.DataFrame(\n",
    "                [[type, mistral_openai, mistral_together, mistral_anthropic, openai_together, openai_anthropic, together_anthropic]],\n",
    "                columns=['type', 'mistral-openai', 'mistral-together', 'mistral-anthropic', 'openai-together', 'openai-anthropic', 'together-anthropic']\n",
    "            )\n",
    "        ],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "similarity.to_csv('js_zl_nk_js_similarity_2.csv', index=False)\n",
    "\n",
    "print(\"Mean similarity between Mistral and OpenAI:\", similarity['mistral-openai'].mean())\n",
    "print(\"Mean similarity between Mistral and Together:\", similarity['mistral-together'].mean())\n",
    "print(\"Mean similarity between Mistral and Anthropic:\", similarity['mistral-anthropic'].mean())\n",
    "print(\"Mean similarity between OpenAI and Together:\", similarity['openai-together'].mean())\n",
    "print(\"Mean similarity between OpenAI and Anthropic:\", similarity['openai-anthropic'].mean())\n",
    "print(\"Mean similarity between Together and Anthropic:\", similarity['together-anthropic'].mean())\n",
    "similarity"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean similarity between Mistral and OpenAI: 68.62595419847328\n",
      "Mean similarity between Mistral and Together: 54.541984732824424\n",
      "Mean similarity between Mistral and Anthropic: 68.16793893129771\n",
      "Mean similarity between OpenAI and Together: 58.587786259541986\n",
      "Mean similarity between OpenAI and Anthropic: 64.50381679389314\n",
      "Mean similarity between Together and Anthropic: 52.86259541984733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        type mistral-openai mistral-together mistral-anthropic  \\\n",
       "0     review             85               80                80   \n",
       "1     review             75               85                70   \n",
       "2     review             80               80                80   \n",
       "3     review             80               75                75   \n",
       "4     review             75               70                75   \n",
       "..       ...            ...              ...               ...   \n",
       "126  product             75               70                70   \n",
       "127  product             80                0                70   \n",
       "128  product             70               80                70   \n",
       "129  product             80               80                70   \n",
       "130  product             85               85                70   \n",
       "\n",
       "    openai-together openai-anthropic together-anthropic  \n",
       "0                80               80                 75  \n",
       "1                75               70                 75  \n",
       "2                80               80                 80  \n",
       "3                75               75                 75  \n",
       "4                75               80                 75  \n",
       "..              ...              ...                ...  \n",
       "126              70               70                 70  \n",
       "127               0               70                  0  \n",
       "128              70               75                 70  \n",
       "129              80               70                 70  \n",
       "130              85               70                 70  \n",
       "\n",
       "[131 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>mistral-openai</th>\n",
       "      <th>mistral-together</th>\n",
       "      <th>mistral-anthropic</th>\n",
       "      <th>openai-together</th>\n",
       "      <th>openai-anthropic</th>\n",
       "      <th>together-anthropic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>review</td>\n",
       "      <td>85</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>review</td>\n",
       "      <td>75</td>\n",
       "      <td>85</td>\n",
       "      <td>70</td>\n",
       "      <td>75</td>\n",
       "      <td>70</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>review</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>review</td>\n",
       "      <td>80</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>review</td>\n",
       "      <td>75</td>\n",
       "      <td>70</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>product</td>\n",
       "      <td>75</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>product</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>product</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>75</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>product</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>product</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows × 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Merging results from OpenAI, Mistral, Together, and Anthropic models for reviews and products"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T18:47:26.104822Z",
     "start_time": "2024-10-27T18:47:26.097349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "leading_model = 'openai'  # Choose the model with the highest similarity score\n",
    "merged_products = []\n",
    "\n",
    "for response in responses:\n",
    "    if 'product' not in response:\n",
    "        continue\n",
    "    \n",
    "    product = response['product']\n",
    "    model_keywords = {\n",
    "        *(response.get('mistral', {}) or {}).get('other keywords', []),\n",
    "        *(response.get('openai', {}) or {}).get('other keywords', []),\n",
    "        *(response.get('together', {}) or {}).get('other keywords', []),\n",
    "        *(response.get('anthropic', {}) or {}).get('other keywords', [])\n",
    "    }\n",
    "    \n",
    "    merged_product = {\n",
    "        \"product\": product,\n",
    "        \"product category\": response[leading_model].get(\"product category\", \"N/A\"),\n",
    "        \"brand\": response[leading_model].get(\"brand\", \"N/A\"),\n",
    "        \"other keywords\": list(model_keywords)\n",
    "    }\n",
    "\n",
    "    merged_products.append(merged_product)\n",
    "\n",
    "merged_reviews = []\n",
    "for response in responses:\n",
    "    if 'review' not in response:\n",
    "        continue\n",
    "    \n",
    "    review = response['review']\n",
    "    model_keywords = {\n",
    "        *(response.get('mistral', {}) or {}).get('other keywords', []),\n",
    "        *(response.get('openai', {}) or {}).get('other keywords', []),\n",
    "        *(response.get('together', {}) or {}).get('other keywords', []),\n",
    "        *(response.get('anthropic', {}) or {}).get('other keywords', [])\n",
    "    }\n",
    "    \n",
    "    merged_review = {\n",
    "        \"review\": review,\n",
    "        \"product category\": response[leading_model].get(\"product category\", \"N/A\"),\n",
    "        \"brand\": response[leading_model].get(\"brand\", \"N/A\"),\n",
    "        \"other keywords\": list(model_keywords)\n",
    "    }\n",
    "\n",
    "    merged_reviews.append(merged_review)\n",
    "    \n",
    "with open('js_zl_nk_js_merged_products.json', 'w') as f:\n",
    "    json.dump(merged_products, f, indent=4)\n",
    "\n",
    "with open('js_zl_nk_js_merged_reviews.json', 'w') as f:\n",
    "    json.dump(merged_reviews, f, indent=4)"
   ],
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open('js_zl_nk_js_merged_products.json', 'r') as f:\n",
    "    merged_products = json.load(f)\n",
    "    \n",
    "with open('js_zl_nk_js_merged_reviews.json', 'r') as f:\n",
    "    merged_reviews = json.load(f)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Comparing similarity of review and product keywords"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T19:05:21.518974Z",
     "start_time": "2024-10-27T19:05:21.516953Z"
    }
   },
   "cell_type": "code",
   "source": "product_review_similarity_results = []",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## BERTScore Comparison"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qPFtArWssT06",
    "outputId": "632be372-052b-4e06-f509-7e677c2e4653",
    "ExecuteTime": {
     "end_time": "2024-10-27T19:06:15.063712Z",
     "start_time": "2024-10-27T19:06:06.448346Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from bert_score import score\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compare_keywords_bert_score(review_keywords, product_keywords):\n",
    "  \"\"\"Compares keywords using BERTScore.\"\"\"\n",
    "\n",
    "  if not review_keywords or not product_keywords:\n",
    "    return 0\n",
    "\n",
    "  max_len = max(len(review_keywords), len(product_keywords))\n",
    "  review_keywords = (review_keywords * (max_len // len(review_keywords) + 1))[:max_len]\n",
    "  product_keywords = (product_keywords * (max_len // len(product_keywords) + 1))[:max_len]\n",
    "\n",
    "  # Calculate BERTScore\n",
    "  P, R, F1 = score(\n",
    "    review_keywords,\n",
    "    product_keywords,\n",
    "    lang=\"en\",\n",
    "    model_type=\"bert-base-uncased\",\n",
    "    verbose=False,\n",
    "    nthreads=4,\n",
    "    device=\"mps\",\n",
    "    use_fast_tokenizer=True\n",
    "  )\n",
    "\n",
    "  return F1.mean().item()\n",
    "\n",
    "tqdm._instances.clear()\n",
    "bar = tqdm(total=len(merged_reviews) * len(merged_products))\n",
    "for review in merged_reviews:\n",
    "    for product in merged_products:\n",
    "        similarity_score = compare_keywords_bert_score(review['other keywords'], product['other keywords'])\n",
    "        product_review_similarity_results.append({\n",
    "            'review': review['review'],\n",
    "            'product': product['product'],\n",
    "            'bert_score': similarity_score\n",
    "        })\n",
    "\n",
    "        bar.update(1)\n",
    "\n",
    "bar.close()\n",
    "print(\"Mean similarity between review and product keywords:\", np.mean([r['bert_score'] for r in product_review_similarity_results if 'bert_score' in r]))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/3168 [00:22<3:13:22,  3.67s/it]\n",
      "  0%|          | 14/3168 [00:08<26:35,  1.98it/s] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[94], line 33\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m review \u001B[38;5;129;01min\u001B[39;00m merged_reviews:\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m product \u001B[38;5;129;01min\u001B[39;00m merged_products:\n\u001B[0;32m---> 33\u001B[0m         similarity_score \u001B[38;5;241m=\u001B[39m \u001B[43mcompare_keywords_bert_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreview\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mother keywords\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mother keywords\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m         product_review_similarity_results\u001B[38;5;241m.\u001B[39mappend({\n\u001B[1;32m     35\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreview\u001B[39m\u001B[38;5;124m'\u001B[39m: review[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreview\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     36\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mproduct\u001B[39m\u001B[38;5;124m'\u001B[39m: product[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mproduct\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     37\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbert_score\u001B[39m\u001B[38;5;124m'\u001B[39m: similarity_score\n\u001B[1;32m     38\u001B[0m         })\n\u001B[1;32m     40\u001B[0m         bar\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;241m1\u001B[39m)\n",
      "Cell \u001B[0;32mIn[94], line 16\u001B[0m, in \u001B[0;36mcompare_keywords_bert_score\u001B[0;34m(review_keywords, product_keywords)\u001B[0m\n\u001B[1;32m     13\u001B[0m product_keywords \u001B[38;5;241m=\u001B[39m (product_keywords \u001B[38;5;241m*\u001B[39m (max_len \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(product_keywords) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m))[:max_len]\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# Calculate BERTScore\u001B[39;00m\n\u001B[0;32m---> 16\u001B[0m P, R, F1 \u001B[38;5;241m=\u001B[39m \u001B[43mscore\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m  \u001B[49m\u001B[43mreview_keywords\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m  \u001B[49m\u001B[43mproduct_keywords\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m  \u001B[49m\u001B[43mlang\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43men\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m  \u001B[49m\u001B[43mmodel_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbert-base-uncased\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m  \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m  \u001B[49m\u001B[43mnthreads\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[43m  \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmps\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[43m  \u001B[49m\u001B[43muse_fast_tokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m     25\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m F1\u001B[38;5;241m.\u001B[39mmean()\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/bert_score/score.py:97\u001B[0m, in \u001B[0;36mscore\u001B[0;34m(cands, refs, model_type, num_layers, verbose, idf, device, batch_size, nthreads, all_layers, lang, return_hash, rescale_with_baseline, baseline_path, use_fast_tokenizer)\u001B[0m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_layers \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     95\u001B[0m     num_layers \u001B[38;5;241m=\u001B[39m model2layers[model_type]\n\u001B[0;32m---> 97\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m \u001B[43mget_tokenizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_fast_tokenizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     98\u001B[0m model \u001B[38;5;241m=\u001B[39m get_model(model_type, num_layers, all_layers)\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/bert_score/utils.py:329\u001B[0m, in \u001B[0;36mget_tokenizer\u001B[0;34m(model_type, use_fast)\u001B[0m\n\u001B[1;32m    326\u001B[0m     model_type \u001B[38;5;241m=\u001B[39m cache_scibert(model_type)\n\u001B[1;32m    328\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m version\u001B[38;5;241m.\u001B[39mparse(trans_version) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m version\u001B[38;5;241m.\u001B[39mparse(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m4.0.0\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 329\u001B[0m     tokenizer \u001B[38;5;241m=\u001B[39m \u001B[43mAutoTokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_fast\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_fast\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    330\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    331\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m use_fast, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFast tokenizer is not available for version < 4.0.0\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:899\u001B[0m, in \u001B[0;36mAutoTokenizer.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001B[0m\n\u001B[1;32m    896\u001B[0m tokenizer_class_py, tokenizer_class_fast \u001B[38;5;241m=\u001B[39m TOKENIZER_MAPPING[\u001B[38;5;28mtype\u001B[39m(config)]\n\u001B[1;32m    898\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tokenizer_class_fast \u001B[38;5;129;01mand\u001B[39;00m (use_fast \u001B[38;5;129;01mor\u001B[39;00m tokenizer_class_py \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 899\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtokenizer_class_fast\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    900\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    901\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m tokenizer_class_py \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2163\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001B[0m\n\u001B[1;32m   2160\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2161\u001B[0m         logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloading file \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m from cache at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresolved_vocab_files[file_id]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 2163\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_from_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2164\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresolved_vocab_files\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2165\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2166\u001B[0m \u001B[43m    \u001B[49m\u001B[43minit_configuration\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2167\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minit_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2168\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2169\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2170\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2171\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_commit_hash\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcommit_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2172\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_is_local\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_local\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2173\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2174\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2175\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2378\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase._from_pretrained\u001B[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001B[0m\n\u001B[1;32m   2375\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tokenizer_file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2376\u001B[0m     \u001B[38;5;66;03m# This is for slow so can be done before\u001B[39;00m\n\u001B[1;32m   2377\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(tokenizer_file, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m tokenizer_file_handle:\n\u001B[0;32m-> 2378\u001B[0m         tokenizer_file_handle \u001B[38;5;241m=\u001B[39m \u001B[43mjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokenizer_file_handle\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2379\u001B[0m         added_tokens \u001B[38;5;241m=\u001B[39m tokenizer_file_handle\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124madded_tokens\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   2380\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m serialized_tokens \u001B[38;5;129;01min\u001B[39;00m added_tokens:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/json/__init__.py:293\u001B[0m, in \u001B[0;36mload\u001B[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[1;32m    274\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload\u001B[39m(fp, \u001B[38;5;241m*\u001B[39m, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, object_hook\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, parse_float\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    275\u001B[0m         parse_int\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, parse_constant\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, object_pairs_hook\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw):\n\u001B[1;32m    276\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001B[39;00m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;124;03m    a JSON document) to a Python object.\u001B[39;00m\n\u001B[1;32m    278\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    291\u001B[0m \u001B[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001B[39;00m\n\u001B[1;32m    292\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 293\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    294\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobject_hook\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobject_hook\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    295\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparse_float\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparse_float\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparse_int\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparse_int\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    296\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparse_constant\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparse_constant\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobject_pairs_hook\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobject_pairs_hook\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/json/__init__.py:346\u001B[0m, in \u001B[0;36mloads\u001B[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[1;32m    341\u001B[0m     s \u001B[38;5;241m=\u001B[39m s\u001B[38;5;241m.\u001B[39mdecode(detect_encoding(s), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msurrogatepass\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    343\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    344\u001B[0m         parse_int \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m parse_float \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    345\u001B[0m         parse_constant \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_pairs_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kw):\n\u001B[0;32m--> 346\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_decoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    347\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    348\u001B[0m     \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m JSONDecoder\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/json/decoder.py:337\u001B[0m, in \u001B[0;36mJSONDecoder.decode\u001B[0;34m(self, s, _w)\u001B[0m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecode\u001B[39m(\u001B[38;5;28mself\u001B[39m, s, _w\u001B[38;5;241m=\u001B[39mWHITESPACE\u001B[38;5;241m.\u001B[39mmatch):\n\u001B[1;32m    333\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001B[39;00m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03m    containing a JSON document).\u001B[39;00m\n\u001B[1;32m    335\u001B[0m \n\u001B[1;32m    336\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 337\u001B[0m     obj, end \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraw_decode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_w\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mend\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    338\u001B[0m     end \u001B[38;5;241m=\u001B[39m _w(s, end)\u001B[38;5;241m.\u001B[39mend()\n\u001B[1;32m    339\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m end \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(s):\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/json/decoder.py:353\u001B[0m, in \u001B[0;36mJSONDecoder.raw_decode\u001B[0;34m(self, s, idx)\u001B[0m\n\u001B[1;32m    344\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001B[39;00m\n\u001B[1;32m    345\u001B[0m \u001B[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001B[39;00m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    350\u001B[0m \n\u001B[1;32m    351\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    352\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 353\u001B[0m     obj, end \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscan_once\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    354\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    355\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m JSONDecodeError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpecting value\u001B[39m\u001B[38;5;124m\"\u001B[39m, s, err\u001B[38;5;241m.\u001B[39mvalue) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Improved BERTScore Comparison"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3u3T-UP-tj2I",
    "outputId": "bffca60a-02ea-4da7-cfd9-3fcd4ecdd2ad",
    "ExecuteTime": {
     "end_time": "2024-10-27T19:06:57.219804Z",
     "start_time": "2024-10-27T19:06:50.753950Z"
    }
   },
   "source": [
    "# prompt: propose other similarity score based on categories, brands and review_keywords; other measure then above, produce sth different ; combine also comaprison between full title of product name and concatenated string from category, brand and keywords from review, print every subsequent result, copare strings with bert score not tiff\n",
    "\n",
    "def compare_product_review_similarity(review_data, product_data):\n",
    "  \"\"\"\n",
    "  Calculates a similarity score between a review and a product based on\n",
    "  categories, brands, and keywords, including a comparison of full product\n",
    "  title with review information using BERTScore.\n",
    "  \"\"\"\n",
    "\n",
    "  similarity_score = 0\n",
    "\n",
    "  # Category Matching (Highest weight)\n",
    "  if review_data.get('product category') == product_data.get('product category'):\n",
    "    similarity_score += 0.5\n",
    "\n",
    "  # Brand Matching (Medium weight)\n",
    "  if review_data.get('brand') == product_data.get('brand'):\n",
    "    similarity_score += 0.3\n",
    "\n",
    "  # String Comparison (BERTScore) between Product Title and Review Data\n",
    "  review_info_string = \" \".join(\n",
    "      [\n",
    "          review_data.get(\"product category\"),\n",
    "          review_data.get(\"brand\"),\n",
    "          \" \".join(review_data.get(\"other keywords\")),\n",
    "      ]\n",
    "  )\n",
    "\n",
    "  product_info_string = \" \".join(\n",
    "      [\n",
    "          product_data.get(\"product category\"),\n",
    "          product_data.get(\"brand\"),\n",
    "          \" \".join(product_data.get(\"other keywords\")),\n",
    "      ]\n",
    "  )\n",
    "\n",
    "  P, R, F1 = score(\n",
    "      [product_info_string],\n",
    "      [review_info_string],\n",
    "      lang=\"en\",\n",
    "      model_type=\"bert-base-uncased\",\n",
    "      verbose=False,\n",
    "      nthreads=4,\n",
    "      device=\"mps\",\n",
    "      use_fast_tokenizer=True\n",
    "  )\n",
    "\n",
    "  similarity_score += F1.mean().item() * 0.2\n",
    "\n",
    "  return round(min(1, similarity_score) * 100)\n",
    "\n",
    "\n",
    "tqdm._instances.clear()\n",
    "bar = tqdm(total=len(merged_reviews) * len(merged_products))\n",
    "\n",
    "for review in merged_reviews:\n",
    "    for product in merged_products:\n",
    "        similarity_score = compare_product_review_similarity(review, product)\n",
    "        product_review_similarity_results.append({\n",
    "            'review': review['review'],\n",
    "            'product': product['product'],\n",
    "            'improved_bert_score': similarity_score\n",
    "        })\n",
    "        bar.update(1)\n",
    "\n",
    "bar.close()\n",
    "print(\"Mean similarity between review and product keywords:\", np.mean([r['improved_bert_score'] for r in product_review_similarity_results if 'improved_bert_score' in r]))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14/3168 [00:44<2:46:22,  3.16s/it]\n",
      "  0%|          | 1/3168 [00:02<1:55:57,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.691392719745636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/3168 [00:02<1:08:28,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5372622609138489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/3168 [00:03<50:38,  1.04it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5889884233474731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/3168 [00:03<41:44,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5989040732383728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/3168 [00:04<36:14,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6121740937232971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/3168 [00:05<34:40,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.607903003692627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/3168 [00:05<34:42,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5260867476463318\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[95], line 59\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m review \u001B[38;5;129;01min\u001B[39;00m merged_reviews:\n\u001B[1;32m     58\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m product \u001B[38;5;129;01min\u001B[39;00m merged_products:\n\u001B[0;32m---> 59\u001B[0m         similarity_score \u001B[38;5;241m=\u001B[39m \u001B[43mcompare_product_review_similarity\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreview\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     60\u001B[0m         product_review_similarity_results\u001B[38;5;241m.\u001B[39mappend({\n\u001B[1;32m     61\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreview\u001B[39m\u001B[38;5;124m'\u001B[39m: review[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreview\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     62\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mproduct\u001B[39m\u001B[38;5;124m'\u001B[39m: product[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mproduct\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     63\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimproved_bert_score\u001B[39m\u001B[38;5;124m'\u001B[39m: similarity_score\n\u001B[1;32m     64\u001B[0m         })\n\u001B[1;32m     65\u001B[0m         bar\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;241m1\u001B[39m)\n",
      "Cell \u001B[0;32mIn[95], line 37\u001B[0m, in \u001B[0;36mcompare_product_review_similarity\u001B[0;34m(review_data, product_data)\u001B[0m\n\u001B[1;32m     21\u001B[0m review_info_string \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\n\u001B[1;32m     22\u001B[0m     [\n\u001B[1;32m     23\u001B[0m         review_data\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mproduct category\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     26\u001B[0m     ]\n\u001B[1;32m     27\u001B[0m )\n\u001B[1;32m     29\u001B[0m product_info_string \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\n\u001B[1;32m     30\u001B[0m     [\n\u001B[1;32m     31\u001B[0m         product_data\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mproduct category\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     34\u001B[0m     ]\n\u001B[1;32m     35\u001B[0m )\n\u001B[0;32m---> 37\u001B[0m P, R, F1 \u001B[38;5;241m=\u001B[39m \u001B[43mscore\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     38\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43mproduct_info_string\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     39\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43mreview_info_string\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlang\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43men\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     41\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbert-base-uncased\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnthreads\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmps\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_fast_tokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m     46\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28mprint\u001B[39m(F1\u001B[38;5;241m.\u001B[39mmean()\u001B[38;5;241m.\u001B[39mitem())\n\u001B[1;32m     49\u001B[0m similarity_score \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m F1\u001B[38;5;241m.\u001B[39mmean()\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m0.2\u001B[39m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/bert_score/score.py:98\u001B[0m, in \u001B[0;36mscore\u001B[0;34m(cands, refs, model_type, num_layers, verbose, idf, device, batch_size, nthreads, all_layers, lang, return_hash, rescale_with_baseline, baseline_path, use_fast_tokenizer)\u001B[0m\n\u001B[1;32m     95\u001B[0m     num_layers \u001B[38;5;241m=\u001B[39m model2layers[model_type]\n\u001B[1;32m     97\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m get_tokenizer(model_type, use_fast_tokenizer)\n\u001B[0;32m---> 98\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mget_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mall_layers\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    100\u001B[0m     device \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/bert_score/utils.py:255\u001B[0m, in \u001B[0;36mget_model\u001B[0;34m(model_type, num_layers, all_layers)\u001B[0m\n\u001B[1;32m    253\u001B[0m     model \u001B[38;5;241m=\u001B[39m T5EncoderModel\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_type)\n\u001B[1;32m    254\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 255\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    256\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(model, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdecoder\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(model, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoder\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:564\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m    562\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(config) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m    563\u001B[0m     model_class \u001B[38;5;241m=\u001B[39m _get_model_class(config, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping)\n\u001B[0;32m--> 564\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    565\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    566\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    567\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    568\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    569\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(c\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    570\u001B[0m )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/transformers/modeling_utils.py:3833\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m   3823\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m dtype_orig \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3824\u001B[0m         torch\u001B[38;5;241m.\u001B[39mset_default_dtype(dtype_orig)\n\u001B[1;32m   3826\u001B[0m     (\n\u001B[1;32m   3827\u001B[0m         model,\n\u001B[1;32m   3828\u001B[0m         missing_keys,\n\u001B[1;32m   3829\u001B[0m         unexpected_keys,\n\u001B[1;32m   3830\u001B[0m         mismatched_keys,\n\u001B[1;32m   3831\u001B[0m         offload_index,\n\u001B[1;32m   3832\u001B[0m         error_msgs,\n\u001B[0;32m-> 3833\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_pretrained_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3834\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3835\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3836\u001B[0m \u001B[43m        \u001B[49m\u001B[43mloaded_state_dict_keys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# XXX: rename?\u001B[39;49;00m\n\u001B[1;32m   3837\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresolved_archive_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3838\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3839\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_mismatched_sizes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_mismatched_sizes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3840\u001B[0m \u001B[43m        \u001B[49m\u001B[43msharded_metadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msharded_metadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3841\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_fast_init\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_fast_init\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3842\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlow_cpu_mem_usage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlow_cpu_mem_usage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3843\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3844\u001B[0m \u001B[43m        \u001B[49m\u001B[43moffload_folder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moffload_folder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3845\u001B[0m \u001B[43m        \u001B[49m\u001B[43moffload_state_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moffload_state_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3846\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3847\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhf_quantizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhf_quantizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3848\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeep_in_fp32_modules\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_in_fp32_modules\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3849\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgguf_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgguf_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3850\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3852\u001B[0m \u001B[38;5;66;03m# make sure token embedding weights are still tied if needed\u001B[39;00m\n\u001B[1;32m   3853\u001B[0m model\u001B[38;5;241m.\u001B[39mtie_weights()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/transformers/modeling_utils.py:4241\u001B[0m, in \u001B[0;36mPreTrainedModel._load_pretrained_model\u001B[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path)\u001B[0m\n\u001B[1;32m   4222\u001B[0m         error_msgs, offload_index, state_dict_index \u001B[38;5;241m=\u001B[39m _load_state_dict_into_meta_model(\n\u001B[1;32m   4223\u001B[0m             model_to_load,\n\u001B[1;32m   4224\u001B[0m             state_dict,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4237\u001B[0m             unexpected_keys\u001B[38;5;241m=\u001B[39munexpected_keys,\n\u001B[1;32m   4238\u001B[0m         )\n\u001B[1;32m   4239\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   4240\u001B[0m         \u001B[38;5;66;03m# Sharded checkpoint or whole but low_cpu_mem_usage==True\u001B[39;00m\n\u001B[0;32m-> 4241\u001B[0m         error_msgs \u001B[38;5;241m=\u001B[39m \u001B[43m_load_state_dict_into_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_to_load\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_prefix\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4243\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   4244\u001B[0m     \u001B[38;5;66;03m# This should always be a list but, just to be sure.\u001B[39;00m\n\u001B[1;32m   4245\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(resolved_archive_file, \u001B[38;5;28mlist\u001B[39m):\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/transformers/modeling_utils.py:711\u001B[0m, in \u001B[0;36m_load_state_dict_into_model\u001B[0;34m(model_to_load, state_dict, start_prefix)\u001B[0m\n\u001B[1;32m    708\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m child \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    709\u001B[0m             load(child, state_dict, prefix \u001B[38;5;241m+\u001B[39m name \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 711\u001B[0m \u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_to_load\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprefix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstart_prefix\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    712\u001B[0m \u001B[38;5;66;03m# Delete `state_dict` so it could be collected by GC earlier. Note that `state_dict` is a copy of the argument, so\u001B[39;00m\n\u001B[1;32m    713\u001B[0m \u001B[38;5;66;03m# it's safe to delete it.\u001B[39;00m\n\u001B[1;32m    714\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m state_dict\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/transformers/modeling_utils.py:709\u001B[0m, in \u001B[0;36m_load_state_dict_into_model.<locals>.load\u001B[0;34m(module, state_dict, prefix)\u001B[0m\n\u001B[1;32m    707\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, child \u001B[38;5;129;01min\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_modules\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m    708\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m child \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 709\u001B[0m         \u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchild\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprefix\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/transformers/modeling_utils.py:709\u001B[0m, in \u001B[0;36m_load_state_dict_into_model.<locals>.load\u001B[0;34m(module, state_dict, prefix)\u001B[0m\n\u001B[1;32m    707\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, child \u001B[38;5;129;01min\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_modules\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m    708\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m child \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 709\u001B[0m         \u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchild\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprefix\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "    \u001B[0;31m[... skipping similar frames: _load_state_dict_into_model.<locals>.load at line 709 (2 times)]\u001B[0m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/transformers/modeling_utils.py:709\u001B[0m, in \u001B[0;36m_load_state_dict_into_model.<locals>.load\u001B[0;34m(module, state_dict, prefix)\u001B[0m\n\u001B[1;32m    707\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, child \u001B[38;5;129;01min\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_modules\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m    708\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m child \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 709\u001B[0m         \u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchild\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprefix\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/transformers/modeling_utils.py:705\u001B[0m, in \u001B[0;36m_load_state_dict_into_model.<locals>.load\u001B[0;34m(module, state_dict, prefix)\u001B[0m\n\u001B[1;32m    703\u001B[0m                     module\u001B[38;5;241m.\u001B[39m_load_from_state_dict(\u001B[38;5;241m*\u001B[39margs)\n\u001B[1;32m    704\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 705\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_from_state_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    707\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, child \u001B[38;5;129;01min\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_modules\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m    708\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m child \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/torch/nn/modules/module.py:2096\u001B[0m, in \u001B[0;36mModule._load_from_state_dict\u001B[0;34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001B[0m\n\u001B[1;32m   2094\u001B[0m             \u001B[38;5;28msetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, input_param)\n\u001B[1;32m   2095\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 2096\u001B[0m             \u001B[43mparam\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy_\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_param\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2097\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m ex:\n\u001B[1;32m   2098\u001B[0m     action \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mswapping\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m use_swap_tensors \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcopying\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Added code"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Cosine Similarity Comparison"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T19:08:59.896316Z",
     "start_time": "2024-10-27T19:08:31.319477Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def compare_keywords_cosine_similarity(review_keywords, product_keywords):\n",
    "    if not review_keywords or not product_keywords:\n",
    "        return 0.0\n",
    "\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')  # Choose an appropriate model\n",
    "\n",
    "    # Compute embeddings\n",
    "    review_embeddings = model.encode(review_keywords, device=\"mps\")\n",
    "    product_embeddings = model.encode(product_keywords, device=\"mps\")\n",
    "    \n",
    "    # Average the embeddings\n",
    "    avg_review_embedding = np.mean(review_embeddings, axis=0)\n",
    "    avg_product_embedding = np.mean(product_embeddings, axis=0)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity = np.dot(avg_review_embedding, avg_product_embedding) / (\n",
    "        np.linalg.norm(avg_review_embedding) * np.linalg.norm(avg_product_embedding)\n",
    "    )\n",
    "\n",
    "    return similarity\n",
    "\n",
    "tqdm._instances.clear()\n",
    "bar = tqdm(total=len(merged_reviews) * len(merged_products))\n",
    "for review in merged_reviews:\n",
    "    for product in merged_products:\n",
    "        similarity_score = compare_keywords_cosine_similarity(review['other keywords'], product['other keywords'])\n",
    "        product_review_similarity_results.append({\n",
    "            'review': review['review'],\n",
    "            'product': product['product'],\n",
    "            'cosine_similarity': similarity_score\n",
    "        })\n",
    "\n",
    "        bar.update(1)\n",
    "    \n",
    "bar.close()\n",
    "print(\"Mean similarity between review and product keywords:\", np.mean([r['cosine_similarity'] for r in product_review_similarity_results if 'cosine_similarity' in r]))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 24/3168 [00:46<1:40:38,  1.92s/it]\n",
      "  1%|          | 17/3168 [00:27<1:19:52,  1.52s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[97], line 29\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m review \u001B[38;5;129;01min\u001B[39;00m merged_reviews:\n\u001B[1;32m     28\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m product \u001B[38;5;129;01min\u001B[39;00m merged_products:\n\u001B[0;32m---> 29\u001B[0m         similarity_score \u001B[38;5;241m=\u001B[39m \u001B[43mcompare_keywords_cosine_similarity\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreview\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mother keywords\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mother keywords\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m         product_review_similarity_results\u001B[38;5;241m.\u001B[39mappend({\n\u001B[1;32m     31\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreview\u001B[39m\u001B[38;5;124m'\u001B[39m: review[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreview\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     32\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mproduct\u001B[39m\u001B[38;5;124m'\u001B[39m: product[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mproduct\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     33\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcosine_similarity\u001B[39m\u001B[38;5;124m'\u001B[39m: similarity_score\n\u001B[1;32m     34\u001B[0m         })\n\u001B[1;32m     36\u001B[0m         bar\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;241m1\u001B[39m)\n",
      "Cell \u001B[0;32mIn[97], line 8\u001B[0m, in \u001B[0;36mcompare_keywords_cosine_similarity\u001B[0;34m(review_keywords, product_keywords)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m review_keywords \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m product_keywords:\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m0.0\u001B[39m\n\u001B[0;32m----> 8\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mSentenceTransformer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mall-MiniLM-L6-v2\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Choose an appropriate model\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# Compute embeddings\u001B[39;00m\n\u001B[1;32m     11\u001B[0m review_embeddings \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mencode(review_keywords, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmps\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:306\u001B[0m, in \u001B[0;36mSentenceTransformer.__init__\u001B[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001B[0m\n\u001B[1;32m    297\u001B[0m         model_name_or_path \u001B[38;5;241m=\u001B[39m __MODEL_HUB_ORGANIZATION__ \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m model_name_or_path\n\u001B[1;32m    299\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_sentence_transformer_model(\n\u001B[1;32m    300\u001B[0m     model_name_or_path,\n\u001B[1;32m    301\u001B[0m     token,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    304\u001B[0m     local_files_only\u001B[38;5;241m=\u001B[39mlocal_files_only,\n\u001B[1;32m    305\u001B[0m ):\n\u001B[0;32m--> 306\u001B[0m     modules, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodule_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_sbert_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    307\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    308\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    309\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_folder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_folder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    310\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    311\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    312\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    313\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    314\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtokenizer_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    315\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    318\u001B[0m     modules \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_load_auto_model(\n\u001B[1;32m    319\u001B[0m         model_name_or_path,\n\u001B[1;32m    320\u001B[0m         token\u001B[38;5;241m=\u001B[39mtoken,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    327\u001B[0m         config_kwargs\u001B[38;5;241m=\u001B[39mconfig_kwargs,\n\u001B[1;32m    328\u001B[0m     )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:1672\u001B[0m, in \u001B[0;36mSentenceTransformer._load_sbert_model\u001B[0;34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001B[0m\n\u001B[1;32m   1662\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m   1663\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m config_name \u001B[38;5;129;01min\u001B[39;00m [\n\u001B[1;32m   1664\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msentence_bert_config.json\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1665\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msentence_roberta_config.json\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1670\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msentence_xlnet_config.json\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1671\u001B[0m ]:\n\u001B[0;32m-> 1672\u001B[0m     config_path \u001B[38;5;241m=\u001B[39m \u001B[43mload_file_path\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1673\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1674\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1675\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1676\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_folder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_folder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1677\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1678\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1679\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1680\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m config_path \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1681\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(config_path) \u001B[38;5;28;01mas\u001B[39;00m fIn:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/sentence_transformers/util.py:1343\u001B[0m, in \u001B[0;36mload_file_path\u001B[0;34m(model_name_or_path, filename, token, cache_folder, revision, local_files_only)\u001B[0m\n\u001B[1;32m   1341\u001B[0m \u001B[38;5;66;03m# If file is remote\u001B[39;00m\n\u001B[1;32m   1342\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1343\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mhf_hub_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1344\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1345\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1346\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1347\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlibrary_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msentence-transformers\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1348\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1349\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_folder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1350\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1351\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1352\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m   1353\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[1;32m    112\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[0;32m--> 114\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/huggingface_hub/file_download.py:1221\u001B[0m, in \u001B[0;36mhf_hub_download\u001B[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001B[0m\n\u001B[1;32m   1202\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _hf_hub_download_to_local_dir(\n\u001B[1;32m   1203\u001B[0m         \u001B[38;5;66;03m# Destination\u001B[39;00m\n\u001B[1;32m   1204\u001B[0m         local_dir\u001B[38;5;241m=\u001B[39mlocal_dir,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1218\u001B[0m         local_files_only\u001B[38;5;241m=\u001B[39mlocal_files_only,\n\u001B[1;32m   1219\u001B[0m     )\n\u001B[1;32m   1220\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1221\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_hf_hub_download_to_cache_dir\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1222\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Destination\u001B[39;49;00m\n\u001B[1;32m   1223\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1224\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# File info\u001B[39;49;00m\n\u001B[1;32m   1225\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrepo_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrepo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1226\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1227\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1228\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1229\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# HTTP info\u001B[39;49;00m\n\u001B[1;32m   1230\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1231\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1232\u001B[0m \u001B[43m        \u001B[49m\u001B[43metag_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43metag_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1233\u001B[0m \u001B[43m        \u001B[49m\u001B[43mendpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mendpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1234\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Additional options\u001B[39;49;00m\n\u001B[1;32m   1235\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1236\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1237\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/huggingface_hub/file_download.py:1282\u001B[0m, in \u001B[0;36m_hf_hub_download_to_cache_dir\u001B[0;34m(cache_dir, repo_id, filename, repo_type, revision, headers, proxies, etag_timeout, endpoint, local_files_only, force_download)\u001B[0m\n\u001B[1;32m   1278\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m pointer_path\n\u001B[1;32m   1280\u001B[0m \u001B[38;5;66;03m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001B[39;00m\n\u001B[1;32m   1281\u001B[0m \u001B[38;5;66;03m# If we can't, a HEAD request error is returned.\u001B[39;00m\n\u001B[0;32m-> 1282\u001B[0m (url_to_download, etag, commit_hash, expected_size, head_call_error) \u001B[38;5;241m=\u001B[39m \u001B[43m_get_metadata_or_catch_error\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1283\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrepo_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrepo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1284\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1285\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1286\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1287\u001B[0m \u001B[43m    \u001B[49m\u001B[43mendpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mendpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1288\u001B[0m \u001B[43m    \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1289\u001B[0m \u001B[43m    \u001B[49m\u001B[43metag_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43metag_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1290\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1291\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1292\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_folder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_folder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1293\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrelative_filename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrelative_filename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1294\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1296\u001B[0m \u001B[38;5;66;03m# etag can be None for several reasons:\u001B[39;00m\n\u001B[1;32m   1297\u001B[0m \u001B[38;5;66;03m# 1. we passed local_files_only.\u001B[39;00m\n\u001B[1;32m   1298\u001B[0m \u001B[38;5;66;03m# 2. we don't have a connection\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1304\u001B[0m \u001B[38;5;66;03m# If the specified revision is a commit hash, look inside \"snapshots\".\u001B[39;00m\n\u001B[1;32m   1305\u001B[0m \u001B[38;5;66;03m# If the specified revision is a branch or tag, look inside \"refs\".\u001B[39;00m\n\u001B[1;32m   1306\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m head_call_error \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1307\u001B[0m     \u001B[38;5;66;03m# Couldn't make a HEAD call => let's try to find a local file\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/huggingface_hub/file_download.py:1722\u001B[0m, in \u001B[0;36m_get_metadata_or_catch_error\u001B[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, local_files_only, relative_filename, storage_folder)\u001B[0m\n\u001B[1;32m   1720\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1721\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1722\u001B[0m         metadata \u001B[38;5;241m=\u001B[39m \u001B[43mget_hf_file_metadata\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43metag_timeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1723\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m EntryNotFoundError \u001B[38;5;28;01mas\u001B[39;00m http_error:\n\u001B[1;32m   1724\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m storage_folder \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m relative_filename \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1725\u001B[0m             \u001B[38;5;66;03m# Cache the non-existence of the file\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[1;32m    112\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[0;32m--> 114\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/huggingface_hub/file_download.py:1645\u001B[0m, in \u001B[0;36mget_hf_file_metadata\u001B[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001B[0m\n\u001B[1;32m   1642\u001B[0m headers[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccept-Encoding\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124midentity\u001B[39m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# prevent any compression => we want to know the real size of the file\u001B[39;00m\n\u001B[1;32m   1644\u001B[0m \u001B[38;5;66;03m# Retrieve metadata\u001B[39;00m\n\u001B[0;32m-> 1645\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43m_request_wrapper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1646\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mHEAD\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1647\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1648\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1649\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1650\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfollow_relative_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1651\u001B[0m \u001B[43m    \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1652\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1653\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1654\u001B[0m hf_raise_for_status(r)\n\u001B[1;32m   1656\u001B[0m \u001B[38;5;66;03m# Return\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/huggingface_hub/file_download.py:372\u001B[0m, in \u001B[0;36m_request_wrapper\u001B[0;34m(method, url, follow_relative_redirects, **params)\u001B[0m\n\u001B[1;32m    370\u001B[0m \u001B[38;5;66;03m# Recursively follow relative redirects\u001B[39;00m\n\u001B[1;32m    371\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m follow_relative_redirects:\n\u001B[0;32m--> 372\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43m_request_wrapper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    373\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    374\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    375\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfollow_relative_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    376\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    377\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    379\u001B[0m     \u001B[38;5;66;03m# If redirection, we redirect only relative paths.\u001B[39;00m\n\u001B[1;32m    380\u001B[0m     \u001B[38;5;66;03m# This is useful in case of a renamed repository.\u001B[39;00m\n\u001B[1;32m    381\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;241m300\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m399\u001B[39m:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/huggingface_hub/file_download.py:395\u001B[0m, in \u001B[0;36m_request_wrapper\u001B[0;34m(method, url, follow_relative_redirects, **params)\u001B[0m\n\u001B[1;32m    392\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m response\n\u001B[1;32m    394\u001B[0m \u001B[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001B[39;00m\n\u001B[0;32m--> 395\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mget_session\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    396\u001B[0m hf_raise_for_status(response)\n\u001B[1;32m    397\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/requests/sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[1;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[1;32m    587\u001B[0m }\n\u001B[1;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[0;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/requests/sessions.py:703\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    700\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[1;32m    702\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[0;32m--> 703\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43madapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[1;32m    706\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:66\u001B[0m, in \u001B[0;36mUniqueRequestIdAdapter.send\u001B[0;34m(self, request, *args, **kwargs)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001B[39;00m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 66\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m requests\u001B[38;5;241m.\u001B[39mRequestException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     68\u001B[0m     request_id \u001B[38;5;241m=\u001B[39m request\u001B[38;5;241m.\u001B[39mheaders\u001B[38;5;241m.\u001B[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/requests/adapters.py:667\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    664\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m TimeoutSauce(connect\u001B[38;5;241m=\u001B[39mtimeout, read\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[1;32m    666\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 667\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    668\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    669\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    670\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    671\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    672\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    673\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    674\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    675\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    676\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    677\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    678\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    679\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    681\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    682\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(err, request\u001B[38;5;241m=\u001B[39mrequest)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/urllib3/connectionpool.py:790\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[0m\n\u001B[1;32m    787\u001B[0m response_conn \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m release_conn \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    789\u001B[0m \u001B[38;5;66;03m# Make the request on the HTTPConnection object\u001B[39;00m\n\u001B[0;32m--> 790\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    791\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    792\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    793\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    794\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    795\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    796\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    797\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    798\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    799\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresponse_conn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresponse_conn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    800\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreload_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    801\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecode_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    802\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mresponse_kw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    803\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    805\u001B[0m \u001B[38;5;66;03m# Everything went great!\u001B[39;00m\n\u001B[1;32m    806\u001B[0m clean_exit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/urllib3/connectionpool.py:536\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001B[0m\n\u001B[1;32m    534\u001B[0m \u001B[38;5;66;03m# Receive the response from the server\u001B[39;00m\n\u001B[1;32m    535\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 536\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    537\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (BaseSSLError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    538\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_timeout(err\u001B[38;5;241m=\u001B[39me, url\u001B[38;5;241m=\u001B[39murl, timeout_value\u001B[38;5;241m=\u001B[39mread_timeout)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/urllib3/connection.py:461\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    458\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mresponse\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HTTPResponse\n\u001B[1;32m    460\u001B[0m \u001B[38;5;66;03m# Get the response from http.client.HTTPConnection\u001B[39;00m\n\u001B[0;32m--> 461\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    463\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    464\u001B[0m     assert_header_parsing(httplib_response\u001B[38;5;241m.\u001B[39mmsg)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/http/client.py:1375\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1373\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1374\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1375\u001B[0m         \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbegin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1376\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n\u001B[1;32m   1377\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/http/client.py:318\u001B[0m, in \u001B[0;36mHTTPResponse.begin\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    316\u001B[0m \u001B[38;5;66;03m# read until we get a non-100 response\u001B[39;00m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 318\u001B[0m     version, status, reason \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status \u001B[38;5;241m!=\u001B[39m CONTINUE:\n\u001B[1;32m    320\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/http/client.py:279\u001B[0m, in \u001B[0;36mHTTPResponse._read_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_read_status\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 279\u001B[0m     line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_MAXLINE\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miso-8859-1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    280\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(line) \u001B[38;5;241m>\u001B[39m _MAXLINE:\n\u001B[1;32m    281\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m LineTooLong(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus line\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/socket.py:705\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    704\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 705\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    707\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/ssl.py:1307\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1303\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1304\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1305\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1306\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1307\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1308\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1309\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/workspace/lib/python3.10/ssl.py:1163\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1161\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1162\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1163\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1164\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1165\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Jaccard Similarity Comparison"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T19:09:48.067403Z",
     "start_time": "2024-10-27T19:09:48.054469Z"
    }
   },
   "source": [
    "def compare_keywords_jaccard_similarity(review_keywords, product_keywords):\n",
    "    set_review = set(review_keywords)\n",
    "    set_product = set(product_keywords)\n",
    "    intersection = set_review.intersection(set_product)\n",
    "    union = set_review.union(set_product)\n",
    "    if not union:\n",
    "        return 0.0\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "tqdm._instances.clear()\n",
    "bar = tqdm(total=len(merged_reviews) * len(merged_products))\n",
    "for review in merged_reviews:\n",
    "    for product in merged_products:\n",
    "        similarity_score = compare_keywords_jaccard_similarity(review['other keywords'], product['other keywords'])\n",
    "        product_review_similarity_results.append({\n",
    "            'review': review['review'],\n",
    "            'product': product['product'],\n",
    "            'jaccard_similarity': similarity_score\n",
    "        })\n",
    "\n",
    "        bar.update(1)\n",
    "        \n",
    "bar.close()\n",
    "print(\"Mean similarity between review and product keywords:\", np.mean([r['jaccard_similarity'] for r in product_review_similarity_results if 'jaccard_similarity' in r]))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3168/3168 [00:00<00:00, 629562.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean similarity between review and product keywords: 0.010297427297152857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Levenshtein Distance Comparison"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T19:10:35.113357Z",
     "start_time": "2024-10-27T19:10:30.200335Z"
    }
   },
   "source": [
    "import Levenshtein\n",
    "\n",
    "def compare_keywords_levenshtein_distance(review_keywords, product_keywords):\n",
    "    total_distance = 0\n",
    "    comparisons = 0\n",
    "    for r_keyword in review_keywords:\n",
    "        for p_keyword in product_keywords:\n",
    "            distance = Levenshtein.distance(r_keyword, p_keyword)\n",
    "            total_distance += distance\n",
    "            comparisons += 1\n",
    "    if comparisons == 0:\n",
    "        return 0.0\n",
    "    # Normalize the distance\n",
    "    average_distance = total_distance / comparisons\n",
    "    max_length = max(len(''.join(review_keywords)), len(''.join(product_keywords)))\n",
    "    similarity = 1 - (average_distance / max_length)\n",
    "    return similarity\n",
    "\n",
    "tqdm._instances.clear()\n",
    "bar = tqdm(total=len(merged_reviews) * len(merged_products))\n",
    "for review in merged_reviews:\n",
    "    for product in merged_products:\n",
    "        similarity_score = compare_keywords_levenshtein_distance(review['other keywords'], product['other keywords'])\n",
    "        product_review_similarity_results.append({\n",
    "            'review': review['review'],\n",
    "            'product': product['product'],\n",
    "            'levenshtein_distance': similarity_score\n",
    "        })\n",
    "\n",
    "        bar.update(1)\n",
    "\n",
    "bar.close()\n",
    "print(\"Mean similarity between review and product keywords:\", np.mean([r['levenshtein_distance'] for r in product_review_similarity_results if 'levenshtein_distance' in r]))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Levenshtein\r\n",
      "  Downloading levenshtein-0.26.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.2 kB)\r\n",
      "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein)\r\n",
      "  Downloading rapidfuzz-3.10.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (11 kB)\r\n",
      "Downloading levenshtein-0.26.0-cp310-cp310-macosx_11_0_arm64.whl (157 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m157.5/157.5 kB\u001B[0m \u001B[31m1.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading rapidfuzz-3.10.1-cp310-cp310-macosx_11_0_arm64.whl (1.4 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.4/1.4 MB\u001B[0m \u001B[31m10.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: rapidfuzz, Levenshtein\r\n",
      "Successfully installed Levenshtein-0.26.0 rapidfuzz-3.10.1\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3168/3168 [00:00<00:00, 42873.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean similarity between review and product keywords: 0.8723675850178576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Overlap Coefficient Comparison"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T19:12:22.448633Z",
     "start_time": "2024-10-27T19:12:22.423923Z"
    }
   },
   "source": [
    "def compare_keywords_overlap_coefficient(review_keywords, product_keywords):\n",
    "    set_review = set(review_keywords)\n",
    "    set_product = set(product_keywords)\n",
    "    intersection = set_review.intersection(set_product)\n",
    "    min_size = min(len(set_review), len(set_product))\n",
    "    if min_size == 0:\n",
    "        return 0.0\n",
    "    return len(intersection) / min_size\n",
    "\n",
    "\n",
    "tqdm._instances.clear()\n",
    "bar = tqdm(total=len(merged_reviews) * len(merged_products))\n",
    "for review in merged_reviews:\n",
    "    for product in merged_products:\n",
    "        similarity_score = compare_keywords_overlap_coefficient(review['other keywords'], product['other keywords'])\n",
    "        product_review_similarity_results.append({\n",
    "            'review': review['review'],\n",
    "            'product': product['product'],\n",
    "            'overlap_coefficient': similarity_score\n",
    "        })\n",
    "\n",
    "        bar.update(1)\n",
    "\n",
    "bar.close()\n",
    "print(\"Mean similarity between review and product keywords:\", np.mean([r['overlap_coefficient'] for r in product_review_similarity_results if 'overlap_coefficient' in r]))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3168/3168 [00:00<00:00, 520549.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean similarity between review and product keywords: 0.023836602861224073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## BLEU Score Comparison"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T19:12:43.705934Z",
     "start_time": "2024-10-27T19:12:43.133663Z"
    }
   },
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def compare_keywords_bleu_score(review_keywords, product_keywords):\n",
    "    if not review_keywords or not product_keywords:\n",
    "        return 0.0\n",
    "    score = sentence_bleu([product_keywords], review_keywords)\n",
    "    return score\n",
    "\n",
    "tqdm._instances.clear() \n",
    "bar = tqdm(total=len(merged_reviews) * len(merged_products))\n",
    "for review in merged_reviews:\n",
    "    for product in merged_products:\n",
    "        similarity_score = compare_keywords_bleu_score(review['other keywords'], product['other keywords'])\n",
    "        product_review_similarity_results.append({\n",
    "            'review': review['review'],\n",
    "            'product': product['product'],\n",
    "            'bleu_score': similarity_score\n",
    "        })\n",
    "\n",
    "        bar.update(1)\n",
    "\n",
    "bar.close()\n",
    "print(\"Mean similarity between review and product keywords:\", np.mean([r['bleu_score'] for r in product_review_similarity_results if 'bleu_score' in r]))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3168 [00:00<?, ?it/s]/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/anaconda3/envs/workspace/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "100%|██████████| 3168/3168 [00:00<00:00, 28004.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean similarity between review and product keywords: 3.368273056482451e-81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ROUGE Score Comparison"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T19:13:07.454388Z",
     "start_time": "2024-10-27T19:13:07.171318Z"
    }
   },
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "def compare_keywords_rouge_score(review_keywords, product_keywords):\n",
    "    if not review_keywords or not product_keywords:\n",
    "        return 0.0\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(' '.join(review_keywords), ' '.join(product_keywords))\n",
    "    return scores[0]['rouge-l']['f']\n",
    "\n",
    "\n",
    "tqdm._instances.clear()\n",
    "bar = tqdm(total=len(merged_reviews) * len(merged_products))\n",
    "for review in merged_reviews:\n",
    "    for product in merged_products:\n",
    "        similarity_score = compare_keywords_rouge_score(review['other keywords'], product['other keywords'])\n",
    "        product_review_similarity_results.append({\n",
    "            'review': review['review'],\n",
    "            'product': product['product'],\n",
    "            'rouge_score': similarity_score\n",
    "        })\n",
    "\n",
    "        bar.update(1)\n",
    "\n",
    "bar.close()\n",
    "print(\"Mean similarity between review and product keywords:\", np.mean([r['rouge_score'] for r in product_review_similarity_results if 'rouge_score' in r]))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3168/3168 [00:00<00:00, 12267.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean similarity between review and product keywords: 0.03231193136848701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## TF-IDF Cosine Similarity Comparison"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T19:13:32.075742Z",
     "start_time": "2024-10-27T19:13:30.002563Z"
    }
   },
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compare_keywords_tfidf_cosine_similarity(review_keywords, product_keywords):\n",
    "    corpus = [' '.join(review_keywords), ' '.join(product_keywords)]\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "    similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "    return similarity[0][0]\n",
    "\n",
    "tqdm._instances.clear()\n",
    "bar = tqdm(total=len(merged_reviews) * len(merged_products))\n",
    "\n",
    "for review in merged_reviews:\n",
    "    for product in merged_products:\n",
    "        similarity_score = compare_keywords_tfidf_cosine_similarity(review['other keywords'], product['other keywords'])\n",
    "        product_review_similarity_results.append({\n",
    "            'review': review['review'],\n",
    "            'product': product['product'],\n",
    "            'tfidf_cosine_similarity': similarity_score\n",
    "        })\n",
    "\n",
    "        bar.update(1)\n",
    "        \n",
    "bar.close()\n",
    "print(\"Mean similarity between review and product keywords:\", np.mean([r['tfidf_cosine_similarity'] for r in product_review_similarity_results if 'tfidf_cosine_similarity' in r]))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3168/3168 [00:02<00:00, 1536.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean similarity between review and product keywords: 0.028697277894282384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Merging results from different similarity measures"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T19:13:52.190721Z",
     "start_time": "2024-10-27T19:13:52.036017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "product_review_similarity_df = pd.DataFrame(product_review_similarity_results)\n",
    "product_review_similarity_df.to_csv('js_zl_nk_js_product_review_similarity.csv', index=False)\n",
    "product_review_similarity_df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  review  \\\n",
       "0      Keeps my coffee hot for hours—just what I need...   \n",
       "1      Keeps my coffee hot for hours—just what I need...   \n",
       "2      Keeps my coffee hot for hours—just what I need...   \n",
       "3      Keeps my coffee hot for hours—just what I need...   \n",
       "4      Keeps my coffee hot for hours—just what I need...   \n",
       "...                                                  ...   \n",
       "38079  This is my new favorite detergent. So much bet...   \n",
       "38080  This is my new favorite detergent. So much bet...   \n",
       "38081  This is my new favorite detergent. So much bet...   \n",
       "38082  This is my new favorite detergent. So much bet...   \n",
       "38083  This is my new favorite detergent. So much bet...   \n",
       "\n",
       "                                                 product  bert_score  \\\n",
       "0      Contigo Workday Travel Mug – Keeps Coffee Hot ...    0.507972   \n",
       "1      Zojirushi Sleek Travel Mug – Perfect Fit for C...    0.500482   \n",
       "2      Hydro Flask Lightweight Insulation Mug – Stay ...    0.545319   \n",
       "3                Yeti Thermal Mug – No More Cold Coffee!    0.503856   \n",
       "4      Contigo All-Day Heat Retention Mug – Ideal for...    0.435202   \n",
       "...                                                  ...         ...   \n",
       "38079  Seventh Generation Powder Detergent – Great fo...         NaN   \n",
       "38080  Ecover Eco-Friendly Detergent – Perfect for th...         NaN   \n",
       "38081  Gain Powder Detergent – Fresh-Smelling Laundry...         NaN   \n",
       "38082  Arm & Hammer Powder Detergent – Great Value, L...         NaN   \n",
       "38083  Dreft Baby Powder Detergent – Gentle on Baby C...         NaN   \n",
       "\n",
       "       improved_bert_score  cosine_similarity  jaccard_similarity  \\\n",
       "0                      NaN                NaN                 NaN   \n",
       "1                      NaN                NaN                 NaN   \n",
       "2                      NaN                NaN                 NaN   \n",
       "3                      NaN                NaN                 NaN   \n",
       "4                      NaN                NaN                 NaN   \n",
       "...                    ...                ...                 ...   \n",
       "38079                  NaN                NaN                 NaN   \n",
       "38080                  NaN                NaN                 NaN   \n",
       "38081                  NaN                NaN                 NaN   \n",
       "38082                  NaN                NaN                 NaN   \n",
       "38083                  NaN                NaN                 NaN   \n",
       "\n",
       "       levenshtein_distance  overlap_coefficient  bleu_score  rouge_score  \\\n",
       "0                       NaN                  NaN         NaN          NaN   \n",
       "1                       NaN                  NaN         NaN          NaN   \n",
       "2                       NaN                  NaN         NaN          NaN   \n",
       "3                       NaN                  NaN         NaN          NaN   \n",
       "4                       NaN                  NaN         NaN          NaN   \n",
       "...                     ...                  ...         ...          ...   \n",
       "38079                   NaN                  NaN         NaN          NaN   \n",
       "38080                   NaN                  NaN         NaN          NaN   \n",
       "38081                   NaN                  NaN         NaN          NaN   \n",
       "38082                   NaN                  NaN         NaN          NaN   \n",
       "38083                   NaN                  NaN         NaN          NaN   \n",
       "\n",
       "       tfidf_cosine_similarity  \n",
       "0                          NaN  \n",
       "1                          NaN  \n",
       "2                          NaN  \n",
       "3                          NaN  \n",
       "4                          NaN  \n",
       "...                        ...  \n",
       "38079                 0.087944  \n",
       "38080                 0.103528  \n",
       "38081                 0.091938  \n",
       "38082                 0.262097  \n",
       "38083                 0.049049  \n",
       "\n",
       "[38084 rows x 11 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>product</th>\n",
       "      <th>bert_score</th>\n",
       "      <th>improved_bert_score</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>jaccard_similarity</th>\n",
       "      <th>levenshtein_distance</th>\n",
       "      <th>overlap_coefficient</th>\n",
       "      <th>bleu_score</th>\n",
       "      <th>rouge_score</th>\n",
       "      <th>tfidf_cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Keeps my coffee hot for hours—just what I need...</td>\n",
       "      <td>Contigo Workday Travel Mug – Keeps Coffee Hot ...</td>\n",
       "      <td>0.507972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Keeps my coffee hot for hours—just what I need...</td>\n",
       "      <td>Zojirushi Sleek Travel Mug – Perfect Fit for C...</td>\n",
       "      <td>0.500482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Keeps my coffee hot for hours—just what I need...</td>\n",
       "      <td>Hydro Flask Lightweight Insulation Mug – Stay ...</td>\n",
       "      <td>0.545319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Keeps my coffee hot for hours—just what I need...</td>\n",
       "      <td>Yeti Thermal Mug – No More Cold Coffee!</td>\n",
       "      <td>0.503856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Keeps my coffee hot for hours—just what I need...</td>\n",
       "      <td>Contigo All-Day Heat Retention Mug – Ideal for...</td>\n",
       "      <td>0.435202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38079</th>\n",
       "      <td>This is my new favorite detergent. So much bet...</td>\n",
       "      <td>Seventh Generation Powder Detergent – Great fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.087944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38080</th>\n",
       "      <td>This is my new favorite detergent. So much bet...</td>\n",
       "      <td>Ecover Eco-Friendly Detergent – Perfect for th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.103528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38081</th>\n",
       "      <td>This is my new favorite detergent. So much bet...</td>\n",
       "      <td>Gain Powder Detergent – Fresh-Smelling Laundry...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.091938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38082</th>\n",
       "      <td>This is my new favorite detergent. So much bet...</td>\n",
       "      <td>Arm &amp; Hammer Powder Detergent – Great Value, L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.262097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38083</th>\n",
       "      <td>This is my new favorite detergent. So much bet...</td>\n",
       "      <td>Dreft Baby Powder Detergent – Gentle on Baby C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.049049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38084 rows × 11 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 112
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
